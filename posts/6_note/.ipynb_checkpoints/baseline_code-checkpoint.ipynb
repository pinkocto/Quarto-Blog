{
 "cells": [
  {
   "cell_type": "raw",
   "id": "155707a0-42f2-4bcd-9477-66d1428701ac",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"연습장2\"\n",
    "author: \"JiyunLim\"\n",
    "date: \"09/09/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108cc31-0795-418f-ae67-c391b1f80807",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd614b80-b28e-4b23-ae2d-736d2072e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7cc11e1-de77-4f35-af0e-a87db4af7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "inputs = pd.read_csv('./farm/train_input.csv')\n",
    "outputs = pd.read_csv('./farm/train_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cd87840-2cb3-4951-841c-30ec853c6160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_no</th>\n",
       "      <th>시설ID</th>\n",
       "      <th>일</th>\n",
       "      <th>주차</th>\n",
       "      <th>내부CO2</th>\n",
       "      <th>내부습도</th>\n",
       "      <th>내부온도</th>\n",
       "      <th>지온</th>\n",
       "      <th>강우감지</th>\n",
       "      <th>일사량</th>\n",
       "      <th>외부온도</th>\n",
       "      <th>외부풍향</th>\n",
       "      <th>외부풍속</th>\n",
       "      <th>지습</th>\n",
       "      <th>급액횟수</th>\n",
       "      <th>급액EC(dS/m)</th>\n",
       "      <th>급액pH</th>\n",
       "      <th>급액량(회당)</th>\n",
       "      <th>품종</th>\n",
       "      <th>재배형태</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>farm25</td>\n",
       "      <td>20220323</td>\n",
       "      <td>30주차</td>\n",
       "      <td>517.041667</td>\n",
       "      <td>84.985417</td>\n",
       "      <td>20.610833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1879</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.42</td>\n",
       "      <td>88</td>\n",
       "      <td>tomato09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>farm25</td>\n",
       "      <td>20220324</td>\n",
       "      <td>30주차</td>\n",
       "      <td>514.416667</td>\n",
       "      <td>88.291250</td>\n",
       "      <td>20.695000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1411</td>\n",
       "      <td>12.708333</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.78</td>\n",
       "      <td>5.63</td>\n",
       "      <td>97</td>\n",
       "      <td>tomato09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>farm25</td>\n",
       "      <td>20220326</td>\n",
       "      <td>30주차</td>\n",
       "      <td>471.875000</td>\n",
       "      <td>83.514583</td>\n",
       "      <td>20.402500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955</td>\n",
       "      <td>8.791667</td>\n",
       "      <td>202.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.69</td>\n",
       "      <td>4.25</td>\n",
       "      <td>101</td>\n",
       "      <td>tomato09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>farm25</td>\n",
       "      <td>20220327</td>\n",
       "      <td>30주차</td>\n",
       "      <td>469.250000</td>\n",
       "      <td>80.916250</td>\n",
       "      <td>20.139167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2231</td>\n",
       "      <td>8.041667</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.25</td>\n",
       "      <td>99</td>\n",
       "      <td>tomato09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>farm25</td>\n",
       "      <td>20220328</td>\n",
       "      <td>30주차</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>82.026250</td>\n",
       "      <td>17.653333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2284</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.66</td>\n",
       "      <td>4.21</td>\n",
       "      <td>94</td>\n",
       "      <td>tomato09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_no    시설ID         일    주차       내부CO2       내부습도       내부온도   지온  \\\n",
       "0          0  farm25  20220323  30주차  517.041667  84.985417  20.610833  0.0   \n",
       "1          0  farm25  20220324  30주차  514.416667  88.291250  20.695000  0.0   \n",
       "2          0  farm25  20220326  30주차  471.875000  83.514583  20.402500  0.0   \n",
       "3          0  farm25  20220327  30주차  469.250000  80.916250  20.139167  0.0   \n",
       "4          0  farm25  20220328  30주차  465.750000  82.026250  17.653333  0.0   \n",
       "\n",
       "   강우감지   일사량       외부온도   외부풍향      외부풍속   지습  급액횟수  급액EC(dS/m)  급액pH  \\\n",
       "0   NaN  1879  11.166667  195.0  0.083333  0.0    14        2.68  4.42   \n",
       "1   NaN  1411  12.708333  142.5  0.000000  0.0    14        2.78  5.63   \n",
       "2   NaN  1955   8.791667  202.5  0.000000  0.0    14        2.69  4.25   \n",
       "3   NaN  2231   8.041667  180.0  0.000000  0.0    14        2.70  4.25   \n",
       "4   NaN  2284   9.000000   97.5  0.041667  0.0    13        2.66  4.21   \n",
       "\n",
       "   급액량(회당)        품종 재배형태  \n",
       "0       88  tomato09  NaN  \n",
       "1       97  tomato09  NaN  \n",
       "2      101  tomato09  NaN  \n",
       "3       99  tomato09  NaN  \n",
       "4       94  tomato09  NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "309d9010-3e1d-48c7-ae85-48dd125546a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_no</th>\n",
       "      <th>조사일</th>\n",
       "      <th>주차</th>\n",
       "      <th>생장길이</th>\n",
       "      <th>줄기직경</th>\n",
       "      <th>개화군</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20220330</td>\n",
       "      <td>30주차</td>\n",
       "      <td>208.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20220330</td>\n",
       "      <td>30주차</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20220330</td>\n",
       "      <td>30주차</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20220330</td>\n",
       "      <td>30주차</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20220406</td>\n",
       "      <td>31주차</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>17.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_no       조사일    주차   생장길이  줄기직경    개화군\n",
       "0          0  20220330  30주차  208.0   6.9  16.67\n",
       "1          1  20220330  30주차  172.0   6.8  17.33\n",
       "2          2  20220330  30주차  150.0   9.3  16.00\n",
       "3          3  20220330  30주차  121.0   5.9  16.20\n",
       "4          4  20220406  31주차  175.0   5.8  17.40"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c7c3063-e8e0-4a56-af7d-03d30fcab90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10112, 20), (1518, 6))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b1b8661-9a0e-48d0-861a-3bbb69cc87c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "품종            7114\n",
       "외부풍향          6993\n",
       "지습            5873\n",
       "재배형태          2408\n",
       "지온            1749\n",
       "강우감지          1505\n",
       "외부풍속           670\n",
       "외부온도           201\n",
       "내부온도             0\n",
       "일사량              0\n",
       "시설ID             0\n",
       "내부습도             0\n",
       "내부CO2            0\n",
       "주차               0\n",
       "급액횟수             0\n",
       "급액EC(dS/m)       0\n",
       "급액pH             0\n",
       "급액량(회당)          0\n",
       "일                0\n",
       "Sample_no        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8845b064-853c-4a74-bb5f-3d9d3f9dad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan 제거  -- 베이스라인이므로 간단한 처리를 위해 nan 항목 보간 없이 학습\n",
    "inputs = inputs.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "734fdcd7-8e55-439f-a09e-ecbd64457778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주차 정보 수치 변환\n",
    "inputs['주차'] = [int(i.replace('주차', \"\")) for i in inputs['주차']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7531cdfb-fdb1-42c3-b4ec-b09c0f489286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "input_scaler = MinMaxScaler()\n",
    "output_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2816fcf1-f4c2-44a7-a43a-5a50a5a27913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주차</th>\n",
       "      <th>내부CO2</th>\n",
       "      <th>내부습도</th>\n",
       "      <th>내부온도</th>\n",
       "      <th>일사량</th>\n",
       "      <th>급액횟수</th>\n",
       "      <th>급액EC(dS/m)</th>\n",
       "      <th>급액pH</th>\n",
       "      <th>급액량(회당)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>517.041667</td>\n",
       "      <td>84.985417</td>\n",
       "      <td>20.610833</td>\n",
       "      <td>1879</td>\n",
       "      <td>14</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.42</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>514.416667</td>\n",
       "      <td>88.291250</td>\n",
       "      <td>20.695000</td>\n",
       "      <td>1411</td>\n",
       "      <td>14</td>\n",
       "      <td>2.78</td>\n",
       "      <td>5.63</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>471.875000</td>\n",
       "      <td>83.514583</td>\n",
       "      <td>20.402500</td>\n",
       "      <td>1955</td>\n",
       "      <td>14</td>\n",
       "      <td>2.69</td>\n",
       "      <td>4.25</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>469.250000</td>\n",
       "      <td>80.916250</td>\n",
       "      <td>20.139167</td>\n",
       "      <td>2231</td>\n",
       "      <td>14</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.25</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>82.026250</td>\n",
       "      <td>17.653333</td>\n",
       "      <td>2284</td>\n",
       "      <td>13</td>\n",
       "      <td>2.66</td>\n",
       "      <td>4.21</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>7</td>\n",
       "      <td>334.684002</td>\n",
       "      <td>65.565417</td>\n",
       "      <td>21.985833</td>\n",
       "      <td>979</td>\n",
       "      <td>26</td>\n",
       "      <td>2.06</td>\n",
       "      <td>5.80</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>7</td>\n",
       "      <td>333.726601</td>\n",
       "      <td>61.144167</td>\n",
       "      <td>22.530833</td>\n",
       "      <td>2515</td>\n",
       "      <td>28</td>\n",
       "      <td>2.43</td>\n",
       "      <td>4.42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>7</td>\n",
       "      <td>344.862883</td>\n",
       "      <td>72.867917</td>\n",
       "      <td>20.397917</td>\n",
       "      <td>1972</td>\n",
       "      <td>21</td>\n",
       "      <td>2.71</td>\n",
       "      <td>5.88</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>7</td>\n",
       "      <td>372.708516</td>\n",
       "      <td>66.672917</td>\n",
       "      <td>24.401667</td>\n",
       "      <td>1314</td>\n",
       "      <td>18</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.39</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>7</td>\n",
       "      <td>372.612192</td>\n",
       "      <td>59.257083</td>\n",
       "      <td>28.352500</td>\n",
       "      <td>1310</td>\n",
       "      <td>16</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.39</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       주차       내부CO2       내부습도       내부온도   일사량  급액횟수  급액EC(dS/m)  급액pH  \\\n",
       "0      30  517.041667  84.985417  20.610833  1879    14        2.68  4.42   \n",
       "1      30  514.416667  88.291250  20.695000  1411    14        2.78  5.63   \n",
       "2      30  471.875000  83.514583  20.402500  1955    14        2.69  4.25   \n",
       "3      30  469.250000  80.916250  20.139167  2231    14        2.70  4.25   \n",
       "4      30  465.750000  82.026250  17.653333  2284    13        2.66  4.21   \n",
       "...    ..         ...        ...        ...   ...   ...         ...   ...   \n",
       "10107   7  334.684002  65.565417  21.985833   979    26        2.06  5.80   \n",
       "10108   7  333.726601  61.144167  22.530833  2515    28        2.43  4.42   \n",
       "10109   7  344.862883  72.867917  20.397917  1972    21        2.71  5.88   \n",
       "10110   7  372.708516  66.672917  24.401667  1314    18        2.50  5.39   \n",
       "10111   7  372.612192  59.257083  28.352500  1310    16        2.50  5.39   \n",
       "\n",
       "       급액량(회당)  \n",
       "0           88  \n",
       "1           97  \n",
       "2          101  \n",
       "3           99  \n",
       "4           94  \n",
       "...        ...  \n",
       "10107       81  \n",
       "10108       32  \n",
       "10109       27  \n",
       "10110       82  \n",
       "10111       82  \n",
       "\n",
       "[10112 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6faac8f5-f807-4c49-a833-6e900c2a9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>생장길이</th>\n",
       "      <th>줄기직경</th>\n",
       "      <th>개화군</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>9.30</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>17.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>150.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>140.0</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>200.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>210.0</td>\n",
       "      <td>8.47</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>150.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       생장길이   줄기직경    개화군\n",
       "0     208.0   6.90  16.67\n",
       "1     172.0   6.80  17.33\n",
       "2     150.0   9.30  16.00\n",
       "3     121.0   5.90  16.20\n",
       "4     175.0   5.80  17.40\n",
       "...     ...    ...    ...\n",
       "1513  150.0   6.95   2.20\n",
       "1514  140.0  10.13   1.40\n",
       "1515  200.0   9.61   1.40\n",
       "1516  210.0   8.47   2.20\n",
       "1517  150.0   9.16   3.20\n",
       "\n",
       "[1518 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1b69348-dc70-4a91-81b1-1a73d360acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "input_sc = input_scaler.fit_transform(inputs.iloc[:,3:].to_numpy())\n",
    "output_sc = output_scaler.fit_transform(outputs.iloc[:,3:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "931ad9fe-0d8f-4ce2-a6c8-a5e22591cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['Sample_no'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ee131bb-97f6-4534-a1ac-e9569c2a7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 시계열화\n",
    "input_ts = []\n",
    "for i in outputs['Sample_no']:\n",
    "    sample = input_sc[inputs['Sample_no'] == i]\n",
    "    if len(sample < 7):\n",
    "        sample = np.append(np.zeros((7-len(sample), sample.shape[-1])), sample,\n",
    "                           axis=0)\n",
    "    sample = np.expand_dims(sample, axis=0)\n",
    "    input_ts.append(sample)\n",
    "input_ts = np.concatenate(input_ts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c0ca6e9-e80e-4fa2-9088-4a82a744110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518, 7, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4e551d5-8105-40f4-bc02-f93f1b01daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셋 분리\n",
    "train_x, val_x, train_y, val_y = train_test_split(input_ts, output_sc, test_size=0.2,\n",
    "                                                  shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195d21c7-211c-4056-89c7-40162f290c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1214, 7, 9), (304, 7, 9), (1214, 3), (304, 3))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, val_x.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ff17d90-40ed-48c5-90e7-a331a1d72fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 9)]            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                18944     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,139\n",
      "Trainable params: 19,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "def create_model():\n",
    "    x = Input(shape=[7, 9])\n",
    "    l1 = LSTM(64)(x)\n",
    "    out = Dense(3, activation='tanh')(l1)\n",
    "    return Model(inputs=x, outputs=out)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "checkpointer = ModelCheckpoint(monitor='val_loss', filepath='baseline.h5',\n",
    "                               verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff349e96-af76-4ebe-abb2-2f11a16a598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0170 - mse: 0.0170 \n",
      "Epoch 1: val_loss improved from inf to 0.00995, saving model to baseline.h5\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 2/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 2: val_loss improved from 0.00995 to 0.00839, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 3/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0109 - mse: 0.0109\n",
      "Epoch 3: val_loss improved from 0.00839 to 0.00777, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 4/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 4: val_loss did not improve from 0.00777\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 5/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 5: val_loss improved from 0.00777 to 0.00757, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 6/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 6: val_loss improved from 0.00757 to 0.00751, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 7/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 7: val_loss improved from 0.00751 to 0.00738, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 8/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 8: val_loss improved from 0.00738 to 0.00709, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 9/50\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 9: val_loss improved from 0.00709 to 0.00702, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 10/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 10: val_loss did not improve from 0.00702\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 11/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 11: val_loss improved from 0.00702 to 0.00696, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 12/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 12: val_loss improved from 0.00696 to 0.00682, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 13/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 13: val_loss did not improve from 0.00682\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 14/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 14: val_loss did not improve from 0.00682\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 15/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 15: val_loss did not improve from 0.00682\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 16/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 16: val_loss improved from 0.00682 to 0.00674, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 17/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 17: val_loss did not improve from 0.00674\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 18/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 18: val_loss did not improve from 0.00674\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 19/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 19: val_loss did not improve from 0.00674\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 20/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 20: val_loss improved from 0.00674 to 0.00670, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 21/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 21: val_loss improved from 0.00670 to 0.00659, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 22/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 22: val_loss did not improve from 0.00659\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 23/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 23: val_loss did not improve from 0.00659\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 24/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 24: val_loss improved from 0.00659 to 0.00650, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 25/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 25: val_loss did not improve from 0.00650\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 26/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 26: val_loss did not improve from 0.00650\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 27/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 27: val_loss did not improve from 0.00650\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 28/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 28: val_loss did not improve from 0.00650\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 29/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 29: val_loss improved from 0.00650 to 0.00637, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 30/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 30: val_loss improved from 0.00637 to 0.00632, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 31/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 31: val_loss did not improve from 0.00632\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 32/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 32: val_loss did not improve from 0.00632\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 33/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 33: val_loss improved from 0.00632 to 0.00623, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 34/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 34: val_loss improved from 0.00623 to 0.00614, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 35/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 35: val_loss improved from 0.00614 to 0.00604, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 36/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 36: val_loss did not improve from 0.00604\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 37/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 37: val_loss improved from 0.00604 to 0.00601, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 38/50\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 38: val_loss improved from 0.00601 to 0.00586, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 39/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 39: val_loss did not improve from 0.00586\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 40/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 40: val_loss improved from 0.00586 to 0.00551, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 41/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 41: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 42/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 42: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 43/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 43: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 44/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 44: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 45/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 45: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 46/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 46: val_loss did not improve from 0.00551\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 47/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 47: val_loss improved from 0.00551 to 0.00509, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 48/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 48: val_loss did not improve from 0.00509\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 49/50\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 49: val_loss improved from 0.00509 to 0.00507, saving model to baseline.h5\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 50/50\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 50: val_loss did not improve from 0.00507\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0056 - val_mse: 0.0056\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "hist = model.fit(train_x, train_y, batch_size=32, epochs=50, validation_data=(val_x, val_y), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7bf4d62-b5bb-462e-af36-335775c42c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss 히스토리 확인\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'g', label='val_loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend()\n",
    "plt.title('Training loss - Validation loss plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce362fe1-ef27-4710-8ef7-0de825d7eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 가중치 불러오기\n",
    "model.load_weights('baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97f855ba-cb34-4f06-ae52-9ba40dacab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 전처리 및 추론\n",
    "test_inputs = pd.read_csv('./farm/test_input.csv')\n",
    "output_sample = pd.read_csv('./farm/answer_sample.csv')\n",
    "\n",
    "test_inputs = test_inputs[inputs.columns]\n",
    "test_inputs['주차'] = [int(i.replace('주차', \"\")) for i in test_inputs['주차']]\n",
    "test_input_sc = input_scaler.transform(test_inputs.iloc[:,3:].to_numpy())\n",
    "\n",
    "test_input_ts = []\n",
    "for i in output_sample['Sample_no']:\n",
    "    sample = test_input_sc[test_inputs['Sample_no'] == i]\n",
    "    if len(sample < 7):\n",
    "        sample = np.append(np.zeros((7-len(sample), sample.shape[-1])), sample,\n",
    "                           axis=0)\n",
    "    sample = np.expand_dims(sample, axis=0)\n",
    "    test_input_ts.append(sample)\n",
    "test_input_ts = np.concatenate(test_input_ts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "642efacd-58b0-42c4-bcf1-c8e9dc1a030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 7, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07faf2f1-ed16-4688-bfcb-3ec08a534f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 793us/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_input_ts)\n",
    "\n",
    "prediction = output_scaler.inverse_transform(prediction)\n",
    "output_sample[['생장길이', '줄기직경', '개화군']] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69ec8199-3801-4ba0-8e76-cf4d4d5fa7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_no</th>\n",
       "      <th>조사일</th>\n",
       "      <th>주차</th>\n",
       "      <th>생장길이</th>\n",
       "      <th>줄기직경</th>\n",
       "      <th>개화군</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>20220413</td>\n",
       "      <td>32주차</td>\n",
       "      <td>47.151882</td>\n",
       "      <td>7.198693</td>\n",
       "      <td>13.229403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>20170312</td>\n",
       "      <td>30주차</td>\n",
       "      <td>420.956116</td>\n",
       "      <td>3.321363</td>\n",
       "      <td>10.489825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>20170319</td>\n",
       "      <td>31주차</td>\n",
       "      <td>589.641235</td>\n",
       "      <td>4.079537</td>\n",
       "      <td>7.553223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>20170326</td>\n",
       "      <td>32주차</td>\n",
       "      <td>281.593994</td>\n",
       "      <td>4.563877</td>\n",
       "      <td>7.977988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>20170430</td>\n",
       "      <td>37주차</td>\n",
       "      <td>89.870880</td>\n",
       "      <td>7.789731</td>\n",
       "      <td>4.768530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2015</td>\n",
       "      <td>20160508</td>\n",
       "      <td>14주차</td>\n",
       "      <td>188.253265</td>\n",
       "      <td>12.274371</td>\n",
       "      <td>5.467629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160529</td>\n",
       "      <td>17주차</td>\n",
       "      <td>1998.461670</td>\n",
       "      <td>4.776089</td>\n",
       "      <td>1.905745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2024</td>\n",
       "      <td>20160828</td>\n",
       "      <td>7주차</td>\n",
       "      <td>49.577644</td>\n",
       "      <td>13.211569</td>\n",
       "      <td>2.025992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2025</td>\n",
       "      <td>20160828</td>\n",
       "      <td>7주차</td>\n",
       "      <td>49.577755</td>\n",
       "      <td>13.211572</td>\n",
       "      <td>2.025991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2026</td>\n",
       "      <td>20160828</td>\n",
       "      <td>7주차</td>\n",
       "      <td>49.577755</td>\n",
       "      <td>13.211572</td>\n",
       "      <td>2.025991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample_no       조사일    주차         생장길이       줄기직경        개화군\n",
       "0            9  20220413  32주차    47.151882   7.198693  13.229403\n",
       "1           12  20170312  30주차   420.956116   3.321363  10.489825\n",
       "2           19  20170319  31주차   589.641235   4.079537   7.553223\n",
       "3           23  20170326  32주차   281.593994   4.563877   7.977988\n",
       "4           27  20170430  37주차    89.870880   7.789731   4.768530\n",
       "..         ...       ...   ...          ...        ...        ...\n",
       "501       2015  20160508  14주차   188.253265  12.274371   5.467629\n",
       "502       2016  20160529  17주차  1998.461670   4.776089   1.905745\n",
       "503       2024  20160828   7주차    49.577644  13.211569   2.025992\n",
       "504       2025  20160828   7주차    49.577755  13.211572   2.025991\n",
       "505       2026  20160828   7주차    49.577755  13.211572   2.025991\n",
       "\n",
       "[506 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12fad5b4-58e7-47a9-9e3d-24914265d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출할 추론 결과 저장\n",
    "output_sample.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724f4de-ed46-4e07-a6ff-302b83a62d9f",
   "metadata": {},
   "source": [
    "`-` 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dc65533-fbf5-4827-ba44-0e4761a90b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0036 - val_mse: 0.0036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2df8e88b80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "cb1 = tf.keras.callbacks.TensorBoard()\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=50, validation_data=(val_x, val_y), callbacks=[cb1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fca2764a-8e3e-4cc2-9dfe-e019c44bf37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 109833), started 0:04:21 ago. (Use '!kill 109833' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ba5dfdfcd755c3d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ba5dfdfcd755c3d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --host "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
