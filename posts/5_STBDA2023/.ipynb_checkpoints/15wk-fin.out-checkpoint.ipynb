{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c7f31299-2923-4bb6-8662-9dedccd84a2b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"15wk-fin\"\n",
    "author: \"JiyunLim\"\n",
    "date: \"12/21/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c1e144d-9488-45db-aea5-bb5bf7f4693e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7966f07-bc0d-48e8-aa8f-c72d54415bbb",
   "metadata": {},
   "source": [
    "1.  의사결정나무의 수동구현은 위에서 제시된 모듈 (numpy, pandas,\n",
    "    sklearn.metrics, matplotlib, seaborn) 만을 사용해야하며 이외의\n",
    "    모듈을 사용할 경우 0점 처리함.\n",
    "2.  True/False를 판단하는 문제는 답만 써도 무방함. (이유를 써도\n",
    "    상관없음)\n",
    "3.  Treu/False의 판단 문제는 모두 맞출 경우만 정답으로 인정함. 다만\n",
    "    틀린이유가 사소하다고 판단할경우 감점없이 만점처리함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c3bef-f7dc-4b98-9d8f-57b0c82568a9",
   "metadata": {},
   "source": [
    "# 1. 의사결정나무의 수동구현 (70점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c487030d-5f91-4ff0-92d5-791961eaf3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>164.227738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>165.798660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.219015</td>\n",
       "      <td>male</td>\n",
       "      <td>165.528672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>163.706442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.476750</td>\n",
       "      <td>male</td>\n",
       "      <td>165.501403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>49.308558</td>\n",
       "      <td>female</td>\n",
       "      <td>148.587771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>164.822474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>163.907671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>161.674476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>53.714772</td>\n",
       "      <td>female</td>\n",
       "      <td>146.775975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        weight     sex      height\n",
       "0          NaN    male  164.227738\n",
       "1          NaN    male  165.798660\n",
       "2    75.219015    male  165.528672\n",
       "3          NaN    male  163.706442\n",
       "4    81.476750    male  165.501403\n",
       "..         ...     ...         ...\n",
       "275  49.308558  female  148.587771\n",
       "276        NaN    male  164.822474\n",
       "277        NaN    male  163.907671\n",
       "278        NaN    male  161.674476\n",
       "279  53.714772  female  146.775975\n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/master/posts/height_train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aad5b6-c019-4eff-b7be-f8316b2077fd",
   "metadata": {},
   "source": [
    "`(1)` `df_train`에서 “sex”,“weight”를 설명변수로 “height”을 반응변수로\n",
    "설정하라. 결측치가 있을 경우 결측값에 일괄적으로 -99로 채워넣어라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f9bc0863-6d44-45a4-b4d3-c94539e1864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight    129\n",
       "sex         0\n",
       "height      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum() # weihgt 129개의 missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "262d2d69-afa3-4180-bfff-d2a27c7e621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight    0\n",
       "sex       0\n",
       "height    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.fillna(-99, inplace=True)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0e9b5c62-768b-463e-b287-1dc06f03a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['sex','weight']]\n",
    "y = df_train[['height']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fd09f-fafb-4e3b-9ae5-1966bc415cc5",
   "metadata": {},
   "source": [
    "`(2)` `height`열의 평균으로 `height`의 값을 추정하라. 추정값을 `yhat`에\n",
    "저장하라. `sklearn.metrics.r2_score()`을 이용하여 `r2_score`를 계산하라.\n",
    "\n",
    "**hint:** 0이 나와야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24859d32-8531-4cdb-997a-539808d045a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.227738</td>\n",
       "      <td>157.986528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.798660</td>\n",
       "      <td>157.986528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165.528672</td>\n",
       "      <td>157.986528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163.706442</td>\n",
       "      <td>157.986528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.501403</td>\n",
       "      <td>157.986528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        yhat\n",
       "0  164.227738  157.986528\n",
       "1  165.798660  157.986528\n",
       "2  165.528672  157.986528\n",
       "3  163.706442  157.986528\n",
       "4  165.501403  157.986528"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb1 = pd.DataFrame({'y':df_train['height'], 'yhat':pd.Series([df_train['height'].mean()]*len(df_train))})\n",
    "tb1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c76b48d2-3c89-4cae-8d02-08f5817d104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = sklearn.metrics.r2_score(tb1['y'], tb1['yhat'])\n",
    "r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d1e2f-ff48-4a65-ade0-0617d20d7d2a",
   "metadata": {},
   "source": [
    "`(3)` 아래를 계산하라.\n",
    "\n",
    "-   `r` = `y` - `yhat`\n",
    "\n",
    "여기에서 `yhat`은 `(2)`의 결과로 얻어진 적합값을 의미한다. 이제 `r`에\n",
    "Weight를 기준으로 의사결정나무를 적용하여 아래와 같은 분할을 만들어라.\n",
    "\n",
    "-   `X['weight']` \\< `c`\n",
    "-   `X['weight']` \\>= `c`\n",
    "\n",
    "`sklearn.metrics.r2_score()`를 이용하여 최적의 $c$값을 구하여라.\n",
    "\n",
    "**참고**\n",
    "\n",
    "아래의 구간을 적당히 등분하여 구할 것. 너무 세밀하게 등분하지 않아도\n",
    "무방함.\n",
    "\n",
    "``` python\n",
    "(X['weight'].min(), X['weight'].max())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e3d5495-75b8-46f2-809f-15d7d002b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tb1['yhat']\n",
    "r = tb1['y'] - tb1['yhat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0863dac7-0cd0-44cd-bc97-1dc9d027a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_range = (X['weight'].min(), X['weight'].max())\n",
    "# weight_range = (X[X['weight']>0]['weight'].min(), X['weight'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ac44c820-d282-4f12-bc99-237bd468e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 c: -98\n",
      "최적의 R-squared: 0.5320524394291483\n"
     ]
    }
   ],
   "source": [
    "best_c = None\n",
    "best_r2_score = 0\n",
    "\n",
    "for c in range(int(weight_range[0]), int(weight_range[1]) + 1):\n",
    "    df_train['weight_split'] = df_train['weight'] < c\n",
    "    y_pred = df_train['weight_split'].map({True: df_train.loc[df_train['weight_split'], 'height'].mean(),\n",
    "                                           False: df_train.loc[~df_train['weight_split'], 'height'].mean()})\n",
    "    current_r2_score = sklearn.metrics.r2_score(df_train['height'], y_pred)\n",
    "\n",
    "    if current_r2_score > best_r2_score:\n",
    "        best_r2_score = current_r2_score\n",
    "        best_c = c\n",
    "\n",
    "print(\"최적의 c:\", best_c)\n",
    "print(\"최적의 R-squared:\", best_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550fe5c-ec61-496a-b4fe-89764a0cb0c4",
   "metadata": {},
   "source": [
    "`(4)` `(3)`의 결과로 얻어진 아래의 분할을 고려하자.\n",
    "\n",
    "``` python\n",
    "X['weight'] >= c\n",
    "```\n",
    "\n",
    "이 분할에서 depth=2 로 나무를 성장하고자 한다. 성장이가능한가? 성장이\n",
    "가능하다면 이때 나무를 성장시키기 위한 변수로 weigth와 sex중 무엇이\n",
    "적절한가? 왜 그렇다고 생각하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ddd058-509f-4bfe-8fef-75ddccfef50a",
   "metadata": {},
   "source": [
    "- 성장가능하다. sex가 더 적절하다고 생각한다. sex를 기준으로 분기하게 되면 해당 노드에서 데이터를 더 효과적으로 구분할 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "86f46a9f-44b3-40ff-b86f-093f29abb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>147.436329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>164.915949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height\n",
       "sex               \n",
       "female  147.436329\n",
       "male    164.915949"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('sex').agg({'height':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c1c3c30e-7609-4603-bd86-01c1505d53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth=1에서의 분할 변수: weight\n",
      "Depth=1에서의 R-squared: 0.5320524394291483\n",
      "\n",
      "Depth=2에서의 분할 변수: sex\n",
      "Depth=2에서의 R-squared: 0.3509606704281393\n"
     ]
    }
   ],
   "source": [
    "y_pred_depth1 = (df_train['weight'] >= -98).astype(int)\n",
    "r_fit_depth1 = df_train['height'] - y_pred_depth1\n",
    "\n",
    "# depth=1\n",
    "df_train['weight_split'] = df_train['weight'] < -98\n",
    "mean_left_depth1 = df_train.loc[df_train['weight_split'], 'height'].mean()\n",
    "mean_right_depth1 = df_train.loc[~df_train['weight_split'], 'height'].mean()\n",
    "y_pred_depth1 = df_train['weight_split'].map({True: mean_left_depth1, False: mean_right_depth1})\n",
    "\n",
    "# R-squared 계산\n",
    "r2_score_depth1 = sklearn.metrics.r2_score(df_train['height'], y_pred_depth1)\n",
    "\n",
    "# depth=1\n",
    "print(\"Depth=1에서의 분할 변수: weight\")\n",
    "print(\"Depth=1에서의 R-squared:\", r2_score_depth1)\n",
    "\n",
    "# r의 적합값 계산\n",
    "r_fit_depth2 = df_train['height'] - y_pred_depth1\n",
    "\n",
    "# depth=2\n",
    "df_train['sex_split'] = df_train['sex'] \n",
    "mean_left_depth2 = df_train.loc[df_train['sex_split'] == 0, 'height'].mean()\n",
    "mean_right_depth2 = df_train.loc[df_train['sex_split'] == 1, 'height'].mean()\n",
    "y_pred_depth2 = df_train['sex_split'].map({0: mean_left_depth2, 1: mean_right_depth2})\n",
    "\n",
    "# R-squared\n",
    "r2_score_depth2 = sklearn.metrics.r2_score(df_train['height'], yhat + 0.5 * r_fit_depth2)\n",
    "\n",
    "print(\"\\nDepth=2에서의 분할 변수: sex\")\n",
    "print(\"Depth=2에서의 R-squared:\", r2_score_depth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a22159-3449-4e1c-801c-e0ae8d20c065",
   "metadata": {},
   "source": [
    "`(5)` `(3)`의 결과로 얻어진 아래의 분할을 고려하자.\n",
    "\n",
    "``` python\n",
    "X['weight'] < c\n",
    "```\n",
    "\n",
    "이 분할에서 depth=2 로 나무를 성장하고자 한다. 성장이가능한가? 성장이\n",
    "가능하다면 이때 나무를 성장시키기 위한 변수로 weigth와 sex중 무엇이\n",
    "적절한가? 왜 그렇다고 생각하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1f771-2a55-4c2d-939e-3397bf3d5d4f",
   "metadata": {},
   "source": [
    "- 성장이 가능하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a30df7-d824-47af-b346-19133c80a7d2",
   "metadata": {},
   "source": [
    "`(6)` `(3)`-`(5)`의 결과를 이용하여 `depth=2`인 의사결정나무에 의한\n",
    "`r`의 적합값을 구하여라. 이를 이용하여 `yhat`을 update하라. 이때\n",
    "학습률은 0.1로 설정하고 업데이트된 결과를 `yhat2`로 저장하라.\n",
    "그리고`sklearn.metrics.r2_score()`을 이용하여 `y`와 `yhat2`의\n",
    "`r2_score`를 계산하라.\n",
    "\n",
    "힌트: 아래의 알고리즘이 동치임을 이용하라.\n",
    "\n",
    "-   `yhat2` $\\leftarrow$ `yhat` + 학습률 $\\times$ `rhat`\n",
    "-   `r2` $\\leftarrow$ `r` - 학습률 $\\times$ `rhat`, where `r2` = `y` -\n",
    "    `yhat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22118586-dca5-4fbe-a523-5733e4098de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depth=2에서의 분할 변수: sex\n",
      "Depth=2에서의 R-squared: 0.08891003650846196\n"
     ]
    }
   ],
   "source": [
    "# R-squared 계산\n",
    "r2_score_depth2 = sklearn.metrics.r2_score(df_train['height'], yhat + 0.1* r_fit_depth2)\n",
    "\n",
    "# depth=2에서의 결과 출력\n",
    "print(\"\\nDepth=2에서의 분할 변수: sex\")\n",
    "print(\"Depth=2에서의 R-squared:\", r2_score_depth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae537d-0059-4ed6-ba45-4585c5a3b190",
   "metadata": {},
   "source": [
    "`(7)` `(6)`에서 학습률이 0.5일 경우 `y`와 `yhat2`의 `r2_score`를\n",
    "계산하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "755df297-8524-4992-9ad0-ba3781e7226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depth=2에서의 분할 변수: sex\n",
      "Depth=2에서의 R-squared: 0.3509606704281393\n"
     ]
    }
   ],
   "source": [
    "# R-squared 계산\n",
    "r2_score_depth2 = sklearn.metrics.r2_score(df_train['height'], yhat + 0.5* r_fit_depth2)\n",
    "\n",
    "# depth=2에서의 결과 출력\n",
    "print(\"\\nDepth=2에서의 분할 변수: sex\")\n",
    "print(\"Depth=2에서의 R-squared:\", r2_score_depth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360b951-badc-41d3-ae75-ec43008af97e",
   "metadata": {},
   "source": [
    "# 2. 다음을 읽고 참거짓을 판단하라. (30점)\n",
    "\n",
    "`(1)` 의사결정나무에서 `max_depth`의 설정값이 커질수록 오버피팅의 위험이\n",
    "있다. **(True)**\n",
    "\n",
    "`(2)` 배깅의 설명변수중 일부를 drop 하며 나무를 성장시킨다. **(False)**\n",
    "\n",
    "`(3)` 랜덤포레스트는 나무가지를 랜덤으로 성장시키기도 하고 파괴시키기도\n",
    "한다. **(True)**\n",
    "\n",
    "`(4)` 부스팅은 여러가지 의사결정나무의 적합값을 평균내는 방식으로\n",
    "최종예측을 한다. **(False)**\n",
    "\n",
    "`(5)` `Accuracy`는 분류문제에서 언제나 가장 합리적인 평가지표이다. **(False)**\n",
    "\n",
    "`(6)` 모듈49의 아래그림은 “sex == ‘male’” 일 경우 “sex=‘female’”\n",
    "일때보다 항상(=모든 관측치에 대하여) 키의 예측값을 +2.1 만큼 보정해야\n",
    "한다는 것을 의미한다. **(False)**\n",
    "\n",
    "![](https://guebin.github.io/MP2023/posts/13wk-49_files/figure-html/cell-14-output-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ca2e1-1b22-4e1b-9c22-2b792f14dfe6",
   "metadata": {},
   "source": [
    "`(7)` 모듈54에서 제시된 아래의 그림은 사실 전혀 고려할 필요가 없다.\n",
    "\n",
    "![](https://guebin.github.io/MP2023/posts/13wk-54_files/figure-html/cell-6-output-6.png)\n",
    "\n",
    "왜냐하면 Exercise는 범주형, Weight_Loss는 연속형이므로 correlation값은\n",
    "의미가 없기 때문이다. **(False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a25cb-7070-481a-8995-7950dfe66435",
   "metadata": {},
   "source": [
    "`(8)` 시계열분석에서 `static_feature`란 이미 알고있는 미래의\n",
    "시계열자료를 의미한다. **(False)**\n",
    "\n",
    "`(9)` 모듈59에서 소개된 자전거대여자료와 같이 시간특징이 포함된 자료는\n",
    "언제나 (과거를 기반으로 미래를 예측하는) 시계열분석을 하는 것이\n",
    "올바르다. **(False)**\n",
    "\n",
    "`(10)` 모듈60에서 소개된 하이퍼파라메터 설정법을 이용하면 때때로 모형의\n",
    "적합도를 높일 수 있다. **(True)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
