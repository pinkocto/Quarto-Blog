{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e12bcd43-ffe1-4726-adcc-2475d746c3d3",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"02wk-008: 타이타닉, Autogluon (best_quality)\"\n",
    "author: \"최규빈\"\n",
    "date: \"09/12/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5354421-f0bf-4054-b8bd-a1c138e812b4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. 강의영상\n",
    "\n",
    "<https://youtu.be/playlist?list=PLQqh36zP38-x6USW3HM9Lm-B19o9qrm19&si=EFy8hdlgDJ-LUFHi>\n",
    "\n",
    "# 2. Import\n",
    "\n",
    "``` python\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "```\n",
    "\n",
    "    /kaggle/input/titanic/train.csv\n",
    "    /kaggle/input/titanic/test.csv\n",
    "    /kaggle/input/titanic/gender_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee63a9f-4df2-46eb-b255-633ad13ef668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb9404e-25d7-4a80-8709-69221a7fbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68129b28-d677-47b3-9610-113789fea8ec",
   "metadata": {},
   "source": [
    "# 3. 분석의 절차\n",
    "\n",
    "## A. 데이터\n",
    "\n",
    "`-` 비유: 문제를 받아오는 과정으로 비유할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac6c193-2953-419d-ac23-d3d9ea3f40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./titanic/train.csv | Columns = 12 / 12 | Rows = 891 -> 891\n",
      "Loaded data from: ./titanic/test.csv | Columns = 11 / 11 | Rows = 418 -> 418"
     ]
    }
   ],
   "source": [
    "tr = TabularDataset(\"/kaggle/input/titanic/train.csv\")\n",
    "tst = TabularDataset(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd093d-da4a-462f-8662-42ba960ff118",
   "metadata": {},
   "source": [
    "## B. Predictor 생성\n",
    "\n",
    "`-` 비유: 문제를 풀 학생을 생성하는 과정으로 비유할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d14af837-2d5e-4dd3-9348-ade59683b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230912_120554/\""
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6545e52-c791-4ab0-806a-238da582b346",
   "metadata": {},
   "source": [
    "## C. 적합(fit)\n",
    "\n",
    "`-` 비유: 학생이 공부를 하는 과정으로 비유할 수 있다.\n",
    "\n",
    "`-` 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d487d466-82e6-4b71-b6c5-037ae26df37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230912_120554/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #26~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jul 13 16:27:29 UTC 2\n",
      "Disk Space Avail:   293.94 GB / 490.57 GB (59.9%)\n",
      "Train Data Rows:    891\n",
      "Train Data Columns: 11\n",
      "Label Column: Survived\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "    2 unique label values:  [0, 1]\n",
      "    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "    Available Memory:                    125495.28 MB\n",
      "    Train Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result = pd.to_datetime(X, errors=\"coerce\")\n",
      "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result = pd.to_datetime(X, errors=\"coerce\")\n",
      "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result = pd.to_datetime(X, errors=\"coerce\")\n",
      "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result = pd.to_datetime(X, errors=\"coerce\")\n",
      "/home/cgb2/anaconda3/envs/mp/lib/python3.10/site-packages/autogluon/common/features/infer_types.py:118: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result = pd.to_datetime(X, errors=\"coerce\")\n",
      "    Stage 1 Generators:\n",
      "        Fitting AsTypeFeatureGenerator...\n",
      "            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "    Stage 2 Generators:\n",
      "        Fitting FillNaFeatureGenerator...\n",
      "    Stage 3 Generators:\n",
      "        Fitting IdentityFeatureGenerator...\n",
      "        Fitting CategoryFeatureGenerator...\n",
      "            Fitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "        Fitting TextSpecialFeatureGenerator...\n",
      "            Fitting BinnedFeatureGenerator...\n",
      "            Fitting DropDuplicatesFeatureGenerator...\n",
      "        Fitting TextNgramFeatureGenerator...\n",
      "            Fitting CountVectorizer for text features: ['Name']\n",
      "            CountVectorizer fit with vocabulary size = 8\n",
      "    Stage 4 Generators:\n",
      "        Fitting DropUniqueFeatureGenerator...\n",
      "    Stage 5 Generators:\n",
      "        Fitting DropDuplicatesFeatureGenerator...\n",
      "    Types of features in original data (raw dtype, special dtypes):\n",
      "        ('float', [])        : 2 | ['Age', 'Fare']\n",
      "        ('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "        ('object', ['text']) : 1 | ['Name']\n",
      "    Types of features in processed data (raw dtype, special dtypes):\n",
      "        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "        ('float', [])                       : 2 | ['Age', 'Fare']\n",
      "        ('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "        ('int', ['bool'])                   : 1 | ['Sex']\n",
      "        ('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "    0.1s = Fit runtime\n",
      "    11 features in original data used to generate 28 features in processed data.\n",
      "    Train Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "    To change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "    'NN_TORCH': {},\n",
      "    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "    'CAT': {},\n",
      "    'XGB': {},\n",
      "    'FASTAI': {},\n",
      "    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "    0.6319   = Validation score   (accuracy)\n",
      "    0.0s     = Training   runtime\n",
      "    0.0s     = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "    0.6364   = Validation score   (accuracy)\n",
      "    0.0s     = Training   runtime\n",
      "    0.0s     = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.835    = Validation score   (accuracy)\n",
      "    0.46s    = Training   runtime\n",
      "    0.03s    = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8406   = Validation score   (accuracy)\n",
      "    0.65s    = Training   runtime\n",
      "    0.03s    = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "    0.8373   = Validation score   (accuracy)\n",
      "    0.34s    = Training   runtime\n",
      "    0.09s    = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "    0.8361   = Validation score   (accuracy)\n",
      "    0.34s    = Training   runtime\n",
      "    0.08s    = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8608   = Validation score   (accuracy)\n",
      "    1.85s    = Training   runtime\n",
      "    0.03s    = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "    0.8294   = Validation score   (accuracy)\n",
      "    0.58s    = Training   runtime\n",
      "    0.1s     = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "    0.8328   = Validation score   (accuracy)\n",
      "    0.3s     = Training   runtime\n",
      "    0.07s    = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8507   = Validation score   (accuracy)\n",
      "    2.85s    = Training   runtime\n",
      "    0.09s    = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8406   = Validation score   (accuracy)\n",
      "    1.09s    = Training   runtime\n",
      "    0.05s    = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8406   = Validation score   (accuracy)\n",
      "    4.25s    = Training   runtime\n",
      "    0.1s     = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "    Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "    0.8406   = Validation score   (accuracy)\n",
      "    1.36s    = Training   runtime\n",
      "    0.03s    = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "    0.8608   = Validation score   (accuracy)\n",
      "    0.4s     = Training   runtime\n",
      "    0.0s     = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230912_120554/\")"
     ]
    }
   ],
   "source": [
    "predictr.fit(tr,presets='best_quality') # 학생(predictr)에게 문제(tr)를 줘서 학습을 시킴(predictr.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266c149-cce5-443c-a310-942e8f86030d",
   "metadata": {},
   "source": [
    "`-` 리더보드확인 (모의고사채점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174c297f-09ab-4fab-8b6a-c1b5f5cc5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1   0.860831       0.026401  1.851676                0.026401           1.851676            1       True          7\n",
      "1       WeightedEnsemble_L2   0.860831       0.027539  2.251745                0.001138           0.400069            2       True         14\n",
      "2    NeuralNetFastAI_BAG_L1   0.850730       0.093112  2.852662                0.093112           2.852662            1       True         10\n",
      "3      LightGBMLarge_BAG_L1   0.840629       0.029128  1.360948                0.029128           1.360948            1       True         13\n",
      "4           LightGBM_BAG_L1   0.840629       0.031956  0.654864                0.031956           0.654864            1       True          4\n",
      "5            XGBoost_BAG_L1   0.840629       0.048379  1.094147                0.048379           1.094147            1       True         11\n",
      "6     NeuralNetTorch_BAG_L1   0.840629       0.102560  4.247738                0.102560           4.247738            1       True         12\n",
      "7   RandomForestGini_BAG_L1   0.837262       0.088506  0.341183                0.088506           0.341183            1       True          5\n",
      "8   RandomForestEntr_BAG_L1   0.836139       0.081470  0.341543                0.081470           0.341543            1       True          6\n",
      "9         LightGBMXT_BAG_L1   0.835017       0.027167  0.462362                0.027167           0.462362            1       True          3\n",
      "10    ExtraTreesEntr_BAG_L1   0.832772       0.073440  0.297061                0.073440           0.297061            1       True          9\n",
      "11    ExtraTreesGini_BAG_L1   0.829405       0.097789  0.580898                0.097789           0.580898            1       True          8\n",
      "12    KNeighborsDist_BAG_L1   0.636364       0.001740  0.003219                0.001740           0.003219            1       True          2\n",
      "13    KNeighborsUnif_BAG_L1   0.631874       0.001945  0.003195                0.001945           0.003195            1       True          1"
     ]
    }
   ],
   "source": [
    "predictr.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faecf94-0951-4983-b851-277dd30bc8bf",
   "metadata": {},
   "source": [
    "## D. 예측 (predict)\n",
    "\n",
    "`-` 비유: 학습이후에 문제를 푸는 과정으로 비유할 수 있다.\n",
    "\n",
    "`-` training set 을 풀어봄 (predict) $\\to$ 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63dde064-62d6-4b36-bade-c3826d031584",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tr.Survived == predictr.predict(tr)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67c122-e2a7-4cd9-bbc8-16f4ce6c8f22",
   "metadata": {},
   "source": [
    "`-` test set 을 풀어봄 (predict) $\\to$ 점수 확인 하러 캐글에 결과제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767c5239-4ba5-4a43-873b-dd1575ef8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.assign(Survived = predictr.predict(tst)).loc[:,['PassengerId','Survived']]\\\n",
    ".to_csv(\"autogluon(best_quality)_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be087d1-e140-47ae-bd97-0579ab1b73b8",
   "metadata": {},
   "source": [
    "# 3. 숙제\n",
    "\n",
    "`-` 캐글에 제출한 결과를 캡쳐하여 LMS에 제출"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
