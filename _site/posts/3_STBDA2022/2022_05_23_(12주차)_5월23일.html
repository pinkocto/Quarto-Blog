<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JiyunLim">
<meta name="dcterms.date" content="2023-07-11">

<title>Quarto-Blog - [STBDA] 12wk. CNN / 모형성능 향상을 위한 노력들</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Quarto-Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pinkocto"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><strong>[STBDA]</strong> 12wk. CNN / 모형성능 향상을 위한 노력들</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block"><strong>[STBDA]</strong> 12wk. CNN / 모형성능 향상을 위한 노력들</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">빅데이터분석특강</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>JiyunLim </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 11, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../1_ip2022.html" class="sidebar-item-text sidebar-link">IP2022</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_dv2022.html" class="sidebar-item-text sidebar-link">DV2022</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../3_stbda2022.html" class="sidebar-item-text sidebar-link">STBDA2022</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../5_study.html" class="sidebar-item-text sidebar-link">STUDY</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#강의영상" id="toc-강의영상" class="nav-link active" data-scroll-target="#강의영상">강의영상</a></li>
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">imports</a></li>
  <li><a href="#cnn" id="toc-cnn" class="nav-link" data-scroll-target="#cnn">CNN</a>
  <ul class="collapse">
  <li><a href="#conv의-역할" id="toc-conv의-역할" class="nav-link" data-scroll-target="#conv의-역할">CONV의 역할</a></li>
  <li><a href="#참고-스트라이드-패딩" id="toc-참고-스트라이드-패딩" class="nav-link" data-scroll-target="#참고-스트라이드-패딩">(참고) 스트라이드, 패딩</a></li>
  <li><a href="#maxpool" id="toc-maxpool" class="nav-link" data-scroll-target="#maxpool">MAXPOOL</a></li>
  <li><a href="#cnn-아키텍처의-표현방법" id="toc-cnn-아키텍처의-표현방법" class="nav-link" data-scroll-target="#cnn-아키텍처의-표현방법">CNN 아키텍처의 표현방법</a></li>
  <li><a href="#discusstion-about-cnn" id="toc-discusstion-about-cnn" class="nav-link" data-scroll-target="#discusstion-about-cnn">Discusstion about CNN</a></li>
  <li><a href="#cnn의-모티브" id="toc-cnn의-모티브" class="nav-link" data-scroll-target="#cnn의-모티브">CNN의 모티브</a></li>
  <li><a href="#cnn-신경망의-기본구조" id="toc-cnn-신경망의-기본구조" class="nav-link" data-scroll-target="#cnn-신경망의-기본구조">CNN 신경망의 기본구조</a></li>
  </ul></li>
  <li><a href="#모형의-성능을-올리기-위한-노력들" id="toc-모형의-성능을-올리기-위한-노력들" class="nav-link" data-scroll-target="#모형의-성능을-올리기-위한-노력들">모형의 성능을 올리기 위한 노력들</a>
  <ul class="collapse">
  <li><a href="#dropout" id="toc-dropout" class="nav-link" data-scroll-target="#dropout">dropout</a></li>
  <li><a href="#train-val-test" id="toc-train-val-test" class="nav-link" data-scroll-target="#train-val-test">train / val / test</a></li>
  <li><a href="#조기종료" id="toc-조기종료" class="nav-link" data-scroll-target="#조기종료">조기종료</a></li>
  <li><a href="#하이퍼파라메터-선택" id="toc-하이퍼파라메터-선택" class="nav-link" data-scroll-target="#하이퍼파라메터-선택">하이퍼파라메터 선택</a></li>
  </ul></li>
  <li><a href="#숙제" id="toc-숙제" class="nav-link" data-scroll-target="#숙제">숙제</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="강의영상" class="level2">
<h2 class="anchored" data-anchor-id="강의영상">강의영상</h2>
<blockquote class="blockquote">
<p>youtube: https://youtube.com/playlist?list=PLQqh36zP38-xOfpHJG0LrtYt4TUVgqUNy</p>
</blockquote>
</section>
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">imports</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> tensorflow.experimental.numpy <span class="im">as</span> tnp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>tnp.experimental_enable_numpy_behavior()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="cnn" class="level2">
<h2 class="anchored" data-anchor-id="cnn">CNN</h2>
<section id="conv의-역할" class="level3">
<h3 class="anchored" data-anchor-id="conv의-역할">CONV의 역할</h3>
<p><code>-</code> 데이터생성 (그냥 흑백대비 데이터)</p>
<div class="cell" data-outputid="bbc34ad1-a620-4afc-a805-d9d0a6cf2c31" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>_X1 <span class="op">=</span> tnp.ones([<span class="dv">50</span>,<span class="dv">25</span>])<span class="op">*</span><span class="dv">10</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>_X1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>&lt;tf.Tensor: shape=(50, 25), dtype=float64, numpy=
array([[10., 10., 10., ..., 10., 10., 10.],
       [10., 10., 10., ..., 10., 10., 10.],
       [10., 10., 10., ..., 10., 10., 10.],
       ...,
       [10., 10., 10., ..., 10., 10., 10.],
       [10., 10., 10., ..., 10., 10., 10.],
       [10., 10., 10., ..., 10., 10., 10.]])&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="88048fff-b88f-438f-df25-41e5f920e281" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>_X2 <span class="op">=</span> tnp.zeros([<span class="dv">50</span>,<span class="dv">25</span>])<span class="op">*</span><span class="dv">10</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>_X2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>&lt;tf.Tensor: shape=(50, 25), dtype=float64, numpy=
array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="a58f0704-2ca1-49a6-8f69-fec6965e4712" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>tf.concat([_X1,_X2],axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>&lt;tf.Tensor: shape=(50, 50), dtype=float64, numpy=
array([[10., 10., 10., ...,  0.,  0.,  0.],
       [10., 10., 10., ...,  0.,  0.,  0.],
       [10., 10., 10., ...,  0.,  0.,  0.],
       ...,
       [10., 10., 10., ...,  0.,  0.,  0.],
       [10., 10., 10., ...,  0.,  0.,  0.],
       [10., 10., 10., ...,  0.,  0.,  0.]])&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>plt.imshow(tf.concat([_X1,_X2], axis<span class="op">=</span><span class="dv">1</span>),cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fdcce3d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-8-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>값이 크면 흰색, 값이 작으면 검정색으로 되어있음.</li>
</ul>
<p>여기다 적당한 noise를 섞어보자.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>_noise_vec <span class="op">=</span> tnp.random.randn(<span class="dv">50</span><span class="op">*</span><span class="dv">50</span>) <span class="co"># 2500개의 vector</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>_noise_vec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>&lt;tf.Tensor: shape=(2500,), dtype=float64, numpy=
array([-0.06902639,  0.76575606,  0.62313143, ..., -0.15415241,
       -0.52788634,  0.77923277])&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="eb00dcf3-cedb-4898-bded-211a258837fb" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>_noise <span class="op">=</span> tnp.random.randn(<span class="dv">50</span><span class="op">*</span><span class="dv">50</span>).reshape(<span class="dv">50</span>,<span class="dv">50</span>) <span class="co"># matrix 형태로</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>_noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>&lt;tf.Tensor: shape=(50, 50), dtype=float64, numpy=
array([[ 0.64448515,  0.48672712, -0.21792212, ..., -0.4029161 ,
        -0.76942793,  0.42752944],
       [-0.85736695,  1.27257844,  0.86595728, ...,  0.17527877,
         1.74959789, -0.8465042 ],
       [-2.37767743,  1.12817978,  0.80667681, ..., -1.69588932,
         0.66389614,  0.04199325],
       ...,
       [ 0.35348866,  0.8854033 ,  0.57155344, ...,  1.47500872,
        -0.56131948,  0.44347445],
       [ 1.58838754, -1.37524759,  1.12635227, ..., -0.6870017 ,
         0.63987008,  0.55168672],
       [ 0.27925012,  0.04426039,  0.19833725, ...,  0.00770918,
        -2.02424407, -0.04405339]])&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># image data 생성</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>XXX <span class="op">=</span> tf.concat([_X1,_X2],axis<span class="op">=</span><span class="dv">1</span>) <span class="op">+</span> _noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># shape을 맞춰줘야함. </span></span>
<span id="cb17-2"><a href="#cb17-2"></a>XXX<span class="op">=</span>XXX.reshape(<span class="dv">1</span>,<span class="dv">50</span>,<span class="dv">50</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="367a706f-d5c8-4569-c1f2-b6393146a5c7" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>plt.imshow(XXX.reshape(<span class="dv">50</span>,<span class="dv">50</span>),cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fdc40490&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-13-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> conv layer 생성</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>conv <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">2</span>,(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="co"># (2,2) kernel</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="f3eb8ee6-019d-42b5-9b57-18c16b9c14b9" data-execution_count="22">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>conv.weights <span class="co"># 처음에는 가중치가 없음</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>[]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>conv(XXX).shape <span class="co"># 2x2 kernel을 만들었으니까 이미지가 하나씩 날라가서 49x49의 이미지 생성</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>TensorShape([1, 49, 49, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="56c26cea-dec7-46ac-9970-aaeeee9d2438" data-execution_count="23">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>conv(XXX) <span class="co"># 가중치를 만들기 위해서 XXX를 conv에 한번 통과시킴</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>conv.weights <span class="co"># 이제 가중치가 생김</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>[&lt;tf.Variable 'conv2d/kernel:0' shape=(2, 2, 1, 2) dtype=float32, numpy=
 array([[[[-0.10361075, -0.03655446]],
 
         [[-0.25615066, -0.6408293 ]]],
 
 
        [[[-0.19069207, -0.6668661 ]],
 
         [[-0.18648207, -0.534903  ]]]], dtype=float32)&gt;,
 &lt;tf.Variable 'conv2d/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;]</code></pre>
</div>
</div>
<ul>
<li>이제 가중치가 생김.</li>
</ul>
<p><code>-</code> 가중치의 값을 확인해보자.</p>
<div class="cell" data-outputid="ac545f6e-87ee-42aa-c1c4-b9b4c428bc1e" data-execution_count="26">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>conv.weights[<span class="dv">0</span>] <span class="co"># kernel에 해당하는것</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>&lt;tf.Variable 'conv2d/kernel:0' shape=(2, 2, 1, 2) dtype=float32, numpy=
array([[[[-0.10361075, -0.03655446]],

        [[-0.25615066, -0.6408293 ]]],


       [[[-0.19069207, -0.6668661 ]],

        [[-0.18648207, -0.534903  ]]]], dtype=float32)&gt;</code></pre>
</div>
</div>
<ul>
<li><code>shape=(2, 2, 1, 2)</code> : 커널사이즈 2x2 // XXX의 채널 1 // Conv(XXX)의 출력채널 2</li>
</ul>
<div class="sourceCode" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="co">## 참고</span></span>
<span id="cb29-2"><a href="#cb29-2"></a>conv <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">2</span>,(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb29-3"><a href="#cb29-3"></a></span>
<span id="cb29-4"><a href="#cb29-4"></a><span class="co"># 여기서 unit을 2개로 받았으니까 2개의 출력 채널이 만들어진다.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-outputid="c3f3e2d2-ae01-437b-e01f-2c2dc5588e04" data-execution_count="27">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>conv.weights[<span class="dv">1</span>] <span class="co"># bias에 해당하는것</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>&lt;tf.Variable 'conv2d/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;</code></pre>
</div>
</div>
<p><code>-</code> 필터값을 원하는 것으로 변경해보자.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a>w0 <span class="op">=</span> [[<span class="fl">0.25</span>,<span class="fl">0.25</span>],[<span class="fl">0.25</span>,<span class="fl">0.25</span>]] <span class="co"># 잡티를 제거하는 효과를 준다.</span></span>
<span id="cb32-2"><a href="#cb32-2"></a>w1 <span class="op">=</span> [[<span class="op">-</span><span class="fl">1.0</span>,<span class="fl">1.0</span>],[<span class="op">-</span><span class="fl">1.0</span>,<span class="fl">1.0</span>]] <span class="co"># 경계를 찾기 좋아보이는 필터이다. (엣지검출)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>np.array(w0), np.array(w1) <span class="co"># (2,2,1,2)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>(array([[0.25, 0.25],
        [0.25, 0.25]]),
 array([[-1.,  1.],
        [-1.,  1.]]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="93b992ec-824a-467f-f3c6-6238cf513c79" data-execution_count="34">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>w<span class="op">=</span>np.concatenate([np.array(w0).reshape(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>),np.array(w1).reshape(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>)],axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb35-2"><a href="#cb35-2"></a>w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>array([[[[ 0.25, -1.  ]],

        [[ 0.25,  1.  ]]],


       [[[ 0.25, -1.  ]],

        [[ 0.25,  1.  ]]]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="edc41b87-f8b1-4682-b47a-6144b9173402" data-execution_count="35">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a>b<span class="op">=</span> np.array([<span class="fl">0.0</span>,<span class="fl">0.0</span>])</span>
<span id="cb37-2"><a href="#cb37-2"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>array([0., 0.])</code></pre>
</div>
</div>
<div class="cell" data-outputid="052601e6-6851-4aa0-f265-ff731b44bd87" data-execution_count="38">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>conv.set_weights([w,b])</span>
<span id="cb39-2"><a href="#cb39-2"></a>conv.get_weights()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>[array([[[[ 0.25, -1.  ]],
 
         [[ 0.25,  1.  ]]],
 
 
        [[[ 0.25, -1.  ]],
 
         [[ 0.25,  1.  ]]]], dtype=float32),
 array([0., 0.], dtype=float32)]</code></pre>
</div>
</div>
<ul>
<li>첫번째는 평균을 구하는 필터,</li>
<li>두번째는 엣지를 검출하는 필터</li>
</ul>
<p><code>-</code> 필터를 넣은 결과를 확인</p>
<div class="cell" data-outputid="cb657811-82c5-47a7-cc3e-9c17cf78bb80" data-execution_count="43">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>XXX0<span class="op">=</span>conv(XXX)[...,<span class="dv">0</span>] <span class="co"># 채널0</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>XXX0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>&lt;tf.Tensor: shape=(1, 49, 49), dtype=float32, numpy=
array([[[10.386606  , 10.601835  , 10.11681   , ..., -0.26418784,
          0.18813315,  0.1402988 ],
        [ 9.791428  , 11.018348  , 10.635733  , ..., -0.15474442,
          0.22322088,  0.4022458 ],
        [ 9.269302  , 10.1986265 , 10.747881  , ..., -0.42707908,
         -0.01979728,  0.31640166],
        ...,
        [10.478983  , 10.708517  ,  9.69488   , ...,  0.23036546,
         -0.513018  , -0.63264334],
        [10.363008  , 10.302015  , 10.524318  , ...,  0.52903736,
          0.21663941,  0.26842797],
        [10.134163  ,  9.9984255 , 10.623085  , ...,  0.01135473,
         -0.5159166 , -0.21918514]]], dtype=float32)&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="4387904f-5812-4e0b-f7c9-ab7205fa34d4" data-execution_count="44">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a>XXX1<span class="op">=</span>conv(XXX)[...,<span class="dv">1</span>] <span class="co"># 채널1</span></span>
<span id="cb43-2"><a href="#cb43-2"></a>XXX1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>&lt;tf.Tensor: shape=(1, 49, 49), dtype=float32, numpy=
array([[[ 1.9721851 , -1.111269  , -0.8288326 , ...,  0.60147667,
          1.2078073 , -1.3991446 ],
        [ 5.6358013 , -0.7281227 , -0.80233765, ..., -2.4222436 ,
          3.9341047 , -3.2180052 ],
        [ 2.7431278 ,  0.9741707 ,  1.222847  , ..., -0.033876  ,
          1.6630032 , -0.31820738],
        ...,
        [ 3.2966785 , -2.378542  , -1.6760101 , ..., -0.11025763,
         -2.863276  ,  2.3847747 ],
        [-2.4317207 ,  2.1877518 , -1.298542  , ..., -0.5401355 ,
         -0.7094564 ,  0.91661054],
        [-3.1986256 ,  2.6556778 , -0.15703964, ..., -1.4040039 ,
         -0.7050814 ,  1.8920072 ]]], dtype=float32)&gt;</code></pre>
</div>
</div>
<p><code>-</code> 각 채널을 시각화</p>
<div class="cell" data-outputid="6c109e4b-6313-4c3e-a0be-b335b3aa62af" data-execution_count="46">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a>fig, ((ax1,ax2),(ax3,ax4)) <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="680e3b1d-409a-49bc-cbf0-7328050be9f2" data-execution_count="47">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a>ax1.imshow(XXX.reshape(<span class="dv">50</span>,<span class="dv">50</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># original image</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fd4f2070&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="b79e0ef8-1023-4675-e383-b8da065e35be" data-execution_count="48">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>ax3.imshow(XXX0.reshape(<span class="dv">49</span>,<span class="dv">49</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 채널0을 통과시킨 이미지</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fd4c2700&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="e8c9f18a-343e-41cc-83f1-64a2dce1da9f" data-execution_count="49">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>ax4.imshow(XXX1.reshape(<span class="dv">49</span>,<span class="dv">49</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 채널1을 통과시킨 이미지</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fd3511c0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="56a7f6d7-925c-41c6-fed2-97ad925b0efd" data-execution_count="50">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a>fig</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>2사분면: 원래이미지</li>
<li>3사분면: 원래이미지 -&gt; 평균을 의미하는 conv적용</li>
<li>4사분면: 원래이미지 -&gt; 엣지를 검출하는 conv적용</li>
</ul>
<p><code>-</code> conv(XXX)의 각 채널에 한번더 conv를 통과시켜보자</p>
<ul>
<li>channel0 : 평균필터</li>
<li>channel1 : 엣지필터</li>
</ul>
<div class="cell" data-outputid="14dfa06a-f793-42f5-91b7-c4900ed88879" data-execution_count="53">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>conv(XXX0.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">0</span>] <span class="co">### XXX0 -&gt; 평균필터 &lt;=&gt; XXX -&gt; 평균필터 -&gt; 평균필터</span></span>
<span id="cb53-2"><a href="#cb53-2"></a>conv(XXX0.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">1</span>] <span class="co">### XXX0 -&gt; 엣지필터 &lt;=&gt; XXX -&gt; 평균필터 -&gt; 엣지필터</span></span>
<span id="cb53-3"><a href="#cb53-3"></a>conv(XXX1.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">0</span>] <span class="co">### XXX1 -&gt; 평균필터 &lt;=&gt; XXX -&gt; 엣지필터 -&gt; 평균필터</span></span>
<span id="cb53-4"><a href="#cb53-4"></a>conv(XXX1.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">1</span>] <span class="co">### XXX1 -&gt; 엣지필터 &lt;=&gt; XXX -&gt; 엣지필터 -&gt; 엣지필터</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>&lt;tf.Tensor: shape=(1, 48, 48), dtype=float32, numpy=
array([[[-9.447378  ,  0.20822144,  0.19534683, ..., -0.7362902 ,
          6.962679  , -9.759062  ],
        [-8.132881  ,  0.17446136, -3.0925026 , ..., -2.7580416 ,
          8.053227  , -9.13332   ],
        [-0.93447495, -2.5899773 , -1.0724258 , ...,  5.2640886 ,
          0.94379497, -3.4876597 ],
        ...,
        [-9.087433  ,  1.0329819 ,  6.3635483 , ...,  0.6270219 ,
         -6.605945  ,  9.485929  ],
        [-1.055748  , -2.783762  ,  2.398777  , ...,  2.1154294 ,
         -2.9223394 ,  6.874118  ],
        [10.473776  , -6.299011  , -0.73449326, ...,  1.5050641 ,
          0.5296016 ,  4.2231555 ]]], dtype=float32)&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="09cfb788-cfe1-4315-e2c9-cae3b1853956" data-execution_count="57">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a>fig,ax <span class="op">=</span>plt.subplots(<span class="dv">3</span>,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="acac1ae2-39fd-47a7-904e-fb6dff0a6dd4" data-execution_count="59">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a>ax[<span class="dv">0</span>][<span class="dv">0</span>].imshow(XXX.reshape(<span class="dv">50</span>,<span class="dv">50</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지</span></span>
<span id="cb56-2"><a href="#cb56-2"></a>ax[<span class="dv">0</span>][<span class="dv">0</span>].set_title(<span class="st">'original image'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>Text(0.5, 1.0, 'original image')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a>fig</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="ea9f8761-bffa-4abb-b171-0e7ffd097f21" data-execution_count="61">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].imshow(XXX0.reshape(<span class="dv">49</span>,<span class="dv">49</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지 -&gt; 평균필터</span></span>
<span id="cb59-2"><a href="#cb59-2"></a>ax[<span class="dv">1</span>][<span class="dv">2</span>].imshow(XXX1.reshape(<span class="dv">49</span>,<span class="dv">49</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지 -&gt; 엣지필터</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fd58ebe0&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1"></a>ax[<span class="dv">1</span>][<span class="dv">0</span>].set_title(<span class="st">'Average filter'</span>)</span>
<span id="cb61-2"><a href="#cb61-2"></a>ax[<span class="dv">1</span>][<span class="dv">2</span>].set_title(<span class="st">'Edge filter'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>Text(0.5, 1.0, 'Edge filter')</code></pre>
</div>
</div>
<div class="cell" data-outputid="986f4fab-fb68-4488-9b04-77a79f039463" data-execution_count="71">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a>ax[<span class="dv">2</span>][<span class="dv">0</span>].imshow(conv(XXX0.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">0</span>].reshape(<span class="dv">48</span>,<span class="dv">48</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지(평균필터를 1번 통과한 이미지) -&gt; 평균필터</span></span>
<span id="cb63-2"><a href="#cb63-2"></a>ax[<span class="dv">2</span>][<span class="dv">1</span>].imshow(conv(XXX0.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">1</span>].reshape(<span class="dv">48</span>,<span class="dv">48</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지(평균필터를 1번 통과한 이미지) -&gt; 엣지필터</span></span>
<span id="cb63-3"><a href="#cb63-3"></a>ax[<span class="dv">2</span>][<span class="dv">2</span>].imshow(conv(XXX1.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">0</span>].reshape(<span class="dv">48</span>,<span class="dv">48</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지(엣지필터를 1번 통과한 이미지) -&gt; 평균필터</span></span>
<span id="cb63-4"><a href="#cb63-4"></a>ax[<span class="dv">2</span>][<span class="dv">3</span>].imshow(conv(XXX1.reshape(<span class="dv">1</span>,<span class="dv">49</span>,<span class="dv">49</span>,<span class="dv">1</span>))[...,<span class="dv">1</span>].reshape(<span class="dv">48</span>,<span class="dv">48</span>),cmap<span class="op">=</span><span class="st">'gray'</span>) <span class="co"># 원래이미지(엣지필터를 1번 통과한 이미지) -&gt; 엣지필터</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f37fced5eb0&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a>ax[<span class="dv">2</span>][<span class="dv">0</span>].set_title(<span class="st">'Average + Average'</span>)</span>
<span id="cb65-2"><a href="#cb65-2"></a>ax[<span class="dv">2</span>][<span class="dv">1</span>].set_title(<span class="st">'Average + Edge'</span>)</span>
<span id="cb65-3"><a href="#cb65-3"></a>ax[<span class="dv">2</span>][<span class="dv">2</span>].set_title(<span class="st">'Edge + Average'</span>)</span>
<span id="cb65-4"><a href="#cb65-4"></a>ax[<span class="dv">2</span>][<span class="dv">3</span>].set_title(<span class="st">'Edge + Edge'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>Text(0.5, 1.0, 'Edge + Edge')</code></pre>
</div>
</div>
<div class="cell" data-outputid="a2cae988-e769-411e-af86-4fb202b33f88" data-execution_count="77">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a>fig.set_figheight(<span class="dv">8</span>)</span>
<span id="cb67-2"><a href="#cb67-2"></a>fig.set_figwidth(<span class="dv">16</span>)</span>
<span id="cb67-3"><a href="#cb67-3"></a>fig.tight_layout()</span>
<span id="cb67-4"><a href="#cb67-4"></a>fig</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-40-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>-</code> 요약 - conv의 weight에 따라서 엣지를 검출하는 필터가 만들어지기도 하고 스무딩의 역할을 하는 필터가 만들어지기도 한다. 그리고 우리는 의미를 알 수 없지만 어떠한 역할을 하는 필터가 만들어질 것이다. - 이것들을 조합하다보면 우연히 이미지를 분류하기에 유리한 특징을 뽑아내는 weight가 맞춰질 수도 있겠다. - 채널수를 많이 만들고 다양한 웨이트조합을 실험하다보면 보다 복잡한 이미지의 특징을 추출할 수도 있을 것이다? - 컨볼루션 레이어의 역할 = <strong><font color="red">이미지의 특징을 추출하는 역할</font></strong></p>
</section>
<section id="참고-스트라이드-패딩" class="level3">
<h3 class="anchored" data-anchor-id="참고-스트라이드-패딩">(참고) 스트라이드, 패딩</h3>
<p><code>-</code> 참고: 스트라이드, 패딩 - 스트라이드: 윈도우가 1칸씩 이동하는 것이 아니라 2~3칸씩 이동함 - 패딩: 이미지의 가장자리에 정당한 값을 넣어서 (예를들어 0) 컨볼루션을 수행. 따라서 컨볼루션 연산 이후에도 이미지의 크기가 줄어들지 않도록 방지한다.</p>
</section>
<section id="maxpool" class="level3">
<h3 class="anchored" data-anchor-id="maxpool">MAXPOOL</h3>
<p><code>-</code> 기본적역할: 이미지의 크기를 줄이는 것 - 이미지의의 크기를 줄여야하는 이유? 어차피 최종적으로 10차원으로 줄어야하므로 - 이미지의 크기를 줄이면서도 동시에 아주 크리티컬한 특징은 손실없이 유지하고 싶다~</p>
<p><code>-</code> 점점 작은 이미지가 되면서 중요한 특징들은 살아남지만 그렇지 않으면 죽는다. (캐리커쳐 느낌)</p>
<p><code>-</code> 평균이 아니라 max를 쓴 이유는? 그냥 평균보다 나을것이라고 생각했음.. - 그런데 사실은 꼭 그렇지만은 않아서 최근에는 꼭 맥스풀링을 고집하진 않는 추세 (평균풀링도 많이씀)</p>
</section>
<section id="cnn-아키텍처의-표현방법" class="level3">
<h3 class="anchored" data-anchor-id="cnn-아키텍처의-표현방법">CNN 아키텍처의 표현방법</h3>
<p><code>-</code> 아래와 같이 아키텍처의 다이어그램형태로 표현하고 굳이 노드별로 이미지를 그리진 않음</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/2560px-Comparison_image_neural_networks.svg.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">위키에서 긁어온 이미지</figcaption><p></p>
</figure>
</div>
<p><code>-</code> 물론 아래와 같이 그리는 경우도 있음</p>
<p><img src="https://editor.analyticsvidhya.com/uploads/90650dnn2.jpeg" class="img-fluid"></p>
</section>
<section id="discusstion-about-cnn" class="level3">
<h3 class="anchored" data-anchor-id="discusstion-about-cnn">Discusstion about CNN</h3>
<p><code>-</code> 격자형태로 배열된 자료를 처리하는데 특화된 신경망이다. - 시계열 (1차원격자), 이미지 (2차원격자)</p>
<p><code>-</code> 실제응용에서 엄청난 성공을 거두었다.</p>
<p><code>-</code> 이름의 유래는 컨볼루션이라는 수학적 연산을 사용했기 때문 - 컨볼루션은 조금 특별한 선형변환이다.</p>
<p><code>-</code> 신경과학의 원리가 심층학습에 영향을 미친 사례이다.</p>
</section>
<section id="cnn의-모티브" class="level3">
<h3 class="anchored" data-anchor-id="cnn의-모티브">CNN의 모티브</h3>
<p><code>-</code> 희소성 + 매개변수의 공유 - 다소 철학적인 모티브임 - 희소성: 이미지를 분석하여 특징을 뽑아낼때 부분부분의 특징만 뽑으면 된다는 의미<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> - 매개변수의 공유: 한 채널에는 하나의 역할을 하는 커널을 설계하면 된다는 의미 (스무딩이든 엣징이든). 즉 어떤지역은 스무딩, 어떤지역은 엣징을 할 필요가 없이 한채널에서는 엣징만, 다른채널에서는 스무딩만 수행한뒤 여러채널을 조합해서 이해하면 된다.</p>
<p><code>-</code> 매개변수 공유효과로 인해서 파라메터가 확 줄어든다.</p>
<p>(예시) (1,6,6,1) -&gt; (1,5,5,2) - MLP방식이면 (36,50) 의 차원을 가진 매트릭스가 필요함 =&gt; 1800개의 매개변수 필요 - CNN은 8개의 매개변수 필요</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1"></a><span class="co">## MLP</span></span>
<span id="cb68-2"><a href="#cb68-2"></a><span class="dv">36</span><span class="op">*</span><span class="dv">50</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>1800</code></pre>
</div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a><span class="co">## CNN</span></span>
<span id="cb70-2"><a href="#cb70-2"></a>(<span class="dv">2</span><span class="op">*</span><span class="dv">2</span>) <span class="op">*</span> <span class="dv">2</span> <span class="co"># (2x2) kernel이 2개</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>8</code></pre>
</div>
</div>
<ul>
<li>매개변수가 적으면 GPU에 올릴때 좋음.</li>
</ul>
</section>
<section id="cnn-신경망의-기본구조" class="level3">
<h3 class="anchored" data-anchor-id="cnn-신경망의-기본구조">CNN 신경망의 기본구조</h3>
<p><code>-</code> 기본유닛 - conv<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> - activation<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> - pooling<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> - conv<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> - conv<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> - activation<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> - pooling<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
</section>
</section>
<section id="모형의-성능을-올리기-위한-노력들" class="level2">
<h2 class="anchored" data-anchor-id="모형의-성능을-올리기-위한-노력들">모형의 성능을 올리기 위한 노력들</h2>
<section id="dropout" class="level3">
<h3 class="anchored" data-anchor-id="dropout">dropout</h3>
<p><code>-</code> 아래의 예제를 복습하자.</p>
<div class="cell" data-outputid="5e32f621-57e0-4b93-90a9-cc8561d280b1" data-execution_count="83">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a>np.random.seed(<span class="dv">43052</span>)</span>
<span id="cb72-2"><a href="#cb72-2"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>).reshape(<span class="dv">100</span>,<span class="dv">1</span>)</span>
<span id="cb72-3"><a href="#cb72-3"></a>y <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>,scale<span class="op">=</span><span class="fl">0.01</span>,size<span class="op">=</span>(<span class="dv">100</span>,<span class="dv">1</span>))</span>
<span id="cb72-4"><a href="#cb72-4"></a>plt.plot(x,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-43-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>이 예제는 랜덤으로 만든 데이터이기 때문에 fitting을 하면 직선이 나와야 한다.</li>
<li>그게 아니라면 오퍼피팅.</li>
</ul>
<p>Dense layer를 <span class="math inline">\(2048\)</span>로 받아서 오버피팅이 일어나기 좋은 환경을 일부러 만들고 있다.</p>
<div class="cell" data-outputid="e7465996-4c24-4d98-a651-64621a1e1770" data-execution_count="84">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb73-2"><a href="#cb73-2"></a>net <span class="op">=</span> tf.keras.Sequential() <span class="co"># 네트워크 생성</span></span>
<span id="cb73-3"><a href="#cb73-3"></a>net.add(tf.keras.layers.Dense(<span class="dv">2048</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb73-4"><a href="#cb73-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">1</span>)) <span class="co"># activation이 identity로 받아지는 것.</span></span>
<span id="cb73-5"><a href="#cb73-5"></a>net.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>,optimizer<span class="op">=</span><span class="st">'adam'</span>)</span>
<span id="cb73-6"><a href="#cb73-6"></a>net.fit(x,y,epochs<span class="op">=</span><span class="dv">5000</span>,verbose<span class="op">=</span><span class="dv">0</span>,batch_size<span class="op">=</span><span class="dv">100</span>) <span class="co"># 적합.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>&lt;keras.callbacks.History at 0x7f37e6134820&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="99931252-e4c2-4dc0-e930-4be7d8570142" data-execution_count="85">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>plt.plot(x,y)</span>
<span id="cb75-2"><a href="#cb75-2"></a>plt.plot(x,net(x),<span class="st">'--'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-45-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li><p>얘는 랜덤인데<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> 위와 같이 데이터를 따라가는 피팅 결과가 나오면 오버피팅이라고 할 수 있다.</p></li>
<li><p>이러한 추세가 있는게 맞을수도 있지 않느냐? 라고 생각할 수 있는데 그것을 아님을 보이기 위해 train/test로 나누어서 생각해보자.</p></li>
</ul>
<p><code>-</code> train/test로 나누어서 생각해보자.</p>
<div class="cell" data-outputid="74481c00-613d-43e6-ba3a-933a9c40497b" data-execution_count="86">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb76-2"><a href="#cb76-2"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb76-3"><a href="#cb76-3"></a>net.add(tf.keras.layers.Dense(<span class="dv">2048</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb76-4"><a href="#cb76-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">1</span>))</span>
<span id="cb76-5"><a href="#cb76-5"></a>net.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>,optimizer<span class="op">=</span><span class="st">'adam'</span>)</span>
<span id="cb76-6"><a href="#cb76-6"></a>net.fit(x[:<span class="dv">80</span>],y[:<span class="dv">80</span>],epochs<span class="op">=</span><span class="dv">5000</span>,verbose<span class="op">=</span><span class="dv">0</span>,batch_size<span class="op">=</span><span class="dv">80</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>&lt;keras.callbacks.History at 0x7f37e5f1eee0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="d3209b5f-305c-44ea-8c7c-0c87b258d225" data-execution_count="87">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1"></a>plt.plot(x,y)</span>
<span id="cb78-2"><a href="#cb78-2"></a>plt.plot(x[:<span class="dv">80</span>],net(x[:<span class="dv">80</span>]),<span class="st">'--'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-47-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="13c015d3-edac-42fb-999e-e5129a8fc57c" data-execution_count="89">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a>plt.plot(x,y)</span>
<span id="cb79-2"><a href="#cb79-2"></a>plt.plot(x[:<span class="dv">80</span>],net(x[:<span class="dv">80</span>]),<span class="st">'--'</span>, label<span class="op">=</span><span class="st">'train'</span>)</span>
<span id="cb79-3"><a href="#cb79-3"></a>plt.plot(x[<span class="dv">80</span>:],net(x[<span class="dv">80</span>:]),<span class="st">'--'</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb79-4"><a href="#cb79-4"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f37fd08b640&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-48-output-2.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>train에서 추세를 따라가는게 좋은게 아니다 <span class="math inline">\(\to\)</span> 그냥 직선으로 핏하는거 이외에는 다 오버핏이다.</li>
</ul>
<p>(생각) 우리가 노드를 <span class="math inline">\(2048\)</span>개를 만들었었는데 학습을 해보니 과적합이 일어났다. 즉, 노드들이 학습을 너무 열심히 했다. 학습을 좀 더 대충했으면 이렇게 세밀하게는 안따라갔을 텐데..</p>
<p><code>-</code> 매 에폭마다 적당히 80%의 노드들을 빼고 학습하자 <span class="math inline">\(\to\)</span> 너무 잘 학습되는 문제는 생기지 않을 것이다 (과적합이 방지될것이다?)</p>
<div class="cell" data-outputid="f6a8df6c-06e4-481f-ff4b-05ed642f736a" data-execution_count="90">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb81-2"><a href="#cb81-2"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb81-3"><a href="#cb81-3"></a>net.add(tf.keras.layers.Dense(<span class="dv">2048</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb81-4"><a href="#cb81-4"></a>net.add(tf.keras.layers.Dropout(<span class="fl">0.8</span>)) <span class="co">## Dropout층 추가</span></span>
<span id="cb81-5"><a href="#cb81-5"></a>net.add(tf.keras.layers.Dense(<span class="dv">1</span>))</span>
<span id="cb81-6"><a href="#cb81-6"></a>net.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>,optimizer<span class="op">=</span><span class="st">'adam'</span>)</span>
<span id="cb81-7"><a href="#cb81-7"></a>net.fit(x[:<span class="dv">80</span>],y[:<span class="dv">80</span>],epochs<span class="op">=</span><span class="dv">5000</span>,verbose<span class="op">=</span><span class="dv">0</span>,batch_size<span class="op">=</span><span class="dv">80</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>&lt;keras.callbacks.History at 0x7f37fd5a9520&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="dfb98553-0e15-45b8-8e38-141283ea0cb2" data-execution_count="91">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1"></a>plt.plot(x,y)</span>
<span id="cb83-2"><a href="#cb83-2"></a>plt.plot(x[:<span class="dv">80</span>],net(x[:<span class="dv">80</span>]),<span class="st">'--'</span>)</span>
<span id="cb83-3"><a href="#cb83-3"></a>plt.plot(x[<span class="dv">80</span>:],net(x[<span class="dv">80</span>:]),<span class="st">'--'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/cell-50-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>오버핏이 확실히 줄어들었다. (완전히 없어진 것은 아니지만)</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(80\%\)</span> 노드를 빼고 학습하면 특징을 잘 학습하지 못하는거 아니냐? 라고 생각할 수 있지만 그렇게 중요한 특징이면 노드들을 랜덤으로 빼도 결국 학습을 해낼 것이라는 믿음이 있는 것이다. 증명이 있는건 아니지만 그렇게 믿음. 그러한 직관이 있다.</p>
</div>
</div>
<p><code>-</code> 드랍아웃에 대한 summary - 직관: 특정노드를 랜덤으로 off시키면 학습이 방해되어 오히려 과적합이 방지되는 효과가 있다 (그렇지만 진짜 중요한 특징이라면 랜덤으로 off 되더라도 어느정도는 학습될 듯) - note: 드랍아웃을 쓰면 오버핏이 줄어드는건 맞지만 완전히 없어지는건 아니다. - note: 오버핏을 줄이는 유일한 방법이 드랍아웃만 있는것도 아니며, 드랍아웃이 오버핏을 줄이는 가장 효과적인 방법도 아니다 (최근에는 dropout보다 batch nomalization을 사용하는 추세임)</p>
</section>
<section id="train-val-test" class="level3">
<h3 class="anchored" data-anchor-id="train-val-test">train / val / test</h3>
<p>만약 train으로 에폭 5000정도로 열심히 학습했다고 가정해보자. 그런데 테스트를 해봤더니 오버피팅이 심한 엉뚱한 모형이 나왔다면 너무 아깝다. (비효율적)</p>
<p>train, validation을 비교해보고, validation loss가 줄어들지 않고 오히려 overfitting이 되면서 커진다면 학습의 에폭을 줄여봐야겠다 내지는 노드를 줄여봐야 겠다 이런식으로 조정을 할 수 있다.</p>
<p><code>-</code> data</p>
<p>Fashion MNIST 데이터셋은 위 그림과 같이 운동화, 셔츠, 샌들과 같은 작은 이미지들의 모음이며, 기본 MNIST 데이터셋과 같이 열 가지로 분류될 수 있는 28×28 픽셀의 이미지 70,000개로 이루어져 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/dfe935e7-8b6e-404b-8ef1-672b8c5b7ee2-1-f992e926-c7c3-4f46-b89c-74662e926813.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Fashion MNIST 이미지 데이터셋.</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> tf.keras.datasets.fashion_mnist.load_data()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1"></a>X<span class="op">=</span> x_train.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>)<span class="op">/</span><span class="dv">255</span> <span class="co">## 입력이 0~255 -&gt; 0~1로 표준화 시키는 효과 + float으로 자료형이 바뀜</span></span>
<span id="cb85-2"><a href="#cb85-2"></a>y <span class="op">=</span> tf.keras.utils.to_categorical(y_train)</span>
<span id="cb85-3"><a href="#cb85-3"></a>XX <span class="op">=</span> x_test.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>)<span class="op">/</span><span class="dv">255</span></span>
<span id="cb85-4"><a href="#cb85-4"></a>yy <span class="op">=</span> tf.keras.utils.to_categorical(y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1"></a>X.shape, y.shape, XX.shape, yy.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb88-2"><a href="#cb88-2"></a>net.add(tf.keras.layers.Flatten()) <span class="co"># DNN 쓸거니까 flatten()!</span></span>
<span id="cb88-3"><a href="#cb88-3"></a>net.add(tf.keras.layers.Dense(<span class="dv">50</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb88-4"><a href="#cb88-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">10</span>,activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb88-5"><a href="#cb88-5"></a>net.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,loss<span class="op">=</span>tf.losses.categorical_crossentropy,metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="41119734-bdd9-4312-e5ed-128f15231636" data-scrolled="true" data-tags="[]" data-execution_count="99">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1"></a><span class="co">#collapse_output</span></span>
<span id="cb89-2"><a href="#cb89-2"></a>cb1 <span class="op">=</span> tf.keras.callbacks.TensorBoard()</span>
<span id="cb89-3"><a href="#cb89-3"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb1,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.7695 - val_loss: 0.4931 - val_accuracy: 0.8338
Epoch 2/200
240/240 [==============================] - 0s 818us/step - loss: 0.4582 - accuracy: 0.8434 - val_loss: 0.4590 - val_accuracy: 0.8414
Epoch 3/200
240/240 [==============================] - 0s 829us/step - loss: 0.4142 - accuracy: 0.8560 - val_loss: 0.4216 - val_accuracy: 0.8543
Epoch 4/200
240/240 [==============================] - 0s 824us/step - loss: 0.3920 - accuracy: 0.8625 - val_loss: 0.3953 - val_accuracy: 0.8624
Epoch 5/200
240/240 [==============================] - 0s 822us/step - loss: 0.3718 - accuracy: 0.8690 - val_loss: 0.3842 - val_accuracy: 0.8654
Epoch 6/200
240/240 [==============================] - 0s 827us/step - loss: 0.3567 - accuracy: 0.8750 - val_loss: 0.3825 - val_accuracy: 0.8662
Epoch 7/200
240/240 [==============================] - 0s 823us/step - loss: 0.3477 - accuracy: 0.8770 - val_loss: 0.3805 - val_accuracy: 0.8684
Epoch 8/200
240/240 [==============================] - 0s 837us/step - loss: 0.3377 - accuracy: 0.8789 - val_loss: 0.3564 - val_accuracy: 0.8741
Epoch 9/200
240/240 [==============================] - 0s 828us/step - loss: 0.3288 - accuracy: 0.8830 - val_loss: 0.3481 - val_accuracy: 0.8758
Epoch 10/200
240/240 [==============================] - 0s 826us/step - loss: 0.3204 - accuracy: 0.8852 - val_loss: 0.3541 - val_accuracy: 0.8771
Epoch 11/200
240/240 [==============================] - 0s 832us/step - loss: 0.3136 - accuracy: 0.8880 - val_loss: 0.3541 - val_accuracy: 0.8749
Epoch 12/200
240/240 [==============================] - 0s 827us/step - loss: 0.3071 - accuracy: 0.8887 - val_loss: 0.3508 - val_accuracy: 0.8748
Epoch 13/200
240/240 [==============================] - 0s 827us/step - loss: 0.3020 - accuracy: 0.8914 - val_loss: 0.3450 - val_accuracy: 0.8796
Epoch 14/200
240/240 [==============================] - 0s 826us/step - loss: 0.2968 - accuracy: 0.8934 - val_loss: 0.3507 - val_accuracy: 0.8752
Epoch 15/200
240/240 [==============================] - 0s 824us/step - loss: 0.2929 - accuracy: 0.8946 - val_loss: 0.3494 - val_accuracy: 0.8772
Epoch 16/200
240/240 [==============================] - 0s 823us/step - loss: 0.2909 - accuracy: 0.8948 - val_loss: 0.3875 - val_accuracy: 0.8594
Epoch 17/200
240/240 [==============================] - 0s 819us/step - loss: 0.2853 - accuracy: 0.8969 - val_loss: 0.3411 - val_accuracy: 0.8792
Epoch 18/200
240/240 [==============================] - 0s 822us/step - loss: 0.2796 - accuracy: 0.8979 - val_loss: 0.3503 - val_accuracy: 0.8773
Epoch 19/200
240/240 [==============================] - 0s 818us/step - loss: 0.2745 - accuracy: 0.9007 - val_loss: 0.3381 - val_accuracy: 0.8800
Epoch 20/200
240/240 [==============================] - 0s 820us/step - loss: 0.2709 - accuracy: 0.9023 - val_loss: 0.3402 - val_accuracy: 0.8807
Epoch 21/200
240/240 [==============================] - 0s 821us/step - loss: 0.2690 - accuracy: 0.9026 - val_loss: 0.3368 - val_accuracy: 0.8805
Epoch 22/200
240/240 [==============================] - 0s 835us/step - loss: 0.2635 - accuracy: 0.9047 - val_loss: 0.3346 - val_accuracy: 0.8816
Epoch 23/200
240/240 [==============================] - 0s 827us/step - loss: 0.2608 - accuracy: 0.9053 - val_loss: 0.3386 - val_accuracy: 0.8812
Epoch 24/200
240/240 [==============================] - 0s 815us/step - loss: 0.2585 - accuracy: 0.9072 - val_loss: 0.3383 - val_accuracy: 0.8808
Epoch 25/200
240/240 [==============================] - 0s 816us/step - loss: 0.2525 - accuracy: 0.9075 - val_loss: 0.3341 - val_accuracy: 0.8809
Epoch 26/200
240/240 [==============================] - 0s 822us/step - loss: 0.2519 - accuracy: 0.9095 - val_loss: 0.3393 - val_accuracy: 0.8810
Epoch 27/200
240/240 [==============================] - 0s 815us/step - loss: 0.2499 - accuracy: 0.9101 - val_loss: 0.3312 - val_accuracy: 0.8859
Epoch 28/200
240/240 [==============================] - 0s 832us/step - loss: 0.2437 - accuracy: 0.9118 - val_loss: 0.3343 - val_accuracy: 0.8844
Epoch 29/200
240/240 [==============================] - 0s 842us/step - loss: 0.2446 - accuracy: 0.9108 - val_loss: 0.3575 - val_accuracy: 0.8759
Epoch 30/200
240/240 [==============================] - 0s 821us/step - loss: 0.2402 - accuracy: 0.9124 - val_loss: 0.3381 - val_accuracy: 0.8802
Epoch 31/200
240/240 [==============================] - 0s 824us/step - loss: 0.2363 - accuracy: 0.9141 - val_loss: 0.3459 - val_accuracy: 0.8787
Epoch 32/200
240/240 [==============================] - 0s 820us/step - loss: 0.2365 - accuracy: 0.9144 - val_loss: 0.3396 - val_accuracy: 0.8804
Epoch 33/200
240/240 [==============================] - 0s 827us/step - loss: 0.2328 - accuracy: 0.9159 - val_loss: 0.3367 - val_accuracy: 0.8837
Epoch 34/200
240/240 [==============================] - 0s 830us/step - loss: 0.2310 - accuracy: 0.9161 - val_loss: 0.3516 - val_accuracy: 0.8808
Epoch 35/200
240/240 [==============================] - 0s 820us/step - loss: 0.2293 - accuracy: 0.9173 - val_loss: 0.3541 - val_accuracy: 0.8766
Epoch 36/200
240/240 [==============================] - 0s 826us/step - loss: 0.2268 - accuracy: 0.9183 - val_loss: 0.3503 - val_accuracy: 0.8802
Epoch 37/200
240/240 [==============================] - 0s 820us/step - loss: 0.2262 - accuracy: 0.9179 - val_loss: 0.3543 - val_accuracy: 0.8797
Epoch 38/200
240/240 [==============================] - 0s 827us/step - loss: 0.2266 - accuracy: 0.9175 - val_loss: 0.3432 - val_accuracy: 0.8825
Epoch 39/200
240/240 [==============================] - 0s 817us/step - loss: 0.2190 - accuracy: 0.9208 - val_loss: 0.3364 - val_accuracy: 0.8847
Epoch 40/200
240/240 [==============================] - 0s 809us/step - loss: 0.2156 - accuracy: 0.9232 - val_loss: 0.3400 - val_accuracy: 0.8838
Epoch 41/200
240/240 [==============================] - 0s 805us/step - loss: 0.2138 - accuracy: 0.9231 - val_loss: 0.3530 - val_accuracy: 0.8776
Epoch 42/200
240/240 [==============================] - 0s 816us/step - loss: 0.2154 - accuracy: 0.9224 - val_loss: 0.3461 - val_accuracy: 0.8833
Epoch 43/200
240/240 [==============================] - 0s 836us/step - loss: 0.2105 - accuracy: 0.9242 - val_loss: 0.3517 - val_accuracy: 0.8806
Epoch 44/200
240/240 [==============================] - 0s 822us/step - loss: 0.2104 - accuracy: 0.9237 - val_loss: 0.3439 - val_accuracy: 0.8852
Epoch 45/200
240/240 [==============================] - 0s 832us/step - loss: 0.2064 - accuracy: 0.9250 - val_loss: 0.3457 - val_accuracy: 0.8840
Epoch 46/200
240/240 [==============================] - 0s 817us/step - loss: 0.2053 - accuracy: 0.9265 - val_loss: 0.3698 - val_accuracy: 0.8756
Epoch 47/200
240/240 [==============================] - 0s 824us/step - loss: 0.2085 - accuracy: 0.9249 - val_loss: 0.3476 - val_accuracy: 0.8824
Epoch 48/200
240/240 [==============================] - 0s 837us/step - loss: 0.1996 - accuracy: 0.9290 - val_loss: 0.3581 - val_accuracy: 0.8812
Epoch 49/200
240/240 [==============================] - 0s 823us/step - loss: 0.2002 - accuracy: 0.9274 - val_loss: 0.3568 - val_accuracy: 0.8802
Epoch 50/200
240/240 [==============================] - 0s 823us/step - loss: 0.1991 - accuracy: 0.9289 - val_loss: 0.3607 - val_accuracy: 0.8798
Epoch 51/200
240/240 [==============================] - 0s 823us/step - loss: 0.1987 - accuracy: 0.9278 - val_loss: 0.3527 - val_accuracy: 0.8832
Epoch 52/200
240/240 [==============================] - 0s 828us/step - loss: 0.1962 - accuracy: 0.9295 - val_loss: 0.3781 - val_accuracy: 0.8738
Epoch 53/200
240/240 [==============================] - 0s 832us/step - loss: 0.1952 - accuracy: 0.9300 - val_loss: 0.3603 - val_accuracy: 0.8807
Epoch 54/200
240/240 [==============================] - 0s 824us/step - loss: 0.1956 - accuracy: 0.9295 - val_loss: 0.3941 - val_accuracy: 0.8712
Epoch 55/200
240/240 [==============================] - 0s 837us/step - loss: 0.1929 - accuracy: 0.9301 - val_loss: 0.3656 - val_accuracy: 0.8806
Epoch 56/200
240/240 [==============================] - 0s 842us/step - loss: 0.1887 - accuracy: 0.9321 - val_loss: 0.3676 - val_accuracy: 0.8788
Epoch 57/200
240/240 [==============================] - 0s 827us/step - loss: 0.1892 - accuracy: 0.9321 - val_loss: 0.3638 - val_accuracy: 0.8806
Epoch 58/200
240/240 [==============================] - 0s 839us/step - loss: 0.1866 - accuracy: 0.9329 - val_loss: 0.3626 - val_accuracy: 0.8808
Epoch 59/200
240/240 [==============================] - 0s 829us/step - loss: 0.1839 - accuracy: 0.9336 - val_loss: 0.3672 - val_accuracy: 0.8797
Epoch 60/200
240/240 [==============================] - 0s 842us/step - loss: 0.1823 - accuracy: 0.9347 - val_loss: 0.3803 - val_accuracy: 0.8773
Epoch 61/200
240/240 [==============================] - 0s 823us/step - loss: 0.1822 - accuracy: 0.9350 - val_loss: 0.3680 - val_accuracy: 0.8801
Epoch 62/200
240/240 [==============================] - 0s 822us/step - loss: 0.1808 - accuracy: 0.9351 - val_loss: 0.3691 - val_accuracy: 0.8815
Epoch 63/200
240/240 [==============================] - 0s 835us/step - loss: 0.1815 - accuracy: 0.9343 - val_loss: 0.3730 - val_accuracy: 0.8792
Epoch 64/200
240/240 [==============================] - 0s 823us/step - loss: 0.1802 - accuracy: 0.9352 - val_loss: 0.3845 - val_accuracy: 0.8775
Epoch 65/200
240/240 [==============================] - 0s 819us/step - loss: 0.1752 - accuracy: 0.9372 - val_loss: 0.3918 - val_accuracy: 0.8770
Epoch 66/200
240/240 [==============================] - 0s 830us/step - loss: 0.1748 - accuracy: 0.9375 - val_loss: 0.3770 - val_accuracy: 0.8818
Epoch 67/200
240/240 [==============================] - 0s 835us/step - loss: 0.1742 - accuracy: 0.9369 - val_loss: 0.3845 - val_accuracy: 0.8783
Epoch 68/200
240/240 [==============================] - 0s 820us/step - loss: 0.1732 - accuracy: 0.9386 - val_loss: 0.3857 - val_accuracy: 0.8798
Epoch 69/200
240/240 [==============================] - 0s 832us/step - loss: 0.1738 - accuracy: 0.9373 - val_loss: 0.3766 - val_accuracy: 0.8813
Epoch 70/200
240/240 [==============================] - 0s 825us/step - loss: 0.1710 - accuracy: 0.9390 - val_loss: 0.3822 - val_accuracy: 0.8797
Epoch 71/200
240/240 [==============================] - 0s 830us/step - loss: 0.1690 - accuracy: 0.9393 - val_loss: 0.3843 - val_accuracy: 0.8784
Epoch 72/200
240/240 [==============================] - 0s 820us/step - loss: 0.1683 - accuracy: 0.9383 - val_loss: 0.3878 - val_accuracy: 0.8803
Epoch 73/200
240/240 [==============================] - 0s 835us/step - loss: 0.1644 - accuracy: 0.9414 - val_loss: 0.3926 - val_accuracy: 0.8792
Epoch 74/200
240/240 [==============================] - 0s 820us/step - loss: 0.1649 - accuracy: 0.9420 - val_loss: 0.3928 - val_accuracy: 0.8773
Epoch 75/200
240/240 [==============================] - 0s 830us/step - loss: 0.1657 - accuracy: 0.9408 - val_loss: 0.3850 - val_accuracy: 0.8816
Epoch 76/200
240/240 [==============================] - 0s 825us/step - loss: 0.1631 - accuracy: 0.9411 - val_loss: 0.3984 - val_accuracy: 0.8806
Epoch 77/200
240/240 [==============================] - 0s 829us/step - loss: 0.1638 - accuracy: 0.9415 - val_loss: 0.3905 - val_accuracy: 0.8804
Epoch 78/200
240/240 [==============================] - 0s 833us/step - loss: 0.1644 - accuracy: 0.9413 - val_loss: 0.4109 - val_accuracy: 0.8789
Epoch 79/200
240/240 [==============================] - 0s 836us/step - loss: 0.1616 - accuracy: 0.9420 - val_loss: 0.3997 - val_accuracy: 0.8764
Epoch 80/200
240/240 [==============================] - 0s 821us/step - loss: 0.1601 - accuracy: 0.9434 - val_loss: 0.4165 - val_accuracy: 0.8758
Epoch 81/200
240/240 [==============================] - 0s 817us/step - loss: 0.1573 - accuracy: 0.9438 - val_loss: 0.4006 - val_accuracy: 0.8807
Epoch 82/200
240/240 [==============================] - 0s 815us/step - loss: 0.1552 - accuracy: 0.9444 - val_loss: 0.4066 - val_accuracy: 0.8792
Epoch 83/200
240/240 [==============================] - 0s 823us/step - loss: 0.1545 - accuracy: 0.9437 - val_loss: 0.4042 - val_accuracy: 0.8792
Epoch 84/200
240/240 [==============================] - 0s 826us/step - loss: 0.1538 - accuracy: 0.9444 - val_loss: 0.4126 - val_accuracy: 0.8753
Epoch 85/200
240/240 [==============================] - 0s 826us/step - loss: 0.1563 - accuracy: 0.9445 - val_loss: 0.4049 - val_accuracy: 0.8799
Epoch 86/200
240/240 [==============================] - 0s 811us/step - loss: 0.1579 - accuracy: 0.9440 - val_loss: 0.4054 - val_accuracy: 0.8770
Epoch 87/200
240/240 [==============================] - 0s 810us/step - loss: 0.1511 - accuracy: 0.9464 - val_loss: 0.4145 - val_accuracy: 0.8789
Epoch 88/200
240/240 [==============================] - 0s 839us/step - loss: 0.1512 - accuracy: 0.9465 - val_loss: 0.4105 - val_accuracy: 0.8780
Epoch 89/200
240/240 [==============================] - 0s 834us/step - loss: 0.1509 - accuracy: 0.9458 - val_loss: 0.4125 - val_accuracy: 0.8784
Epoch 90/200
240/240 [==============================] - 0s 820us/step - loss: 0.1515 - accuracy: 0.9461 - val_loss: 0.4185 - val_accuracy: 0.8784
Epoch 91/200
240/240 [==============================] - 0s 813us/step - loss: 0.1464 - accuracy: 0.9485 - val_loss: 0.4116 - val_accuracy: 0.8797
Epoch 92/200
240/240 [==============================] - 0s 830us/step - loss: 0.1492 - accuracy: 0.9474 - val_loss: 0.4180 - val_accuracy: 0.8784
Epoch 93/200
240/240 [==============================] - 0s 826us/step - loss: 0.1501 - accuracy: 0.9460 - val_loss: 0.4196 - val_accuracy: 0.8797
Epoch 94/200
240/240 [==============================] - 0s 823us/step - loss: 0.1460 - accuracy: 0.9485 - val_loss: 0.4242 - val_accuracy: 0.8789
Epoch 95/200
240/240 [==============================] - 0s 825us/step - loss: 0.1465 - accuracy: 0.9473 - val_loss: 0.4143 - val_accuracy: 0.8794
Epoch 96/200
240/240 [==============================] - 0s 823us/step - loss: 0.1436 - accuracy: 0.9490 - val_loss: 0.4276 - val_accuracy: 0.8789
Epoch 97/200
240/240 [==============================] - 0s 830us/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.4361 - val_accuracy: 0.8788
Epoch 98/200
240/240 [==============================] - 0s 843us/step - loss: 0.1404 - accuracy: 0.9507 - val_loss: 0.4261 - val_accuracy: 0.8783
Epoch 99/200
240/240 [==============================] - 0s 816us/step - loss: 0.1391 - accuracy: 0.9507 - val_loss: 0.4392 - val_accuracy: 0.8788
Epoch 100/200
240/240 [==============================] - 0s 822us/step - loss: 0.1437 - accuracy: 0.9487 - val_loss: 0.4266 - val_accuracy: 0.8776
Epoch 101/200
240/240 [==============================] - 0s 820us/step - loss: 0.1378 - accuracy: 0.9506 - val_loss: 0.4445 - val_accuracy: 0.8767
Epoch 102/200
240/240 [==============================] - 0s 813us/step - loss: 0.1385 - accuracy: 0.9506 - val_loss: 0.4478 - val_accuracy: 0.8733
Epoch 103/200
240/240 [==============================] - 0s 824us/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: 0.4424 - val_accuracy: 0.8767
Epoch 104/200
240/240 [==============================] - 0s 816us/step - loss: 0.1404 - accuracy: 0.9495 - val_loss: 0.4454 - val_accuracy: 0.8783
Epoch 105/200
240/240 [==============================] - 0s 827us/step - loss: 0.1396 - accuracy: 0.9499 - val_loss: 0.4475 - val_accuracy: 0.8739
Epoch 106/200
240/240 [==============================] - 0s 820us/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 0.4597 - val_accuracy: 0.8762
Epoch 107/200
240/240 [==============================] - 0s 813us/step - loss: 0.1363 - accuracy: 0.9512 - val_loss: 0.4534 - val_accuracy: 0.8743
Epoch 108/200
240/240 [==============================] - 0s 844us/step - loss: 0.1341 - accuracy: 0.9525 - val_loss: 0.4524 - val_accuracy: 0.8772
Epoch 109/200
240/240 [==============================] - 0s 819us/step - loss: 0.1314 - accuracy: 0.9535 - val_loss: 0.4499 - val_accuracy: 0.8781
Epoch 110/200
240/240 [==============================] - 0s 821us/step - loss: 0.1329 - accuracy: 0.9530 - val_loss: 0.4555 - val_accuracy: 0.8772
Epoch 111/200
240/240 [==============================] - 0s 823us/step - loss: 0.1320 - accuracy: 0.9532 - val_loss: 0.4566 - val_accuracy: 0.8757
Epoch 112/200
240/240 [==============================] - 0s 831us/step - loss: 0.1324 - accuracy: 0.9532 - val_loss: 0.4464 - val_accuracy: 0.8786
Epoch 113/200
240/240 [==============================] - 0s 831us/step - loss: 0.1300 - accuracy: 0.9534 - val_loss: 0.4571 - val_accuracy: 0.8765
Epoch 114/200
240/240 [==============================] - 0s 843us/step - loss: 0.1294 - accuracy: 0.9543 - val_loss: 0.4609 - val_accuracy: 0.8759
Epoch 115/200
240/240 [==============================] - 0s 829us/step - loss: 0.1294 - accuracy: 0.9546 - val_loss: 0.4627 - val_accuracy: 0.8769
Epoch 116/200
240/240 [==============================] - 0s 825us/step - loss: 0.1268 - accuracy: 0.9548 - val_loss: 0.4595 - val_accuracy: 0.8785
Epoch 117/200
240/240 [==============================] - 0s 813us/step - loss: 0.1279 - accuracy: 0.9546 - val_loss: 0.4736 - val_accuracy: 0.8745
Epoch 118/200
240/240 [==============================] - 0s 831us/step - loss: 0.1303 - accuracy: 0.9532 - val_loss: 0.4683 - val_accuracy: 0.8770
Epoch 119/200
240/240 [==============================] - 0s 831us/step - loss: 0.1257 - accuracy: 0.9550 - val_loss: 0.4896 - val_accuracy: 0.8696
Epoch 120/200
240/240 [==============================] - 0s 820us/step - loss: 0.1275 - accuracy: 0.9539 - val_loss: 0.4760 - val_accuracy: 0.8758
Epoch 121/200
240/240 [==============================] - 0s 831us/step - loss: 0.1242 - accuracy: 0.9558 - val_loss: 0.4716 - val_accuracy: 0.8758
Epoch 122/200
240/240 [==============================] - 0s 818us/step - loss: 0.1227 - accuracy: 0.9570 - val_loss: 0.4944 - val_accuracy: 0.8706
Epoch 123/200
240/240 [==============================] - 0s 816us/step - loss: 0.1225 - accuracy: 0.9565 - val_loss: 0.4770 - val_accuracy: 0.8755
Epoch 124/200
240/240 [==============================] - 0s 809us/step - loss: 0.1215 - accuracy: 0.9564 - val_loss: 0.4969 - val_accuracy: 0.8732
Epoch 125/200
240/240 [==============================] - 0s 815us/step - loss: 0.1246 - accuracy: 0.9554 - val_loss: 0.4846 - val_accuracy: 0.8766
Epoch 126/200
240/240 [==============================] - 0s 821us/step - loss: 0.1210 - accuracy: 0.9578 - val_loss: 0.5119 - val_accuracy: 0.8697
Epoch 127/200
240/240 [==============================] - 0s 820us/step - loss: 0.1213 - accuracy: 0.9571 - val_loss: 0.4964 - val_accuracy: 0.8737
Epoch 128/200
240/240 [==============================] - 0s 838us/step - loss: 0.1176 - accuracy: 0.9586 - val_loss: 0.4787 - val_accuracy: 0.8767
Epoch 129/200
240/240 [==============================] - 0s 824us/step - loss: 0.1200 - accuracy: 0.9581 - val_loss: 0.4976 - val_accuracy: 0.8733
Epoch 130/200
240/240 [==============================] - 0s 817us/step - loss: 0.1177 - accuracy: 0.9587 - val_loss: 0.4856 - val_accuracy: 0.8759
Epoch 131/200
240/240 [==============================] - 0s 837us/step - loss: 0.1165 - accuracy: 0.9590 - val_loss: 0.4881 - val_accuracy: 0.8742
Epoch 132/200
240/240 [==============================] - 0s 826us/step - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.4968 - val_accuracy: 0.8737
Epoch 133/200
240/240 [==============================] - 0s 826us/step - loss: 0.1182 - accuracy: 0.9581 - val_loss: 0.5100 - val_accuracy: 0.8739
Epoch 134/200
240/240 [==============================] - 0s 822us/step - loss: 0.1161 - accuracy: 0.9595 - val_loss: 0.5058 - val_accuracy: 0.8727
Epoch 135/200
240/240 [==============================] - 0s 828us/step - loss: 0.1198 - accuracy: 0.9578 - val_loss: 0.5181 - val_accuracy: 0.8730
Epoch 136/200
240/240 [==============================] - 0s 818us/step - loss: 0.1157 - accuracy: 0.9587 - val_loss: 0.5176 - val_accuracy: 0.8744
Epoch 137/200
240/240 [==============================] - 0s 826us/step - loss: 0.1145 - accuracy: 0.9592 - val_loss: 0.5112 - val_accuracy: 0.8773
Epoch 138/200
240/240 [==============================] - 0s 830us/step - loss: 0.1121 - accuracy: 0.9614 - val_loss: 0.5236 - val_accuracy: 0.8728
Epoch 139/200
240/240 [==============================] - 0s 812us/step - loss: 0.1120 - accuracy: 0.9601 - val_loss: 0.5358 - val_accuracy: 0.8698
Epoch 140/200
240/240 [==============================] - 0s 829us/step - loss: 0.1116 - accuracy: 0.9603 - val_loss: 0.5276 - val_accuracy: 0.8717
Epoch 141/200
240/240 [==============================] - 0s 827us/step - loss: 0.1111 - accuracy: 0.9612 - val_loss: 0.5178 - val_accuracy: 0.8721
Epoch 142/200
240/240 [==============================] - 0s 812us/step - loss: 0.1124 - accuracy: 0.9604 - val_loss: 0.5285 - val_accuracy: 0.8738
Epoch 143/200
240/240 [==============================] - 0s 825us/step - loss: 0.1102 - accuracy: 0.9607 - val_loss: 0.5256 - val_accuracy: 0.8734
Epoch 144/200
240/240 [==============================] - 0s 820us/step - loss: 0.1095 - accuracy: 0.9608 - val_loss: 0.5328 - val_accuracy: 0.8727
Epoch 145/200
240/240 [==============================] - 0s 828us/step - loss: 0.1115 - accuracy: 0.9615 - val_loss: 0.5214 - val_accuracy: 0.8739
Epoch 146/200
240/240 [==============================] - 0s 835us/step - loss: 0.1134 - accuracy: 0.9591 - val_loss: 0.5244 - val_accuracy: 0.8730
Epoch 147/200
240/240 [==============================] - 0s 820us/step - loss: 0.1082 - accuracy: 0.9619 - val_loss: 0.5270 - val_accuracy: 0.8724
Epoch 148/200
240/240 [==============================] - 0s 839us/step - loss: 0.1061 - accuracy: 0.9629 - val_loss: 0.5361 - val_accuracy: 0.8723
Epoch 149/200
240/240 [==============================] - 0s 820us/step - loss: 0.1076 - accuracy: 0.9621 - val_loss: 0.5285 - val_accuracy: 0.8749
Epoch 150/200
240/240 [==============================] - 0s 813us/step - loss: 0.1068 - accuracy: 0.9626 - val_loss: 0.5590 - val_accuracy: 0.8675
Epoch 151/200
240/240 [==============================] - 0s 812us/step - loss: 0.1065 - accuracy: 0.9623 - val_loss: 0.5348 - val_accuracy: 0.8748
Epoch 152/200
240/240 [==============================] - 0s 823us/step - loss: 0.1056 - accuracy: 0.9636 - val_loss: 0.5363 - val_accuracy: 0.8725
Epoch 153/200
240/240 [==============================] - 0s 823us/step - loss: 0.1077 - accuracy: 0.9621 - val_loss: 0.5535 - val_accuracy: 0.8683
Epoch 154/200
240/240 [==============================] - 0s 814us/step - loss: 0.1030 - accuracy: 0.9642 - val_loss: 0.5398 - val_accuracy: 0.8726
Epoch 155/200
240/240 [==============================] - 0s 836us/step - loss: 0.1076 - accuracy: 0.9618 - val_loss: 0.5322 - val_accuracy: 0.8757
Epoch 156/200
240/240 [==============================] - 0s 826us/step - loss: 0.1065 - accuracy: 0.9630 - val_loss: 0.5485 - val_accuracy: 0.8730
Epoch 157/200
240/240 [==============================] - 0s 814us/step - loss: 0.1054 - accuracy: 0.9634 - val_loss: 0.5554 - val_accuracy: 0.8749
Epoch 158/200
240/240 [==============================] - 0s 826us/step - loss: 0.1015 - accuracy: 0.9645 - val_loss: 0.5482 - val_accuracy: 0.8736
Epoch 159/200
240/240 [==============================] - 0s 814us/step - loss: 0.1021 - accuracy: 0.9641 - val_loss: 0.5769 - val_accuracy: 0.8652
Epoch 160/200
240/240 [==============================] - 0s 824us/step - loss: 0.1002 - accuracy: 0.9651 - val_loss: 0.5563 - val_accuracy: 0.8738
Epoch 161/200
240/240 [==============================] - 0s 827us/step - loss: 0.1059 - accuracy: 0.9627 - val_loss: 0.5700 - val_accuracy: 0.8712
Epoch 162/200
240/240 [==============================] - 0s 823us/step - loss: 0.1009 - accuracy: 0.9647 - val_loss: 0.5543 - val_accuracy: 0.8725
Epoch 163/200
240/240 [==============================] - 0s 835us/step - loss: 0.0978 - accuracy: 0.9666 - val_loss: 0.5470 - val_accuracy: 0.8733
Epoch 164/200
240/240 [==============================] - 0s 818us/step - loss: 0.1007 - accuracy: 0.9648 - val_loss: 0.5643 - val_accuracy: 0.8731
Epoch 165/200
240/240 [==============================] - 0s 832us/step - loss: 0.1005 - accuracy: 0.9653 - val_loss: 0.5695 - val_accuracy: 0.8735
Epoch 166/200
240/240 [==============================] - 0s 826us/step - loss: 0.0998 - accuracy: 0.9650 - val_loss: 0.5811 - val_accuracy: 0.8703
Epoch 167/200
240/240 [==============================] - 0s 818us/step - loss: 0.0980 - accuracy: 0.9659 - val_loss: 0.5800 - val_accuracy: 0.8723
Epoch 168/200
240/240 [==============================] - 0s 851us/step - loss: 0.0967 - accuracy: 0.9665 - val_loss: 0.5753 - val_accuracy: 0.8741
Epoch 169/200
240/240 [==============================] - 0s 824us/step - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.5742 - val_accuracy: 0.8732
Epoch 170/200
240/240 [==============================] - 0s 815us/step - loss: 0.0957 - accuracy: 0.9674 - val_loss: 0.5791 - val_accuracy: 0.8729
Epoch 171/200
240/240 [==============================] - 0s 828us/step - loss: 0.0965 - accuracy: 0.9661 - val_loss: 0.5887 - val_accuracy: 0.8707
Epoch 172/200
240/240 [==============================] - 0s 831us/step - loss: 0.0956 - accuracy: 0.9674 - val_loss: 0.5799 - val_accuracy: 0.8736
Epoch 173/200
240/240 [==============================] - 0s 840us/step - loss: 0.0958 - accuracy: 0.9669 - val_loss: 0.5815 - val_accuracy: 0.8742
Epoch 174/200
240/240 [==============================] - 0s 825us/step - loss: 0.0953 - accuracy: 0.9668 - val_loss: 0.5971 - val_accuracy: 0.8684
Epoch 175/200
240/240 [==============================] - 0s 829us/step - loss: 0.0952 - accuracy: 0.9662 - val_loss: 0.6041 - val_accuracy: 0.8700
Epoch 176/200
240/240 [==============================] - 0s 827us/step - loss: 0.0900 - accuracy: 0.9691 - val_loss: 0.5917 - val_accuracy: 0.8719
Epoch 177/200
240/240 [==============================] - 0s 815us/step - loss: 0.0961 - accuracy: 0.9661 - val_loss: 0.5820 - val_accuracy: 0.8724
Epoch 178/200
240/240 [==============================] - 0s 823us/step - loss: 0.0928 - accuracy: 0.9685 - val_loss: 0.6020 - val_accuracy: 0.8708
Epoch 179/200
240/240 [==============================] - 0s 819us/step - loss: 0.0913 - accuracy: 0.9683 - val_loss: 0.6174 - val_accuracy: 0.8692
Epoch 180/200
240/240 [==============================] - 0s 824us/step - loss: 0.0953 - accuracy: 0.9662 - val_loss: 0.5866 - val_accuracy: 0.8705
Epoch 181/200
240/240 [==============================] - 0s 816us/step - loss: 0.0928 - accuracy: 0.9679 - val_loss: 0.6090 - val_accuracy: 0.8708
Epoch 182/200
240/240 [==============================] - 0s 825us/step - loss: 0.0935 - accuracy: 0.9673 - val_loss: 0.5961 - val_accuracy: 0.8719
Epoch 183/200
240/240 [==============================] - 0s 859us/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.6071 - val_accuracy: 0.8687
Epoch 184/200
240/240 [==============================] - 0s 818us/step - loss: 0.0890 - accuracy: 0.9694 - val_loss: 0.6067 - val_accuracy: 0.8707
Epoch 185/200
240/240 [==============================] - 0s 817us/step - loss: 0.0896 - accuracy: 0.9700 - val_loss: 0.6109 - val_accuracy: 0.8716
Epoch 186/200
240/240 [==============================] - 0s 815us/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 0.6126 - val_accuracy: 0.8727
Epoch 187/200
240/240 [==============================] - 0s 824us/step - loss: 0.0943 - accuracy: 0.9665 - val_loss: 0.6081 - val_accuracy: 0.8708
Epoch 188/200
240/240 [==============================] - 0s 843us/step - loss: 0.0858 - accuracy: 0.9699 - val_loss: 0.6124 - val_accuracy: 0.8736
Epoch 189/200
240/240 [==============================] - 0s 825us/step - loss: 0.0900 - accuracy: 0.9693 - val_loss: 0.6128 - val_accuracy: 0.8703
Epoch 190/200
240/240 [==============================] - 0s 833us/step - loss: 0.0860 - accuracy: 0.9699 - val_loss: 0.6175 - val_accuracy: 0.8726
Epoch 191/200
240/240 [==============================] - 0s 823us/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 0.6292 - val_accuracy: 0.8693
Epoch 192/200
240/240 [==============================] - 0s 831us/step - loss: 0.0866 - accuracy: 0.9709 - val_loss: 0.6300 - val_accuracy: 0.8700
Epoch 193/200
240/240 [==============================] - 0s 832us/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.6230 - val_accuracy: 0.8700
Epoch 194/200
240/240 [==============================] - 0s 819us/step - loss: 0.0894 - accuracy: 0.9686 - val_loss: 0.6218 - val_accuracy: 0.8737
Epoch 195/200
240/240 [==============================] - 0s 828us/step - loss: 0.0864 - accuracy: 0.9707 - val_loss: 0.6399 - val_accuracy: 0.8713
Epoch 196/200
240/240 [==============================] - 0s 815us/step - loss: 0.0855 - accuracy: 0.9704 - val_loss: 0.6343 - val_accuracy: 0.8691
Epoch 197/200
240/240 [==============================] - 0s 825us/step - loss: 0.0852 - accuracy: 0.9702 - val_loss: 0.6686 - val_accuracy: 0.8656
Epoch 198/200
240/240 [==============================] - 0s 824us/step - loss: 0.0852 - accuracy: 0.9712 - val_loss: 0.6403 - val_accuracy: 0.8706
Epoch 199/200
240/240 [==============================] - 0s 826us/step - loss: 0.0833 - accuracy: 0.9719 - val_loss: 0.6442 - val_accuracy: 0.8698
Epoch 200/200
240/240 [==============================] - 0s 814us/step - loss: 0.0849 - accuracy: 0.9702 - val_loss: 0.6350 - val_accuracy: 0.8728</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>&lt;keras.callbacks.History at 0x7f37e5e348b0&gt;</code></pre>
</div>
</div>
<ul>
<li>40에폭쯤에서 멈췄었어야 할 것 같은데?</li>
<li>그래서 나온 개념이 early stopping!</li>
</ul>
<p><code>-</code> 텐서보드 여는 방법1</p>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1"></a><span class="op">%</span>load_ext tensorboard</span>
<span id="cb92-2"><a href="#cb92-2"></a><span class="co"># 주피터노트북 (혹은 주피터랩)에서 텐서보드를 임베딩하여 넣을 수 있도록 도와주는 매직펑션</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1"></a><span class="co">#</span></span>
<span id="cb93-2"><a href="#cb93-2"></a><span class="op">!</span>rm <span class="op">-</span>rf logs <span class="co"># lags 파일 삭제</span></span>
<span id="cb93-3"><a href="#cb93-3"></a><span class="co"># !kill 313799</span></span>
<span id="cb93-4"><a href="#cb93-4"></a><span class="op">!</span>kill <span class="dv">507234</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1"></a><span class="co">#</span></span>
<span id="cb94-2"><a href="#cb94-2"></a><span class="co"># %tensorboard --logdir logs --host 0.0.0.0</span></span>
<span id="cb94-3"><a href="#cb94-3"></a><span class="co"># %tensorboard --logdir logs # &lt;-- 실습에서는 이렇게 하면됩니다.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/c1a71359-d2f1-46e0-8017-8ad81dfe1741-1-d59d818a-2e0f-46b2-9c25-31614e8657d1.png" class="img-fluid"></p>
<ul>
<li>train accuray는 점점 증가하는데 validation accuracy는 오히려 지지부진해 지다 점점 떨어진다. <span class="math inline">\(\to\)</span> 오버피팅의 징조</li>
<li>training loss는 계속 떨어지고 있지만 validation loss는 감소하다 어느 시점이 지나면 오히려 점점 증가한다. <span class="math inline">\(\to\)</span> 오버피팅의 징조</li>
</ul>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body" title="(참고사항) 파이썬 3.10의 경우 아래의 수정이 필요">
<p><code>?/python3.10/site-packages/tensorboard/_vendor/html5lib/_trie/_base.py</code> 을 열고</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1"></a><span class="im">from</span> collections <span class="im">import</span> Mapping <span class="co">### 수정전</span></span>
<span id="cb95-2"><a href="#cb95-2"></a><span class="im">from</span> collections.abc <span class="im">import</span> Mapping <span class="co">### 수정후</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>와 같이 수정한다.</p>
<ul>
<li>왜냐하면 파이썬 3.10부터 <code>from collections import Mapping</code> 가 동작하지 않고 <code>from collections.abc import Mapping</code> 가 동작하도록 문법이 바뀜</li>
</ul>
</div>
</div>
<p><code>-</code> 텐서보드를 실행하는 방법2</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1"></a><span class="co">#</span></span>
<span id="cb96-2"><a href="#cb96-2"></a><span class="co"># !tensorboard --logdir logs --host 0.0.0.0</span></span>
<span id="cb96-3"><a href="#cb96-3"></a><span class="co"># !tensorboard --logdir logs # &lt;-- 실습에서는 이렇게 하면됩니다.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="조기종료" class="level3">
<h3 class="anchored" data-anchor-id="조기종료">조기종료</h3>
<p><code>-</code> 텐서보드를 살펴보니 특정에폭 이후에는 오히려 과적합이 진행되는 듯 하다 (학습할수록 손해인듯 하다) <span class="math inline">\(\to\)</span> 그 특정에폭까지만 학습해보자</p>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb97-2"><a href="#cb97-2"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb97-3"><a href="#cb97-3"></a>net.add(tf.keras.layers.Flatten())</span>
<span id="cb97-4"><a href="#cb97-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">5000</span>,activation<span class="op">=</span><span class="st">'relu'</span>)) <span class="co">## 과적합좀 시키려고</span></span>
<span id="cb97-5"><a href="#cb97-5"></a>net.add(tf.keras.layers.Dense(<span class="dv">5000</span>,activation<span class="op">=</span><span class="st">'relu'</span>)) <span class="co">## 레이어를 2장만듬 + 레이어하나당 노드수도 증가</span></span>
<span id="cb97-6"><a href="#cb97-6"></a>net.add(tf.keras.layers.Dense(<span class="dv">10</span>,activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb97-7"><a href="#cb97-7"></a>net.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,loss<span class="op">=</span>tf.losses.categorical_crossentropy,metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="2e1065a4-342b-4b72-e5b7-6f306a178878" data-execution_count="108">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1"></a><span class="co">#</span></span>
<span id="cb98-2"><a href="#cb98-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb98-3"><a href="#cb98-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">1</span>) <span class="co"># val-loss가 1회증가하면 멈추어라</span></span>
<span id="cb98-4"><a href="#cb98-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 40s 164ms/step - loss: 0.5284 - accuracy: 0.8175 - val_loss: 0.4271 - val_accuracy: 0.8418
Epoch 2/200
240/240 [==============================] - 40s 165ms/step - loss: 0.3579 - accuracy: 0.8672 - val_loss: 0.3539 - val_accuracy: 0.8719
Epoch 3/200
240/240 [==============================] - 40s 165ms/step - loss: 0.3207 - accuracy: 0.8802 - val_loss: 0.3578 - val_accuracy: 0.8716</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>&lt;keras.callbacks.History at 0x7f37e5586550&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="d12cc789-3fae-4f75-c67f-ac57ebe47d96" data-execution_count="109">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1"></a><span class="co">#</span></span>
<span id="cb101-2"><a href="#cb101-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb101-3"><a href="#cb101-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">1</span>) <span class="co"># val-loss가 1회증가하면 멈추어라</span></span>
<span id="cb101-4"><a href="#cb101-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 40s 165ms/step - loss: 0.2977 - accuracy: 0.8891 - val_loss: 0.3353 - val_accuracy: 0.8752
Epoch 2/200
240/240 [==============================] - 40s 165ms/step - loss: 0.2783 - accuracy: 0.8941 - val_loss: 0.3460 - val_accuracy: 0.8802</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>&lt;keras.callbacks.History at 0x7f37e4c0ca90&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="9e9dd8c5-c4d6-44ce-d05c-b110f1126296" data-execution_count="110">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1"></a><span class="co">#</span></span>
<span id="cb104-2"><a href="#cb104-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb104-3"><a href="#cb104-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">1</span>) <span class="co"># val-loss가 1회증가하면 멈추어라</span></span>
<span id="cb104-4"><a href="#cb104-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2627 - accuracy: 0.9010 - val_loss: 0.3251 - val_accuracy: 0.8799
Epoch 2/200
240/240 [==============================] - 39s 165ms/step - loss: 0.2463 - accuracy: 0.9068 - val_loss: 0.3460 - val_accuracy: 0.8823</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>&lt;keras.callbacks.History at 0x7f37e44f8790&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="5d86ea07-a2df-43f7-8d8d-ffbfd14b3323" data-execution_count="111">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1"></a><span class="co">#</span></span>
<span id="cb107-2"><a href="#cb107-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb107-3"><a href="#cb107-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">1</span>) <span class="co"># val-loss가 1회증가하면 멈추어라</span></span>
<span id="cb107-4"><a href="#cb107-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2339 - accuracy: 0.9104 - val_loss: 0.3190 - val_accuracy: 0.8873
Epoch 2/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2207 - accuracy: 0.9157 - val_loss: 0.3449 - val_accuracy: 0.8837</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="111">
<pre><code>&lt;keras.callbacks.History at 0x7f37e55660a0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="ba6d3e79-f3ef-4f8d-9cdc-4ffd4c212b14" data-execution_count="112">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1"></a><span class="co">#</span></span>
<span id="cb110-2"><a href="#cb110-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb110-3"><a href="#cb110-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">1</span>) <span class="co"># val-loss가 1회증가하면 멈추어라</span></span>
<span id="cb110-4"><a href="#cb110-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2111 - accuracy: 0.9188 - val_loss: 0.3703 - val_accuracy: 0.8785
Epoch 2/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2030 - accuracy: 0.9225 - val_loss: 0.3199 - val_accuracy: 0.8922
Epoch 3/200
240/240 [==============================] - 39s 164ms/step - loss: 0.2002 - accuracy: 0.9236 - val_loss: 0.3231 - val_accuracy: 0.8881</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>&lt;keras.callbacks.History at 0x7f37e5521a30&gt;</code></pre>
</div>
</div>
<p><code>-</code> 몇 번 좀 참았다가 멈추면 좋겠다.</p>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb113-2"><a href="#cb113-2"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb113-3"><a href="#cb113-3"></a>net.add(tf.keras.layers.Flatten())</span>
<span id="cb113-4"><a href="#cb113-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">5000</span>,activation<span class="op">=</span><span class="st">'relu'</span>)) <span class="co">## 과적합좀 시키려고</span></span>
<span id="cb113-5"><a href="#cb113-5"></a>net.add(tf.keras.layers.Dense(<span class="dv">5000</span>,activation<span class="op">=</span><span class="st">'relu'</span>)) <span class="co">## 레이어를 2장만듬 + 레이어하나당 노드수도 증가</span></span>
<span id="cb113-6"><a href="#cb113-6"></a>net.add(tf.keras.layers.Dense(<span class="dv">10</span>,activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb113-7"><a href="#cb113-7"></a>net.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,loss<span class="op">=</span>tf.losses.categorical_crossentropy,metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="34d8bea6-e562-4f52-9b1f-4eead09e9a89" data-execution_count="114">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1"></a><span class="co">#</span></span>
<span id="cb114-2"><a href="#cb114-2"></a><span class="co">#cb1 = tf.keras.callbacks.TensorBoard()</span></span>
<span id="cb114-3"><a href="#cb114-3"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">5</span>) <span class="co"># 좀더 참다가 멈추어라</span></span>
<span id="cb114-4"><a href="#cb114-4"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>cb2,verbose<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 40s 167ms/step - loss: 0.5611 - accuracy: 0.8114 - val_loss: 0.4034 - val_accuracy: 0.8518
Epoch 2/200
240/240 [==============================] - 40s 166ms/step - loss: 0.3582 - accuracy: 0.8669 - val_loss: 0.3627 - val_accuracy: 0.8688
Epoch 3/200
240/240 [==============================] - 40s 166ms/step - loss: 0.3252 - accuracy: 0.8784 - val_loss: 0.3576 - val_accuracy: 0.8723
Epoch 4/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2966 - accuracy: 0.8887 - val_loss: 0.3566 - val_accuracy: 0.8767
Epoch 5/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2789 - accuracy: 0.8959 - val_loss: 0.3215 - val_accuracy: 0.8852
Epoch 6/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2621 - accuracy: 0.9010 - val_loss: 0.3186 - val_accuracy: 0.8844
Epoch 7/200
240/240 [==============================] - 40s 167ms/step - loss: 0.2466 - accuracy: 0.9085 - val_loss: 0.3297 - val_accuracy: 0.8852
Epoch 8/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2350 - accuracy: 0.9107 - val_loss: 0.3187 - val_accuracy: 0.8905
Epoch 9/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2266 - accuracy: 0.9143 - val_loss: 0.3132 - val_accuracy: 0.8921
Epoch 10/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2114 - accuracy: 0.9196 - val_loss: 0.3212 - val_accuracy: 0.8938
Epoch 11/200
240/240 [==============================] - 40s 166ms/step - loss: 0.2059 - accuracy: 0.9206 - val_loss: 0.3292 - val_accuracy: 0.8896
Epoch 12/200
240/240 [==============================] - 40s 166ms/step - loss: 0.1969 - accuracy: 0.9247 - val_loss: 0.3230 - val_accuracy: 0.8959
Epoch 13/200
240/240 [==============================] - 40s 166ms/step - loss: 0.1868 - accuracy: 0.9274 - val_loss: 0.3289 - val_accuracy: 0.8929
Epoch 14/200
240/240 [==============================] - 40s 166ms/step - loss: 0.1807 - accuracy: 0.9306 - val_loss: 0.3586 - val_accuracy: 0.8892</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>&lt;keras.callbacks.History at 0x7f37e44f8d60&gt;</code></pre>
</div>
</div>
<p><code>-</code> 텐서보드로 그려보자?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1"></a><span class="co">#</span></span>
<span id="cb117-2"><a href="#cb117-2"></a><span class="co"># %tensorboard --logdir logs --host 0.0.0.0</span></span>
<span id="cb117-3"><a href="#cb117-3"></a><span class="co"># 아무것도 안나온다 -&gt; 왜? cb1을 써야 텐서보드가 나옴</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> 조기종료와 텐서보드를 같이 쓰려면?</p>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1"></a>tf.random.set_seed(<span class="dv">43052</span>)</span>
<span id="cb118-2"><a href="#cb118-2"></a>net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb118-3"><a href="#cb118-3"></a>net.add(tf.keras.layers.Flatten())</span>
<span id="cb118-4"><a href="#cb118-4"></a>net.add(tf.keras.layers.Dense(<span class="dv">50</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb118-5"><a href="#cb118-5"></a>net.add(tf.keras.layers.Dense(<span class="dv">10</span>,activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb118-6"><a href="#cb118-6"></a>net.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,loss<span class="op">=</span>tf.losses.categorical_crossentropy,metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="777dffd9-3ec1-492a-a379-701190300d66" data-execution_count="116">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1"></a>cb1 <span class="op">=</span> tf.keras.callbacks.TensorBoard()</span>
<span id="cb119-2"><a href="#cb119-2"></a>cb2 <span class="op">=</span> tf.keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">7</span>) <span class="co"># 좀더 참다가 멈추어라</span></span>
<span id="cb119-3"><a href="#cb119-3"></a>net.fit(X,y,epochs<span class="op">=</span><span class="dv">200</span>,batch_size<span class="op">=</span><span class="dv">200</span>,validation_split<span class="op">=</span><span class="fl">0.2</span>,callbacks<span class="op">=</span>[cb1,cb2]) <span class="co"># callbacks에 cb1,cb2 리스트로 같이 전달.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/200
240/240 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.7593 - val_loss: 0.5007 - val_accuracy: 0.8295
Epoch 2/200
240/240 [==============================] - 0s 825us/step - loss: 0.4678 - accuracy: 0.8409 - val_loss: 0.4602 - val_accuracy: 0.8397
Epoch 3/200
240/240 [==============================] - 0s 823us/step - loss: 0.4223 - accuracy: 0.8521 - val_loss: 0.4262 - val_accuracy: 0.8525
Epoch 4/200
240/240 [==============================] - 0s 832us/step - loss: 0.3984 - accuracy: 0.8594 - val_loss: 0.4001 - val_accuracy: 0.8612
Epoch 5/200
240/240 [==============================] - 0s 825us/step - loss: 0.3773 - accuracy: 0.8675 - val_loss: 0.3906 - val_accuracy: 0.8614
Epoch 6/200
240/240 [==============================] - 0s 838us/step - loss: 0.3638 - accuracy: 0.8713 - val_loss: 0.3897 - val_accuracy: 0.8604
Epoch 7/200
240/240 [==============================] - 0s 833us/step - loss: 0.3516 - accuracy: 0.8749 - val_loss: 0.3808 - val_accuracy: 0.8672
Epoch 8/200
240/240 [==============================] - 0s 822us/step - loss: 0.3425 - accuracy: 0.8773 - val_loss: 0.3640 - val_accuracy: 0.8721
Epoch 9/200
240/240 [==============================] - 0s 836us/step - loss: 0.3347 - accuracy: 0.8811 - val_loss: 0.3567 - val_accuracy: 0.8739
Epoch 10/200
240/240 [==============================] - 0s 836us/step - loss: 0.3249 - accuracy: 0.8834 - val_loss: 0.3585 - val_accuracy: 0.8737
Epoch 11/200
240/240 [==============================] - 0s 825us/step - loss: 0.3175 - accuracy: 0.8868 - val_loss: 0.3582 - val_accuracy: 0.8728
Epoch 12/200
240/240 [==============================] - 0s 827us/step - loss: 0.3104 - accuracy: 0.8884 - val_loss: 0.3531 - val_accuracy: 0.8734
Epoch 13/200
240/240 [==============================] - 0s 819us/step - loss: 0.3047 - accuracy: 0.8909 - val_loss: 0.3513 - val_accuracy: 0.8758
Epoch 14/200
240/240 [==============================] - 0s 838us/step - loss: 0.3000 - accuracy: 0.8915 - val_loss: 0.3624 - val_accuracy: 0.8714
Epoch 15/200
240/240 [==============================] - 0s 828us/step - loss: 0.2962 - accuracy: 0.8937 - val_loss: 0.3492 - val_accuracy: 0.8781
Epoch 16/200
240/240 [==============================] - 0s 828us/step - loss: 0.2948 - accuracy: 0.8934 - val_loss: 0.3793 - val_accuracy: 0.8650
Epoch 17/200
240/240 [==============================] - 0s 837us/step - loss: 0.2875 - accuracy: 0.8951 - val_loss: 0.3459 - val_accuracy: 0.8783
Epoch 18/200
240/240 [==============================] - 0s 829us/step - loss: 0.2834 - accuracy: 0.8963 - val_loss: 0.3452 - val_accuracy: 0.8775
Epoch 19/200
240/240 [==============================] - 0s 843us/step - loss: 0.2788 - accuracy: 0.8977 - val_loss: 0.3482 - val_accuracy: 0.8769
Epoch 20/200
240/240 [==============================] - 0s 837us/step - loss: 0.2737 - accuracy: 0.8997 - val_loss: 0.3446 - val_accuracy: 0.8759
Epoch 21/200
240/240 [==============================] - 0s 814us/step - loss: 0.2724 - accuracy: 0.9018 - val_loss: 0.3377 - val_accuracy: 0.8797
Epoch 22/200
240/240 [==============================] - 0s 839us/step - loss: 0.2666 - accuracy: 0.9033 - val_loss: 0.3370 - val_accuracy: 0.8832
Epoch 23/200
240/240 [==============================] - 0s 827us/step - loss: 0.2638 - accuracy: 0.9039 - val_loss: 0.3398 - val_accuracy: 0.8789
Epoch 24/200
240/240 [==============================] - 0s 833us/step - loss: 0.2603 - accuracy: 0.9067 - val_loss: 0.3458 - val_accuracy: 0.8812
Epoch 25/200
240/240 [==============================] - 0s 831us/step - loss: 0.2549 - accuracy: 0.9072 - val_loss: 0.3407 - val_accuracy: 0.8779
Epoch 26/200
240/240 [==============================] - 0s 821us/step - loss: 0.2546 - accuracy: 0.9067 - val_loss: 0.3381 - val_accuracy: 0.8848
Epoch 27/200
240/240 [==============================] - 0s 823us/step - loss: 0.2519 - accuracy: 0.9093 - val_loss: 0.3401 - val_accuracy: 0.8806
Epoch 28/200
240/240 [==============================] - 0s 818us/step - loss: 0.2461 - accuracy: 0.9112 - val_loss: 0.3469 - val_accuracy: 0.8812
Epoch 29/200
240/240 [==============================] - 0s 840us/step - loss: 0.2468 - accuracy: 0.9096 - val_loss: 0.3478 - val_accuracy: 0.8807</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="116">
<pre><code>&lt;keras.callbacks.History at 0x7f37e5426c40&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1"></a><span class="co">#</span></span>
<span id="cb122-2"><a href="#cb122-2"></a><span class="co"># 조기종료가 구현된 그림이 출력</span></span>
<span id="cb122-3"><a href="#cb122-3"></a><span class="co"># %tensorboard --logdir logs --host 0.0.0.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/4bae3e8f-d629-4ff7-a13a-69557f269013-1-60249ac2-7a54-4044-a69d-507d683fbf24.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">EarlyStopping을 적용한 결과 텐서보드로 실행한 결과</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1"></a><span class="co"># !kill 508556</span></span>
<span id="cb123-2"><a href="#cb123-2"></a><span class="co"># !rm -rf logs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="하이퍼파라메터-선택" class="level3">
<h3 class="anchored" data-anchor-id="하이퍼파라메터-선택">하이퍼파라메터 선택</h3>
<p><code>-</code> 하이퍼파라메터 설정</p>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1"></a><span class="im">from</span> tensorboard.plugins.hparams <span class="im">import</span> api <span class="im">as</span> hp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="0f029592-d90f-4290-90aa-01f8fd1f31df" data-execution_count="123">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1"></a>a<span class="op">=</span>net.evaluate(XX,yy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 [==============================] - 0s 368us/step - loss: 0.3726 - accuracy: 0.8690</code></pre>
</div>
</div>
<div class="cell" data-outputid="b5d88e1e-80eb-4919-bb51-1f0be67d857e" data-execution_count="125">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1"></a><span class="op">!</span>rm <span class="op">-</span>rf logs</span>
<span id="cb127-2"><a href="#cb127-2"></a><span class="cf">for</span> u <span class="kw">in</span> [<span class="dv">50</span>,<span class="dv">5000</span>]:</span>
<span id="cb127-3"><a href="#cb127-3"></a>    <span class="cf">for</span> d <span class="kw">in</span> [<span class="fl">0.0</span>,<span class="fl">0.5</span>]:</span>
<span id="cb127-4"><a href="#cb127-4"></a>        <span class="cf">for</span> o <span class="kw">in</span> [<span class="st">'adam'</span>,<span class="st">'sgd'</span>]:</span>
<span id="cb127-5"><a href="#cb127-5"></a>            logdir <span class="op">=</span> <span class="st">'logs/hpguebin_</span><span class="sc">{}</span><span class="st">_</span><span class="sc">{}</span><span class="st">_</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(u,d,o)</span>
<span id="cb127-6"><a href="#cb127-6"></a>            <span class="cf">with</span> tf.summary.create_file_writer(logdir).as_default():</span>
<span id="cb127-7"><a href="#cb127-7"></a>                net <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb127-8"><a href="#cb127-8"></a>                net.add(tf.keras.layers.Flatten())</span>
<span id="cb127-9"><a href="#cb127-9"></a>                net.add(tf.keras.layers.Dense(u,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb127-10"><a href="#cb127-10"></a>                net.add(tf.keras.layers.Dropout(d))</span>
<span id="cb127-11"><a href="#cb127-11"></a>                net.add(tf.keras.layers.Dense(<span class="dv">10</span>,activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb127-12"><a href="#cb127-12"></a>                net.<span class="bu">compile</span>(optimizer<span class="op">=</span>o,loss<span class="op">=</span>tf.losses.categorical_crossentropy,metrics<span class="op">=</span>[<span class="st">'accuracy'</span>,<span class="st">'Recall'</span>])</span>
<span id="cb127-13"><a href="#cb127-13"></a>                cb3 <span class="op">=</span> hp.KerasCallback(logdir, {<span class="st">'유닛수'</span>:u, <span class="st">'드랍아웃비율'</span>:d, <span class="st">'옵티마이저'</span>:o})</span>
<span id="cb127-14"><a href="#cb127-14"></a>                net.fit(X,y,epochs<span class="op">=</span><span class="dv">3</span>,callbacks<span class="op">=</span>cb3)</span>
<span id="cb127-15"><a href="#cb127-15"></a>                _rslt<span class="op">=</span>net.evaluate(XX,yy)  <span class="co"># test accuracy, test recall</span></span>
<span id="cb127-16"><a href="#cb127-16"></a>                _mymetric<span class="op">=</span>_rslt[<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.8</span> <span class="op">+</span> _rslt[<span class="dv">2</span>]<span class="op">*</span><span class="fl">0.2</span></span>
<span id="cb127-17"><a href="#cb127-17"></a>                tf.summary.scalar(<span class="st">'애큐러시와리컬의가중평균(테스트셋)'</span>, _mymetric, step<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/3
1875/1875 [==============================] - 1s 523us/step - loss: 0.5223 - accuracy: 0.8170 - recall: 0.7559
Epoch 2/3
1875/1875 [==============================] - 1s 513us/step - loss: 0.3940 - accuracy: 0.8602 - recall: 0.8296
Epoch 3/3
1875/1875 [==============================] - 1s 517us/step - loss: 0.3578 - accuracy: 0.8711 - recall: 0.8455
313/313 [==============================] - 0s 390us/step - loss: 0.3902 - accuracy: 0.8600 - recall: 0.8347
Epoch 1/3
1875/1875 [==============================] - 1s 483us/step - loss: 0.7881 - accuracy: 0.7447 - recall: 0.5665
Epoch 2/3
1875/1875 [==============================] - 1s 478us/step - loss: 0.5283 - accuracy: 0.8214 - recall: 0.7521
Epoch 3/3
1875/1875 [==============================] - 1s 465us/step - loss: 0.4769 - accuracy: 0.8361 - recall: 0.7843
313/313 [==============================] - 0s 401us/step - loss: 0.4903 - accuracy: 0.8302 - recall: 0.7817
Epoch 1/3
1875/1875 [==============================] - 1s 527us/step - loss: 0.7370 - accuracy: 0.7401 - recall: 0.6217
Epoch 2/3
1875/1875 [==============================] - 1s 522us/step - loss: 0.5597 - accuracy: 0.7993 - recall: 0.7249
Epoch 3/3
1875/1875 [==============================] - 1s 520us/step - loss: 0.5226 - accuracy: 0.8110 - recall: 0.7480
313/313 [==============================] - 0s 393us/step - loss: 0.4303 - accuracy: 0.8447 - recall: 0.7962
Epoch 1/3
1875/1875 [==============================] - 1s 488us/step - loss: 1.0124 - accuracy: 0.6446 - recall: 0.4268
Epoch 2/3
1875/1875 [==============================] - 1s 488us/step - loss: 0.7222 - accuracy: 0.7500 - recall: 0.6124
Epoch 3/3
1875/1875 [==============================] - 1s 488us/step - loss: 0.6513 - accuracy: 0.7767 - recall: 0.6656
313/313 [==============================] - 0s 382us/step - loss: 0.5226 - accuracy: 0.8165 - recall: 0.7442
Epoch 1/3
1875/1875 [==============================] - 28s 15ms/step - loss: 0.4779 - accuracy: 0.8285 - recall: 0.7886
Epoch 2/3
1875/1875 [==============================] - 28s 15ms/step - loss: 0.3614 - accuracy: 0.8677 - recall: 0.8425
Epoch 3/3
1875/1875 [==============================] - 28s 15ms/step - loss: 0.3205 - accuracy: 0.8819 - recall: 0.8609
313/313 [==============================] - 0s 994us/step - loss: 0.3640 - accuracy: 0.8684 - recall: 0.8475
Epoch 1/3
1875/1875 [==============================] - 7s 3ms/step - loss: 0.6689 - accuracy: 0.7886 - recall: 0.6448
Epoch 2/3
1875/1875 [==============================] - 6s 3ms/step - loss: 0.4828 - accuracy: 0.8371 - recall: 0.7770
Epoch 3/3
1875/1875 [==============================] - 6s 3ms/step - loss: 0.4422 - accuracy: 0.8490 - recall: 0.8011
313/313 [==============================] - 0s 967us/step - loss: 0.4644 - accuracy: 0.8375 - recall: 0.7946
Epoch 1/3
1875/1875 [==============================] - 29s 15ms/step - loss: 0.5713 - accuracy: 0.7975 - recall: 0.7544
Epoch 2/3
1875/1875 [==============================] - 29s 15ms/step - loss: 0.4424 - accuracy: 0.8395 - recall: 0.8069
Epoch 3/3
1875/1875 [==============================] - 29s 15ms/step - loss: 0.4066 - accuracy: 0.8521 - recall: 0.8217
313/313 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8602 - recall: 0.8310
Epoch 1/3
1875/1875 [==============================] - 7s 4ms/step - loss: 0.6914 - accuracy: 0.7763 - recall: 0.6367
Epoch 2/3
1875/1875 [==============================] - 7s 4ms/step - loss: 0.5047 - accuracy: 0.8304 - recall: 0.7671
Epoch 3/3
1875/1875 [==============================] - 7s 4ms/step - loss: 0.4622 - accuracy: 0.8413 - recall: 0.7901
313/313 [==============================] - 0s 985us/step - loss: 0.4639 - accuracy: 0.8398 - recall: 0.7945</code></pre>
</div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1"></a><span class="co">#</span></span>
<span id="cb129-2"><a href="#cb129-2"></a><span class="op">%</span>tensorboard <span class="op">--</span>logdir logs <span class="op">--</span>host <span class="fl">0.0.0.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

      <iframe id="tensorboard-frame-592baf6cb33b9477" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-592baf6cb33b9477");
          const url = new URL("/", window.location);
          const port = 6006;
          if (port) {
            url.port = port;
          }
          frame.src = url;
        })();
      </script>
    
</div>
</div>
<p><img src="2022_05_23_(12주차)_5월23일_files/figure-html/2bb1a707-28a6-46ea-8fe4-9475fe8ca457-1-312540fb-617e-4cee-a15e-01e96dea2b47.png" class="img-fluid"></p>
</section>
</section>
<section id="숙제" class="level2">
<h2 class="anchored" data-anchor-id="숙제">숙제</h2>
<p><code>-</code> 아래의 네트워크에서 옵티마이저를 adam, sgd를 선택하여 각각 적합시켜보고 testset의 loss를 성능비교를 하라. epoch은 5정도로 설정하라.</p>
<pre><code>net = tf.keras.Sequential()
net.add(tf.keras.layers.Flatten())
net.add(tf.keras.layers.Dense(50,activation='relu'))
net.add(tf.keras.layers.Dense(50,activation='relu'))
net.add(tf.keras.layers.Dense(10,activation='softmax'))
net.compile(optimizer=???,loss=tf.losses.categorical_crossentropy,metrics=['accuracy','Recall'])</code></pre>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>케리커쳐 처럼.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>DNN식으로 이해: linear transform<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>non-linear activation<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>축소<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>linear transform<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>linear transform<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>non-linear activation<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>축소<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>얘를 가장 잘맞추는 하나의 직선을 골라라 하면 0근처 직선.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>