{"title":"**[수리통계학]** 추정 for JY","markdown":{"yaml":{"title":"**[수리통계학]** 추정 for JY","author":"신록예찬","date":"06/14/2023"},"headingText":"Intro","containsRefs":false,"markdown":"\n\n\n`-` 비편향추정량(UB)란 $\\theta$의 추정량 중 \n\n$$\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta$$\n\n를 만족하는 추정량 $\\hat{\\theta}$을 의미한다. \n\n`-` (예시) 아래와 같은 상황을 가정하자. \n\n$$X_n \\overset{iid}{\\sim} N(\\theta,1)$$\n\n여기에서 \n\n1. $\\hat{\\theta}_1=0$ 은 $\\theta=0$ 일 경우에는 $E(\\hat{\\theta})=\\theta$ 를 만족하지만 그 외의 경우에는 $E(\\hat{\\theta})\\neq\\theta$ 이므로 UB가 아니다. \n2. $\\hat{\\theta}_2=X_1$ 은 UB이다. \n3. $\\hat{\\theta}_3=\\frac{X_1+X_2}{2}$ 역시 UB이다. \n4. $\\hat{\\theta}_4=X_1+X_2-X_3$ 역시 UB이다. \n5. $\\hat{\\theta}_5=-99X_1+100X_2$ 역시 UB이다. \n6. $\\hat{\\theta}_6=\\frac{X_1+0}{2}$ 은 1과 동일한 이유로 UB가 아니다. \n6. $\\hat{\\theta}_7=\\bar{X}$는 UB이다. \n7. $\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n$ ,where $\\sum_{i=1}^{n}w_i=1$ 형태의 estimator는 모두 UB이다. \n\n`-` 최소분산비편향추정량(MVUE)란 $\\theta$에 대한 비편향추정량을 모아놓은 집합 $\\hat{\\Theta}_{UB}$ 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다. \n\n> $\\theta$에 대한 모든 비편향추정량을 구한다. 즉 집합 $\\hat{\\Theta}_{UB}$를 구한다. 그리고 $\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}$ 에 대하여 $V(\\hat{\\theta})$ 를 구한 뒤 $V(\\hat{\\theta})$가 가장 작은 $\\hat{\\theta}$를 선택한다. \n\n예를들어 위의 예제에서 $V(\\hat{\\theta}_2)=1$ 이고 $V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}$ 이므로 $\\hat{\\theta}_3$ 이 더 좋은 추정량이라 볼 수 있다. \n\n`-` (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n- $\\hat{\\theta}_1$와 같은 추정량은 $V(\\hat{\\theta}_1)=0$ 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함. \n\n`-` 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n> $\\theta$에 대한 모든 비편향추정량을 구한다. 즉 집합 $\\hat{\\Theta}_{UB}$를 구한다. 그리고 $\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}$ 에 대하여 $V(\\hat{\\theta})$ 를 구한 뒤 $V(\\hat{\\theta})$가 가장 작은 $\\hat{\\theta}$를 선택한다. \n\n\n\n`-` 이론: 크래머라오 하한값(편의상 $L^\\star$이라고 하자)이라고 있는데, 이는 ${\\Theta}_{UB}$에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.^[(사실 ${\\Theta}_{UB}$가 아닌 집합에 대해서도 하한값을 제공함, 그런데 교재에서는 ${\\Theta}_{UB}$에 대한 하한값만 다루는듯] 즉 아래가 성립한다. \n\n- $L^\\star$ is Cramer-Rao lower bound $\\Rightarrow$ $\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star$\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 $L$이 존재할 수 있다. \n\n- $V(\\hat{\\theta}) \\geq L > L^\\star$ for some $\\hat{\\theta} \\in \\Theta_{UB}$\n\n`-` 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다. \n\n1. $L^\\star$를 구한다. \n2. 왠지 MVUE가 될 것 같은 $\\hat{\\theta}$을 하나 찍고 그것의 분산 $V(\\hat{\\theta})$를 구한다. \n3. 만약에 $V(\\hat{\\theta})=L^\\star$를 만족하면 그 $\\hat{\\theta}$이 MVUE라고 주장할 수 있다. \n\n`-` 위의 논리전개에 대한 불만 [@ p.212]\n\n- $V(\\hat{\\theta})=L^\\star$ 이길 기도해야함. \n- $\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L > L^\\star$ 와 같은 $L$이 존재하는 경우는 쓸 수 없음. \n\n`-` 또 다른 방법: 완비충분통계량을 이용함 \n\n## 충분통계량 \n\n아래와 같은 상황을 가정하자. \n\n$$ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}$$\n\n`-` 충분통계량(SS)의 느낌: \"이 값만 기억하면 $\\theta$를 추정하는데 무난할듯\" \n\n`-` 예시1: $X_1 \\sim N(\\theta,1)$ \n\n- $X_1$은 $\\theta_1$ 의 SS. (하나밖에 없으니 그거라도 기억해야지) \n- 즉 $\\hat{\\theta}=X_1$은 $\\theta$의 SS\n\n`-` 예시2: $X_1,X_2 \\sim N(\\theta,1)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2)$는 $\\theta$의 SS (둘다 기억하면 당연히 $\\theta$를 추정함에 있어서 충분함) \n- 그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 $\\frac{1}{2}(X_1+X_2)$의 값만 기억해도 ***왠지 충분할것 같음***. 따라서 $\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)$ 역시 $\\theta$의 SS 일듯\n- 그런데 좀 더 생각해보니까 $X_1+X_2$의 값만 기억해도 $\\frac{1}{2}(X_1+X_2)$를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 $X_1+X_2$만 기억해도 ***왠지 충분할 것 같음***. 따라서 $\\hat{\\theta}=X_1+X_2$ 역시 $\\theta$의 SS 일듯\n\n`-` 예시3: $X_1,\\dots,X_n \\sim N(\\theta,1)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)$은 $\\theta$의 SS. \n- 하지만 $n$개의 숫자를 기억할 필요 없이 $\\sum_{i=1}^{n} X_i$ 하나의 숫자만 기억해도 ***왠지 충분할듯***. 그래서 $\\hat{\\theta} = \\sum_{i=1}^{n} X_i$ 역시 $\\theta$의 SS 일듯\n\n`-` SS에 대한 직관1\n\n- 기억할 숫자가 적을수록 유리 -> MSS의 개념\n- 충분통계량의 1:1은 충분통계량 ($\\frac{1}{2}(X_1+X_2)$을 기억하면 충분한 상황이라면, $X_1+X_2$를 기억해도 충분하니까..)\n\n`-` 예시4: $X_1,X_2 \\sim {\\cal B}er(\\theta)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2)$은 $\\theta$의 SS. \n- 그리고 $\\hat{\\theta}=X_1+X_2$ 역시 $\\theta$ SS 일듯. \n- 두개보다 한개가 유리하니까 둘다 SS이면 $(X_1,X_2)$보다 $X_1+X_2$가 더 좋은 SS. \n- $X_1$은 SS가 아닐듯. $p$를 추정함에 있어서 $X_1$만 가지고서는 충분하지 않아보임 \n- $X_2$도 SS가 아닐듯. \n\n***왠지 충분할 것 같은 느낌의 정의***\n\n아래와 같은 상황을 가정하자.\n\n$$X_1,X_2 \\sim {\\cal B}er(\\theta)$$\n\n`-` 일반적으로 \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2$ \n\n와 같은 확률들은 $\\theta$가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 $\\theta=0$ 이라면 아래와 같을 것이고 \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0$ \n\n$\\theta=1/2$ 이라면 아래와 같을 것이다. \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4$\n\n즉 $X_1,X_2$의 결합확률분포는 $\\theta$가 변함에 따라 같이 변화한다. 이를 이용해 우리는 $X_1,X_2$의 결합확률분포에서 관찰한 샘플들을 이용하여 $\\theta$의 값을 역으로 추론한다. \n\n`-` 만약에 어떠한 \"특수한 정보를 알고 있을 경우\" $X_1,X_2$의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자. \n\n`-` 경우1: $\\theta$를 알고 있을 경우. $(X_1,X_2)$의 조인트를 완벽하게 기술할 수 있다. 예를들어 $\\theta=1/2$일 경우는 아래와 같다.\n\n- $P(X_1=0,X_2=0 | \\theta=1/2)=1/4$\n- $P(X_1=0,X_2=1 | \\theta=1/2)=1/4$ \n- $P(X_1=1,X_2=0 | \\theta=1/2)=1/4$ \n- $P(X_1=1,X_2=1 | \\theta=1/2)=1/4$\n\n`-` 경우2: $X_1,X_2$의 realization을 알고 있을 경우. $(X_1,X_2)$의 조인트를 완벽하게 기술할 수 있다. 예를들어 $X_1=0,X_2=1$일 경우는 아래와 같다.\n\n- $P(X_1=0,X_2=0 | X_1=0,X_2=0)=0$\n- $P(X_1=0,X_2=1| X_1=0,X_2=1)=0$ \n- $P(X_1=1,X_2=0| X_1=1,X_2=0)=1$ \n- $P(X_1=1,X_2=1| X_1=1,X_2=1)=0$\n\n`-` 경우3: $(X_1+X_2)(\\omega)$의 realization을 알고 있을 경우. 이때도 ***매우 특이하게*** $(X_1,X_2)$ 의 조인트를 완벽하게 기술할 수 있다.\n\n***case1: $X_1+X_2=0$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=0)=1$\n- $P(X_1=0,X_2=1| X_1+X_2=0)=0$ \n- $P(X_1=1,X_2=0| X_1+X_2=0)=0$ \n- $P(X_1=1,X_2=1| X_1+X_2=0)=0$\n\n***case2: $X_1+X_2=1$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=1)=0$\n- $P(X_1=0,X_2=1| X_1+X_2=1)=1/2$ \n- $P(X_1=1,X_2=0| X_1+X_2=1)=1/2$ \n- $P(X_1=1,X_2=1| X_1+X_2=1)=0$\n\n***case3: $X_1+X_2=2$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=2)=0$\n- $P(X_1=0,X_2=1| X_1+X_2=2)=0$ \n- $P(X_1=1,X_2=0| X_1+X_2=2)=0$ \n- $P(X_1=1,X_2=1| X_1+X_2=2)=1$\n\n`-` 경우4: $X_1$의 realization만 알고 있을 경우. 이때는 $(X_1,X_2)$ 의 조인트를 완벽하게 기술할 수 없다. \n\n***case1: $X_1=0$일 경우***\n\n- $P(X_1=0,X_2=0| X_1=0)=1-\\theta$\n- $P(X_1=0,X_2=1| X_1=0)=\\theta$ \n- $P(X_1=1,X_2=0| X_1=0)=0$ \n- $P(X_1=1,X_2=1| X_1=0)=0$\n\n***case2: $X_1=1$일 경우***\n\n- $P(X_1=0,X_2=0| X_1=1)=0$\n- $P(X_1=0,X_2=1| X_1=1)=0$ \n- $P(X_1=1,X_2=0| X_1=1)=1-\\theta$ \n- $P(X_1=1,X_2=1| X_1=1)=\\theta$\n\n\n`-` 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 $\\theta$에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n- 경우1: 당연히 $\\theta$를 줬으니까 $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n- 경우2: $X_1,X_2$를 줬음. $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n- 경우3: $X_1+X_2$를 줬음. $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 **$\\theta$에 대한 완전한 정보를 준 상황**이므로 당연히 조인트는 $\\theta$에 의존하지 않는다. 경우2-3은 $\\theta$를 주지 않았음에도 조인트가 $\\theta$에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면 \n\n> 경우2에서는 $(X_1,X_2)$ 가 경우3에서는 $X_1+X_2$가 $\\theta$에 대한 완전한 정보를 대신하고 있는것 아닐까? \n\n라는 생각이 든다. 정리하면 \n\n- 경우2: $(X_1,X_2)$을 주는 것은 $\\theta$의 값을 그냥 알려주는 것과 대등한 효과 \n- 경우3: $X_1+X_2$를 주는 것은 $\\theta$의 값을 그냥 알려주는 것과 대등한 효과 \n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다. \n\n\n`-` 대충정의: 어떠한 통계량 $S$의 값을 줬을때, $(X_1,X_2\\dots,X_n)$의 조인트가 $\\theta$에 의존하지 않으면 그 통계량 $S$를 $\\theta$의 충분통계량이라고 한다. \n\n`-` 충분통계량 구하는 방법\n\n1. 지수족일때 구하는 방식이 있음! <-- 외우세여\n2. 분해정리를 쓰는 경우. <-- 거의 안쓰는거같은데..\n3. 1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n## 최소충분통계량 \n\n`-` 충분통계량에 대한 realization을 알려주면 $\\theta$의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임 \n\n`-` 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자. \n\n$$X_1,X_2 \\sim {\\cal B}er(\\theta)$$\n\n이 경우 \n\n1. $(X_1,X_2)$는 SS\n2. $X_1+X_2$는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n\n`-` 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다. \n\n- 두가지 상태 \"500원을 가지고 있음\", \"1000원을 가지고 있음\" 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다. \n\n`-` 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서 \n\n1. $(X_1,X_2)$는 SS\n2. $X_1+X_2$는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 $1\\to 2$ 인 변환(=함수)는 가능하지만 $2\\to 1$로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다. \n\n`-` 이를 확장하자. 어떠한 충분 통계량 $S^\\star$가 있다고 가정하자. 다른 모든 충분통계량 $S_1,S_2,S_3 \\dots$에서 $S^\\star$로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 $S^\\star$의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 $S^\\star$는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자. \n\n## 라오블랙웰\n\n`-` 충분통계량 $S$을 알려주면 (기븐하면) $\\theta$에 대한 완벽한 정보를 알려주는 셈이다. 따라서 $\\theta$를 추정하는 어떠한 추정량 $\\hat{\\theta}$도 충분통계량의 정보 $S$가 있다면 $\\hat{\\theta}$를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다) \n\n`-` 충분통계량을 줬을때 $\\hat{\\theta}$의 업그레이드 방법은 \n\n$$\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$$\n\n와 같이 할 수 있는데 이는 충분통계량 $S$의 정보를 받아서 어떠한 방식으로 업데이트된 $\\hat{\\theta}$ 이므로 $S$의 함수라 해석할 수 있다. \n\n`-` 이론 (라오블랙웰, @Thm, 4.5): $\\hat{\\theta}$가 UB일때 충분통계량의 값을 알려주면 $\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$와 같이 $\\hat{\\theta}$를 업그레이드 할 수 있다.  \n\n## 레만쉐페정리\n\n`-` 충분통계량 $S$을 알려주면 (기븐하면) $\\theta$에 대한 완벽한 정보를 알려주는 셈이다. 따라서 $\\theta$를 추정하는 어떠한 추정량 $\\hat{\\theta}$도 충분통계량의 정보 $S$가 있다면 $\\hat{\\theta}$를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다) \n\n`-` 충분통계량을 줬을때 $\\hat{\\theta}$의 업그레이드 방법은 \n\n$$\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$$\n\n와 같이 할 수 있는데 이는 충분통계량 $S$의 정보를 받아서 어떠한 방식으로 업데이트된 $\\hat{\\theta}$ 이므로 $S$의 함수라 해석할 수 있다. \n\n`-` 이론 (라오블랙웰, @Thm, 4.5): $\\hat{\\theta}$가 UB일때 충분통계량의 값을 알려주면 $\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$와 같이 $\\hat{\\theta}$를 업그레이드 할 수 있다.  \n","srcMarkdownNoYaml":"\n\n# Intro\n\n`-` 비편향추정량(UB)란 $\\theta$의 추정량 중 \n\n$$\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta$$\n\n를 만족하는 추정량 $\\hat{\\theta}$을 의미한다. \n\n`-` (예시) 아래와 같은 상황을 가정하자. \n\n$$X_n \\overset{iid}{\\sim} N(\\theta,1)$$\n\n여기에서 \n\n1. $\\hat{\\theta}_1=0$ 은 $\\theta=0$ 일 경우에는 $E(\\hat{\\theta})=\\theta$ 를 만족하지만 그 외의 경우에는 $E(\\hat{\\theta})\\neq\\theta$ 이므로 UB가 아니다. \n2. $\\hat{\\theta}_2=X_1$ 은 UB이다. \n3. $\\hat{\\theta}_3=\\frac{X_1+X_2}{2}$ 역시 UB이다. \n4. $\\hat{\\theta}_4=X_1+X_2-X_3$ 역시 UB이다. \n5. $\\hat{\\theta}_5=-99X_1+100X_2$ 역시 UB이다. \n6. $\\hat{\\theta}_6=\\frac{X_1+0}{2}$ 은 1과 동일한 이유로 UB가 아니다. \n6. $\\hat{\\theta}_7=\\bar{X}$는 UB이다. \n7. $\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n$ ,where $\\sum_{i=1}^{n}w_i=1$ 형태의 estimator는 모두 UB이다. \n\n`-` 최소분산비편향추정량(MVUE)란 $\\theta$에 대한 비편향추정량을 모아놓은 집합 $\\hat{\\Theta}_{UB}$ 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다. \n\n> $\\theta$에 대한 모든 비편향추정량을 구한다. 즉 집합 $\\hat{\\Theta}_{UB}$를 구한다. 그리고 $\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}$ 에 대하여 $V(\\hat{\\theta})$ 를 구한 뒤 $V(\\hat{\\theta})$가 가장 작은 $\\hat{\\theta}$를 선택한다. \n\n예를들어 위의 예제에서 $V(\\hat{\\theta}_2)=1$ 이고 $V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}$ 이므로 $\\hat{\\theta}_3$ 이 더 좋은 추정량이라 볼 수 있다. \n\n`-` (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n- $\\hat{\\theta}_1$와 같은 추정량은 $V(\\hat{\\theta}_1)=0$ 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함. \n\n`-` 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n> $\\theta$에 대한 모든 비편향추정량을 구한다. 즉 집합 $\\hat{\\Theta}_{UB}$를 구한다. 그리고 $\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}$ 에 대하여 $V(\\hat{\\theta})$ 를 구한 뒤 $V(\\hat{\\theta})$가 가장 작은 $\\hat{\\theta}$를 선택한다. \n\n\n\n`-` 이론: 크래머라오 하한값(편의상 $L^\\star$이라고 하자)이라고 있는데, 이는 ${\\Theta}_{UB}$에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.^[(사실 ${\\Theta}_{UB}$가 아닌 집합에 대해서도 하한값을 제공함, 그런데 교재에서는 ${\\Theta}_{UB}$에 대한 하한값만 다루는듯] 즉 아래가 성립한다. \n\n- $L^\\star$ is Cramer-Rao lower bound $\\Rightarrow$ $\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star$\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 $L$이 존재할 수 있다. \n\n- $V(\\hat{\\theta}) \\geq L > L^\\star$ for some $\\hat{\\theta} \\in \\Theta_{UB}$\n\n`-` 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다. \n\n1. $L^\\star$를 구한다. \n2. 왠지 MVUE가 될 것 같은 $\\hat{\\theta}$을 하나 찍고 그것의 분산 $V(\\hat{\\theta})$를 구한다. \n3. 만약에 $V(\\hat{\\theta})=L^\\star$를 만족하면 그 $\\hat{\\theta}$이 MVUE라고 주장할 수 있다. \n\n`-` 위의 논리전개에 대한 불만 [@ p.212]\n\n- $V(\\hat{\\theta})=L^\\star$ 이길 기도해야함. \n- $\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L > L^\\star$ 와 같은 $L$이 존재하는 경우는 쓸 수 없음. \n\n`-` 또 다른 방법: 완비충분통계량을 이용함 \n\n## 충분통계량 \n\n아래와 같은 상황을 가정하자. \n\n$$ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}$$\n\n`-` 충분통계량(SS)의 느낌: \"이 값만 기억하면 $\\theta$를 추정하는데 무난할듯\" \n\n`-` 예시1: $X_1 \\sim N(\\theta,1)$ \n\n- $X_1$은 $\\theta_1$ 의 SS. (하나밖에 없으니 그거라도 기억해야지) \n- 즉 $\\hat{\\theta}=X_1$은 $\\theta$의 SS\n\n`-` 예시2: $X_1,X_2 \\sim N(\\theta,1)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2)$는 $\\theta$의 SS (둘다 기억하면 당연히 $\\theta$를 추정함에 있어서 충분함) \n- 그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 $\\frac{1}{2}(X_1+X_2)$의 값만 기억해도 ***왠지 충분할것 같음***. 따라서 $\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)$ 역시 $\\theta$의 SS 일듯\n- 그런데 좀 더 생각해보니까 $X_1+X_2$의 값만 기억해도 $\\frac{1}{2}(X_1+X_2)$를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 $X_1+X_2$만 기억해도 ***왠지 충분할 것 같음***. 따라서 $\\hat{\\theta}=X_1+X_2$ 역시 $\\theta$의 SS 일듯\n\n`-` 예시3: $X_1,\\dots,X_n \\sim N(\\theta,1)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)$은 $\\theta$의 SS. \n- 하지만 $n$개의 숫자를 기억할 필요 없이 $\\sum_{i=1}^{n} X_i$ 하나의 숫자만 기억해도 ***왠지 충분할듯***. 그래서 $\\hat{\\theta} = \\sum_{i=1}^{n} X_i$ 역시 $\\theta$의 SS 일듯\n\n`-` SS에 대한 직관1\n\n- 기억할 숫자가 적을수록 유리 -> MSS의 개념\n- 충분통계량의 1:1은 충분통계량 ($\\frac{1}{2}(X_1+X_2)$을 기억하면 충분한 상황이라면, $X_1+X_2$를 기억해도 충분하니까..)\n\n`-` 예시4: $X_1,X_2 \\sim {\\cal B}er(\\theta)$ \n\n- 당연히 $\\hat{\\boldsymbol \\theta}=(X_1,X_2)$은 $\\theta$의 SS. \n- 그리고 $\\hat{\\theta}=X_1+X_2$ 역시 $\\theta$ SS 일듯. \n- 두개보다 한개가 유리하니까 둘다 SS이면 $(X_1,X_2)$보다 $X_1+X_2$가 더 좋은 SS. \n- $X_1$은 SS가 아닐듯. $p$를 추정함에 있어서 $X_1$만 가지고서는 충분하지 않아보임 \n- $X_2$도 SS가 아닐듯. \n\n***왠지 충분할 것 같은 느낌의 정의***\n\n아래와 같은 상황을 가정하자.\n\n$$X_1,X_2 \\sim {\\cal B}er(\\theta)$$\n\n`-` 일반적으로 \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2$ \n\n와 같은 확률들은 $\\theta$가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 $\\theta=0$ 이라면 아래와 같을 것이고 \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0$ \n\n$\\theta=1/2$ 이라면 아래와 같을 것이다. \n\n- $P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4$\n- $P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4$ \n- $P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4$ \n- $P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4$\n\n즉 $X_1,X_2$의 결합확률분포는 $\\theta$가 변함에 따라 같이 변화한다. 이를 이용해 우리는 $X_1,X_2$의 결합확률분포에서 관찰한 샘플들을 이용하여 $\\theta$의 값을 역으로 추론한다. \n\n`-` 만약에 어떠한 \"특수한 정보를 알고 있을 경우\" $X_1,X_2$의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자. \n\n`-` 경우1: $\\theta$를 알고 있을 경우. $(X_1,X_2)$의 조인트를 완벽하게 기술할 수 있다. 예를들어 $\\theta=1/2$일 경우는 아래와 같다.\n\n- $P(X_1=0,X_2=0 | \\theta=1/2)=1/4$\n- $P(X_1=0,X_2=1 | \\theta=1/2)=1/4$ \n- $P(X_1=1,X_2=0 | \\theta=1/2)=1/4$ \n- $P(X_1=1,X_2=1 | \\theta=1/2)=1/4$\n\n`-` 경우2: $X_1,X_2$의 realization을 알고 있을 경우. $(X_1,X_2)$의 조인트를 완벽하게 기술할 수 있다. 예를들어 $X_1=0,X_2=1$일 경우는 아래와 같다.\n\n- $P(X_1=0,X_2=0 | X_1=0,X_2=0)=0$\n- $P(X_1=0,X_2=1| X_1=0,X_2=1)=0$ \n- $P(X_1=1,X_2=0| X_1=1,X_2=0)=1$ \n- $P(X_1=1,X_2=1| X_1=1,X_2=1)=0$\n\n`-` 경우3: $(X_1+X_2)(\\omega)$의 realization을 알고 있을 경우. 이때도 ***매우 특이하게*** $(X_1,X_2)$ 의 조인트를 완벽하게 기술할 수 있다.\n\n***case1: $X_1+X_2=0$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=0)=1$\n- $P(X_1=0,X_2=1| X_1+X_2=0)=0$ \n- $P(X_1=1,X_2=0| X_1+X_2=0)=0$ \n- $P(X_1=1,X_2=1| X_1+X_2=0)=0$\n\n***case2: $X_1+X_2=1$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=1)=0$\n- $P(X_1=0,X_2=1| X_1+X_2=1)=1/2$ \n- $P(X_1=1,X_2=0| X_1+X_2=1)=1/2$ \n- $P(X_1=1,X_2=1| X_1+X_2=1)=0$\n\n***case3: $X_1+X_2=2$일 경우***\n\n- $P(X_1=0,X_2=0| X_1+X_2=2)=0$\n- $P(X_1=0,X_2=1| X_1+X_2=2)=0$ \n- $P(X_1=1,X_2=0| X_1+X_2=2)=0$ \n- $P(X_1=1,X_2=1| X_1+X_2=2)=1$\n\n`-` 경우4: $X_1$의 realization만 알고 있을 경우. 이때는 $(X_1,X_2)$ 의 조인트를 완벽하게 기술할 수 없다. \n\n***case1: $X_1=0$일 경우***\n\n- $P(X_1=0,X_2=0| X_1=0)=1-\\theta$\n- $P(X_1=0,X_2=1| X_1=0)=\\theta$ \n- $P(X_1=1,X_2=0| X_1=0)=0$ \n- $P(X_1=1,X_2=1| X_1=0)=0$\n\n***case2: $X_1=1$일 경우***\n\n- $P(X_1=0,X_2=0| X_1=1)=0$\n- $P(X_1=0,X_2=1| X_1=1)=0$ \n- $P(X_1=1,X_2=0| X_1=1)=1-\\theta$ \n- $P(X_1=1,X_2=1| X_1=1)=\\theta$\n\n\n`-` 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 $\\theta$에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n- 경우1: 당연히 $\\theta$를 줬으니까 $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n- 경우2: $X_1,X_2$를 줬음. $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n- 경우3: $X_1+X_2$를 줬음. $(X_1,X_2)$의 조인트는 $\\theta$에 의존하지 않음. \n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 **$\\theta$에 대한 완전한 정보를 준 상황**이므로 당연히 조인트는 $\\theta$에 의존하지 않는다. 경우2-3은 $\\theta$를 주지 않았음에도 조인트가 $\\theta$에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면 \n\n> 경우2에서는 $(X_1,X_2)$ 가 경우3에서는 $X_1+X_2$가 $\\theta$에 대한 완전한 정보를 대신하고 있는것 아닐까? \n\n라는 생각이 든다. 정리하면 \n\n- 경우2: $(X_1,X_2)$을 주는 것은 $\\theta$의 값을 그냥 알려주는 것과 대등한 효과 \n- 경우3: $X_1+X_2$를 주는 것은 $\\theta$의 값을 그냥 알려주는 것과 대등한 효과 \n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다. \n\n\n`-` 대충정의: 어떠한 통계량 $S$의 값을 줬을때, $(X_1,X_2\\dots,X_n)$의 조인트가 $\\theta$에 의존하지 않으면 그 통계량 $S$를 $\\theta$의 충분통계량이라고 한다. \n\n`-` 충분통계량 구하는 방법\n\n1. 지수족일때 구하는 방식이 있음! <-- 외우세여\n2. 분해정리를 쓰는 경우. <-- 거의 안쓰는거같은데..\n3. 1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n## 최소충분통계량 \n\n`-` 충분통계량에 대한 realization을 알려주면 $\\theta$의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임 \n\n`-` 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자. \n\n$$X_1,X_2 \\sim {\\cal B}er(\\theta)$$\n\n이 경우 \n\n1. $(X_1,X_2)$는 SS\n2. $X_1+X_2$는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n\n`-` 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다. \n\n- 두가지 상태 \"500원을 가지고 있음\", \"1000원을 가지고 있음\" 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다. \n\n`-` 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서 \n\n1. $(X_1,X_2)$는 SS\n2. $X_1+X_2$는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 $1\\to 2$ 인 변환(=함수)는 가능하지만 $2\\to 1$로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다. \n\n`-` 이를 확장하자. 어떠한 충분 통계량 $S^\\star$가 있다고 가정하자. 다른 모든 충분통계량 $S_1,S_2,S_3 \\dots$에서 $S^\\star$로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 $S^\\star$의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 $S^\\star$는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자. \n\n## 라오블랙웰\n\n`-` 충분통계량 $S$을 알려주면 (기븐하면) $\\theta$에 대한 완벽한 정보를 알려주는 셈이다. 따라서 $\\theta$를 추정하는 어떠한 추정량 $\\hat{\\theta}$도 충분통계량의 정보 $S$가 있다면 $\\hat{\\theta}$를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다) \n\n`-` 충분통계량을 줬을때 $\\hat{\\theta}$의 업그레이드 방법은 \n\n$$\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$$\n\n와 같이 할 수 있는데 이는 충분통계량 $S$의 정보를 받아서 어떠한 방식으로 업데이트된 $\\hat{\\theta}$ 이므로 $S$의 함수라 해석할 수 있다. \n\n`-` 이론 (라오블랙웰, @Thm, 4.5): $\\hat{\\theta}$가 UB일때 충분통계량의 값을 알려주면 $\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$와 같이 $\\hat{\\theta}$를 업그레이드 할 수 있다.  \n\n## 레만쉐페정리\n\n`-` 충분통계량 $S$을 알려주면 (기븐하면) $\\theta$에 대한 완벽한 정보를 알려주는 셈이다. 따라서 $\\theta$를 추정하는 어떠한 추정량 $\\hat{\\theta}$도 충분통계량의 정보 $S$가 있다면 $\\hat{\\theta}$를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다) \n\n`-` 충분통계량을 줬을때 $\\hat{\\theta}$의 업그레이드 방법은 \n\n$$\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$$\n\n와 같이 할 수 있는데 이는 충분통계량 $S$의 정보를 받아서 어떠한 방식으로 업데이트된 $\\hat{\\theta}$ 이므로 $S$의 함수라 해석할 수 있다. \n\n`-` 이론 (라오블랙웰, @Thm, 4.5): $\\hat{\\theta}$가 UB일때 충분통계량의 값을 알려주면 $\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)$와 같이 $\\hat{\\theta}$를 업그레이드 할 수 있다.  \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"2023-05-13-추정 for JY.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.315","theme":"cosmo","code-copy":true,"title-block-banner":true,"title":"**[수리통계학]** 추정 for JY","author":"신록예찬","date":"06/14/2023"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}