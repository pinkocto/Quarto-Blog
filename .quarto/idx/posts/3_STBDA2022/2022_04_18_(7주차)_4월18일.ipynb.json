{"title":"**[STBDA]** 7wk. Piece-wise LR / Logistic Regression","markdown":{"yaml":{"title":"**[STBDA]** 7wk. Piece-wise LR / Logistic Regression","author":"JiyunLim","date":"05/20/2023","categories":["빅데이터분석특강"]},"headingText":"강의영상","containsRefs":false,"markdown":"\n\n\n> youtube: https://youtube.com/playlist?list=PLQqh36zP38-ws3T1xD-bBU46dtduUlwmP\n\n### imports\n\n### piece-wise linear regression \n\nmodel: $y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x>0 \\end{cases}$ \n\n#### 풀이1: 단순회귀모형 \n\n`-` 실패: 이 모형은 epoch을 10억번 돌려도 실패할 모형임 \n- 왜? 아키텍처 설계자체가 틀렸음 \n- 꺽인부분을 표현하기에는 아키텍처의 표현력이 너무 부족하다 -> under fit의 문제 \n\n#### 풀이2: 비선형 활성화 함수의 도입 \n\n`-` 여기에서 비선형 활성화 함수는 relu\n\n`-` 네트워크를 아래와 같이 수정하자. \n\n(수정전) hat은 생략\n\n(수정후) hat은 생략\n\n- 마지막에 **$f(x)=x$ 라는 함수대신에 <font color='blue'>relu</font>** 를 취하는 것으로 구조를 약간 변경 \n- **활성화함수(acitivation function)를 indentity에서 relu로 변경**\n\n`-` relu함수란? \n\n- 파란색을 주황색으로 바꿔주는 것이 렐루함수임 \n- $f(x)=\\max(0,x)=\\begin{cases} 0 & x\\leq 0 \\\\ x & x>0 \\end{cases}$\n\n`-` 아키텍처: $\\hat{y}_i=relu(\\hat{w}_0+\\hat{w}_1x_i)$,  $relu(x)=\\max(0,x)$\n\n`-` 풀이시작 \n\n**1단계**\n\n**2단계**\n\n- l1에 있는 weight가 net2에 그대로 들어가게 된다.\n- 왜 시드고정이 안되는거지??\n\n(네트워크 상황 확인)\n\n**3단계**\n\n**4단계**\n\n`-` result\n\n`-` discussion \n- 이것 역시 수백억번 에폭을 반복해도 이 이상 적합이 힘들다 $\\to$ 모형의 표현력이 떨어진다. \n- 해결책: 주황색점선이 2개 있다면 어떨까? \n\n#### 풀이3: 노드수추가 + 레이어추가\n\n목표: 2개의 주황색 점선을 만들자. \n\n**1단계** \n\n**2단계** \n\n(네트워크 상황 확인) \n\n- 출력차원이 2라고 했으니까!\n\n`-` 이 상태에서는 yhat이 안나온다. 왜? \n- 차원이 안맞음. `a1(l1(x))`의 차원은 (N,2)인데 최종적인 yhat의 차원은 (N,1)이어야 함. (선이 하나여야 하잖아..)\n- 차원이 어찌저찌 맞다고 쳐도 relu를 통과하면 항상 yhat>0 임. 따라서 음수값을 가지는 y는 0으로 밖에 맞출 수 없음. \n\n`-` 해결책: a1(l1(x))에 연속으로(Sequential하게!) 또 다른 레이어를 설계! (N,2) -> (N,1) 이 되도록! \n- `yhat= bias + weight1 * a1(l1(x))[0] + weight2 * a1(l1(x))[1]` \n\n`-` 즉 a1(l1(x)) 를 새로운 입력으로 해석하고 출력을 만들어주는 선형모형을 다시태우면 된다. \n- 입력차원: 2 \n- 출력차원: 1 \n\n- Dense layer $\\to$ activation $\\to$ Dense layer\n\n`-` 추정해야할 파라메터수가 4,0,3으로 나온다. \n\n`-` 수식표현: $X \\to X@W^{(1)}+b^{(1)} \\to relu(X@W^{(1)}+b^{(1)}) \\to relu(X@W^{(1)}+b^{(1)})@W^{(2)}+b^{(2)}=yhat$\n\n- $X$: (N,1) \n- $W^{(1)}$: (1,2) ==> 파라메터 2개 추정 \n- $b^{(1)}$: (2,) ==> 파라메터 2개가 추가 // 여기까지 추정할 파라메터는 4개 \n- $W^{(2)}$: (2,1) ==> 파라메터 2개 추정 \n- $b^{(2)}$: (1,) ==> 파라메터 1개가 추가 // 따라서 3개\n\n`-` 참고: 추정할 파라메터수가 많다 = 복잡한 모형이다. \n- 초거대AI: 추정할 파라메터수가 엄청 많은.. \n\n`-` 좀 더 간단한 수식표현: $X \\to (u_1 \\to v_1) \\to (u_2 \\to v_2) = yhat$\n- $u_1= X@W^{(1)}+b^{(1)}$\n- <font color='blue'>$v_1= relu(u_1)$</font>\n- $u_2= v_1@W^{(2)}+b^{(2)}$\n- <font color='blue'>$v_2= indentity(u_2):=yhat$</font>\n\n- 하나는 주황색선, 하나는 초록색선이 만들어진다.\n- 너무 복잡한데..?\n\n- 좀 더 간단한 형태의 아키텍쳐\n\n**3단계**\n\n**4단계**\n\n`-` 결과확인 \n\n- 잘 맞춤!\n\n`-` 분석 \n\n`-` 마지막 2개의 그림을 분석 \n\n#### 풀이3의 실패\n\n`-` 엥? 에폭이 부족한가?\n\n- 똑같은데...? 결국 에폭문제가 아니였음.\n\n`-` 실패분석 \n\n- 보니까 빨간색선이 하는 역할을 없음 \n- 그런데 생각해보니까 이 상황에서는 빨간색선이 할수 있는 일이 별로 없음 \n- 왜? 지금은 나름 파란색선에 의해서 최적화가 된 상태임 $\\to$ 빨간선이 뭔가 하려고하면 최적화된 상태가 깨질 수 있음 (loss 증가) \n- 즉 이 상황 자체가 나름 최적화된 상태이다. 이러한 현상을 \"global minimum을 찾지 못하고 **local minimum에 빠졌다\"** 라고 표현한다. \n\n확인:\n\n예상대로 계수값이 거의 다 0이다. \n\n#### 풀이4: 노드수를 더 추가한다면? \n\n`-` 노드수를 더 추가해보면 어떻게 될까? (주황색 점선이 더 여러개 있다면?)\n\n- 잘된다.. \n- 한두개의 노드가 역할을 못해도 다른노드들이 잘 보완해주는듯!\n\n`-` 노드수가 많으면 무조건 좋다? -> 대부분 나쁘지 않음. 그런데 종종 맞추지 말아야할것도 맞춤.. (overfit) \n\n- 맞추지 말아야 할 것까지 맞춘다..\n- 가장 좋은 fit은 직선으로 맞추는것.\n\n- 이 예제는 추후 다시 공부할 예정  \n\n### Logistic regression \n\n#### motive \n\n`-` 현실에서 이런 경우가 많음 \n- $x$가 커질수록 (혹은 작아질수록) 성공확률이 올라간다. \n\nex) 전자제품에 열을 많이 가할수록 불량률일 증가한다.\n\nex) 성적이 좋을수록 합격률이 증가한다.\n\n`-` 이러한 모형은 아래와 같이 설계할 수 있음 <-- 외우세요!!\n- $y_i \\sim Ber(\\pi_i)$, where $\\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}$\n\n- $\\hat{y}_i =\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+exp(-\\hat{w}_0-\\hat{w}_1x_i)}$\n\n- $loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$\n\n`-` 위와 같은 손실함수를 BCEloss라고 부른다. (BCE는 Binary Cross Entropy의 약자)\n\n#### 예제 \n\n`-` 이 아키텍처(yhat을 얻어내는 과정)를 다어어그램으로 나타내면 아래와 같다.  \n\n`-` 또는 간단하게 아래와 같이 쓸 수 있다. \n\n`-` 케라스를 이용하여 적합을 해보면 \n\n- $loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$\n\n- 거의 비슷하게 잘 추정되었다.\n\n#### MSE loss? \n\n`-` mse loss를 쓰면 왜 안되는지? \n\nMSE loss를 써서 다시 돌려보자.\n\n- 일단 BCE loss와 비교해보니까 동일 초기값, 동일 epochs에서 적합이 별로임 \n\n#### MSE loss vs BCE loss \n\n`-` MSEloss, BCEloss의 시각화 \n\n- 왼쪽곡면(MSEloss)보다 오른쪽곡면(BCEloss)이 좀더 예쁘게 생김 -> 오른쪽 곡면에서 더 학습이 잘될것 같음 \n\n#### 학습과정 시각화예시1\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: SGD, 초기값: (w0,w1) = (-3.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n- 둘이 weight이 다르니까 강제로 맞춰놓자.\n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n- 왼쪽 MSE, 오른쪽 BCE\n- MSE의 경우 너무 천천히 수렴을 한다.\n- 동일 학습조건에서 오른쪽이 학습이 더 잘된다.\n\n#### 학습과정 시각화예시2\n\n이번에는 똑같은 초깃값에 다른 옵티마이저(Adam)를 써보자.\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-3.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n**Adam을 쓴게 확실히 학습을 효율적으로 빨리함!**\n\n- 동일한 loss function에 동일한 초깃값이라 해도 Adam을 쓰면 학습이 더 빠르다.\n- 그럼 MSE+Adam 조합으로 하면 적합이 잘 되겠구나? 라고 생각할 수 있는데 그건 아님.\n\n#### 학습과정 시각화예시3\n\n이번에는 Adam을 쓸건데 다른 초깃값에서 시작해보자.\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-10.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n- 아무리 아담이라고 해도 이건 힘듬 \n\n학습을 잘 되게 하기 위해서 옵티마이저를 개선하는 것은 되게 좋은 방법이지만 그것보다 근본적으로 loss function을 좀 더 예쁘게 만드려는 노력이 훨씬 더 좋은 생각..\n\n#### discussion / Summary\n\n`-` discussion \n- mse_loss는 경우에 따라서 엄청 수렴속도가 느릴수도 있음. \n- 근본적인 문제점: mse_loss일 경우 loss function의 곡면이 예쁘지 않음. (전문용어로 convex가 아니라고 말함)\n- 좋은 옵티마지어를 이용하면 mse_loss일 경우에도 수렴속도를 올릴 수 있음 (학습과정 시각화예시2). 그렇지만 이는 근본적인 해결책은 아님. (학습과정 시각화예시3)\n\n`-` 요약: 왜 logistic regression에서 mse loss를 쓰면 안되는가? \n- **<font color='blue'>mse loss를 사용하면 손실함수가 convex하지 않으니까!</font>**\n- **<font color='green'>그리고 bce loss를 사용하면 손실함수가 convex하니까!</font>**\n","srcMarkdownNoYaml":"\n\n### 강의영상 \n\n> youtube: https://youtube.com/playlist?list=PLQqh36zP38-ws3T1xD-bBU46dtduUlwmP\n\n### imports\n\n### piece-wise linear regression \n\nmodel: $y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x>0 \\end{cases}$ \n\n#### 풀이1: 단순회귀모형 \n\n`-` 실패: 이 모형은 epoch을 10억번 돌려도 실패할 모형임 \n- 왜? 아키텍처 설계자체가 틀렸음 \n- 꺽인부분을 표현하기에는 아키텍처의 표현력이 너무 부족하다 -> under fit의 문제 \n\n#### 풀이2: 비선형 활성화 함수의 도입 \n\n`-` 여기에서 비선형 활성화 함수는 relu\n\n`-` 네트워크를 아래와 같이 수정하자. \n\n(수정전) hat은 생략\n\n(수정후) hat은 생략\n\n- 마지막에 **$f(x)=x$ 라는 함수대신에 <font color='blue'>relu</font>** 를 취하는 것으로 구조를 약간 변경 \n- **활성화함수(acitivation function)를 indentity에서 relu로 변경**\n\n`-` relu함수란? \n\n- 파란색을 주황색으로 바꿔주는 것이 렐루함수임 \n- $f(x)=\\max(0,x)=\\begin{cases} 0 & x\\leq 0 \\\\ x & x>0 \\end{cases}$\n\n`-` 아키텍처: $\\hat{y}_i=relu(\\hat{w}_0+\\hat{w}_1x_i)$,  $relu(x)=\\max(0,x)$\n\n`-` 풀이시작 \n\n**1단계**\n\n**2단계**\n\n- l1에 있는 weight가 net2에 그대로 들어가게 된다.\n- 왜 시드고정이 안되는거지??\n\n(네트워크 상황 확인)\n\n**3단계**\n\n**4단계**\n\n`-` result\n\n`-` discussion \n- 이것 역시 수백억번 에폭을 반복해도 이 이상 적합이 힘들다 $\\to$ 모형의 표현력이 떨어진다. \n- 해결책: 주황색점선이 2개 있다면 어떨까? \n\n#### 풀이3: 노드수추가 + 레이어추가\n\n목표: 2개의 주황색 점선을 만들자. \n\n**1단계** \n\n**2단계** \n\n(네트워크 상황 확인) \n\n- 출력차원이 2라고 했으니까!\n\n`-` 이 상태에서는 yhat이 안나온다. 왜? \n- 차원이 안맞음. `a1(l1(x))`의 차원은 (N,2)인데 최종적인 yhat의 차원은 (N,1)이어야 함. (선이 하나여야 하잖아..)\n- 차원이 어찌저찌 맞다고 쳐도 relu를 통과하면 항상 yhat>0 임. 따라서 음수값을 가지는 y는 0으로 밖에 맞출 수 없음. \n\n`-` 해결책: a1(l1(x))에 연속으로(Sequential하게!) 또 다른 레이어를 설계! (N,2) -> (N,1) 이 되도록! \n- `yhat= bias + weight1 * a1(l1(x))[0] + weight2 * a1(l1(x))[1]` \n\n`-` 즉 a1(l1(x)) 를 새로운 입력으로 해석하고 출력을 만들어주는 선형모형을 다시태우면 된다. \n- 입력차원: 2 \n- 출력차원: 1 \n\n- Dense layer $\\to$ activation $\\to$ Dense layer\n\n`-` 추정해야할 파라메터수가 4,0,3으로 나온다. \n\n`-` 수식표현: $X \\to X@W^{(1)}+b^{(1)} \\to relu(X@W^{(1)}+b^{(1)}) \\to relu(X@W^{(1)}+b^{(1)})@W^{(2)}+b^{(2)}=yhat$\n\n- $X$: (N,1) \n- $W^{(1)}$: (1,2) ==> 파라메터 2개 추정 \n- $b^{(1)}$: (2,) ==> 파라메터 2개가 추가 // 여기까지 추정할 파라메터는 4개 \n- $W^{(2)}$: (2,1) ==> 파라메터 2개 추정 \n- $b^{(2)}$: (1,) ==> 파라메터 1개가 추가 // 따라서 3개\n\n`-` 참고: 추정할 파라메터수가 많다 = 복잡한 모형이다. \n- 초거대AI: 추정할 파라메터수가 엄청 많은.. \n\n`-` 좀 더 간단한 수식표현: $X \\to (u_1 \\to v_1) \\to (u_2 \\to v_2) = yhat$\n- $u_1= X@W^{(1)}+b^{(1)}$\n- <font color='blue'>$v_1= relu(u_1)$</font>\n- $u_2= v_1@W^{(2)}+b^{(2)}$\n- <font color='blue'>$v_2= indentity(u_2):=yhat$</font>\n\n- 하나는 주황색선, 하나는 초록색선이 만들어진다.\n- 너무 복잡한데..?\n\n- 좀 더 간단한 형태의 아키텍쳐\n\n**3단계**\n\n**4단계**\n\n`-` 결과확인 \n\n- 잘 맞춤!\n\n`-` 분석 \n\n`-` 마지막 2개의 그림을 분석 \n\n#### 풀이3의 실패\n\n`-` 엥? 에폭이 부족한가?\n\n- 똑같은데...? 결국 에폭문제가 아니였음.\n\n`-` 실패분석 \n\n- 보니까 빨간색선이 하는 역할을 없음 \n- 그런데 생각해보니까 이 상황에서는 빨간색선이 할수 있는 일이 별로 없음 \n- 왜? 지금은 나름 파란색선에 의해서 최적화가 된 상태임 $\\to$ 빨간선이 뭔가 하려고하면 최적화된 상태가 깨질 수 있음 (loss 증가) \n- 즉 이 상황 자체가 나름 최적화된 상태이다. 이러한 현상을 \"global minimum을 찾지 못하고 **local minimum에 빠졌다\"** 라고 표현한다. \n\n확인:\n\n예상대로 계수값이 거의 다 0이다. \n\n#### 풀이4: 노드수를 더 추가한다면? \n\n`-` 노드수를 더 추가해보면 어떻게 될까? (주황색 점선이 더 여러개 있다면?)\n\n- 잘된다.. \n- 한두개의 노드가 역할을 못해도 다른노드들이 잘 보완해주는듯!\n\n`-` 노드수가 많으면 무조건 좋다? -> 대부분 나쁘지 않음. 그런데 종종 맞추지 말아야할것도 맞춤.. (overfit) \n\n- 맞추지 말아야 할 것까지 맞춘다..\n- 가장 좋은 fit은 직선으로 맞추는것.\n\n- 이 예제는 추후 다시 공부할 예정  \n\n### Logistic regression \n\n#### motive \n\n`-` 현실에서 이런 경우가 많음 \n- $x$가 커질수록 (혹은 작아질수록) 성공확률이 올라간다. \n\nex) 전자제품에 열을 많이 가할수록 불량률일 증가한다.\n\nex) 성적이 좋을수록 합격률이 증가한다.\n\n`-` 이러한 모형은 아래와 같이 설계할 수 있음 <-- 외우세요!!\n- $y_i \\sim Ber(\\pi_i)$, where $\\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}$\n\n- $\\hat{y}_i =\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+exp(-\\hat{w}_0-\\hat{w}_1x_i)}$\n\n- $loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$\n\n`-` 위와 같은 손실함수를 BCEloss라고 부른다. (BCE는 Binary Cross Entropy의 약자)\n\n#### 예제 \n\n`-` 이 아키텍처(yhat을 얻어내는 과정)를 다어어그램으로 나타내면 아래와 같다.  \n\n`-` 또는 간단하게 아래와 같이 쓸 수 있다. \n\n`-` 케라스를 이용하여 적합을 해보면 \n\n- $loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)$\n\n- 거의 비슷하게 잘 추정되었다.\n\n#### MSE loss? \n\n`-` mse loss를 쓰면 왜 안되는지? \n\nMSE loss를 써서 다시 돌려보자.\n\n- 일단 BCE loss와 비교해보니까 동일 초기값, 동일 epochs에서 적합이 별로임 \n\n#### MSE loss vs BCE loss \n\n`-` MSEloss, BCEloss의 시각화 \n\n- 왼쪽곡면(MSEloss)보다 오른쪽곡면(BCEloss)이 좀더 예쁘게 생김 -> 오른쪽 곡면에서 더 학습이 잘될것 같음 \n\n#### 학습과정 시각화예시1\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: SGD, 초기값: (w0,w1) = (-3.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n- 둘이 weight이 다르니까 강제로 맞춰놓자.\n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n- 왼쪽 MSE, 오른쪽 BCE\n- MSE의 경우 너무 천천히 수렴을 한다.\n- 동일 학습조건에서 오른쪽이 학습이 더 잘된다.\n\n#### 학습과정 시각화예시2\n\n이번에는 똑같은 초깃값에 다른 옵티마이저(Adam)를 써보자.\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-3.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n**Adam을 쓴게 확실히 학습을 효율적으로 빨리함!**\n\n- 동일한 loss function에 동일한 초깃값이라 해도 Adam을 쓰면 학습이 더 빠르다.\n- 그럼 MSE+Adam 조합으로 하면 적합이 잘 되겠구나? 라고 생각할 수 있는데 그건 아님.\n\n#### 학습과정 시각화예시3\n\n이번에는 Adam을 쓸건데 다른 초깃값에서 시작해보자.\n\n`-` 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-10.0,-1.0) \n\n(1) 데이터정리 \n\n(2) 1ter돌려봄 \n\n(4) 학습과정기록: 15에폭마다 기록 \n\n(5) 시각화\n\n- 아무리 아담이라고 해도 이건 힘듬 \n\n학습을 잘 되게 하기 위해서 옵티마이저를 개선하는 것은 되게 좋은 방법이지만 그것보다 근본적으로 loss function을 좀 더 예쁘게 만드려는 노력이 훨씬 더 좋은 생각..\n\n#### discussion / Summary\n\n`-` discussion \n- mse_loss는 경우에 따라서 엄청 수렴속도가 느릴수도 있음. \n- 근본적인 문제점: mse_loss일 경우 loss function의 곡면이 예쁘지 않음. (전문용어로 convex가 아니라고 말함)\n- 좋은 옵티마지어를 이용하면 mse_loss일 경우에도 수렴속도를 올릴 수 있음 (학습과정 시각화예시2). 그렇지만 이는 근본적인 해결책은 아님. (학습과정 시각화예시3)\n\n`-` 요약: 왜 logistic regression에서 mse loss를 쓰면 안되는가? \n- **<font color='blue'>mse loss를 사용하면 손실함수가 convex하지 않으니까!</font>**\n- **<font color='green'>그리고 bce loss를 사용하면 손실함수가 convex하니까!</font>**\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022_04_18_(7주차)_4월18일.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.315","theme":"cosmo","code-copy":true,"title-block-banner":true,"title":"**[STBDA]** 7wk. Piece-wise LR / Logistic Regression","author":"JiyunLim","date":"05/20/2023","categories":["빅데이터분석특강"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}