{"title":"**[STBDA]** 12wk. CNN / 모형성능 향상을 위한 노력들","markdown":{"yaml":{"title":"**[STBDA]** 12wk. CNN / 모형성능 향상을 위한 노력들","author":"JiyunLim","date":"07/11/2023","categories":["빅데이터분석특강"]},"headingText":"강의영상","containsRefs":false,"markdown":"\n\n\n> youtube: https://youtube.com/playlist?list=PLQqh36zP38-xOfpHJG0LrtYt4TUVgqUNy\n\n## imports\n\n## CNN\n\n### CONV의 역할\n\n`-` 데이터생성 (그냥 흑백대비 데이터)\n\n- 값이 크면 흰색, 값이 작으면 검정색으로 되어있음.\n\n여기다 적당한 noise를 섞어보자.\n\n`-` conv layer 생성\n\n- 이제 가중치가 생김.\n\n`-` 가중치의 값을 확인해보자.\n\n- `shape=(2, 2, 1, 2)` : 커널사이즈 2x2 // XXX의 채널 1 // Conv(XXX)의 출력채널 2\n\n```python\n## 참고\nconv = tf.keras.layers.Conv2D(2,(2,2))\n\n# 여기서 unit을 2개로 받았으니까 2개의 출력 채널이 만들어진다.\n```\n\n`-` 필터값을 원하는 것으로 변경해보자.\n\n- 첫번째는 평균을 구하는 필터,\n- 두번째는 엣지를 검출하는 필터\n\n`-` 필터를 넣은 결과를 확인\n\n`-` 각 채널을 시각화\n\n- 2사분면: 원래이미지\n- 3사분면: 원래이미지 -> 평균을 의미하는 conv적용\n- 4사분면: 원래이미지 -> 엣지를 검출하는 conv적용\n\n`-` conv(XXX)의 각 채널에 한번더 conv를 통과시켜보자\n\n- channel0 : 평균필터\n- channel1 : 엣지필터\n\n`-` 요약\n- conv의 weight에 따라서 엣지를 검출하는 필터가 만들어지기도 하고 스무딩의 역할을 하는 필터가 만들어지기도 한다. 그리고 우리는 의미를 알 수 없지만 어떠한 역할을 하는 필터가 만들어질 것이다.\n- 이것들을 조합하다보면 우연히 이미지를 분류하기에 유리한 특징을 뽑아내는 weight가 맞춰질 수도 있겠다.\n- 채널수를 많이 만들고 다양한 웨이트조합을 실험하다보면 보다 복잡한 이미지의 특징을 추출할 수도 있을 것이다?\n- 컨볼루션 레이어의 역할 = **<font color='red'>이미지의 특징을 추출하는 역할</font>**\n\n### (참고) 스트라이드, 패딩\n\n`-` 참고: 스트라이드, 패딩\n- 스트라이드: 윈도우가 1칸씩 이동하는 것이 아니라 2~3칸씩 이동함\n- 패딩: 이미지의 가장자리에 정당한 값을 넣어서 (예를들어 0) 컨볼루션을 수행. 따라서 컨볼루션 연산 이후에도 이미지의 크기가 줄어들지 않도록 방지한다.\n\n### MAXPOOL\n\n`-` 기본적역할: 이미지의 크기를 줄이는 것\n- 이미지의의 크기를 줄여야하는 이유? 어차피 최종적으로 10차원으로 줄어야하므로\n- 이미지의 크기를 줄이면서도 동시에 아주 크리티컬한 특징은 손실없이 유지하고 싶다~\n\n`-` 점점 작은 이미지가 되면서 중요한 특징들은 살아남지만 그렇지 않으면 죽는다. (캐리커쳐 느낌)\n\n`-` 평균이 아니라 max를 쓴 이유는? 그냥 평균보다 나을것이라고 생각했음..\n- 그런데 사실은 꼭 그렇지만은 않아서 최근에는 꼭 맥스풀링을 고집하진 않는 추세 (평균풀링도 많이씀)\n\n### CNN 아키텍처의 표현방법\n\n`-` 아래와 같이 아키텍처의 다이어그램형태로 표현하고 굳이 노드별로 이미지를 그리진 않음\n\n![위키에서 긁어온 이미지](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/2560px-Comparison_image_neural_networks.svg.png)\n\n`-` 물론 아래와 같이 그리는 경우도 있음\n\n![](https://editor.analyticsvidhya.com/uploads/90650dnn2.jpeg)\n\n### Discusstion about CNN\n\n`-` 격자형태로 배열된 자료를 처리하는데 특화된 신경망이다.\n- 시계열 (1차원격자), 이미지 (2차원격자)\n\n`-` 실제응용에서 엄청난 성공을 거두었다.\n\n`-` 이름의 유래는 컨볼루션이라는 수학적 연산을 사용했기 때문\n- 컨볼루션은 조금 특별한 선형변환이다.\n\n`-` 신경과학의 원리가 심층학습에 영향을 미친 사례이다.\n\n### CNN의 모티브\n\n`-` 희소성 + 매개변수의 공유\n- 다소 철학적인 모티브임\n- 희소성: 이미지를 분석하여 특징을 뽑아낼때 부분부분의 특징만 뽑으면 된다는 의미^[케리커쳐 처럼.]\n- 매개변수의 공유: 한 채널에는 하나의 역할을 하는 커널을 설계하면 된다는 의미 (스무딩이든 엣징이든). 즉 어떤지역은 스무딩, 어떤지역은 엣징을 할 필요가 없이 한채널에서는 엣징만, 다른채널에서는 스무딩만 수행한뒤 여러채널을 조합해서 이해하면 된다.\n\n`-` 매개변수 공유효과로 인해서 파라메터가 확 줄어든다.\n\n(예시) (1,6,6,1) -> (1,5,5,2)\n- MLP방식이면 (36,50) 의 차원을 가진 매트릭스가 필요함 => 1800개의 매개변수 필요\n- CNN은 8개의 매개변수 필요\n\n- 매개변수가 적으면 GPU에 올릴때 좋음.\n\n### CNN 신경망의 기본구조\n\n`-` 기본유닛\n- conv^[DNN식으로 이해: linear transform] - activation^[non-linear activation] - pooling^[축소]\n- conv^[linear transform] - conv^[linear transform] - activation^[non-linear activation] - pooling^[축소]\n\n## 모형의 성능을 올리기 위한 노력들\n\n### dropout\n\n`-` 아래의 예제를 복습하자.\n\n- 이 예제는 랜덤으로 만든 데이터이기 때문에 fitting을 하면 직선이 나와야 한다.\n- 그게 아니라면 오퍼피팅.\n\nDense layer를 $2048$로 받아서 오버피팅이 일어나기 좋은 환경을 일부러 만들고 있다.\n\n- 얘는 랜덤인데^[얘를 가장 잘맞추는 하나의 직선을 골라라 하면 0근처 직선.] 위와 같이 데이터를 따라가는 피팅 결과가 나오면 오버피팅이라고 할 수 있다.\n\n- 이러한 추세가 있는게 맞을수도 있지 않느냐? 라고 생각할 수 있는데 그것을 아님을 보이기 위해 train/test로 나누어서 생각해보자.\n\n`-` train/test로 나누어서 생각해보자.\n\n- train에서 추세를 따라가는게 좋은게 아니다 $\\to$ 그냥 직선으로 핏하는거 이외에는 다 오버핏이다.\n\n(생각) 우리가 노드를 $2048$개를 만들었었는데 학습을 해보니 과적합이 일어났다. 즉, 노드들이 학습을 너무 열심히 했다. 학습을 좀 더 대충했으면 이렇게 세밀하게는 안따라갔을 텐데..\n\n`-` 매 에폭마다 적당히 80%의 노드들을 빼고 학습하자 $\\to$ 너무 잘 학습되는 문제는 생기지 않을 것이다 (과적합이 방지될것이다?)\n\n- 오버핏이 확실히 줄어들었다. (완전히 없어진 것은 아니지만)\n\n::: {.callout-note}\n$80\\%$ 노드를 빼고 학습하면 특징을 잘 학습하지 못하는거 아니냐? 라고 생각할 수 있지만 그렇게 중요한 특징이면 노드들을 랜덤으로 빼도 결국 학습을 해낼 것이라는 믿음이 있는 것이다. 증명이 있는건 아니지만 그렇게 믿음. 그러한 직관이 있다.\n:::\n\n`-` 드랍아웃에 대한 summary\n- 직관: 특정노드를 랜덤으로 off시키면 학습이 방해되어 오히려 과적합이 방지되는 효과가 있다 (그렇지만 진짜 중요한 특징이라면 랜덤으로 off 되더라도 어느정도는 학습될 듯)\n- note: 드랍아웃을 쓰면 오버핏이 줄어드는건 맞지만 완전히 없어지는건 아니다.\n- note: 오버핏을 줄이는 유일한 방법이 드랍아웃만 있는것도 아니며, 드랍아웃이 오버핏을 줄이는 가장 효과적인 방법도 아니다 (최근에는 dropout보다 batch nomalization을 사용하는 추세임)\n\n### train / val / test\n\n만약 train으로 에폭 5000정도로 열심히 학습했다고 가정해보자. 그런데 테스트를 해봤더니  오버피팅이 심한 엉뚱한 모형이 나왔다면 너무 아깝다. (비효율적)\n\ntrain, validation을 비교해보고, validation loss가 줄어들지 않고 오히려 overfitting이 되면서 커진다면 학습의 에폭을 줄여봐야겠다 내지는 노드를 줄여봐야 겠다 이런식으로 조정을 할 수 있다.\n\n`-` data\n\nFashion MNIST 데이터셋은 위 그림과 같이 운동화, 셔츠, 샌들과 같은 작은 이미지들의 모음이며, 기본 MNIST 데이터셋과 같이 열 가지로 분류될 수 있는 28×28 픽셀의 이미지 70,000개로 이루어져 있습니다.\n\n![Fashion MNIST 이미지 데이터셋.](attachment:f992e926-c7c3-4f46-b89c-74662e926813.png)\n\n- 40에폭쯤에서 멈췄었어야 할 것 같은데?\n- 그래서 나온 개념이 early stopping!\n\n`-` 텐서보드 여는 방법1\n\n![](attachment:d59d818a-2e0f-46b2-9c25-31614e8657d1.png)\n\n- train accuray는 점점 증가하는데 validation accuracy는 오히려 지지부진해 지다 점점 떨어진다. $\\to$ 오버피팅의 징조\n- training loss는 계속 떨어지고 있지만 validation loss는 감소하다 어느 시점이 지나면 오히려 점점 증가한다. $\\to$ 오버피팅의 징조\n\n::: {.callout-warning title=\"(참고사항) 파이썬 3.10의 경우 아래의 수정이 필요\"}\n\n`?/python3.10/site-packages/tensorboard/_vendor/html5lib/_trie/_base.py` 을 열고\n```python\nfrom collections import Mapping ### 수정전\nfrom collections.abc import Mapping ### 수정후\n```\n와 같이 수정한다.\n\n- 왜냐하면 파이썬 3.10부터 `from collections import Mapping` 가 동작하지 않고 `from collections.abc import Mapping` 가 동작하도록 문법이 바뀜\n:::\n\n`-` 텐서보드를 실행하는 방법2\n\n### 조기종료\n\n`-` 텐서보드를 살펴보니 특정에폭 이후에는 오히려 과적합이 진행되는 듯 하다 (학습할수록 손해인듯 하다) $\\to$ 그 특정에폭까지만 학습해보자\n\n`-` 몇 번 좀 참았다가 멈추면 좋겠다.\n\n`-` 텐서보드로 그려보자?\n\n`-` 조기종료와 텐서보드를 같이 쓰려면?\n\n![EarlyStopping을 적용한 결과 텐서보드로 실행한 결과](attachment:60249ac2-7a54-4044-a69d-507d683fbf24.png)\n\n### 하이퍼파라메터 선택\n\n`-` 하이퍼파라메터 설정\n\n![](attachment:312540fb-617e-4cee-a15e-01e96dea2b47.png)\n\n## 숙제\n\n`-` 아래의 네트워크에서 옵티마이저를 adam, sgd를 선택하여 각각 적합시켜보고 testset의 loss를 성능비교를 하라. epoch은 5정도로 설정하라.\n```\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer=???,loss=tf.losses.categorical_crossentropy,metrics=['accuracy','Recall'])\n```\n","srcMarkdownNoYaml":"\n\n## 강의영상\n\n> youtube: https://youtube.com/playlist?list=PLQqh36zP38-xOfpHJG0LrtYt4TUVgqUNy\n\n## imports\n\n## CNN\n\n### CONV의 역할\n\n`-` 데이터생성 (그냥 흑백대비 데이터)\n\n- 값이 크면 흰색, 값이 작으면 검정색으로 되어있음.\n\n여기다 적당한 noise를 섞어보자.\n\n`-` conv layer 생성\n\n- 이제 가중치가 생김.\n\n`-` 가중치의 값을 확인해보자.\n\n- `shape=(2, 2, 1, 2)` : 커널사이즈 2x2 // XXX의 채널 1 // Conv(XXX)의 출력채널 2\n\n```python\n## 참고\nconv = tf.keras.layers.Conv2D(2,(2,2))\n\n# 여기서 unit을 2개로 받았으니까 2개의 출력 채널이 만들어진다.\n```\n\n`-` 필터값을 원하는 것으로 변경해보자.\n\n- 첫번째는 평균을 구하는 필터,\n- 두번째는 엣지를 검출하는 필터\n\n`-` 필터를 넣은 결과를 확인\n\n`-` 각 채널을 시각화\n\n- 2사분면: 원래이미지\n- 3사분면: 원래이미지 -> 평균을 의미하는 conv적용\n- 4사분면: 원래이미지 -> 엣지를 검출하는 conv적용\n\n`-` conv(XXX)의 각 채널에 한번더 conv를 통과시켜보자\n\n- channel0 : 평균필터\n- channel1 : 엣지필터\n\n`-` 요약\n- conv의 weight에 따라서 엣지를 검출하는 필터가 만들어지기도 하고 스무딩의 역할을 하는 필터가 만들어지기도 한다. 그리고 우리는 의미를 알 수 없지만 어떠한 역할을 하는 필터가 만들어질 것이다.\n- 이것들을 조합하다보면 우연히 이미지를 분류하기에 유리한 특징을 뽑아내는 weight가 맞춰질 수도 있겠다.\n- 채널수를 많이 만들고 다양한 웨이트조합을 실험하다보면 보다 복잡한 이미지의 특징을 추출할 수도 있을 것이다?\n- 컨볼루션 레이어의 역할 = **<font color='red'>이미지의 특징을 추출하는 역할</font>**\n\n### (참고) 스트라이드, 패딩\n\n`-` 참고: 스트라이드, 패딩\n- 스트라이드: 윈도우가 1칸씩 이동하는 것이 아니라 2~3칸씩 이동함\n- 패딩: 이미지의 가장자리에 정당한 값을 넣어서 (예를들어 0) 컨볼루션을 수행. 따라서 컨볼루션 연산 이후에도 이미지의 크기가 줄어들지 않도록 방지한다.\n\n### MAXPOOL\n\n`-` 기본적역할: 이미지의 크기를 줄이는 것\n- 이미지의의 크기를 줄여야하는 이유? 어차피 최종적으로 10차원으로 줄어야하므로\n- 이미지의 크기를 줄이면서도 동시에 아주 크리티컬한 특징은 손실없이 유지하고 싶다~\n\n`-` 점점 작은 이미지가 되면서 중요한 특징들은 살아남지만 그렇지 않으면 죽는다. (캐리커쳐 느낌)\n\n`-` 평균이 아니라 max를 쓴 이유는? 그냥 평균보다 나을것이라고 생각했음..\n- 그런데 사실은 꼭 그렇지만은 않아서 최근에는 꼭 맥스풀링을 고집하진 않는 추세 (평균풀링도 많이씀)\n\n### CNN 아키텍처의 표현방법\n\n`-` 아래와 같이 아키텍처의 다이어그램형태로 표현하고 굳이 노드별로 이미지를 그리진 않음\n\n![위키에서 긁어온 이미지](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/2560px-Comparison_image_neural_networks.svg.png)\n\n`-` 물론 아래와 같이 그리는 경우도 있음\n\n![](https://editor.analyticsvidhya.com/uploads/90650dnn2.jpeg)\n\n### Discusstion about CNN\n\n`-` 격자형태로 배열된 자료를 처리하는데 특화된 신경망이다.\n- 시계열 (1차원격자), 이미지 (2차원격자)\n\n`-` 실제응용에서 엄청난 성공을 거두었다.\n\n`-` 이름의 유래는 컨볼루션이라는 수학적 연산을 사용했기 때문\n- 컨볼루션은 조금 특별한 선형변환이다.\n\n`-` 신경과학의 원리가 심층학습에 영향을 미친 사례이다.\n\n### CNN의 모티브\n\n`-` 희소성 + 매개변수의 공유\n- 다소 철학적인 모티브임\n- 희소성: 이미지를 분석하여 특징을 뽑아낼때 부분부분의 특징만 뽑으면 된다는 의미^[케리커쳐 처럼.]\n- 매개변수의 공유: 한 채널에는 하나의 역할을 하는 커널을 설계하면 된다는 의미 (스무딩이든 엣징이든). 즉 어떤지역은 스무딩, 어떤지역은 엣징을 할 필요가 없이 한채널에서는 엣징만, 다른채널에서는 스무딩만 수행한뒤 여러채널을 조합해서 이해하면 된다.\n\n`-` 매개변수 공유효과로 인해서 파라메터가 확 줄어든다.\n\n(예시) (1,6,6,1) -> (1,5,5,2)\n- MLP방식이면 (36,50) 의 차원을 가진 매트릭스가 필요함 => 1800개의 매개변수 필요\n- CNN은 8개의 매개변수 필요\n\n- 매개변수가 적으면 GPU에 올릴때 좋음.\n\n### CNN 신경망의 기본구조\n\n`-` 기본유닛\n- conv^[DNN식으로 이해: linear transform] - activation^[non-linear activation] - pooling^[축소]\n- conv^[linear transform] - conv^[linear transform] - activation^[non-linear activation] - pooling^[축소]\n\n## 모형의 성능을 올리기 위한 노력들\n\n### dropout\n\n`-` 아래의 예제를 복습하자.\n\n- 이 예제는 랜덤으로 만든 데이터이기 때문에 fitting을 하면 직선이 나와야 한다.\n- 그게 아니라면 오퍼피팅.\n\nDense layer를 $2048$로 받아서 오버피팅이 일어나기 좋은 환경을 일부러 만들고 있다.\n\n- 얘는 랜덤인데^[얘를 가장 잘맞추는 하나의 직선을 골라라 하면 0근처 직선.] 위와 같이 데이터를 따라가는 피팅 결과가 나오면 오버피팅이라고 할 수 있다.\n\n- 이러한 추세가 있는게 맞을수도 있지 않느냐? 라고 생각할 수 있는데 그것을 아님을 보이기 위해 train/test로 나누어서 생각해보자.\n\n`-` train/test로 나누어서 생각해보자.\n\n- train에서 추세를 따라가는게 좋은게 아니다 $\\to$ 그냥 직선으로 핏하는거 이외에는 다 오버핏이다.\n\n(생각) 우리가 노드를 $2048$개를 만들었었는데 학습을 해보니 과적합이 일어났다. 즉, 노드들이 학습을 너무 열심히 했다. 학습을 좀 더 대충했으면 이렇게 세밀하게는 안따라갔을 텐데..\n\n`-` 매 에폭마다 적당히 80%의 노드들을 빼고 학습하자 $\\to$ 너무 잘 학습되는 문제는 생기지 않을 것이다 (과적합이 방지될것이다?)\n\n- 오버핏이 확실히 줄어들었다. (완전히 없어진 것은 아니지만)\n\n::: {.callout-note}\n$80\\%$ 노드를 빼고 학습하면 특징을 잘 학습하지 못하는거 아니냐? 라고 생각할 수 있지만 그렇게 중요한 특징이면 노드들을 랜덤으로 빼도 결국 학습을 해낼 것이라는 믿음이 있는 것이다. 증명이 있는건 아니지만 그렇게 믿음. 그러한 직관이 있다.\n:::\n\n`-` 드랍아웃에 대한 summary\n- 직관: 특정노드를 랜덤으로 off시키면 학습이 방해되어 오히려 과적합이 방지되는 효과가 있다 (그렇지만 진짜 중요한 특징이라면 랜덤으로 off 되더라도 어느정도는 학습될 듯)\n- note: 드랍아웃을 쓰면 오버핏이 줄어드는건 맞지만 완전히 없어지는건 아니다.\n- note: 오버핏을 줄이는 유일한 방법이 드랍아웃만 있는것도 아니며, 드랍아웃이 오버핏을 줄이는 가장 효과적인 방법도 아니다 (최근에는 dropout보다 batch nomalization을 사용하는 추세임)\n\n### train / val / test\n\n만약 train으로 에폭 5000정도로 열심히 학습했다고 가정해보자. 그런데 테스트를 해봤더니  오버피팅이 심한 엉뚱한 모형이 나왔다면 너무 아깝다. (비효율적)\n\ntrain, validation을 비교해보고, validation loss가 줄어들지 않고 오히려 overfitting이 되면서 커진다면 학습의 에폭을 줄여봐야겠다 내지는 노드를 줄여봐야 겠다 이런식으로 조정을 할 수 있다.\n\n`-` data\n\nFashion MNIST 데이터셋은 위 그림과 같이 운동화, 셔츠, 샌들과 같은 작은 이미지들의 모음이며, 기본 MNIST 데이터셋과 같이 열 가지로 분류될 수 있는 28×28 픽셀의 이미지 70,000개로 이루어져 있습니다.\n\n![Fashion MNIST 이미지 데이터셋.](attachment:f992e926-c7c3-4f46-b89c-74662e926813.png)\n\n- 40에폭쯤에서 멈췄었어야 할 것 같은데?\n- 그래서 나온 개념이 early stopping!\n\n`-` 텐서보드 여는 방법1\n\n![](attachment:d59d818a-2e0f-46b2-9c25-31614e8657d1.png)\n\n- train accuray는 점점 증가하는데 validation accuracy는 오히려 지지부진해 지다 점점 떨어진다. $\\to$ 오버피팅의 징조\n- training loss는 계속 떨어지고 있지만 validation loss는 감소하다 어느 시점이 지나면 오히려 점점 증가한다. $\\to$ 오버피팅의 징조\n\n::: {.callout-warning title=\"(참고사항) 파이썬 3.10의 경우 아래의 수정이 필요\"}\n\n`?/python3.10/site-packages/tensorboard/_vendor/html5lib/_trie/_base.py` 을 열고\n```python\nfrom collections import Mapping ### 수정전\nfrom collections.abc import Mapping ### 수정후\n```\n와 같이 수정한다.\n\n- 왜냐하면 파이썬 3.10부터 `from collections import Mapping` 가 동작하지 않고 `from collections.abc import Mapping` 가 동작하도록 문법이 바뀜\n:::\n\n`-` 텐서보드를 실행하는 방법2\n\n### 조기종료\n\n`-` 텐서보드를 살펴보니 특정에폭 이후에는 오히려 과적합이 진행되는 듯 하다 (학습할수록 손해인듯 하다) $\\to$ 그 특정에폭까지만 학습해보자\n\n`-` 몇 번 좀 참았다가 멈추면 좋겠다.\n\n`-` 텐서보드로 그려보자?\n\n`-` 조기종료와 텐서보드를 같이 쓰려면?\n\n![EarlyStopping을 적용한 결과 텐서보드로 실행한 결과](attachment:60249ac2-7a54-4044-a69d-507d683fbf24.png)\n\n### 하이퍼파라메터 선택\n\n`-` 하이퍼파라메터 설정\n\n![](attachment:312540fb-617e-4cee-a15e-01e96dea2b47.png)\n\n## 숙제\n\n`-` 아래의 네트워크에서 옵티마이저를 adam, sgd를 선택하여 각각 적합시켜보고 testset의 loss를 성능비교를 하라. epoch은 5정도로 설정하라.\n```\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer=???,loss=tf.losses.categorical_crossentropy,metrics=['accuracy','Recall'])\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022_05_23_(12주차)_5월23일.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.315","theme":"cosmo","code-copy":true,"title-block-banner":true,"title":"**[STBDA]** 12wk. CNN / 모형성능 향상을 위한 노력들","author":"JiyunLim","date":"07/11/2023","categories":["빅데이터분석특강"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}