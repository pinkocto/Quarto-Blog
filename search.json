[
  {
    "objectID": "3_stbda2022.html",
    "href": "3_stbda2022.html",
    "title": "STBDA2022",
    "section": "",
    "text": "This page is organized based on the contents of the Big Data Analysis Special Lecture (2022-1) and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n(12주차) 5월23일\n\n\n\n\n\n\nMay 30, 2023\n\n\n[STBDA] 11wk. MaxPool2D, Conv2D\n\n\nJiyunLim\n\n\n\n\nMay 28, 2023\n\n\n[STBDA] 10wk. 로지스틱 모형\n\n\nJiyunLim\n\n\n\n\nMay 26, 2023\n\n\n[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법\n\n\nJiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[STBDA] 9wk. Likelihood function\n\n\nJiyunLim\n\n\n\n\nMay 22, 2023\n\n\n[STBDA] 중간고사\n\n\nJiyunLim\n\n\n\n\nMay 20, 2023\n\n\n[STBDA] 7wk. Piece-wise LR / Logistic Regression\n\n\nJiyunLim\n\n\n\n\nMay 18, 2023\n\n\n[STBDA] 6wk. 회귀모형 적합 with keras\n\n\nJiyunLim\n\n\n\n\nMay 16, 2023\n\n\n[STBDA] 5wk. optimizer를 이용한 최적화\n\n\nJiyunLim\n\n\n\n\nMay 14, 2023\n\n\n[STBDA] 4wk. 미분 / 경사하강법\n\n\nJiyunLim\n\n\n\n\nMay 12, 2023\n\n\n[STBDA] 3wk. 텐서플로우 intro2 (tf.GradientTape())\n\n\nJiyunLim\n\n\n\n\nMay 10, 2023\n\n\n[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)\n\n\nJiyunLim\n\n\n\n\nMay 8, 2023\n\n\n[STBDA] 1wk. 강의소개 및 단순선형회귀\n\n\nJiyunLim\n\n\n\n\nJan 1, 2023\n\n\nJupyter\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_dv2022.html",
    "href": "2_dv2022.html",
    "title": "DV2022",
    "section": "",
    "text": "This page is organized based on the contents of the Data Visualization (2022-2) and lecture notes of Professor Guebin Choi of Jeonbuk National University."
  },
  {
    "objectID": "2_dv2022.html#contents",
    "href": "2_dv2022.html#contents",
    "title": "DV2022",
    "section": "Contents",
    "text": "Contents\n1. 시각화 차트 소개\n\nboxplot, histogram, lineplot, scatterplot\n\n2. 파이썬 데이터 시각화 패키지 사용법\n\nmatplotlib, seaborn, plotnine/ggplot2\n\n3. 데이터 시각화와 통계적 해석\n\n히스토그램 이퀄라이제이션\n표본상관계수, 앤스콤의 플랏, 무상관, 무상관과 독립\n\n4. Data Wrangling\n\nlambda, map\npandas: indexing\n\n5. 인포그래픽과 데이터시각화\n\n나이젤홈즈와 애드워드터프티, 찰스미나드의 도표"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog ~~~"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "",
    "text": "아이스크림을 많이 먹으면 걸리는 병(2)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "자료생성: 좀 더 그럴듯한 자료 (만들기)",
    "text": "자료생성: 좀 더 그럴듯한 자료 (만들기)\n- 지난 시간의 toy example은 데이터가 너무 작아서 억지스러움 \\(\\to\\) 기상자료개방포털, 회원가입해야 자료받을 수 있음.\n\n_df=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv')\n_df\n\n\n\n\n\n  \n    \n      \n      지점번호\n      지점명\n      일시\n      평균기온(℃)\n      최고기온(℃)\n      최고기온시각\n      최저기온(℃)\n    \n  \n  \n    \n      0\n      146\n      전주\n      2020-01-01\n      -0.5\n      4.3\n      15:09\n      -6.4\n    \n    \n      1\n      146\n      전주\n      2020-01-02\n      1.4\n      6.5\n      14:12\n      -3.0\n    \n    \n      2\n      146\n      전주\n      2020-01-03\n      2.6\n      7.6\n      13:32\n      -0.5\n    \n    \n      3\n      146\n      전주\n      2020-01-04\n      2.0\n      7.7\n      13:51\n      -2.6\n    \n    \n      4\n      146\n      전주\n      2020-01-05\n      2.5\n      8.6\n      14:05\n      -3.2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      146\n      전주\n      2021-10-13\n      19.9\n      25.5\n      14:29\n      15.6\n    \n    \n      652\n      146\n      전주\n      2021-10-14\n      20.4\n      25.5\n      13:36\n      17.0\n    \n    \n      653\n      146\n      전주\n      2021-10-15\n      18.3\n      22.0\n      13:47\n      15.7\n    \n    \n      654\n      146\n      전주\n      2021-10-16\n      12.8\n      17.4\n      0:01\n      6.5\n    \n    \n      655\n      146\n      전주\n      2021-10-17\n      6.7\n      12.4\n      15:18\n      2.2\n    \n  \n\n656 rows × 7 columns\n\n\n\n- 평균기온만 선택\n\npd.Series(_df.columns)\n\n0       지점번호\n1        지점명\n2         일시\n3    평균기온(℃)\n4    최고기온(℃)\n5     최고기온시각\n6    최저기온(℃)\ndtype: object\n\n\n\ntemp = np.array(_df.iloc[:,3])\ntemp[:5]\n\narray([-0.5,  1.4,  2.6,  2. ,  2.5])\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps = np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2*temp + eps\n\n\nplt.plot(temp,icecream,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"icecream\",size=15)\n\nText(0, 0.5, 'icecream')\n\n\n\n\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(2) \neps=np.random.normal(size=len(temp),scale=1)\ndisease= 30 + 0.5 * temp + eps\n\n\nplt.plot(temp,disease,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\n\n# 우리가 관측한 상황 (온도는 은닉되어있음)\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.xlabel(\"icecream\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\nnp.corrcoef(icecream,disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\n\n0.86정도.."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "직관: 여름만 뽑아서 plot 해보자.",
    "text": "직관: 여름만 뽑아서 plot 해보자.\n- temp>25 (여름으로 간주) 인 관측치만 플랏\n\nplt.plot(icecream[temp>25],disease[temp>25], 'o', color='C1') ## 평균기온이 25도가 넘어가면 여름이라 생각 \n\n\n\n\n- 전체적인 산점도\n\nfig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) \nax1.plot(temp,icecream,'o',alpha=0.2); ax1.set_xlabel('temp'); ax1.set_ylabel('icecream'); ax1.set_title(\"hidden1\")\nax2.plot(temp,disease,'o',alpha=0.2); ax2.set_xlabel('temp'); ax2.set_ylabel('disease'); ax2.set_title(\"hidden2\")\nax3.plot(icecream,disease,'o',alpha=0.2); ax3.set_xlabel('icecream'); ax3.set_ylabel('disease'); ax3.set_title(\"observed\")\nax4.plot(icecream,disease,'o',alpha=0.2); ax4.set_xlabel('icecream'); ax4.set_ylabel('disease'); ax4.set_title(\"observed\")\nax4.plot(icecream[temp>25],disease[temp>25],'o',label='temp>25')\nax4.legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "ggplot: 온도구간을 세분화 하여 시각화",
    "text": "ggplot: 온도구간을 세분화 하여 시각화\n- 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자.\n\n사실 지금 변수는 온도, 아이스크림판매량, 소아마비\n온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함\n\n\n# df로 자료정리\n- 일단 데이터 프레임을 정리하자.\n\ndf = pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n    \n  \n\n656 rows × 3 columns\n\n\n\n\n\n# 구간세분화\n- 온도를 카테고리화 하자 \\(\\to\\) 적당한 구긴을 설정하기 위해서 히스토그램을 그려보자.\n\ndf.temp.hist() # ? 이거 14주차쯤 배우는데 미리 스포합니다.. 엄청 편해요 \n\n<AxesSubplot:>\n\n\n\n\n\n\nplt.hist(df.temp) # 원래는 이걸 배웠죠\n\n(array([  3.,   9.,  29.,  60.,  92.,  86.,  65.,  93., 139.,  80.]),\n array([-12.4 ,  -8.16,  -3.92,   0.32,   4.56,   8.8 ,  13.04,  17.28,\n         21.52,  25.76,  30.  ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 구간은 5정도로 하면 적당할 것 같다.\n\ndef cut(x): # 이거보다 더 좋은 방법이 있을 것 같긴 한데요..\n    if x<0: \n        y='Temp: <0'\n    elif x<5: \n        y='Temp: 0~5'\n    elif x<10: \n        y='Temp: 5~10'\n    elif x<15: \n        y='Temp: 10~15'\n    elif x<20:\n        y='Temp: 15~20'\n    elif x<25: \n        y='Temp: 20~25'\n    else: \n        y='Temp: >30'\n    return y \n\n\ndf.assign(temp2 = list(map(cut,df.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\n\n# ggplot\n- 온도를 색으로 구분하면\n\nfig = ggplot(data=df.assign(temp2 = list(map(cut,df.temp))))\np1 = geom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.5)\nfig + p1\n\n\n\n\n<ggplot: (8762005360345)>\n\n\n- 추세선을 추가하면\n\nl1 = geom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n\nfig+p1+l1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762010169613)>\n\n\n\n각 온도별로 추세선은 거의 기울기가 0이다. \\(\\to\\) 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 거!\n아이스크림 판매량과 소아마비의 corr은 유의미해보이지만, 온도를 통제하였을 경우 아이스크림 판매량과 소아마비의 partial corr은 유의미해보이지 않음.\n\n\n\n# 해석\n- 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. \\(\\to\\) 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 “온도->아이스크림판매량,소아마비” 이라는 합리적인 진리를 얻을 수 있었다.\n\n온도와 같은 변수를 은닉변수라고 한다.\n\n- 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지?\n\n이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능.\n그런데 이론적으로는 “세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)” 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 “상관성=인과성”이다.\n\n- 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능\n\n피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가)\n인과추론: 실험계획이 사실상 불가능한 경우가 있음 \\(\\to\\) 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 “매칭”을 시킨다!"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?",
    "text": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?\n- 온도는 아이스크림 판매에 여전히 영향을 주지만\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps=np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2 * temp + eps \n\n- 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면?\n\\[\\text{소아마비 반응수치} = 30 + 0 \\times \\text{온도} + 0.15 \\times \\text{아이스크림 판매량} + \\epsilon\\]\n\nnp.random.seed(2) \neps = np.random.normal(size=len(temp),scale=2)\ndisease= 30+ 0*temp + 0.15*icecream + eps\n\n\ndf2=pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf2.assign(temp2=list(map(cut,df2.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      34.453002\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      32.389832\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      28.715350\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      35.271089\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      31.461240\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.693811\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.924088\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      41.765212\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.842022\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      37.715537\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\nggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+\\\ngeom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.2)+\\\ngeom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762005194073)>\n\n\n\n이번엔 partial corr도 유의미하게 나옴\n\n- 단순 corr을 봐서는 “온도->아이스크림,소아마비” 인지, “온도->아이스크림->소아마비” 인지 알기 어렵다.\n\ndf.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.975609\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.862990\n    \n    \n      disease\n      0.975609\n      0.862990\n      1.000000\n    \n  \n\n\n\n\n\ndf2.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.725505\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.830539\n    \n    \n      disease\n      0.725505\n      0.830539\n      1.000000"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html",
    "title": "10wk-2 심슨의 역설",
    "section": "",
    "text": "심슨의 역설을 bar plot으로 시각화하는 방법과 왜 생기게 되는지에 대해 알아보자."
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#버클리대학교의-입학데이터",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#버클리대학교의-입학데이터",
    "title": "10wk-2 심슨의 역설",
    "section": "버클리대학교의 입학데이터",
    "text": "버클리대학교의 입학데이터\n\nhttps://github.com/pinkocto/Quarto-Blog/blob/main/posts/DV/ds.pdf\n\n- 주장: 버클리대학에 gender bias가 존재한다.\n\n1973년 가을학기의 입학통계에 따르면 지원하는 남성이 여성보다 훨씬 많이 합격했고, 그 차이가 너무 커서 우연의 일치라 보기 어렵다.\n\n\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack().reset_index()\\\n.rename({'level_0':'department','level_1':'result','level_2':'gender',0:'count'},axis=1)\ndf\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n    \n    \n      1\n      A\n      fail\n      male\n      314\n    \n    \n      2\n      A\n      pass\n      female\n      89\n    \n    \n      3\n      A\n      pass\n      male\n      511\n    \n    \n      4\n      B\n      fail\n      female\n      7\n    \n    \n      5\n      B\n      fail\n      male\n      208\n    \n    \n      6\n      B\n      pass\n      female\n      18\n    \n    \n      7\n      B\n      pass\n      male\n      352\n    \n    \n      8\n      C\n      fail\n      female\n      391\n    \n    \n      9\n      C\n      fail\n      male\n      204\n    \n    \n      10\n      C\n      pass\n      female\n      202\n    \n    \n      11\n      C\n      pass\n      male\n      121\n    \n    \n      12\n      D\n      fail\n      female\n      244\n    \n    \n      13\n      D\n      fail\n      male\n      279\n    \n    \n      14\n      D\n      pass\n      female\n      131\n    \n    \n      15\n      D\n      pass\n      male\n      138\n    \n    \n      16\n      E\n      fail\n      female\n      299\n    \n    \n      17\n      E\n      fail\n      male\n      137\n    \n    \n      18\n      E\n      pass\n      female\n      94\n    \n    \n      19\n      E\n      pass\n      male\n      54\n    \n    \n      20\n      F\n      fail\n      female\n      103\n    \n    \n      21\n      F\n      fail\n      male\n      149\n    \n    \n      22\n      F\n      pass\n      female\n      238\n    \n    \n      23\n      F\n      pass\n      male\n      224"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "title": "10wk-2 심슨의 역설",
    "section": "시각화1: 전체합격률",
    "text": "시각화1: 전체합격률\n- df1\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n    \n    \n      1\n      female\n      pass\n      772\n    \n    \n      2\n      male\n      fail\n      1291\n    \n    \n      3\n      male\n      pass\n      1400\n    \n  \n\n\n\n\n- df2\n\n# df.query('gender ==\"female\"')\n\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n- merge: 두개의 데이터프레임을 합친다\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- 비율계산\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n      0.579292\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n      0.420708\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n      0.479747\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n      0.520253\n    \n  \n\n\n\n\n- 시각화\n\ndata1= df.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data1.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate')) # 합격률만 시각화.\n\n\n\n\n<ggplot: (8769600261271)>\n\n\n- 결론: 남자의 합격률이 더 높다. \\(\\to\\) 성차별이 있어보인다(?)"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "title": "10wk-2 심슨의 역설",
    "section": "시각화2: 학과별 합격률",
    "text": "시각화2: 학과별 합격률\n- df2\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n    \n    \n      1\n      A\n      male\n      825\n    \n    \n      2\n      B\n      female\n      25\n    \n    \n      3\n      B\n      male\n      560\n    \n    \n      4\n      C\n      female\n      593\n    \n    \n      5\n      C\n      male\n      325\n    \n    \n      6\n      D\n      female\n      375\n    \n    \n      7\n      D\n      male\n      417\n    \n    \n      8\n      E\n      female\n      393\n    \n    \n      9\n      E\n      male\n      191\n    \n    \n      10\n      F\n      female\n      341\n    \n    \n      11\n      F\n      male\n      373\n    \n  \n\n\n\n\n- merge\n\ndf.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n      108\n      0.175926\n    \n    \n      1\n      A\n      pass\n      female\n      89\n      108\n      0.824074\n    \n    \n      2\n      A\n      fail\n      male\n      314\n      825\n      0.380606\n    \n    \n      3\n      A\n      pass\n      male\n      511\n      825\n      0.619394\n    \n    \n      4\n      B\n      fail\n      female\n      7\n      25\n      0.280000\n    \n    \n      5\n      B\n      pass\n      female\n      18\n      25\n      0.720000\n    \n    \n      6\n      B\n      fail\n      male\n      208\n      560\n      0.371429\n    \n    \n      7\n      B\n      pass\n      male\n      352\n      560\n      0.628571\n    \n    \n      8\n      C\n      fail\n      female\n      391\n      593\n      0.659359\n    \n    \n      9\n      C\n      pass\n      female\n      202\n      593\n      0.340641\n    \n    \n      10\n      C\n      fail\n      male\n      204\n      325\n      0.627692\n    \n    \n      11\n      C\n      pass\n      male\n      121\n      325\n      0.372308\n    \n    \n      12\n      D\n      fail\n      female\n      244\n      375\n      0.650667\n    \n    \n      13\n      D\n      pass\n      female\n      131\n      375\n      0.349333\n    \n    \n      14\n      D\n      fail\n      male\n      279\n      417\n      0.669065\n    \n    \n      15\n      D\n      pass\n      male\n      138\n      417\n      0.330935\n    \n    \n      16\n      E\n      fail\n      female\n      299\n      393\n      0.760814\n    \n    \n      17\n      E\n      pass\n      female\n      94\n      393\n      0.239186\n    \n    \n      18\n      E\n      fail\n      male\n      137\n      191\n      0.717277\n    \n    \n      19\n      E\n      pass\n      male\n      54\n      191\n      0.282723\n    \n    \n      20\n      F\n      fail\n      female\n      103\n      341\n      0.302053\n    \n    \n      21\n      F\n      pass\n      female\n      238\n      341\n      0.697947\n    \n    \n      22\n      F\n      fail\n      male\n      149\n      373\n      0.399464\n    \n    \n      23\n      F\n      pass\n      male\n      224\n      373\n      0.600536\n    \n  \n\n\n\n\n- 시각화\n\ndata2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8789343111249)>\n\n\n\n학과별로 살펴보니 오히려 A,B,F,D의 경우 여성의 합격률이 높다.\n\n- 교재에서 설명한 이유: 여성이 합격률이 낮은 학과에만 많이 지원하였기 때문\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='department',y='count2',fill='gender'),position='dodge')\n\n\n\n\n<ggplot: (8789343070225)>\n\n\n\n살펴보니 합격률이 높은 A,B학과의 경우 상대적으로 남성이 많이 지원하였음. 합격률이 낮은 C,D학과는 상대적으로 여성이 많이 지원함. D,F의 지원수는 비슷"
  },
  {
    "objectID": "posts/2_DV2022/dv1.html",
    "href": "posts/2_DV2022/dv1.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "# for test\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4], [1,4,9,16],'ro')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html",
    "title": "05wk-1",
    "section": "",
    "text": "seaborn(2)–scatterplot, mpl미세먼지팁(2)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#plt-복습",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#plt-복습",
    "title": "05wk-1",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.plot(x1,y1,'o')\nplt.plot(x2,y2,'o')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-array",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-array",
    "title": "05wk-1",
    "section": "sns: array",
    "text": "sns: array\n\nsns.scatterplot(data=None,x=x1,y=y1)\nsns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-wide-df",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-wide-df",
    "title": "05wk-1",
    "section": "sns: wide df",
    "text": "sns: wide df\n\nsns.scatterplot(data=pd.DataFrame({'x':x1,'y':y1}),x='x',y='y')\nsns.scatterplot(data=pd.DataFrame({'x':x2,'y':y2}),x='x',y='y')\n#sns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\n\n\n\n억지로 그리긴 했는데 이 경우는 wide하게 만든 df는 별로 경쟁력이 없음"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-long-df",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-long-df",
    "title": "05wk-1",
    "section": "sns: long df",
    "text": "sns: long df\n\nx= np.concatenate([x1,x2])\ny= np.concatenate([y1,y2])\ncat = ['x1']*len(x1) + ['x2']*len(x2)\ndf2 = pd.DataFrame({'x':x,'y':y,'cat':cat})\ndf2\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cat\n    \n  \n  \n    \n      0\n      2.023919\n      -0.400176\n      x1\n    \n    \n      1\n      1.229622\n      -1.763752\n      x1\n    \n    \n      2\n      -0.413211\n      2.293004\n      x1\n    \n    \n      3\n      -1.343073\n      0.404232\n      x1\n    \n    \n      4\n      1.062845\n      0.030775\n      x1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      2.226805\n      3.683857\n      x2\n    \n    \n      1996\n      2.768263\n      2.678292\n      x2\n    \n    \n      1997\n      2.525295\n      2.815478\n      x2\n    \n    \n      1998\n      1.750193\n      2.289812\n      x2\n    \n    \n      1999\n      1.153290\n      2.095922\n      x2\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x',y='y',hue='cat') \n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#예제1",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#예제1",
    "title": "05wk-1",
    "section": "예제1",
    "text": "예제1\n\nfig,ax = plt.subplots(1,3,figsize=(12,4))\nax[0].plot([1,2,4,3],'--o')\nsns.scatterplot(x=x1,y=y1,ax=ax[1])\nsns.scatterplot(x=x1,y=y1,ax=ax[2])\nsns.scatterplot(x=x2,y=y2,ax=ax[2])\nax[2].plot([1,2,4,3],'-r',lw=5)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#예제2",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#예제2",
    "title": "05wk-1",
    "section": "예제2",
    "text": "예제2\n\nimport cv2\n\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg \nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0)\n!rm Unequalized_Hawkes_Bay_NZ.jpg \n\n--2022-10-05 16:33:56--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   548KB/s    in 0.2s    \n\n2022-10-05 16:33:57 (548 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895]\n\n\n\n\nimg2 = cv2.equalizeHist(img)\n\n\nimg.reshape(-1)\n\narray([127, 145, 149, ..., 146, 145, 144], dtype=uint8)\n\n\n\nfig,ax = plt.subplots(2,2,figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img.reshape(-1),ax=ax[0,1],bins=15,lw=0,kde=True,color='C1')\nax[0,1].set_xlim(0,255)\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1],bins=15,lw=0,kde=True,color='C1')\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- seaborn: figure-level vs axes-level 의 개념\nref: https://seaborn.pydata.org/tutorial/function_overview.html#figure-level-vs-axes-level-functions"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-간격조정",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-간격조정",
    "title": "05wk-1",
    "section": "축 간격조정",
    "text": "축 간격조정\n\nimport matplotlib as mpl\n\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로\nax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-삭제",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-삭제",
    "title": "05wk-1",
    "section": "축 삭제",
    "text": "축 삭제\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제\nax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-범위조정",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-범위조정",
    "title": "05wk-1",
    "section": "축 범위조정",
    "text": "축 범위조정\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.set_ylim(-1,2) \nax.set_xlim(-5,35)\n#plt.ylim(-1,2)\n#plt.xlim(-5,35)\n\n(-5.0, 35.0)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#gcf-gca",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#gcf-gca",
    "title": "05wk-1",
    "section": "gcf, gca",
    "text": "gcf, gca\n- gcf\n\nplt.plot([1,2,3,2])\nfig = plt.gcf()\n\n\n\n\n\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\nfig\n\n\n\n\n- gca\n\nfig\n\n\n\n\n\nax = fig.gca()\n\n\nax.set_title('title') \nfig"
  },
  {
    "objectID": "posts/2_DV2022/9999.html",
    "href": "posts/2_DV2022/9999.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "!wget https://raw.githubusercontent.com/guebin/DV2022/main/posts/2022-10-03-5wk-1.ipynb\n\n--2023-05-21 02:24:58--  https://raw.githubusercontent.com/guebin/DV2022/main/posts/2022-10-03-5wk-1.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 488865 (477K) [text/plain]\nSaving to: ‘2022-10-03-5wk-1.ipynb’\n\n2022-10-03-5wk-1.ip 100%[===================>] 477.41K  --.-KB/s    in 0.02s   \n\n2023-05-21 02:24:58 (25.0 MB/s) - ‘2022-10-03-5wk-1.ipynb’ saved [488865/488865]"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "",
    "text": "판다스– 인덱싱(2), 판다스–새로운열의할당(1), 아이스크림을 많이 먹으면 걸리는 병(1)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#데이터",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#데이터",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "데이터",
    "text": "데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      ...\n      num_user_for_reviews\n      language\n      country\n      content_rating\n      budget\n      title_year\n      actor_2_facebook_likes\n      imdb_score\n      aspect_ratio\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      ...\n      3054.0\n      English\n      USA\n      PG-13\n      237000000.0\n      2009.0\n      936.0\n      7.9\n      1.78\n      33000\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      ...\n      1238.0\n      English\n      USA\n      PG-13\n      300000000.0\n      2007.0\n      5000.0\n      7.1\n      2.35\n      0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      ...\n      994.0\n      English\n      UK\n      PG-13\n      245000000.0\n      2015.0\n      393.0\n      6.8\n      2.35\n      85000\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      ...\n      2701.0\n      English\n      USA\n      PG-13\n      250000000.0\n      2012.0\n      23000.0\n      8.5\n      2.35\n      164000\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      7.1\n      NaN\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      ...\n      6.0\n      English\n      Canada\n      NaN\n      NaN\n      2013.0\n      470.0\n      7.7\n      NaN\n      84\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      ...\n      359.0\n      English\n      USA\n      TV-14\n      NaN\n      NaN\n      593.0\n      7.5\n      16.00\n      32000\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      ...\n      3.0\n      English\n      USA\n      NaN\n      1400.0\n      2013.0\n      0.0\n      6.3\n      NaN\n      16\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      ...\n      9.0\n      English\n      USA\n      PG-13\n      NaN\n      2012.0\n      719.0\n      6.3\n      2.35\n      660\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      ...\n      84.0\n      English\n      USA\n      PG\n      1100.0\n      2004.0\n      23.0\n      6.6\n      1.85\n      456\n    \n  \n\n4916 rows × 28 columns\n\n\n\n- 열의 이름을 출력하여 보자.\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\ndf.keys()\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "기본인덱싱 (df 인덱싱공부 1단계 내용)",
    "text": "기본인덱싱 (df 인덱싱공부 1단계 내용)\n- color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. -> loc으로는 못하겠어요..\n\ndf.loc[:,['color':'num_voted_users','aspect_ratio']] # 이건 안됨.\n\nSyntaxError: invalid syntax (<ipython-input-7-0b4cb2e2977c>, line 1)\n\n\n\ndf.loc[:,'color':'num_voted_users'].head(2) # 이건 잘 됨.\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n    \n  \n\n\n\n\n- (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. \\(\\to\\) 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 \\(\\to\\) 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음\n\npd.Series(df.columns) ## 제일 편함.\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\nlist(range(13))+[26]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26]\n\n\n\ndf.iloc[:,list(range(13))+[26]].head(2)\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "actor라는 단어가 포함된 column 선택",
    "text": "actor라는 단어가 포함된 column 선택\n- 다시 열의 이름들을 확인\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n- 방법1\n\n'actor' in 'actor_1_facebook_likes'\n\nTrue\n\n\n\n# list(map(lambda x: 'actor' in x, df.columns))\n\n\ndf.columns[list(map(lambda x: 'actor' in x, df.columns))]\n\nIndex(['actor_3_facebook_likes', 'actor_2_name', 'actor_1_facebook_likes',\n       'actor_1_name', 'actor_3_name', 'actor_2_facebook_likes'],\n      dtype='object')\n\n\n\ndf.iloc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법2\n\ndf.loc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법3\n\ndf.iloc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법4\n\ndf.loc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "s로 끝나는 column 선택",
    "text": "s로 끝나는 column 선택\n\n## 참고 (iterable object -> for문 안에 넣어서 돌릴 수 있다.)\n_map = df.loc[:,map(lambda x: x[-1] == 's', df.columns)]\nset(dir(_map)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\n_gen = iter(_map)\n\n\n_gen.__next__()\n\n'num_critic_for_reviews'\n\n\n\n_gen.__next__()\n\n'director_facebook_likes'\n\n\n- 방법1\n\ndf.iloc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "c 혹은 d로 시작하는 column 선택",
    "text": "c 혹은 d로 시작하는 column 선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n_str = 'color'\n(_str[0] == 'c') or (_str[0] =='d')\n\nTrue\n\n\n\nlist(map(lambda x: (x[0] == 'c') or (x[0] =='d'), df.columns)) # list안해도 이미 iterable object.\n\n[True,\n True,\n False,\n True,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n True,\n False,\n False,\n False,\n False,\n False,\n False]\n\n\n- 방법1\n\ndf.iloc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법1-concat",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법1-concat",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법1: concat",
    "text": "방법1: concat\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n_df = pd.DataFrame({'c':[3,4,5]}) \n_df\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      3\n    \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\npd.concat([df,_df],axis=1)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법2: 4가지 컨셉에 따른 할당",
    "text": "방법2: 4가지 컨셉에 따른 할당\n\n# 컨셉1: 불가능\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.c = pd.Series([1,2,3]) \ndf\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n# 컨셉2: 가능\n(예시1) – 사실상 이렇게 해야함.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c']=[3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 이렇게까지 할필요는 없음.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['c','d']]=np.array([[3,4,5],[4,5,6]]).T # 굳이.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c'],df['d']=[3,4,5],[4,5,6]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n# 컨셉3: 불가능\n(예시1)\n\name({'a':[1,2,3],'b':[2,3,4]})\ndfdf = pd.DataFr\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.iloc[:,2] = [3,4,5] \ndf\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n# 컨셉4: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'] = [3,4,5] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) – 굳이 쓸 필요가 없다.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,['c','d']] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'],df.loc[:,'d'] = [3,4,5],[4,5,6] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애",
    "text": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애\n\n확장성이 있고 다양한 상황에 사용하기 좋음.\n\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]) \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5],d=[4,5,6]) \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6]) # 1->2, 2->3 으로 가는 과정이 메모리 공간안에 모두 저장되어 있다.\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n오오오오 원래 df가 살아있음."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법4: .eval을 이용한 할당",
    "text": "방법4: .eval을 이용한 할당\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]').eval('d=[4,5,6]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n이 방법은 좀 꺼려하는데 아래의 예제를 통해 이유를 알아보자."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#연습해보기",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#연습해보기",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "연습해보기",
    "text": "연습해보기\n\n# 데이터프레임 생성\n\ndf=pd.DataFrame({'x':np.random.randn(1000),'y':np.random.randn(1000)})\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -0.528686\n      -0.822504\n    \n    \n      1\n      -0.570925\n      0.177597\n    \n    \n      2\n      -2.095003\n      0.334422\n    \n    \n      3\n      -0.382900\n      0.573522\n    \n    \n      4\n      -0.971033\n      -1.840163\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      0.172025\n      -0.770867\n    \n    \n      996\n      -0.086068\n      -0.087574\n    \n    \n      997\n      0.691668\n      0.850134\n    \n    \n      998\n      -0.359600\n      0.913740\n    \n    \n      999\n      0.568702\n      -0.808420\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n\n# 새로운열 r을 생성하고 \\(r=\\sqrt{x^2 + y^2}\\)를 계산\n- 방법1: 브로드캐스팅\n\ndf.assign(r=np.sqrt(df.x**2 + df.y**2))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법2: lambda + map을 이용한 개별원소 계산\n\ndf.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x,df.y)))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법3: eval\n\ndf.eval('r=sqrt(x**2+y**2)')\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.528686\n      -0.822504\n      0.977764\n    \n    \n      1\n      -0.570925\n      0.177597\n      0.597910\n    \n    \n      2\n      -2.095003\n      0.334422\n      2.121527\n    \n    \n      3\n      -0.382900\n      0.573522\n      0.689594\n    \n    \n      4\n      -0.971033\n      -1.840163\n      2.080650\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      0.172025\n      -0.770867\n      0.789828\n    \n    \n      996\n      -0.086068\n      -0.087574\n      0.122788\n    \n    \n      997\n      0.691668\n      0.850134\n      1.095962\n    \n    \n      998\n      -0.359600\n      0.913740\n      0.981954\n    \n    \n      999\n      0.568702\n      -0.808420\n      0.988415\n    \n  \n\n1000 rows × 3 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#toy-exam",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#toy-exam",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "Toy exam",
    "text": "Toy exam\n- 교재의 예제상황은 예를들면 아래와 같다.\n(숨은진짜상황1)\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1) \ntemp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, \n                25.4, 26.8, 28.9, 35.1, 32.2, 34.6])\neps= np.random.normal(size=12,scale=5)\nicecream= 20 + temp * 2 + eps\n\n\nplt.plot(temp,icecream,'.')\n\n\n\n\n\n온도와 아이스크림 판매량의 산점도\n\n(숨은진짜상황2)\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\] - 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자.\n\nnp.random.seed(2) \neps = np.random.normal(size=12,scale=5) \ndisease = 30+ temp* 0.5 + eps\n\n\nplt.plot(temp,disease,'.')\n\n\n\n\n\n온도와 소아마비의 산점도\n\n(우리가 데이터로부터 관측한 상황)\n- 아이스크림과 질병의 산점도를 그려보자.\n\nplt.plot(icecream,disease,'.')\n\n\n\n\n\n양의 상관관계에 있다.\n\n- 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. <– 여기서부터 틀렸음\n\\[{\\tt disease}_i =\\beta_0 +\\beta_1 {\\tt icecream}_i +\\epsilon_i,\\quad \\textbf{for} ~~ i=1,2,\\dots, 12\\]\n- 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. <– 틀린주장\n\n틀린 모형\n도데체 우리가 뭘 잘못했는가?\n\n- 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다.\n(ex1)\n\n온도 \\(\\to\\) 익사\n온도 \\(\\to\\) 아이스크림\n아이스크림과 익사자도 양의 상관관계에 있을것이다.\n아이스크림을 먹이면 물에 빠져 죽는다 \\(\\to\\) 틀린주장\n사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다.\n\n(ex2)\n\n인구수 \\(\\to\\) 교회\n인구수 \\(\\to\\) 범죄건수\n지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임\n교회를 지으면 범죄건수도 증가한다? \\(\\to\\) 틀린주장\n사실 인구가 숨겨진 요인임\n\n- ex2, ex1에 대하여 바른 분석을 하려면?\n\nex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임\nex1: 온도가 비슷한 그룹끼리 묶어보자.\n\n- 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. \\(\\to\\) 상관계수가 줄어들 것이다.\n\nplt.plot(icecream[:6],disease[:6],'.')\n\n\n\n\n\nplt.plot(icecream[6:],disease[6:],'.')\n\n\n\n\n\n진짜로 선형관계가 약해졌다.."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html",
    "title": "05wk-2",
    "section": "",
    "text": "훌륭한 시각화, mpg 데이터 소개, plotnine(p9)을 이용한 고차원 산점도"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#애드워드-터프티",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#애드워드-터프티",
    "title": "05wk-2",
    "section": "애드워드 터프티",
    "text": "애드워드 터프티\n- 데이터 시각화계의 거장\n- 터프티의 이론중 백미: 엄격한 미니멀리즘\n\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다.\n\n- 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량\n- 차트정크 (나이젤홈즈의 그래프)\n\n\n“Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (…) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (…) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.”\n\n\n차트정크 = 대중을 멸시 + 데이터에 대한 모독\n차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다..\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 제 생각: 글쎄…"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "title": "05wk-2",
    "section": "찰스미나드의 도표",
    "text": "찰스미나드의 도표\n\n인류역사상 가장 훌륭한 시각화\n\n\n- 터프티의 평\n\n지금까지 그려진 최고의 통계 그래픽일지도 모른다.\n여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 \\(\\to\\) 6차원의 변수\n백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. \\(\\to\\) 미니멀리즘..\n\n- 왜 우수한 그래프일까?\n\n자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존\n이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임\n미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "title": "05wk-2",
    "section": "미나드처럼 그리는게 왜 어려운가?",
    "text": "미나드처럼 그리는게 왜 어려운가?\n- 몸무게, 키, 성별, 국적\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')  \ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv') \ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv')\n\n- 미나드의 접근방법\n\n_df = pd.concat([pd.concat([df1,df2],axis=1).assign(g='m'),df3.assign(g='f')])\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')]).reset_index(drop=True)\ndf\n\n\n\n\n\n  \n    \n      \n      w\n      h\n      g\n      g2\n    \n  \n  \n    \n      0\n      72.788217\n      183.486773\n      m\n      korea\n    \n    \n      1\n      66.606430\n      173.599877\n      m\n      korea\n    \n    \n      2\n      69.806324\n      173.237903\n      m\n      korea\n    \n    \n      3\n      67.449439\n      173.223805\n      m\n      korea\n    \n    \n      4\n      70.463183\n      174.931946\n      m\n      korea\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1525\n      78.154632\n      188.324350\n      m\n      foreign\n    \n    \n      1526\n      74.754308\n      183.017979\n      f\n      foreign\n    \n    \n      1527\n      91.196208\n      190.100456\n      m\n      foreign\n    \n    \n      1528\n      87.770394\n      187.987255\n      m\n      foreign\n    \n    \n      1529\n      88.021995\n      193.456798\n      m\n      foreign\n    \n  \n\n1530 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df,x='w',y='h',hue='g',style='g2')\n\n<AxesSubplot:xlabel='w', ylabel='h'>\n\n\n\n\n\n- 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름\n\n\n기획력부족 -> 훌륭한 시각화를 많이 볼 것\n\n\n데이터프레임에 대한 이해부족 -> tidydata에 대한 개념\n\n\n프로그래밍 능력 -> 코딩공부열심히 (pandas를 엄청 잘해야함)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "title": "05wk-2",
    "section": "방법1: rpy2 (코랩 아닌경우 실습금지)",
    "text": "방법1: rpy2 (코랩 아닌경우 실습금지)\n\nimport rpy2\n%load_ext rpy2.ipython\n\n\n%%R \n### 여기는 R처럼 쓸 수 있다. \na <- c(1,2,3) \na+1\n\n[1] 2 3 4\n\n\n\na\n\nNameError: name 'a' is not defined\n\n\n\n%%R \nlibrary(tidyverse)\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nmpg\n\nNameError: name 'mpg' is not defined\n\n\n\n%R -o mpg # R에 있는 자료가 파이썬으로 넘어옴\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      5\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      234\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "title": "05wk-2",
    "section": "방법2: 저장된 csv파일을 통하여 데이터를 확보",
    "text": "방법2: 저장된 csv파일을 통하여 데이터를 확보\n\nmpg.to_csv(\"mpg.csv\",index=False)\n\n\npd.read_csv(\"mpg.csv\")\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "title": "05wk-2",
    "section": "방법3: github등에 공개된 csv를 읽어오기",
    "text": "방법3: github등에 공개된 csv를 읽어오기\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\n- 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#data-설명",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#data-설명",
    "title": "05wk-2",
    "section": "data 설명",
    "text": "data 설명\n- displ: 자동차의 엔진크기\n- hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐?\n- 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "title": "05wk-2",
    "section": "python에서: plotnine을 이용한 산점도",
    "text": "python에서: plotnine을 이용한 산점도\n\nggplot(data=mpg) + geom_point(mapping=aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726736046009)>\n\n\n\n산점도 해석: 엔진크기가 클수록 효율이 낮음.\n\n- 빠르게 그리기: data=와 mapping=은 생략가능함\n\nggplot(mpg) + geom_point(aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726735544581)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "title": "05wk-2",
    "section": "R에서: ggplot2를 이용한 산점도",
    "text": "R에서: ggplot2를 이용한 산점도\n- R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!)\n\n%%R -w 800\nggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "title": "05wk-2",
    "section": "python에서: 객체지향적인 느낌으로 산점도 그리기",
    "text": "python에서: 객체지향적인 느낌으로 산점도 그리기\nstep1: 도화지를 준비한다.\n\nfig = ggplot(data=mpg)\nfig\n\n\n\n\n<ggplot: (8726735085529)>\n\n\nstep2 변수와 에스테틱사이의 맵핑을 설정한다.\n\na1= aes(x='displ',y='hwy')\na1\n\n{'x': 'displ', 'y': 'hwy'}\n\n\nstep3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다.\n\npoint1=geom_point(mapping=a1)\n\n\ngeom_point(): 점들을 그려! 어떻게?\na1에서 설정된 표를 보고\n\nstep4 도화지와 지옴을 합친다.\n\nfig+point1\n\n\n\n\n<ggplot: (8726775447877)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경",
    "text": "산점도 + 점크기변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734563561)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도변경",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도변경",
    "title": "05wk-2",
    "section": "산점도 + 투명도변경",
    "text": "산점도 + 투명도변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734989121)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "title": "05wk-2",
    "section": "산점도 + 투명도/점크기를 동시에 적용",
    "text": "산점도 + 투명도/점크기를 동시에 적용\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734522405)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-형태",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-형태",
    "title": "05wk-2",
    "section": "산점도 + 형태",
    "text": "산점도 + 형태\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',shape='class'))\n\n\n\n\n<ggplot: (8726734265229)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔",
    "title": "05wk-2",
    "section": "산점도 + 색깔",
    "text": "산점도 + 색깔\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',color='class'))\n\n\n\n\n<ggplot: (8726734017473)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "title": "05wk-2",
    "section": "객체지향적 느낌으로?",
    "text": "객체지향적 느낌으로?\n\na2 = aes(x='displ', y='hwy', color='class') \n\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\npoint2=geom_point(a2)\n\n\nfig+point2\n\n\n\n\n<ggplot: (8726733712885)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "title": "05wk-2",
    "section": "산점도 + 색깔 + 적합선",
    "text": "산점도 + 색깔 + 적합선\n- 일단 색깔이 없는 포인트 지옴부터 연습\n\nfig+point1\n\n\n\n\n<ggplot: (8726733452617)>\n\n\n\nline1 = geom_smooth(a1)\n\n\nfig+point1+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732994973)>\n\n\n- point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능!\n\nfig+point2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732661565)>\n\n\n- 명령어로 한번에 그리기\n\nggplot(data=mpg) + \\\ngeom_point(mapping=aes(x='displ',y='hwy',color='class')) + \\\ngeom_smooth(mapping=aes(x='displ',y='hwy'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732727485)>\n\n\n- 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함)\n\nggplot(data=mpg,mapping=aes(x='displ',y='hwy')) + \\\ngeom_point(mapping=aes(color='class')) + \\\ngeom_smooth()\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733489953)>\n\n\n- R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다.\n\n%%R -w 800\nggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth()\n\nR[write to console]: `geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔",
    "text": "산점도 + 점크기변경 + 색깔\n- drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다.\n\nggplot(data=mpg, mapping=aes(x='displ',y='hwy')) + geom_point(mapping=aes(size='class',color='drv'),alpha=0.3)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731152845)>\n\n\n\n모든 \\(x\\)에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 \\(\\to\\) 4륜구동방식이 연비가 좋지 않음"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 (객체지향버전)",
    "text": "산점도 + 점크기변경 + 색깔 (객체지향버전)\n- 맵핑규칙\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\na3 = a2.copy() \n\n\na3['color'] = 'drv'\na3['size'] = 'class'\na3\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'}\n\n\n\n아래와 같이 선언해도 괜찮음\n\na3= aes(x='displ',y='hwy',color='drv',size='class')\n\npoint3=geom_point(a3)\n\n\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731065581)>\n\n\n\n그림의 전체적인 투명도를 조절하면 좋겠음\n\n\npoint3=geom_point(a3,alpha=0.2)\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726730819657)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + 선추가\n\nfig+point3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726730575253)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + drv별로 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + drv별로 선추가\n- 맵핑규칙\n\na1,a2,a3\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'})\n\n\n\na4 = a2.copy() \na4['color']='drv'\na4\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv'}\n\n\n\nline2 = geom_smooth(a4)\n\n\nfig + point3 +line2\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726729919385)>\n\n\n- 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면?\n\na1,a2,a3,a4\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv'})\n\n\n\na5=a1.copy()\na5['linetype']='drv' \na5\n\n{'x': 'displ', 'y': 'hwy', 'linetype': 'drv'}\n\n\n\nline3 = geom_smooth(a5,size=0.5,color='gray')\n\n\nfig+point3+line3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732637457)>\n\n\n- 전체적인 추세선도 추가하고 싶다면?\n\nfig+point3+line3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732939513)>\n\n\n- 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음.\n\nline2 = geom_smooth(a4,size=0.5,linetype='dashed')\nfig+point3+line2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733678229)>\n\n\n- 고차원을 변수를 표현할 수 있는 무기는 다양하다.\n\n산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도\n라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_07_(1주차)_3월7일.html",
    "href": "posts/3_STBDA2022/2022_03_07_(1주차)_3월7일.html",
    "title": "[STBDA] 1wk. 강의소개 및 단순선형회귀",
    "section": "",
    "text": "(1주차) 3월7일\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yKGpQh49tnRrA-o2Odea8r\n\n\n\n강의보충자료\n- https://github.com/guebin/STBDA2022/blob/master/_notebooks/2022-03-07-supp1.pdf\n- https://github.com/guebin/STBDA2022/blob/master/_notebooks/2022-03-07-supp2.pdf\n\n\n로드맵\n- 오늘수업할내용: 단순선형회귀\n- 단순선형회귀를 배우는 이유?\n\n우리가 배우고싶은것: 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN) \\(\\to\\) 적대적생성신경망(GAN)\n심층신경망을 바로 이해하기 어려움\n다음의 과정으로 이해해야함: (선형대수학 \\(\\to\\)) 회귀분석 \\(\\to\\) 로지스틱회귀분석 \\(\\to\\) 심층신경망\n\n\n\n선형회귀\n- 상황극 - 나는 동네에 커피점을 하나 차렸음. - 장사를 하다보니까 날이 더울수록 아이스아메리카노의 판매량이 증가한다는 사실을 깨달았다. - 일기예보는 미리 나와있으니까 그 정보를 잘 이용하면 ‘온도 -> 아이스아메리카노 판매량 예측’ 이 가능할것 같다. (내가 앞으로 얼마나 벌지 예측가능)\n- 가짜자료 생성\n\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \n\n온도 \\({\\bf x}\\)가 아래와 같다고 하자.\n\nx=tf.constant([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) # 기온 \nx\n\n<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4],\n      dtype=float32)>\n\n\n아이스아메리카노의 판매량 \\({\\bf y}\\)이 아래와 같다고 하자. (판매량은 정수로 나오겠지만 편의상 소수점도 가능하다고 생각하자)\n\\[{\\bf y} \\approx 10.2 +2.2 {\\bf x}\\]\n\n여기에서 10.2, 2.2 의 숫자는 제가 임의로 정한것임\n식의의미: 온도가 0일때 10.2잔정도 팔림 + 온도가 1도 증가하면 2.2잔정도 더 팔림\n물결의의미: 현실반영. 세상은 꼭 수식대로 정확하게 이루어지지 않음.\n\n\ntf.random.set_seed(43052)\nepsilon=tf.random.normal([10])\ny=10.2 + 2.2*x + epsilon\ny\n\n<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([55.418365, 58.194283, 61.230827, 62.312557, 63.107002, 63.69569 ,\n       67.247055, 71.4365  , 73.1013  , 77.84988 ], dtype=float32)>\n\n\n- 우리는 아래와 같은 자료를 모았다고 생각하자.\n\ntf.transpose(tf.concat([[x],[y]],0))\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[20.1     , 55.418365],\n       [22.2     , 58.194283],\n       [22.7     , 61.230827],\n       [23.3     , 62.312557],\n       [24.4     , 63.107002],\n       [25.1     , 63.69569 ],\n       [26.2     , 67.247055],\n       [27.3     , 71.4365  ],\n       [28.4     , 73.1013  ],\n       [30.4     , 77.84988 ]], dtype=float32)>\n\n\n- 그려보자.\n\nplt.plot(x,y,'.') # 파란점, 관측한 데이터 \nplt.plot(x,10.2 + 2.2*x, '--')  # 주황색점선, 세상의 법칙 \n\n\n\n\n- 우리의 목표: 파란색점 \\(\\to\\) 주황색점선을 추론 // 데이터를 바탕으로 세상의 법칙을 추론\n- 아이디어: 데이터를 보니까 \\(x\\)와 \\(y\\)가 선형의 관계에 있는듯 보인다. 즉 모든 \\(i=1,2,\\dots, 10\\)에 대하여 아래를 만족하는 적당한 a,b (혹은 \\(\\beta_0,\\beta_1\\)) 가 존재할것 같다. - \\(y_{i} \\approx ax_{i}+b\\) - \\(y_{i} \\approx \\beta_1 x_{i}+\\beta_0\\)\n- 어림짐작으로 \\(a,b\\)를 알아내보자.\n데이터를 살펴보자.\n\ntf.transpose(tf.concat([[x],[y]],0))\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[20.1     , 55.418365],\n       [22.2     , 58.194283],\n       [22.7     , 61.230827],\n       [23.3     , 62.312557],\n       [24.4     , 63.107002],\n       [25.1     , 63.69569 ],\n       [26.2     , 67.247055],\n       [27.3     , 71.4365  ],\n       [28.4     , 73.1013  ],\n       [30.4     , 77.84988 ]], dtype=float32)>\n\n\n적당히 왼쪽*2+15 = 오른쪽의 관계가 성립하는것 같다.\n따라서 \\(a=2, b=15\\) 혹은 \\(\\beta_0=15, \\beta_1=2\\) 로 추론할 수 있겠다.\n- 누군가가 \\((\\beta_0,\\beta_1)=(14,2)\\) 이라고 주장할 수 있다. (어차피 지금은 감각으로 추론하는 과정이니까)\n- 새로운 주장으로 인해서 \\((\\beta_0,\\beta_1)=(15,2)\\) 로 볼 수도 있고 \\((\\beta_0,\\beta_1)=(14,2)\\) 로 볼 수도 있다. 이중에서 어떠한 추정치가 좋은지 판단할 수 있을까? - 후보1: \\((\\beta_0,\\beta_1)=(15,2)\\) - 후보2: \\((\\beta_0,\\beta_1)=(14,2)\\)\n- 가능한 \\(y_i \\approx \\beta_0 + \\beta_1 x_i\\) 이 되도록 만드는 \\((\\beta_0,\\beta_1)\\) 이 좋을 것이다. \\(\\to\\) 후보 1,2를 비교해보자.\n(관찰에 의한 비교)\n후보1에 대해서 \\(i=1,2\\)를 넣고 관찰하여 보자.\n\n20.1 * 2 + 15 , 55.418365 # i=1 \n\n(55.2, 55.418365)\n\n\n\n22.2 * 2 + 15 , 58.194283 # i=2\n\n(59.4, 58.194283)\n\n\n후보2에 대하여 \\(i=1,2\\)를 넣고 관찰하여 보자.\n\n20.1 * 2 + 14 , 55.418365 # i=1 \n\n(54.2, 55.418365)\n\n\n\n22.2 * 2 + 14 , 58.194283 # i=2\n\n(58.4, 58.194283)\n\n\n\\(i=1\\)인 경우에는 후보1이 더 잘맞는것 같은데 \\(i=2\\)인 경우는 후보2가 더 잘맞는것 같다.\n(좀 더 체계적인 비교)\n\\(i=1,2,3, \\dots, 10\\) 에서 후보1과 후보2중 어떤것이 더 좋은지 비교하는 체계적인 방법을 생각해보자.\n후보 1,2에 대하여 \\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)를 계산하여 비교해보자.\n\nsum1=0 \nfor i in range(10):\n    sum1=sum1+(y[i]-15-2*x[i])**2 \n\n\nsum2=0 \nfor i in range(10):\n    sum2=sum2+(y[i]-14-2*x[i])**2 \n\n\nsum1,sum2\n\n(<tf.Tensor: shape=(), dtype=float32, numpy=14.734169>,\n <tf.Tensor: shape=(), dtype=float32, numpy=31.521088>)\n\n\n후보1이 더 \\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)의 값이 작다.\n후보1이 종합적으로 후보2에 비하여 좋다. 이 과정을 무한번 반복하면 최적의 추정치를 찾을 수 있다.\n- 그런데 이 알고리즘은 현실적으로 구현이 불가능하다. (무한번 계산하기도 힘들고, 언제 멈출지도 애매함)\n- 수학을 이용해서 좀 더 체계적으로 찾아보자. 결국 아래식을 가장 작게 만드는 \\(\\beta_0,\\beta_1\\)을 찾으면 된다.\n\\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)\n그런데 결국 \\(\\beta_0, \\beta_1\\)에 대한 이차식인데 이 식을 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하기 위해서는 아래를 연립하여 풀면된다.\n\\(\\begin{cases} \\frac{\\partial}{\\partial \\beta_0}\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2=0 \\\\ \\frac{\\partial}{\\partial \\beta_1}\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2=0 \\end{cases}\\)\n- 풀어보자.\n\\(\\begin{cases} \\sum_{i=1}^{10} -2(y_i -\\beta_0 -\\beta_1 x_i)=0 \\\\ \\sum_{i=1}^{10} -2x_i(y_i -\\beta_0 -\\beta_1 x_i)=0 \\end{cases}\\)\n정리하면\n\\[\\hat{\\beta}_0= \\bar{y}-\\hat{\\beta}_1 \\bar{x}\\]\n\\[\\hat{\\beta}_1= \\frac{S_{xy}}{S_{xx}}=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\]\n- 따라서 최적의 추정치 \\((\\hat{\\beta}_0,\\hat{\\beta}_1)\\)를 이용한 추세선을 아래와 같이 계산할 수 있음.\n\nSxx= sum((x-sum(x)/10)**2)\nSxx\n\n<tf.Tensor: shape=(), dtype=float32, numpy=87.848976>\n\n\n\nSxy=  sum((x-sum(x)/10)*(y-sum(y)/10))\nSxy\n\n<tf.Tensor: shape=(), dtype=float32, numpy=194.64737>\n\n\n\nbeta1_estimated = Sxy/Sxx \nbeta1_estimated\n\n<tf.Tensor: shape=(), dtype=float32, numpy=2.2157044>\n\n\n\nbeta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 \nbeta0_estimated\n\n<tf.Tensor: shape=(), dtype=float32, numpy=9.944572>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,beta0_estimated + beta1_estimated * x, '--') # 주황색선: 세상의 법칙을 추정한선 \nplt.plot(x,10.2 + 2.2* x, '--') # 초록색선: ture, 세상의법칙 \n\n\n\n\n\nNote: 샘플수가 커질수록 주황색선은 점점 초록색선으로 가까워진다.\n\n- 꽤 훌륭한 도구임. 그런데 약간의 단점이 존재한다.\n\n공식이 좀 복잡함..\n\\(x\\)가 여러개일 경우 확장이 어려움\n\n- 단점을 극복하기 위해서 우리가 지금까지 했던논의를 매트릭스로 바꾸어서 다시 써보자.\n- 모형의 매트릭스화\n우리의 모형은 아래와 같다.\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad i=1,2,\\dots,10\\)\n풀어서 쓰면\n\\(\\begin{cases} y_1 = \\beta_0 +\\beta_1 x_1 + \\epsilon_1 \\\\ y_2 = \\beta_0 +\\beta_1 x_2 + \\epsilon_2 \\\\ \\dots \\\\ y_{10} = \\beta_0 +\\beta_1 x_{10} + \\epsilon_{10} \\end{cases}\\)\n아래와 같이 쓸 수 있다.\n$\n\\[\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\dots \\\\\ny_{10}\n\\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\dots & \\dots \\\\\n1 & x_{10}\n\\end{bmatrix}\\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\dots \\\\\n\\epsilon_{10}\n\\end{bmatrix}\\]\n$\n\n벡터와 매트릭스 형태로 정리하면\n\\({\\bf y} = {\\bf X} {\\boldsymbol \\beta} + \\boldsymbol{\\epsilon}\\)\n- 손실함수의 매트릭스화: 우리가 최소화 하려던 손실함수는 아래와 같다.\n\\(loss=\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2\\)\n이것을 벡터표현으로 하면 아래와 같다.\n\\(loss=\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2=({\\bf y}-{\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y}-{\\bf X}{\\boldsymbol \\beta})\\)\n풀어보면\n\\(loss=({\\bf y}-{\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y}-{\\bf X}{\\boldsymbol \\beta})={\\bf y}^\\top {\\bf y} - {\\bf y}^\\top {\\bf X}{\\boldsymbol\\beta} - {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf y} + {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf X} {\\boldsymbol\\beta}\\)\n- 미분하는 과정의 매트릭스화\nloss를 최소화하는 \\({\\boldsymbol \\beta}\\)를 구해야하므로 loss를 \\({\\boldsymbol \\beta}\\)로 미분한식을 0이라고 놓고 풀면 된다.\n\\(\\frac{\\partial}{\\partial \\boldsymbol{\\beta}} loss = \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\bf y}^\\top {\\bf y} - \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\bf y}^\\top {\\bf X}{\\boldsymbol\\beta} - \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf y} + \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf X} {\\boldsymbol\\beta}\\)\n$= 0 - {}^- {}^ + 2{}^ $\n따라서 \\(\\frac{\\partial}{\\partial \\boldsymbol{\\beta}}loss=0\\)을 풀면 아래와 같다.\n$= ({}){-1}{}^ $\n- 공식도 매트릭스로 표현하면: $= ({}){-1}{}^ $ <– 외우세요\n- 적용을 해보자.\n(X를 만드는 방법1)\n\nX=tf.transpose(tf.concat([[[1.0]*10],[x]],0)) # \nX\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[ 1. , 20.1],\n       [ 1. , 22.2],\n       [ 1. , 22.7],\n       [ 1. , 23.3],\n       [ 1. , 24.4],\n       [ 1. , 25.1],\n       [ 1. , 26.2],\n       [ 1. , 27.3],\n       [ 1. , 28.4],\n       [ 1. , 30.4]], dtype=float32)>\n\n\n(X를 만드는 방법2)\n\nfrom tensorflow.python.ops.numpy_ops import np_config\nnp_config.enable_numpy_behavior()\n\n\nX=tf.concat([[[1.0]*10],[x]],0).T\nX\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[ 1. , 20.1],\n       [ 1. , 22.2],\n       [ 1. , 22.7],\n       [ 1. , 23.3],\n       [ 1. , 24.4],\n       [ 1. , 25.1],\n       [ 1. , 26.2],\n       [ 1. , 27.3],\n       [ 1. , 28.4],\n       [ 1. , 30.4]], dtype=float32)>\n\n\n\ntf.linalg.inv(X.T @ X) @ X.T @ y\n\n<tf.Tensor: shape=(2,), dtype=float32, numpy=array([9.944702, 2.215706], dtype=float32)>\n\n\n- 잘 구해진다.\n- 그런데..\n\nbeta0_estimated,beta1_estimated\n\n(<tf.Tensor: shape=(), dtype=float32, numpy=9.944572>,\n <tf.Tensor: shape=(), dtype=float32, numpy=2.2157044>)\n\n\n값이 좀 다르다..?\n- 같은 값입니다! 신경쓰지 마세요! 텐서플로우가 좀 대충계산합니다.\n\nimport tensorflow.experimental.numpy as tnp \n\n\nx=tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) \ny=10.2 + 2.2*x + epsilon \n\n\nbeta1_estimated = sum((x-sum(x)/10)*(y-sum(y)/10)) / sum((x-sum(x)/10)**2)\nbeta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 \n\n\nbeta0_estimated, beta1_estimated\n\n(<tf.Tensor: shape=(), dtype=float64, numpy=9.944573294798559>,\n <tf.Tensor: shape=(), dtype=float64, numpy=2.2157046054834106>)\n\n\n\nX=tnp.concatenate([[tnp.array([1.0]*10)],[x]],0).T\ntf.linalg.inv(X.T @ X) @ X.T @ y\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([9.94457329, 2.21570461])>\n\n\n\n\n앞으로 할것\n- 선형대수학의 미분이론..\n- 실습 (tensorflow에서 매트릭스를 자유롭게 다루기!)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_21_(3주차)_3월21일.html",
    "href": "posts/3_STBDA2022/2022_03_21_(3주차)_3월21일.html",
    "title": "[STBDA] 3wk. 텐서플로우 intro2 (tf.GradientTape())",
    "section": "",
    "text": "(3주차) 3월21일\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yCZH5zqsORTEkCZ082SCYc\n\n\n\nimports\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\n\n\n\n지난강의 보충\n- max, min, sum, mean\n\na= tf.constant([1.0,2.0,3.0,4.0])\na\n\n<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>\n\n\n\ntf.reduce_mean(a)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=2.5>\n\n\n\nconcat, stack\n- 예제: (2,3,4,5) stack (2,3,4,5) -> (?,?,?,?,?)\n\na = tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5))\nb = -a \n\n\nTip: 총 5가지 case가 있다. case1 (1,2,3,4,5) stack (1,2,3,4,5) –> (2,2,3,4,5) # axis=0  case2 (2,1,3,4,5) stack (2,1,3,4,5) –> (2,2,3,4,5) # axis=1  case3 (2,3,1,4,5) stack (2,3,1,4,5) –> (2,3,2,4,5) # axis=2  case4 (2,3,4,1,5) stack (2,3,4,1,5) –> (2,3,4,2,5) # axis=3  case5 (2,3,4,5,1) stack (2,3,4,5,1) –> (2,3,4,5,2) # axis=4\n\ncase1 (1,2,3,4,5) stack (1,2,3,4,5) –> (2,2,3,4,5) # axis=0\n\ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]]],\n\n\n\n       [[[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase2 (2,1,3,4,5) stack (2,1,3,4,5) –> (2,2,3,4,5) # axis=1\n\ntf.stack([a,b],axis=1)\n\n<tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase3 (2,3,1,4,5) stack (2,3,1,4,5) –> (2,3,2,4,5) # axis=2\n\ntf.stack([a,b],axis=2)\n\n<tf.Tensor: shape=(2, 3, 2, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase4 (2,3,4,1,5) stack (2,3,4,1,5) –> (2,3,4,2,5) # axis=3\n\ntf.stack([a,b],axis=-2).shape\n\nTensorShape([2, 3, 4, 2, 5])\n\n\n\ntf.stack([a,b],axis=-2)\n\n<tf.Tensor: shape=(2, 3, 4, 2, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   0,   -1,   -2,   -3,   -4]],\n\n         [[   5,    6,    7,    8,    9],\n          [  -5,   -6,   -7,   -8,   -9]],\n\n         [[  10,   11,   12,   13,   14],\n          [ -10,  -11,  -12,  -13,  -14]],\n\n         [[  15,   16,   17,   18,   19],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [ -20,  -21,  -22,  -23,  -24]],\n\n         [[  25,   26,   27,   28,   29],\n          [ -25,  -26,  -27,  -28,  -29]],\n\n         [[  30,   31,   32,   33,   34],\n          [ -30,  -31,  -32,  -33,  -34]],\n\n         [[  35,   36,   37,   38,   39],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [ -40,  -41,  -42,  -43,  -44]],\n\n         [[  45,   46,   47,   48,   49],\n          [ -45,  -46,  -47,  -48,  -49]],\n\n         [[  50,   51,   52,   53,   54],\n          [ -50,  -51,  -52,  -53,  -54]],\n\n         [[  55,   56,   57,   58,   59],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [ -60,  -61,  -62,  -63,  -64]],\n\n         [[  65,   66,   67,   68,   69],\n          [ -65,  -66,  -67,  -68,  -69]],\n\n         [[  70,   71,   72,   73,   74],\n          [ -70,  -71,  -72,  -73,  -74]],\n\n         [[  75,   76,   77,   78,   79],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [ -80,  -81,  -82,  -83,  -84]],\n\n         [[  85,   86,   87,   88,   89],\n          [ -85,  -86,  -87,  -88,  -89]],\n\n         [[  90,   91,   92,   93,   94],\n          [ -90,  -91,  -92,  -93,  -94]],\n\n         [[  95,   96,   97,   98,   99],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [-100, -101, -102, -103, -104]],\n\n         [[ 105,  106,  107,  108,  109],\n          [-105, -106, -107, -108, -109]],\n\n         [[ 110,  111,  112,  113,  114],\n          [-110, -111, -112, -113, -114]],\n\n         [[ 115,  116,  117,  118,  119],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase5 (2,3,4,5,1) stack (2,3,4,5,1) –> (2,3,4,5,2) # axis=4\n\ntf.stack([a,b],axis=-1).shape\n\nTensorShape([2, 3, 4, 5, 2])\n\n\n\ntf.stack([a,b],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 5, 2), dtype=int32, numpy=\narray([[[[[   0,    0],\n          [   1,   -1],\n          [   2,   -2],\n          [   3,   -3],\n          [   4,   -4]],\n\n         [[   5,   -5],\n          [   6,   -6],\n          [   7,   -7],\n          [   8,   -8],\n          [   9,   -9]],\n\n         [[  10,  -10],\n          [  11,  -11],\n          [  12,  -12],\n          [  13,  -13],\n          [  14,  -14]],\n\n         [[  15,  -15],\n          [  16,  -16],\n          [  17,  -17],\n          [  18,  -18],\n          [  19,  -19]]],\n\n\n        [[[  20,  -20],\n          [  21,  -21],\n          [  22,  -22],\n          [  23,  -23],\n          [  24,  -24]],\n\n         [[  25,  -25],\n          [  26,  -26],\n          [  27,  -27],\n          [  28,  -28],\n          [  29,  -29]],\n\n         [[  30,  -30],\n          [  31,  -31],\n          [  32,  -32],\n          [  33,  -33],\n          [  34,  -34]],\n\n         [[  35,  -35],\n          [  36,  -36],\n          [  37,  -37],\n          [  38,  -38],\n          [  39,  -39]]],\n\n\n        [[[  40,  -40],\n          [  41,  -41],\n          [  42,  -42],\n          [  43,  -43],\n          [  44,  -44]],\n\n         [[  45,  -45],\n          [  46,  -46],\n          [  47,  -47],\n          [  48,  -48],\n          [  49,  -49]],\n\n         [[  50,  -50],\n          [  51,  -51],\n          [  52,  -52],\n          [  53,  -53],\n          [  54,  -54]],\n\n         [[  55,  -55],\n          [  56,  -56],\n          [  57,  -57],\n          [  58,  -58],\n          [  59,  -59]]]],\n\n\n\n       [[[[  60,  -60],\n          [  61,  -61],\n          [  62,  -62],\n          [  63,  -63],\n          [  64,  -64]],\n\n         [[  65,  -65],\n          [  66,  -66],\n          [  67,  -67],\n          [  68,  -68],\n          [  69,  -69]],\n\n         [[  70,  -70],\n          [  71,  -71],\n          [  72,  -72],\n          [  73,  -73],\n          [  74,  -74]],\n\n         [[  75,  -75],\n          [  76,  -76],\n          [  77,  -77],\n          [  78,  -78],\n          [  79,  -79]]],\n\n\n        [[[  80,  -80],\n          [  81,  -81],\n          [  82,  -82],\n          [  83,  -83],\n          [  84,  -84]],\n\n         [[  85,  -85],\n          [  86,  -86],\n          [  87,  -87],\n          [  88,  -88],\n          [  89,  -89]],\n\n         [[  90,  -90],\n          [  91,  -91],\n          [  92,  -92],\n          [  93,  -93],\n          [  94,  -94]],\n\n         [[  95,  -95],\n          [  96,  -96],\n          [  97,  -97],\n          [  98,  -98],\n          [  99,  -99]]],\n\n\n        [[[ 100, -100],\n          [ 101, -101],\n          [ 102, -102],\n          [ 103, -103],\n          [ 104, -104]],\n\n         [[ 105, -105],\n          [ 106, -106],\n          [ 107, -107],\n          [ 108, -108],\n          [ 109, -109]],\n\n         [[ 110, -110],\n          [ 111, -111],\n          [ 112, -112],\n          [ 113, -113],\n          [ 114, -114]],\n\n         [[ 115, -115],\n          [ 116, -116],\n          [ 117, -117],\n          [ 118, -118],\n          [ 119, -119]]]]], dtype=int32)>\n\n\n- 예제: (2,3,4), (2,3,4), (2,3,4)\n\na= tf.reshape(tf.constant(range(2*3*4)),(2,3,4))\nb= -a \nc= 2*a\n\n(예시1) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (6,3,4)\n\ntf.concat([a,b,c],axis=0)\n\n<tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)>\n\n\n(예시2) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,9,4)\n\ntf.concat([a,b,c],axis=1)\n\n<tf.Tensor: shape=(2, 9, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11],\n        [  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23],\n        [ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)>\n\n\n(예시3) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,12)\n\ntf.concat([a,b,c],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 12), dtype=int32, numpy=\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3,   0,   2,   4,   6],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7,   8,  10,  12,  14],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11,  16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15,  24,  26,  28,  30],\n        [ 16,  17,  18,  19, -16, -17, -18, -19,  32,  34,  36,  38],\n        [ 20,  21,  22,  23, -20, -21, -22, -23,  40,  42,  44,  46]]],\n      dtype=int32)>\n\n\n(예시4) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (3,2,3,4)\n\n축이 늘어난 경우\n\n\ntf.stack([a,b,c],axis=0)\n\n<tf.Tensor: shape=(3, 2, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]]],\n\n\n       [[[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]]],\n\n\n       [[[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시5) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=1).shape\n\nTensorShape([2, 3, 3, 4])\n\n\n\ntf.stack([a,b,c],axis=1)\n\n<tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시6) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=2)\n\n<tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  0,  -1,  -2,  -3],\n         [  0,   2,   4,   6]],\n\n        [[  4,   5,   6,   7],\n         [ -4,  -5,  -6,  -7],\n         [  8,  10,  12,  14]],\n\n        [[  8,   9,  10,  11],\n         [ -8,  -9, -10, -11],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [-12, -13, -14, -15],\n         [ 24,  26,  28,  30]],\n\n        [[ 16,  17,  18,  19],\n         [-16, -17, -18, -19],\n         [ 32,  34,  36,  38]],\n\n        [[ 20,  21,  22,  23],\n         [-20, -21, -22, -23],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시7) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,4,3)\n\ntf.stack([a,b,c],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 3), dtype=int32, numpy=\narray([[[[  0,   0,   0],\n         [  1,  -1,   2],\n         [  2,  -2,   4],\n         [  3,  -3,   6]],\n\n        [[  4,  -4,   8],\n         [  5,  -5,  10],\n         [  6,  -6,  12],\n         [  7,  -7,  14]],\n\n        [[  8,  -8,  16],\n         [  9,  -9,  18],\n         [ 10, -10,  20],\n         [ 11, -11,  22]]],\n\n\n       [[[ 12, -12,  24],\n         [ 13, -13,  26],\n         [ 14, -14,  28],\n         [ 15, -15,  30]],\n\n        [[ 16, -16,  32],\n         [ 17, -17,  34],\n         [ 18, -18,  36],\n         [ 19, -19,  38]],\n\n        [[ 20, -20,  40],\n         [ 21, -21,  42],\n         [ 22, -22,  44],\n         [ 23, -23,  46]]]], dtype=int32)>\n\n\n- 예제: (2,3,4) (4,3,4) \\(\\to\\) (6,3,4)\n\na=tf.reshape(tf.constant(range(2*3*4)),(2,3,4))\nb=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4))\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[-24, -25, -26, -27],\n        [-28, -29, -30, -31],\n        [-32, -33, -34, -35]],\n\n       [[-36, -37, -38, -39],\n        [-40, -41, -42, -43],\n        [-44, -45, -46, -47]]], dtype=int32)>\n\n\n\ntf.concat([a,b],axis=1) # dimension이 달라 오류!\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat\n\n\n\ntf.concat([a,b],axis=2)\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat\n\n\n- (2,2) @ (2,) 의 연산?\nnumpy\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88])\n\narray([ 77, -88])\n\n\n\n차원이 안맞는데 계산이 된다?\n\n\nnp.array([77,-88]) @ np.array([[1,0],[0,1]])\n\narray([ 77, -88])\n\n\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88]).reshape(2,1) # dimension 명시\n\narray([[ 77],\n       [-88]])\n\n\n\nnp.array([77,-88]).reshape(2,1) @ np.array([[1,0],[0,1]]) # 잘못된 걸 명시해주니까 계산 안됨!\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)\n\n\n\nnp.array([77,-88]).reshape(1,2) @ np.array([[1,0],[0,1]]) \n\narray([[ 77, -88]])\n\n\n–> 요약: numpy에서 길이가 2인 벡터는 매트릭스를 곱할 때 알아서 계산이 되서 결과가 나옴.\ntensorflow\n\nI = tf.constant([[1.0,0.0],[0.0,1.0]]) \nx = tf.constant([77.0,-88.0]) \n\n\nI @ x \n\nInvalidArgumentError: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] has different ndims: [2,2] vs. [2] [Op:MatMul]\n\n\n\nx @ I\n\nInvalidArgumentError: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] has different ndims: [2] vs. [2,2] [Op:MatMul]\n\n\n\nI @ tf.reshape(x,(2,1))\n\n<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\narray([[ 77.],\n       [-88.]], dtype=float32)>\n\n\n\ntf.reshape(x,(1,2)) @ I \n\n<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 77., -88.]], dtype=float32)>\n\n\n\n\n\n\ntf.Variable\n되게 쓸모없어 보이는데 쉽고, 중요합니다.\n\n선언\n- tf.Variable()로 선언\n\ntf.Variable([1,2,3,4])\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntf.Variable([1.0,2.0,3.0,4.0])\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>\n\n\n- tf.constant() 선언후 변환\n\na_ = tf.Variable(tf.constant([1,2,3,4]))\ntype(a_)\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\ntype이 ResourceVariable\n\n\ntf.Variable(tf.constant([1,2,3,4])) # type이렇게 바로 변환 가능\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n- np 등으로 선언후 변환\n\ntf.Variable(np.array([1,2,3,4]))\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int64, numpy=array([1, 2, 3, 4])>\n\n\n\n\n타입\n\ntype(tf.Variable([1,2,3,4]))\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\n\n인덱싱\n\na=tf.Variable([1,2,3,4])\na\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntype(a)\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\na[:2] # 처음 2개의 원소.\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\ntype(a[:2])\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n연산하는 순간 type이 EagerTensor로 바뀜\n\n\n\n연산가능\n\na=tf.Variable([1,2,3,4])\nb=tf.Variable([-1,-2,-3,-4])\n\n\na+b\n\n<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>\n\n\ntf.Variable로 열심히 만들어도 연산하는 순간 tf.constant로 바뀜.. (자료형이 깨짐)\n\n\ntf.Variable도 쓰기 불편함\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14]) ## 에러\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]\n\n\n\n\ntnp의 은총도 일부만 가능\n\nimport tensorflow.experimental.numpy as tnp \ntnp.experimental_enable_numpy_behavior() \n\n- 알아서 형 변환\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14])\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([4.1400001, 5.1400001])>\n\n\n- .reshape 메소드\n\ntf.Variable([1,2,3,4]).reshape(2,2)\n\nAttributeError: 'ResourceVariable' object has no attribute 'reshape'\n\n\n\ntf.constant는 되는데 tf.Variable은 또 안됨…\n\n\n\n대부분의 동작은 tf.constant랑 큰 차이를 모르겠음\n- tf.concat\n\na= tf.Variable([[1,2],[3,4]]) \nb= tf.Variable([[-1,-2],[-3,-4]]) \ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1,  2],\n       [ 3,  4],\n       [-1, -2],\n       [-3, -4]], dtype=int32)>\n\n\n- tf.stack\n\na= tf.Variable([[1,2],[3,4]]) \nb= tf.Variable([[-1,-2],[-3,-4]]) \ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\narray([[[ 1,  2],\n        [ 3,  4]],\n\n       [[-1, -2],\n        [-3, -4]]], dtype=int32)>\n\n\n\n이건 비슷한데?\n\n\n\n변수값변경가능(?)\n\na = 1\nid(a)\n\n7585472\n\n\n\na = 456\nid(a)\n\n140177070372624\n\n\n\n새로만드는 것은 되는데 수정은 안됨. (즉, 재할당밖에 안됨. 수정은 안돼)\n근데 가변형으로 만들어 주는것이 좋은데.. (불변형을 사용하려면 메모리가 커야해..)\n그래서 편집 가능한 변수로 선언하는 것이 의미가 있다.\n보통 딥러닝 학습할 때 Data는 RAM에 올리고 파라미터는 GPU에 올린다. (GPU에 올리면 미분계산(선형연산)이 빨라짐)\n\n\na= tf.Variable([1,2,3,4])\nid(a)\n\n140177068844272\n\n\n\na.assign_add([-1,-2,-3,-4]) # 편집기능.\nid(a)\n\n140177068844272\n\n\n\n주소값이 똑같으니까 편집!\n\n\n\n요약\n- tf.Variable()로 만들어야 하는 뚜렷한 차이는 모르겠음.\n- 애써 tf.Variable()로 만들어도 간단한연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐.\n\n\n\n미분\n\n모티브\n- 예제: 컴퓨터를 이용하여 \\(x=2\\)에서 \\(y=3x^2\\)의 접선의 기울기를 구해보자.\n(손풀이)\n\\[\\frac{dy}{dx}=6x\\]\n이므로 \\(x=2\\)를 대입하면 12이다.\n(컴퓨터를 이용한 풀이)\n단계1\n\nx1=2 \ny1= 3*x1**2 \n\n\nx2=2+0.000000001\ny2= 3*x2**2\n\n\n(y2-y1)/(x2-x1)\n\n12.0\n\n\n단계2\n\ndef f(x):\n    return(3*x**2)\n\n\nf(3)\n\n27\n\n\n\ndef d(f,x):\n    return (f(x+0.000000001)-f(x))/0.000000001\n\n\nd(f,2)\n\n12.000000992884452\n\n\n단계3\n\nd(lambda x: 3*x**2 ,2)\n\n12.000000992884452\n\n\n\nd(lambda x: x**2 ,0)\n\n1e-09\n\n\n단계4\n\\[f(x,y)= x^2 +3y\\]\n\ndef f(x,y):\n    return(x**2 +3*y)\n\n\nd(f,(2,3))\n\nTypeError: can only concatenate tuple (not \"float\") to tuple\n\n\n\n\ntf.GradientTape() 사용방법\n- 예제1: \\(x=2\\)에서 \\(y=3x^2\\)의 도함수값을 구하라.\n\nx=tf.Variable(2.0) # 미분 기울기를 구하고 싶은 지점을 tf.Variable로 선언\na=tf.constant(3.0) # 숫자로 선언하고 싶은 것.\n\n\ntf.GradientTape()     # Tape: 뭔가 기록할 수 있는 것.\n\n<tensorflow.python.eager.backprop.GradientTape at 0x7f7d84347bb0>\n\n\n\n실행결과 오브젝트로 나왔는데 ,그것이 0x7f7d4c6cfdf0 이 메모리 주소 안에 있다.\n\n\ndir(mytape) # 여기서 __enter__와 __exit__에 주목!\n\n['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__enter__',\n '__eq__',\n '__exit__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_ensure_recording',\n '_persistent',\n '_pop_tape',\n '_push_tape',\n '_recording',\n '_tape',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_watch_accessed_variables',\n '_watched_variables',\n 'batch_jacobian',\n 'gradient',\n 'jacobian',\n 'reset',\n 'stop_recording',\n 'watch',\n 'watched_variables']\n\n\n\nmytape=tf.GradientTape() \nmytape.__enter__() # 기록 시작 \ny=a*x**2 # y=ax^2 = 3x^2 (기록하고 싶은 것)\nmytape.__exit__(None,None,None) # 기록 끝 \n\n\n그럼 mytape에는 뭔가가 기록되어 있을 것이다.\n위의 코드에서 __enter__()와 __exit__()는 고정이라고 생각\n그 사이에는 수식쓰기\n\n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n\n미분 결과 12\n\n- 예제2: 조금 다른예제\n\nx=tf.Variable(2.0)\n#a=tf.constant(3.0)\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작 \na=(x/2)*3 ## a=(3/2)x \ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝 \n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n\n실행은 되는데 결과가 틀림! 왜 18이지?\n\n\\[a=\\frac{3}{2}x\\] \\[y=ax^2=\\frac{3}{2}x^3\\]\n\\[\\frac{dy}{dx}=\\frac{3}{2} 3x^2\\]\n\n3/2*3*4\n\n18.0\n\n\n- 테이프의 개념 (\\(\\star\\))\n(상황)\n우리가 어려운 미분계산을 컴퓨터에게 부탁하는 상황임. (예를들면 \\(y=3x^2\\)) 컴퓨터에게 부탁을 하기 위해서는 연습장(=테이프)에 \\(y=3x^2\\)이라는 수식을 써서 보여줘야하는데 이때 컴퓨터에게 target이 무엇인지 그리고 무엇으로 미분하고 싶은 것인지를 명시해야함.\n\nmytape = tf.GradientTape(): tf.GradientTape()는 연습장을 만드는 명령어, 만들어진 연습장을 mytape라고 이름을 붙인다.\nmytape.__enter__(): 만들어진 공책을 연다 (=기록할수 있는 상태로 만든다)\na=x/2*3; y=a*x**2: 컴퓨터에게 전달할 수식을 쓴다\nmytape.__exit__(None,None,None): 공책을 닫는다.\nmytape.gradient(y,x): \\(y\\)를 \\(x\\)로 미분하라는 메모를 남기고 컴퓨터에게 전달한다.\n\n- 예제3: 연습장을 언제 열고 닫을지 결정하는건 중요하다.\n\nx=tf.Variable(2.0)\na=(x/2)*3 ## a=(3/2)x\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작 \ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝 \n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n- 예제4: with문과 함께 쓰는 tf.GradientTape()\n열고 > 쓰고 > 닫고 > 컴퓨터에 전달 –>> 이 과정을 간략하게 매크로화 시키자.\n\nx=tf.Variable(2.0)\na=(x/2)*3 \n\n\nwith tf.GradientTape() as mytape:\n    ## with문 시작 \n    y=a*x**2 \n    ## with문 끝 \n\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n(문법해설)\n아래와 같이 쓴다.\nwith expression as myname:\n    ## with문 시작: myname.__enter__() \n    blabla ~ \n    yadiyadi !! \n    ## with문 끝: myname.__exit__()\n\nexpression 의 실행결과 오브젝트가 생성, 생성된 오브젝트는 myname라고 이름붙임. 이 오브젝트는 .__enter__()와 .__exit__()를 숨겨진 기능으로 포함해야 한다.\nwith문이 시작되면서 myname.__enter__()이 실행된다.\n블라블라와 야디야디가 실행된다.\nwith문이 종료되면서 myname.__exit__()이 실행된다.\n\n- 예제5: 예제2를 with문과 함께 구현\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n- 예제6: persistent = True\n(관찰1)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상 실행해서 에러를 관측하라\n\nRuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n\n\n(관찰2)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상실행해도 에러가 나지않음 \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n- 예제7: watch\n(관찰1)\n\nx=tf.constant(2.0)\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰2)\n\nx=tf.constant(2.0)\nwith tf.GradientTape(persistent=True) as mytape:\n    mytape.watch(x) # 수동감시\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n(관찰3)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제 \n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰4)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제\n    mytape.watch(x)\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n(관찰5)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True) as mytape: \n    mytape.watch(x)\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n- 예제9: 카페예제로 돌아오자.\n- 예제10: 카페예제의 매트릭스 버전\n- 예제11: 위의 예제에서 이론적인 \\(\\boldsymbol{\\beta}\\)의 최적값을 찾아보고 (즉 \\(\\hat{\\boldsymbol{\\beta}}\\)을 찾고) 그곳에서 loss의 미분을 구하라. 구한결과가 \\(\\begin{bmatrix}0 \\\\ 0 \\end{bmatrix}\\) 임을 확인하라."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_23_(12주차)_5월23일.html",
    "href": "posts/3_STBDA2022/2022_05_23_(12주차)_5월23일.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-xOfpHJG0LrtYt4TUVgqUNy\n\n\n\n\n\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\n\n\n\n- 데이터생성 (그냥 흑백대비 데이터)\n\n_X1 = tnp.ones([50,25])*10\n_X1\n\n<tf.Tensor: shape=(50, 25), dtype=float64, numpy=\narray([[10., 10., 10., ..., 10., 10., 10.],\n       [10., 10., 10., ..., 10., 10., 10.],\n       [10., 10., 10., ..., 10., 10., 10.],\n       ...,\n       [10., 10., 10., ..., 10., 10., 10.],\n       [10., 10., 10., ..., 10., 10., 10.],\n       [10., 10., 10., ..., 10., 10., 10.]])>\n\n\n\n_X2 = tnp.zeros([50,25])*10\n_X2\n\n<tf.Tensor: shape=(50, 25), dtype=float64, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])>\n\n\n\ntf.concat([_X1,_X2],axis=1)\n\n<tf.Tensor: shape=(50, 50), dtype=float64, numpy=\narray([[10., 10., 10., ...,  0.,  0.,  0.],\n       [10., 10., 10., ...,  0.,  0.,  0.],\n       [10., 10., 10., ...,  0.,  0.,  0.],\n       ...,\n       [10., 10., 10., ...,  0.,  0.,  0.],\n       [10., 10., 10., ...,  0.,  0.,  0.],\n       [10., 10., 10., ...,  0.,  0.,  0.]])>\n\n\n\n_noise = tnp.random.randn(50*50).reshape(50,50)\n_noise\n\n<tf.Tensor: shape=(50, 50), dtype=float64, numpy=\narray([[-0.30380244,  0.06484819,  0.60069937, ..., -0.49237769,\n         1.72552047,  0.32319886],\n       [-0.1442766 ,  0.32071132,  0.27135225, ...,  0.12584098,\n         1.77500838,  0.30678486],\n       [-0.98493241,  0.70428041, -0.10798709, ..., -0.07145503,\n         0.11185082,  1.4473293 ],\n       ...,\n       [ 0.41430467, -0.67483518, -0.46844066, ...,  0.76154689,\n        -1.60328529, -0.37098601],\n       [-1.65297477, -1.45893833, -1.7887122 , ..., -0.81344932,\n        -0.21032504, -0.53206832],\n       [-0.2352507 , -0.77675024, -2.01329394, ..., -1.41071477,\n        -1.20259288,  0.07060629]])>\n\n\n\nXXX = tf.concat([_X1,_X2],axis=1) + _noise\n\n\nXXX=XXX.reshape(1,50,50,1)\n\n\nplt.imshow(XXX.reshape(50,50),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f6769d77f10>\n\n\n\n\n\n- conv layer 생성\n\nconv = tf.keras.layers.Conv2D(2,(2,2))\n\n\nconv.weights # 처음에는 가중치가 없음\n\n[]\n\n\n\nconv(XXX) # 가중치를 만들기 위해서 XXX를 conv에 한번 통과시킴\nconv.weights # 이제 가중치가 생김\n\n[<tf.Variable 'conv2d_1/kernel:0' shape=(2, 2, 1, 2) dtype=float32, numpy=\n array([[[[ 0.06554878,  0.39761645]],\n \n         [[-0.4267348 , -0.376472  ]]],\n \n \n        [[[ 0.2653011 ,  0.42274743]],\n \n         [[ 0.4461723 , -0.6650867 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n\n\n- 가중치의 값을 확인해보자.\n\nconv.weights[0] # kernel에 해당하는것\n\n<tf.Variable 'conv2d_1/kernel:0' shape=(2, 2, 1, 2) dtype=float32, numpy=\narray([[[[ 0.06554878,  0.39761645]],\n\n        [[-0.4267348 , -0.376472  ]]],\n\n\n       [[[ 0.2653011 ,  0.42274743]],\n\n        [[ 0.4461723 , -0.6650867 ]]]], dtype=float32)>\n\n\n\nconv.weights[1] # bias에 해당하는것\n\n<tf.Variable 'conv2d_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n\n\n- 필터값을 원하는 것으로 변경해보자.\n\nw0 = [[0.25,0.25],[0.25,0.25]] # 잡티를 제거하는 효과를 준다.\nw1 = [[-1.0,1.0],[-1.0,1.0]] # 경계를 찾기 좋아보이는 필터이다. (엣지검출)\n\n\nw=np.concatenate([np.array(w0).reshape(2,2,1,1),np.array(w1).reshape(2,2,1,1)],axis=-1)\nw\n\narray([[[[ 0.25, -1.  ]],\n\n        [[ 0.25,  1.  ]]],\n\n\n       [[[ 0.25, -1.  ]],\n\n        [[ 0.25,  1.  ]]]])\n\n\n\nb= np.array([0.0,0.0])\nb\n\narray([0., 0.])\n\n\n\nconv.set_weights([w,b])\nconv.get_weights()\n\n[array([[[[ 0.25, -1.  ]],\n \n         [[ 0.25,  1.  ]]],\n \n \n        [[[ 0.25, -1.  ]],\n \n         [[ 0.25,  1.  ]]]], dtype=float32),\n array([0., 0.], dtype=float32)]\n\n\n\n첫번째는 평균을 구하는 필터,\n두번째는 엣지를 검출하는 필터\n\n- 필터를 넣은 결과를 확인\n\nXXX0=conv(XXX)[...,0] # 채널0\nXXX0\n\n<tf.Tensor: shape=(1, 49, 49), dtype=float32, numpy=\narray([[[ 9.984369  , 10.314403  , 10.114662  , ..., -0.2716803 ,\n          0.78349805,  1.032628  ],\n        [ 9.973946  , 10.29709   , 10.011451  , ..., -0.78137755,\n          0.4853113 ,  0.91024333],\n        [ 9.694317  , 10.180944  , 10.165418  , ..., -1.1441237 ,\n         -0.10771888,  0.0131253 ],\n        ...,\n        [ 9.950029  ,  9.197831  ,  9.421099  , ...,  0.2848997 ,\n         -0.24674678, -0.35682005],\n        [ 9.156889  ,  8.902268  ,  9.352164  , ...,  0.01892059,\n         -0.46637818, -0.67916614],\n        [ 8.969021  ,  8.490577  ,  9.140195  , ..., -0.2541374 ,\n         -0.9092705 , -0.46859497]]], dtype=float32)>\n\n\n\nXXX1=conv(XXX)[...,1] # 채널1\nXXX1\n\n<tf.Tensor: shape=(1, 49, 49), dtype=float32, numpy=\narray([[[ 0.8336382 ,  0.48649216, -1.2854509 , ...,  0.35364777,\n          3.8670654 , -2.8705451 ],\n        [ 2.1542006 , -0.8616276 , -0.28092575, ...,  3.2342823 ,\n          1.8324732 , -0.13274503],\n        [ 2.0953035 , -0.14879417,  0.08668804, ...,  5.0843253 ,\n         -0.93870586,  1.4220824 ],\n        ...,\n        [-1.498992  , -1.5097971 ,  2.4028683 , ...,  1.3495452 ,\n         -3.4761312 ,  3.0358381 ],\n        [-0.89510345, -0.12337971,  1.9229631 , ..., -0.17948717,\n         -1.7617078 ,  0.910556  ],\n        [-0.3474636 , -1.5663171 ,  4.1647916 , ..., -3.4317784 ,\n          0.81124616,  0.9514559 ]]], dtype=float32)>\n\n\n- 각 채널을 시각화\n\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\n\n\n\n\n\nax1.imshow(XXX.reshape(50,50),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f67684b5720>\n\n\n\nax3.imshow(XXX0.reshape(49,49),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f67684b47c0>\n\n\n\nax4.imshow(XXX1.reshape(49,49),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7f67684b72e0>\n\n\n\nfig\n\n\n\n\n\n2사분면: 원래이미지\n3사분면: 원래이미지 -> 평균을 의미하는 conv적용\n4사분면: 원래이미지 -> 엣지를 검출하는 conv적용\n\n- conv(XXX)의 각 채널에 한번더 conv를 통과시켜보자\n\nconv(XXX0.reshape(1,49,49,1))[...,0] ### XXX0 -> 평균필터 <=> XXX -> 평균필터 -> 평균필터\nconv(XXX0.reshape(1,49,49,1))[...,1] ### XXX0 -> 엣지필터 <=> XXX -> 평균필터 -> 엣지필터\nconv(XXX1.reshape(1,49,49,1))[...,0] ### XXX1 -> 평균필터 <=> XXX -> 엣지필터 -> 평균필터\nconv(XXX1.reshape(1,49,49,1))[...,1] ### XXX1 -> 엣지필터 <=> XXX -> 엣지필터 -> 엣지필터\n\n<tf.Tensor: shape=(1, 48, 48), dtype=float32, numpy=\narray([[[ 1.01424513e+01,  1.01844015e+01,  9.86733055e+00, ...,\n         -4.99692082e-01,  5.39378747e-02,  8.02920163e-01],\n        [ 1.00365734e+01,  1.01637259e+01,  1.02149420e+01, ...,\n         -7.43912578e-01, -3.86977196e-01,  3.25240284e-01],\n        [ 9.74410343e+00,  1.01362820e+01,  1.04401426e+01, ...,\n         -8.01947534e-01, -6.61381423e-01, -1.04143508e-01],\n        ...,\n        [ 9.49301243e+00,  9.22852516e+00,  9.76124573e+00, ...,\n         -3.70009184e-01, -2.82902658e-01, -3.20988595e-01],\n        [ 9.30175495e+00,  9.21834087e+00,  9.71927547e+00, ...,\n         -1.98229820e-01, -1.02326170e-01, -4.37277794e-01],\n        [ 8.87968922e+00,  8.97130108e+00,  9.59087849e+00, ...,\n         -5.38469851e-03, -4.02716398e-01, -6.30852461e-01]]],\n      dtype=float32)>\n\n\n\nfig,ax =plt.subplots(3,4)\n\n\n\n\n\nax[0][0].imshow(XXX.reshape(50,50),cmap='gray') # 원래이미지\n\n<matplotlib.image.AxesImage at 0x7f61a4265540>\n\n\n\nax[1][0].imshow(XXX0.reshape(49,49),cmap='gray') # 원래이미지 -> 평균필터\nax[1][2].imshow(XXX1.reshape(49,49),cmap='gray') # 원래이미지 -> 엣지필터\n\n<matplotlib.image.AxesImage at 0x7f61a429b880>\n\n\n\nax[2][0].imshow(conv(XXX0.reshape(1,49,49,1))[...,0].reshape(48,48),cmap='gray') # 원래이미지 -> 평균필터\nax[2][1].imshow(conv(XXX0.reshape(1,49,49,1))[...,1].reshape(48,48),cmap='gray') # 원래이미지 -> 엣지필터\nax[2][2].imshow(conv(XXX1.reshape(1,49,49,1))[...,0].reshape(48,48),cmap='gray') # 원래이미지 -> 평균필터\nax[2][3].imshow(conv(XXX1.reshape(1,49,49,1))[...,1].reshape(48,48),cmap='gray') # 원래이미지 -> 엣지필터\n\n<matplotlib.image.AxesImage at 0x7f61a415e380>\n\n\n\nfig.set_figheight(8)\nfig.set_figwidth(16)\nfig.tight_layout()\nfig\n\n\n\n\n- 요약 - conv의 weight에 따라서 엣지를 검출하는 필터가 만들어지기도 하고 스무딩의 역할을 하는 필터가 만들어지기도 한다. 그리고 우리는 의미를 알 수 없지만 어떠한 역할을 하는 필터가 만들어질 것이다. - 이것들을 조합하다보면 우연히 이미지를 분류하기에 유리한 특징을 뽑아내는 weight가 맞춰질 수도 있겠다. - 채널수를 많이 만들고 다양한 웨이트조합을 실험하다보면 보다 복잡한 이미지의 특징을 추출할 수도 있을 것이다? - 컨볼루션 레이어의 역할 = 이미지의 특징을 추출하는 역할\n- 참고: 스트라이드, 패딩 - 스트라이드: 윈도우가 1칸씩 이동하는 것이 아니라 2~3칸씩 이동함 - 패딩: 이미지의 가장자리에 정당한 값을 넣어서 (예를들어 0) 컨볼루션을 수행. 따라서 컨볼루션 연산 이후에도 이미지의 크기가 줄어들지 않도록 방지한다.\n\n\n\n- 기본적역할: 이미지의 크기를 줄이는 것 - 이미지의의 크기를 줄여야하는 이유? 어차피 최종적으로 10차원으로 줄어야하므로 - 이미지의 크기를 줄이면서도 동시에 아주 크리티컬한 특징은 손실없이 유지하고 싶다~\n- 점점 작은 이미지가 되면서 중요한 특징들은 살아남지만 그렇지 않으면 죽는다. (캐리커쳐 느낌)\n- 평균이 아니라 max를 쓴 이유는? 그냥 평균보다 나을것이라고 생각했음.. - 그런데 사실은 꼭 그렇지만은 않아서 최근에는 꼭 맥스풀링을 고집하진 않는 추세 (평균풀링도 많이씀)\n\n\n\n- 아래와 같이 아키텍처의 다이어그램형태로 표현하고 굳이 노드별로 이미지를 그리진 않음\n\n- 물론 아래와 같이 그리는 경우도 있음\n\n\n\n\n- 격자형태로 배열된 자료를 처리하는데 특화된 신경망이다. - 시계열 (1차원격자), 이미지 (2차원격자)\n- 실제응용에서 엄청난 성공을 거두었다.\n- 이름의 유래는 컨볼루션이라는 수학적 연산을 사용했기 때문 - 컨볼루션은 조금 특별한 선형변환이다.\n- 신경과학의 원리가 심층학습에 영향을 미친 사례이다.\n\n\n\n- 희소성 + 매개변수의 공유 - 다소 철학적인 모티브임 - 희소성: 이미지를 분석하여 특징을 뽑아낼때 부분부분의 특징만 뽑으면 된다는 의미 - 매개변수의 공유: 한 채널에는 하나의 역할을 하는 커널을 설계하면 된다는 의미 (스무딩이든 엣징이든). 즉 어떤지역은 스무딩, 어떤지역은 엣징을 할 필요가 없이 한채널에서는 엣징만, 다른채널에서는 스무딩만 수행한뒤 여러채널을 조합해서 이해하면 된다.\n- 매개변수 공유효과로 인해서 파라메터가 확 줄어든다.\n(예시) (1,6,6,1) -> (1,5,5,2) - MLP방식이면 (36,50) 의 차원을 가진 매트릭스가 필요함 => 1800개의 매개변수 필요 - CNN은 8개의 매개변수 필요\n\n\n\n- 기본유닛 - conv - activation - pooling - conv - conv - activation - pooling\n\n\n\n\n\n\n- 아래의 예제를 복습하자.\n\nnp.random.seed(43052)\nx = np.linspace(0,1,100).reshape(100,1)\ny = np.random.normal(loc=0,scale=0.01,size=(100,1))\nplt.plot(x,y)\n\n\n\n\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(2048,activation='relu'))\nnet.add(tf.keras.layers.Dense(1))\nnet.compile(loss='mse',optimizer='adam')\nnet.fit(x,y,epochs=5000,verbose=0,batch_size=100)\n\n2022-05-23 19:33:01.211991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n\n\n<keras.callbacks.History at 0x7f1b9528feb0>\n\n\n\nplt.plot(x,y)\nplt.plot(x,net(x),'--')\n\n\n\n\n- train/test로 나누어서 생각해보자.\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(2048,activation='relu'))\nnet.add(tf.keras.layers.Dense(1))\nnet.compile(loss='mse',optimizer='adam')\nnet.fit(x[:80],y[:80],epochs=5000,verbose=0,batch_size=80)\n\n<keras.callbacks.History at 0x7f1b881f9840>\n\n\n\nplt.plot(x,y)\nplt.plot(x[:80],net(x[:80]),'--')\n\n\n\n\n\nplt.plot(x,y)\nplt.plot(x[:80],net(x[:80]),'--')\nplt.plot(x[80:],net(x[80:]),'--')\n\n\n\n\n\ntrain에서 추세를 따라가는게 좋은게 아니다 \\(\\to\\) 그냥 직선으로 핏하는거 이외에는 다 오버핏이다.\n\n- 매 에폭마다 적당히 80%의 노드들을 빼고 학습하자 \\(\\to\\) 너무 잘 학습되는 문제는 생기지 않을 것이다 (과적합이 방지될것이다?)\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(2048,activation='relu'))\nnet.add(tf.keras.layers.Dropout(0.8))\nnet.add(tf.keras.layers.Dense(1))\nnet.compile(loss='mse',optimizer='adam')\nnet.fit(x[:80],y[:80],epochs=5000,verbose=0,batch_size=80)\n\n<keras.callbacks.History at 0x7f1b80381a50>\n\n\n\nplt.plot(x,y)\nplt.plot(x[:80],net(x[:80]),'--')\nplt.plot(x[80:],net(x[80:]),'--')\n\n\n\n\n- 드랍아웃에 대한 summary - 직관: 특정노드를 랜덤으로 off시키면 학습이 방해되어 오히려 과적합이 방지되는 효과가 있다 (그렇지만 진짜 중요한 특징이라면 랜덤으로 off 되더라도 어느정도는 학습될 듯) - note: 드랍아웃을 쓰면 오버핏이 줄어드는건 맞지만 완전히 없어지는건 아니다. - note: 오버핏을 줄이는 유일한 방법이 드랍아웃만 있는것도 아니며, 드랍아웃이 오버핏을 줄이는 가장 효과적인 방법도 아니다 (최근에는 dropout보다 batch nomalization을 사용하는 추세임)\n\n\n\n- data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n\nX= x_train.reshape(-1,28,28,1)/255 ## 입력이 0~255 -> 0~1로 표준화 시키는 효과 + float으로 자료형이 바뀜\ny = tf.keras.utils.to_categorical(y_train)\nXX = x_test.reshape(-1,28,28,1)/255\nyy = tf.keras.utils.to_categorical(y_test)\n\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer='adam',loss=tf.losses.categorical_crossentropy,metrics='accuracy')\n\n\n#collapse_output\ncb1 = tf.keras.callbacks.TensorBoard()\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb1,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.7666 - val_loss: 0.4976 - val_accuracy: 0.8320\nEpoch 2/200\n240/240 [==============================] - 0s 887us/step - loss: 0.4703 - accuracy: 0.8400 - val_loss: 0.4822 - val_accuracy: 0.8320\nEpoch 3/200\n240/240 [==============================] - 0s 915us/step - loss: 0.4287 - accuracy: 0.8518 - val_loss: 0.4339 - val_accuracy: 0.8535\nEpoch 4/200\n240/240 [==============================] - 0s 949us/step - loss: 0.4061 - accuracy: 0.8592 - val_loss: 0.4077 - val_accuracy: 0.8568\nEpoch 5/200\n240/240 [==============================] - 0s 937us/step - loss: 0.3851 - accuracy: 0.8661 - val_loss: 0.3948 - val_accuracy: 0.8619\nEpoch 6/200\n240/240 [==============================] - 0s 951us/step - loss: 0.3703 - accuracy: 0.8699 - val_loss: 0.3900 - val_accuracy: 0.8617\nEpoch 7/200\n240/240 [==============================] - 0s 879us/step - loss: 0.3587 - accuracy: 0.8746 - val_loss: 0.3846 - val_accuracy: 0.8678\nEpoch 8/200\n240/240 [==============================] - 0s 897us/step - loss: 0.3468 - accuracy: 0.8768 - val_loss: 0.3684 - val_accuracy: 0.8716\nEpoch 9/200\n240/240 [==============================] - 0s 905us/step - loss: 0.3397 - accuracy: 0.8788 - val_loss: 0.3678 - val_accuracy: 0.8708\nEpoch 10/200\n240/240 [==============================] - 0s 918us/step - loss: 0.3307 - accuracy: 0.8806 - val_loss: 0.3619 - val_accuracy: 0.8726\nEpoch 11/200\n240/240 [==============================] - 0s 961us/step - loss: 0.3208 - accuracy: 0.8843 - val_loss: 0.3619 - val_accuracy: 0.8711\nEpoch 12/200\n240/240 [==============================] - 0s 896us/step - loss: 0.3160 - accuracy: 0.8857 - val_loss: 0.3572 - val_accuracy: 0.8734\nEpoch 13/200\n240/240 [==============================] - 0s 879us/step - loss: 0.3098 - accuracy: 0.8889 - val_loss: 0.3567 - val_accuracy: 0.8723\nEpoch 14/200\n240/240 [==============================] - 0s 914us/step - loss: 0.3023 - accuracy: 0.8915 - val_loss: 0.3545 - val_accuracy: 0.8751\nEpoch 15/200\n240/240 [==============================] - 0s 972us/step - loss: 0.2983 - accuracy: 0.8937 - val_loss: 0.3514 - val_accuracy: 0.8763\nEpoch 16/200\n240/240 [==============================] - 0s 963us/step - loss: 0.2945 - accuracy: 0.8939 - val_loss: 0.3745 - val_accuracy: 0.8639\nEpoch 17/200\n240/240 [==============================] - 0s 884us/step - loss: 0.2901 - accuracy: 0.8956 - val_loss: 0.3427 - val_accuracy: 0.8786\nEpoch 18/200\n240/240 [==============================] - 0s 876us/step - loss: 0.2835 - accuracy: 0.8972 - val_loss: 0.3470 - val_accuracy: 0.8770\nEpoch 19/200\n240/240 [==============================] - 0s 916us/step - loss: 0.2787 - accuracy: 0.8997 - val_loss: 0.3457 - val_accuracy: 0.8803\nEpoch 20/200\n240/240 [==============================] - 0s 943us/step - loss: 0.2741 - accuracy: 0.9007 - val_loss: 0.3373 - val_accuracy: 0.8814\nEpoch 21/200\n240/240 [==============================] - 0s 883us/step - loss: 0.2699 - accuracy: 0.9016 - val_loss: 0.3352 - val_accuracy: 0.8832\nEpoch 22/200\n240/240 [==============================] - 0s 880us/step - loss: 0.2644 - accuracy: 0.9036 - val_loss: 0.3320 - val_accuracy: 0.8817\nEpoch 23/200\n240/240 [==============================] - 0s 948us/step - loss: 0.2610 - accuracy: 0.9059 - val_loss: 0.3384 - val_accuracy: 0.8768\nEpoch 24/200\n240/240 [==============================] - 0s 946us/step - loss: 0.2575 - accuracy: 0.9076 - val_loss: 0.3446 - val_accuracy: 0.8785\nEpoch 25/200\n240/240 [==============================] - 0s 939us/step - loss: 0.2532 - accuracy: 0.9084 - val_loss: 0.3312 - val_accuracy: 0.8820\nEpoch 26/200\n240/240 [==============================] - 0s 967us/step - loss: 0.2509 - accuracy: 0.9094 - val_loss: 0.3383 - val_accuracy: 0.8833\nEpoch 27/200\n240/240 [==============================] - 0s 929us/step - loss: 0.2487 - accuracy: 0.9106 - val_loss: 0.3365 - val_accuracy: 0.8827\nEpoch 28/200\n240/240 [==============================] - 0s 943us/step - loss: 0.2450 - accuracy: 0.9123 - val_loss: 0.3376 - val_accuracy: 0.8827\nEpoch 29/200\n240/240 [==============================] - 0s 922us/step - loss: 0.2424 - accuracy: 0.9122 - val_loss: 0.3346 - val_accuracy: 0.8823\nEpoch 30/200\n240/240 [==============================] - 0s 903us/step - loss: 0.2407 - accuracy: 0.9137 - val_loss: 0.3367 - val_accuracy: 0.8813\nEpoch 31/200\n240/240 [==============================] - 0s 906us/step - loss: 0.2380 - accuracy: 0.9147 - val_loss: 0.3376 - val_accuracy: 0.8813\nEpoch 32/200\n240/240 [==============================] - 0s 885us/step - loss: 0.2349 - accuracy: 0.9155 - val_loss: 0.3372 - val_accuracy: 0.8856\nEpoch 33/200\n240/240 [==============================] - 0s 891us/step - loss: 0.2324 - accuracy: 0.9167 - val_loss: 0.3362 - val_accuracy: 0.8833\nEpoch 34/200\n240/240 [==============================] - 0s 900us/step - loss: 0.2285 - accuracy: 0.9177 - val_loss: 0.3486 - val_accuracy: 0.8810\nEpoch 35/200\n240/240 [==============================] - 0s 858us/step - loss: 0.2270 - accuracy: 0.9188 - val_loss: 0.3364 - val_accuracy: 0.8817\nEpoch 36/200\n240/240 [==============================] - 0s 893us/step - loss: 0.2241 - accuracy: 0.9204 - val_loss: 0.3401 - val_accuracy: 0.8852\nEpoch 37/200\n240/240 [==============================] - 0s 907us/step - loss: 0.2258 - accuracy: 0.9178 - val_loss: 0.3451 - val_accuracy: 0.8811\nEpoch 38/200\n240/240 [==============================] - 0s 899us/step - loss: 0.2249 - accuracy: 0.9196 - val_loss: 0.3377 - val_accuracy: 0.8836\nEpoch 39/200\n240/240 [==============================] - 0s 876us/step - loss: 0.2187 - accuracy: 0.9215 - val_loss: 0.3298 - val_accuracy: 0.8867\nEpoch 40/200\n240/240 [==============================] - 0s 905us/step - loss: 0.2148 - accuracy: 0.9229 - val_loss: 0.3342 - val_accuracy: 0.8853\nEpoch 41/200\n240/240 [==============================] - 0s 954us/step - loss: 0.2118 - accuracy: 0.9240 - val_loss: 0.3378 - val_accuracy: 0.8840\nEpoch 42/200\n240/240 [==============================] - 0s 916us/step - loss: 0.2135 - accuracy: 0.9243 - val_loss: 0.3348 - val_accuracy: 0.8857\nEpoch 43/200\n240/240 [==============================] - 0s 943us/step - loss: 0.2101 - accuracy: 0.9247 - val_loss: 0.3369 - val_accuracy: 0.8857\nEpoch 44/200\n240/240 [==============================] - 0s 877us/step - loss: 0.2069 - accuracy: 0.9261 - val_loss: 0.3400 - val_accuracy: 0.8832\nEpoch 45/200\n240/240 [==============================] - 0s 900us/step - loss: 0.2040 - accuracy: 0.9267 - val_loss: 0.3358 - val_accuracy: 0.8854\nEpoch 46/200\n240/240 [==============================] - 0s 926us/step - loss: 0.2029 - accuracy: 0.9271 - val_loss: 0.3562 - val_accuracy: 0.8802\nEpoch 47/200\n240/240 [==============================] - 0s 901us/step - loss: 0.2052 - accuracy: 0.9263 - val_loss: 0.3509 - val_accuracy: 0.8841\nEpoch 48/200\n240/240 [==============================] - 0s 927us/step - loss: 0.1977 - accuracy: 0.9296 - val_loss: 0.3434 - val_accuracy: 0.8852\nEpoch 49/200\n240/240 [==============================] - 0s 870us/step - loss: 0.1980 - accuracy: 0.9281 - val_loss: 0.3587 - val_accuracy: 0.8810\nEpoch 50/200\n240/240 [==============================] - 0s 874us/step - loss: 0.1972 - accuracy: 0.9292 - val_loss: 0.3483 - val_accuracy: 0.8828\nEpoch 51/200\n240/240 [==============================] - 0s 924us/step - loss: 0.1973 - accuracy: 0.9286 - val_loss: 0.3518 - val_accuracy: 0.8834\nEpoch 52/200\n240/240 [==============================] - 0s 886us/step - loss: 0.1920 - accuracy: 0.9309 - val_loss: 0.3647 - val_accuracy: 0.8796\nEpoch 53/200\n240/240 [==============================] - 0s 901us/step - loss: 0.1935 - accuracy: 0.9306 - val_loss: 0.3571 - val_accuracy: 0.8831\nEpoch 54/200\n240/240 [==============================] - 0s 946us/step - loss: 0.1918 - accuracy: 0.9311 - val_loss: 0.3545 - val_accuracy: 0.8834\nEpoch 55/200\n240/240 [==============================] - 0s 950us/step - loss: 0.1921 - accuracy: 0.9306 - val_loss: 0.3643 - val_accuracy: 0.8823\nEpoch 56/200\n240/240 [==============================] - 0s 913us/step - loss: 0.1870 - accuracy: 0.9335 - val_loss: 0.3665 - val_accuracy: 0.8798\nEpoch 57/200\n240/240 [==============================] - 0s 908us/step - loss: 0.1857 - accuracy: 0.9328 - val_loss: 0.3539 - val_accuracy: 0.8833\nEpoch 58/200\n240/240 [==============================] - 0s 919us/step - loss: 0.1815 - accuracy: 0.9353 - val_loss: 0.3569 - val_accuracy: 0.8833\nEpoch 59/200\n240/240 [==============================] - 0s 863us/step - loss: 0.1832 - accuracy: 0.9337 - val_loss: 0.3603 - val_accuracy: 0.8833\nEpoch 60/200\n240/240 [==============================] - 0s 912us/step - loss: 0.1804 - accuracy: 0.9361 - val_loss: 0.3690 - val_accuracy: 0.8812\nEpoch 61/200\n240/240 [==============================] - 0s 858us/step - loss: 0.1769 - accuracy: 0.9368 - val_loss: 0.3624 - val_accuracy: 0.8840\nEpoch 62/200\n240/240 [==============================] - 0s 885us/step - loss: 0.1756 - accuracy: 0.9366 - val_loss: 0.3637 - val_accuracy: 0.8829\nEpoch 63/200\n240/240 [==============================] - 0s 903us/step - loss: 0.1766 - accuracy: 0.9363 - val_loss: 0.3663 - val_accuracy: 0.8824\nEpoch 64/200\n240/240 [==============================] - 0s 878us/step - loss: 0.1767 - accuracy: 0.9363 - val_loss: 0.3694 - val_accuracy: 0.8825\nEpoch 65/200\n240/240 [==============================] - 0s 866us/step - loss: 0.1733 - accuracy: 0.9377 - val_loss: 0.3820 - val_accuracy: 0.8838\nEpoch 66/200\n240/240 [==============================] - 0s 949us/step - loss: 0.1742 - accuracy: 0.9370 - val_loss: 0.3721 - val_accuracy: 0.8825\nEpoch 67/200\n240/240 [==============================] - 0s 887us/step - loss: 0.1698 - accuracy: 0.9386 - val_loss: 0.3717 - val_accuracy: 0.8838\nEpoch 68/200\n240/240 [==============================] - 0s 942us/step - loss: 0.1683 - accuracy: 0.9399 - val_loss: 0.3823 - val_accuracy: 0.8821\nEpoch 69/200\n240/240 [==============================] - 0s 951us/step - loss: 0.1680 - accuracy: 0.9406 - val_loss: 0.3739 - val_accuracy: 0.8865\nEpoch 70/200\n240/240 [==============================] - 0s 900us/step - loss: 0.1673 - accuracy: 0.9395 - val_loss: 0.3789 - val_accuracy: 0.8821\nEpoch 71/200\n240/240 [==============================] - 0s 904us/step - loss: 0.1671 - accuracy: 0.9396 - val_loss: 0.3881 - val_accuracy: 0.8808\nEpoch 72/200\n240/240 [==============================] - 0s 915us/step - loss: 0.1664 - accuracy: 0.9396 - val_loss: 0.3821 - val_accuracy: 0.8824\nEpoch 73/200\n240/240 [==============================] - 0s 899us/step - loss: 0.1603 - accuracy: 0.9433 - val_loss: 0.3864 - val_accuracy: 0.8822\nEpoch 74/200\n240/240 [==============================] - 0s 926us/step - loss: 0.1621 - accuracy: 0.9411 - val_loss: 0.3850 - val_accuracy: 0.8820\nEpoch 75/200\n240/240 [==============================] - 0s 902us/step - loss: 0.1578 - accuracy: 0.9439 - val_loss: 0.3827 - val_accuracy: 0.8838\nEpoch 76/200\n240/240 [==============================] - 0s 899us/step - loss: 0.1589 - accuracy: 0.9431 - val_loss: 0.4160 - val_accuracy: 0.8751\nEpoch 77/200\n240/240 [==============================] - 0s 909us/step - loss: 0.1597 - accuracy: 0.9426 - val_loss: 0.3934 - val_accuracy: 0.8810\nEpoch 78/200\n240/240 [==============================] - 0s 894us/step - loss: 0.1582 - accuracy: 0.9420 - val_loss: 0.4076 - val_accuracy: 0.8777\nEpoch 79/200\n240/240 [==============================] - 0s 897us/step - loss: 0.1573 - accuracy: 0.9439 - val_loss: 0.3890 - val_accuracy: 0.8832\nEpoch 80/200\n240/240 [==============================] - 0s 917us/step - loss: 0.1567 - accuracy: 0.9445 - val_loss: 0.4039 - val_accuracy: 0.8805\nEpoch 81/200\n240/240 [==============================] - 0s 921us/step - loss: 0.1529 - accuracy: 0.9455 - val_loss: 0.3967 - val_accuracy: 0.8818\nEpoch 82/200\n240/240 [==============================] - 0s 919us/step - loss: 0.1522 - accuracy: 0.9456 - val_loss: 0.4028 - val_accuracy: 0.8796\nEpoch 83/200\n240/240 [==============================] - 0s 984us/step - loss: 0.1501 - accuracy: 0.9462 - val_loss: 0.4147 - val_accuracy: 0.8802\nEpoch 84/200\n240/240 [==============================] - 0s 873us/step - loss: 0.1493 - accuracy: 0.9466 - val_loss: 0.3956 - val_accuracy: 0.8818\nEpoch 85/200\n240/240 [==============================] - 0s 882us/step - loss: 0.1484 - accuracy: 0.9470 - val_loss: 0.4121 - val_accuracy: 0.8807\nEpoch 86/200\n240/240 [==============================] - 0s 894us/step - loss: 0.1504 - accuracy: 0.9449 - val_loss: 0.4089 - val_accuracy: 0.8790\nEpoch 87/200\n240/240 [==============================] - 0s 924us/step - loss: 0.1437 - accuracy: 0.9493 - val_loss: 0.4243 - val_accuracy: 0.8776\nEpoch 88/200\n240/240 [==============================] - 0s 905us/step - loss: 0.1462 - accuracy: 0.9478 - val_loss: 0.4123 - val_accuracy: 0.8799\nEpoch 89/200\n240/240 [==============================] - 0s 950us/step - loss: 0.1444 - accuracy: 0.9479 - val_loss: 0.4105 - val_accuracy: 0.8823\nEpoch 90/200\n240/240 [==============================] - 0s 908us/step - loss: 0.1460 - accuracy: 0.9482 - val_loss: 0.4103 - val_accuracy: 0.8827\nEpoch 91/200\n240/240 [==============================] - 0s 889us/step - loss: 0.1425 - accuracy: 0.9489 - val_loss: 0.4112 - val_accuracy: 0.8819\nEpoch 92/200\n240/240 [==============================] - 0s 869us/step - loss: 0.1455 - accuracy: 0.9483 - val_loss: 0.4115 - val_accuracy: 0.8818\nEpoch 93/200\n240/240 [==============================] - 0s 917us/step - loss: 0.1412 - accuracy: 0.9491 - val_loss: 0.4177 - val_accuracy: 0.8805\nEpoch 94/200\n240/240 [==============================] - 0s 865us/step - loss: 0.1398 - accuracy: 0.9500 - val_loss: 0.4177 - val_accuracy: 0.8813\nEpoch 95/200\n240/240 [==============================] - 0s 910us/step - loss: 0.1417 - accuracy: 0.9504 - val_loss: 0.4248 - val_accuracy: 0.8796\nEpoch 96/200\n240/240 [==============================] - 0s 917us/step - loss: 0.1392 - accuracy: 0.9499 - val_loss: 0.4207 - val_accuracy: 0.8840\nEpoch 97/200\n240/240 [==============================] - 0s 872us/step - loss: 0.1366 - accuracy: 0.9514 - val_loss: 0.4218 - val_accuracy: 0.8810\nEpoch 98/200\n240/240 [==============================] - 0s 896us/step - loss: 0.1344 - accuracy: 0.9519 - val_loss: 0.4281 - val_accuracy: 0.8794\nEpoch 99/200\n240/240 [==============================] - 0s 928us/step - loss: 0.1346 - accuracy: 0.9521 - val_loss: 0.4304 - val_accuracy: 0.8803\nEpoch 100/200\n240/240 [==============================] - 0s 849us/step - loss: 0.1368 - accuracy: 0.9511 - val_loss: 0.4335 - val_accuracy: 0.8800\nEpoch 101/200\n240/240 [==============================] - 0s 930us/step - loss: 0.1317 - accuracy: 0.9540 - val_loss: 0.4345 - val_accuracy: 0.8799\nEpoch 102/200\n240/240 [==============================] - 0s 919us/step - loss: 0.1318 - accuracy: 0.9530 - val_loss: 0.4430 - val_accuracy: 0.8774\nEpoch 103/200\n240/240 [==============================] - 0s 905us/step - loss: 0.1306 - accuracy: 0.9538 - val_loss: 0.4427 - val_accuracy: 0.8783\nEpoch 104/200\n240/240 [==============================] - 0s 892us/step - loss: 0.1322 - accuracy: 0.9532 - val_loss: 0.4409 - val_accuracy: 0.8797\nEpoch 105/200\n240/240 [==============================] - 0s 853us/step - loss: 0.1322 - accuracy: 0.9524 - val_loss: 0.4631 - val_accuracy: 0.8759\nEpoch 106/200\n240/240 [==============================] - 0s 901us/step - loss: 0.1295 - accuracy: 0.9540 - val_loss: 0.4451 - val_accuracy: 0.8811\nEpoch 107/200\n240/240 [==============================] - 0s 910us/step - loss: 0.1287 - accuracy: 0.9539 - val_loss: 0.4393 - val_accuracy: 0.8795\nEpoch 108/200\n240/240 [==============================] - 0s 927us/step - loss: 0.1265 - accuracy: 0.9549 - val_loss: 0.4547 - val_accuracy: 0.8783\nEpoch 109/200\n240/240 [==============================] - 0s 899us/step - loss: 0.1257 - accuracy: 0.9553 - val_loss: 0.4467 - val_accuracy: 0.8798\nEpoch 110/200\n240/240 [==============================] - 0s 911us/step - loss: 0.1264 - accuracy: 0.9558 - val_loss: 0.4494 - val_accuracy: 0.8775\nEpoch 111/200\n240/240 [==============================] - 0s 911us/step - loss: 0.1256 - accuracy: 0.9550 - val_loss: 0.4600 - val_accuracy: 0.8777\nEpoch 112/200\n240/240 [==============================] - 0s 897us/step - loss: 0.1241 - accuracy: 0.9561 - val_loss: 0.4468 - val_accuracy: 0.8785\nEpoch 113/200\n240/240 [==============================] - 0s 904us/step - loss: 0.1242 - accuracy: 0.9556 - val_loss: 0.4592 - val_accuracy: 0.8788\nEpoch 114/200\n240/240 [==============================] - 0s 913us/step - loss: 0.1224 - accuracy: 0.9574 - val_loss: 0.4640 - val_accuracy: 0.8778\nEpoch 115/200\n240/240 [==============================] - 0s 912us/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.4590 - val_accuracy: 0.8777\nEpoch 116/200\n240/240 [==============================] - 0s 907us/step - loss: 0.1222 - accuracy: 0.9568 - val_loss: 0.4762 - val_accuracy: 0.8781\nEpoch 117/200\n240/240 [==============================] - 0s 913us/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 0.4585 - val_accuracy: 0.8818\nEpoch 118/200\n240/240 [==============================] - 0s 901us/step - loss: 0.1207 - accuracy: 0.9571 - val_loss: 0.4796 - val_accuracy: 0.8770\nEpoch 119/200\n240/240 [==============================] - 0s 883us/step - loss: 0.1194 - accuracy: 0.9574 - val_loss: 0.4711 - val_accuracy: 0.8790\nEpoch 120/200\n240/240 [==============================] - 0s 953us/step - loss: 0.1204 - accuracy: 0.9565 - val_loss: 0.4612 - val_accuracy: 0.8796\nEpoch 121/200\n240/240 [==============================] - 0s 887us/step - loss: 0.1138 - accuracy: 0.9596 - val_loss: 0.4792 - val_accuracy: 0.8770\nEpoch 122/200\n240/240 [==============================] - 0s 874us/step - loss: 0.1142 - accuracy: 0.9602 - val_loss: 0.4784 - val_accuracy: 0.8762\nEpoch 123/200\n240/240 [==============================] - 0s 914us/step - loss: 0.1184 - accuracy: 0.9574 - val_loss: 0.4791 - val_accuracy: 0.8787\nEpoch 124/200\n240/240 [==============================] - 0s 922us/step - loss: 0.1161 - accuracy: 0.9593 - val_loss: 0.4876 - val_accuracy: 0.8763\nEpoch 125/200\n240/240 [==============================] - 0s 882us/step - loss: 0.1159 - accuracy: 0.9584 - val_loss: 0.4888 - val_accuracy: 0.8745\nEpoch 126/200\n240/240 [==============================] - 0s 951us/step - loss: 0.1140 - accuracy: 0.9597 - val_loss: 0.5025 - val_accuracy: 0.8754\nEpoch 127/200\n240/240 [==============================] - 0s 900us/step - loss: 0.1151 - accuracy: 0.9593 - val_loss: 0.4892 - val_accuracy: 0.8747\nEpoch 128/200\n240/240 [==============================] - 0s 890us/step - loss: 0.1100 - accuracy: 0.9611 - val_loss: 0.4833 - val_accuracy: 0.8777\nEpoch 129/200\n240/240 [==============================] - 0s 890us/step - loss: 0.1121 - accuracy: 0.9606 - val_loss: 0.4996 - val_accuracy: 0.8720\nEpoch 130/200\n240/240 [==============================] - 0s 892us/step - loss: 0.1097 - accuracy: 0.9614 - val_loss: 0.4904 - val_accuracy: 0.8779\nEpoch 131/200\n240/240 [==============================] - 0s 888us/step - loss: 0.1084 - accuracy: 0.9620 - val_loss: 0.4944 - val_accuracy: 0.8748\nEpoch 132/200\n240/240 [==============================] - 0s 931us/step - loss: 0.1123 - accuracy: 0.9604 - val_loss: 0.4892 - val_accuracy: 0.8778\nEpoch 133/200\n240/240 [==============================] - 0s 896us/step - loss: 0.1097 - accuracy: 0.9621 - val_loss: 0.5165 - val_accuracy: 0.8733\nEpoch 134/200\n240/240 [==============================] - 0s 897us/step - loss: 0.1050 - accuracy: 0.9631 - val_loss: 0.5124 - val_accuracy: 0.8731\nEpoch 135/200\n240/240 [==============================] - 0s 915us/step - loss: 0.1093 - accuracy: 0.9618 - val_loss: 0.5165 - val_accuracy: 0.8733\nEpoch 136/200\n240/240 [==============================] - 0s 909us/step - loss: 0.1045 - accuracy: 0.9640 - val_loss: 0.5045 - val_accuracy: 0.8781\nEpoch 137/200\n240/240 [==============================] - 0s 931us/step - loss: 0.1056 - accuracy: 0.9627 - val_loss: 0.5124 - val_accuracy: 0.8773\nEpoch 138/200\n240/240 [==============================] - 0s 905us/step - loss: 0.1089 - accuracy: 0.9610 - val_loss: 0.5152 - val_accuracy: 0.8751\nEpoch 139/200\n240/240 [==============================] - 0s 922us/step - loss: 0.1059 - accuracy: 0.9628 - val_loss: 0.5150 - val_accuracy: 0.8744\nEpoch 140/200\n240/240 [==============================] - 0s 923us/step - loss: 0.1031 - accuracy: 0.9638 - val_loss: 0.5156 - val_accuracy: 0.8740\nEpoch 141/200\n240/240 [==============================] - 0s 870us/step - loss: 0.1063 - accuracy: 0.9620 - val_loss: 0.5207 - val_accuracy: 0.8719\nEpoch 142/200\n240/240 [==============================] - 0s 904us/step - loss: 0.1054 - accuracy: 0.9621 - val_loss: 0.5220 - val_accuracy: 0.8740\nEpoch 143/200\n240/240 [==============================] - 0s 929us/step - loss: 0.1043 - accuracy: 0.9623 - val_loss: 0.5356 - val_accuracy: 0.8736\nEpoch 144/200\n240/240 [==============================] - 0s 869us/step - loss: 0.1039 - accuracy: 0.9636 - val_loss: 0.5403 - val_accuracy: 0.8737\nEpoch 145/200\n240/240 [==============================] - 0s 872us/step - loss: 0.1014 - accuracy: 0.9649 - val_loss: 0.5294 - val_accuracy: 0.8751\nEpoch 146/200\n240/240 [==============================] - 0s 903us/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 0.5321 - val_accuracy: 0.8770\nEpoch 147/200\n240/240 [==============================] - 0s 906us/step - loss: 0.1012 - accuracy: 0.9646 - val_loss: 0.5329 - val_accuracy: 0.8748\nEpoch 148/200\n240/240 [==============================] - 0s 909us/step - loss: 0.1006 - accuracy: 0.9645 - val_loss: 0.5368 - val_accuracy: 0.8743\nEpoch 149/200\n240/240 [==============================] - 0s 872us/step - loss: 0.0975 - accuracy: 0.9656 - val_loss: 0.5320 - val_accuracy: 0.8759\nEpoch 150/200\n240/240 [==============================] - 0s 895us/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.5357 - val_accuracy: 0.8745\nEpoch 151/200\n240/240 [==============================] - 0s 896us/step - loss: 0.0962 - accuracy: 0.9668 - val_loss: 0.5353 - val_accuracy: 0.8748\nEpoch 152/200\n240/240 [==============================] - 0s 936us/step - loss: 0.0955 - accuracy: 0.9674 - val_loss: 0.5318 - val_accuracy: 0.8763\nEpoch 153/200\n240/240 [==============================] - 0s 878us/step - loss: 0.0970 - accuracy: 0.9660 - val_loss: 0.5866 - val_accuracy: 0.8702\nEpoch 154/200\n240/240 [==============================] - 0s 940us/step - loss: 0.0992 - accuracy: 0.9646 - val_loss: 0.5421 - val_accuracy: 0.8750\nEpoch 155/200\n240/240 [==============================] - 0s 931us/step - loss: 0.0965 - accuracy: 0.9661 - val_loss: 0.5436 - val_accuracy: 0.8739\nEpoch 156/200\n240/240 [==============================] - 0s 939us/step - loss: 0.0959 - accuracy: 0.9666 - val_loss: 0.5542 - val_accuracy: 0.8745\nEpoch 157/200\n240/240 [==============================] - 0s 898us/step - loss: 0.0980 - accuracy: 0.9647 - val_loss: 0.5441 - val_accuracy: 0.8747\nEpoch 158/200\n240/240 [==============================] - 0s 905us/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.5507 - val_accuracy: 0.8746\nEpoch 159/200\n240/240 [==============================] - 0s 905us/step - loss: 0.0950 - accuracy: 0.9663 - val_loss: 0.5700 - val_accuracy: 0.8712\nEpoch 160/200\n240/240 [==============================] - 0s 927us/step - loss: 0.0908 - accuracy: 0.9679 - val_loss: 0.5641 - val_accuracy: 0.8727\nEpoch 161/200\n240/240 [==============================] - 0s 937us/step - loss: 0.0936 - accuracy: 0.9668 - val_loss: 0.5689 - val_accuracy: 0.8750\nEpoch 162/200\n240/240 [==============================] - 0s 899us/step - loss: 0.0888 - accuracy: 0.9694 - val_loss: 0.5641 - val_accuracy: 0.8772\nEpoch 163/200\n240/240 [==============================] - 0s 907us/step - loss: 0.0903 - accuracy: 0.9685 - val_loss: 0.5628 - val_accuracy: 0.8737\nEpoch 164/200\n240/240 [==============================] - 0s 908us/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.5623 - val_accuracy: 0.8752\nEpoch 165/200\n240/240 [==============================] - 0s 949us/step - loss: 0.0880 - accuracy: 0.9696 - val_loss: 0.5775 - val_accuracy: 0.8713\nEpoch 166/200\n240/240 [==============================] - 0s 930us/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 0.5924 - val_accuracy: 0.8719\nEpoch 167/200\n240/240 [==============================] - 0s 932us/step - loss: 0.0868 - accuracy: 0.9697 - val_loss: 0.5952 - val_accuracy: 0.8719\nEpoch 168/200\n240/240 [==============================] - 0s 861us/step - loss: 0.0910 - accuracy: 0.9679 - val_loss: 0.5820 - val_accuracy: 0.8733\nEpoch 169/200\n240/240 [==============================] - 0s 938us/step - loss: 0.0871 - accuracy: 0.9700 - val_loss: 0.5781 - val_accuracy: 0.8734\nEpoch 170/200\n240/240 [==============================] - 0s 912us/step - loss: 0.0885 - accuracy: 0.9691 - val_loss: 0.5683 - val_accuracy: 0.8742\nEpoch 171/200\n240/240 [==============================] - 0s 939us/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 0.5945 - val_accuracy: 0.8721\nEpoch 172/200\n240/240 [==============================] - 0s 888us/step - loss: 0.0878 - accuracy: 0.9684 - val_loss: 0.5798 - val_accuracy: 0.8744\nEpoch 173/200\n240/240 [==============================] - 0s 917us/step - loss: 0.0852 - accuracy: 0.9710 - val_loss: 0.6017 - val_accuracy: 0.8690\nEpoch 174/200\n240/240 [==============================] - 0s 872us/step - loss: 0.0838 - accuracy: 0.9714 - val_loss: 0.5840 - val_accuracy: 0.8753\nEpoch 175/200\n240/240 [==============================] - 0s 937us/step - loss: 0.0863 - accuracy: 0.9697 - val_loss: 0.5770 - val_accuracy: 0.8726\nEpoch 176/200\n240/240 [==============================] - 0s 892us/step - loss: 0.0854 - accuracy: 0.9697 - val_loss: 0.5971 - val_accuracy: 0.8741\nEpoch 177/200\n240/240 [==============================] - 0s 924us/step - loss: 0.0896 - accuracy: 0.9674 - val_loss: 0.5859 - val_accuracy: 0.8743\nEpoch 178/200\n240/240 [==============================] - 0s 904us/step - loss: 0.0845 - accuracy: 0.9699 - val_loss: 0.6103 - val_accuracy: 0.8723\nEpoch 179/200\n240/240 [==============================] - 0s 889us/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.6157 - val_accuracy: 0.8708\nEpoch 180/200\n240/240 [==============================] - 0s 902us/step - loss: 0.0850 - accuracy: 0.9697 - val_loss: 0.5974 - val_accuracy: 0.8752\nEpoch 181/200\n240/240 [==============================] - 0s 899us/step - loss: 0.0825 - accuracy: 0.9710 - val_loss: 0.6102 - val_accuracy: 0.8736\nEpoch 182/200\n240/240 [==============================] - 0s 895us/step - loss: 0.0833 - accuracy: 0.9709 - val_loss: 0.6265 - val_accuracy: 0.8690\nEpoch 183/200\n240/240 [==============================] - 0s 899us/step - loss: 0.0821 - accuracy: 0.9715 - val_loss: 0.6197 - val_accuracy: 0.8718\nEpoch 184/200\n240/240 [==============================] - 0s 940us/step - loss: 0.0791 - accuracy: 0.9727 - val_loss: 0.6139 - val_accuracy: 0.8727\nEpoch 185/200\n240/240 [==============================] - 0s 880us/step - loss: 0.0815 - accuracy: 0.9716 - val_loss: 0.6055 - val_accuracy: 0.8718\nEpoch 186/200\n240/240 [==============================] - 0s 878us/step - loss: 0.0860 - accuracy: 0.9696 - val_loss: 0.6192 - val_accuracy: 0.8713\nEpoch 187/200\n240/240 [==============================] - 0s 925us/step - loss: 0.0905 - accuracy: 0.9680 - val_loss: 0.6147 - val_accuracy: 0.8722\nEpoch 188/200\n240/240 [==============================] - 0s 884us/step - loss: 0.0826 - accuracy: 0.9707 - val_loss: 0.6203 - val_accuracy: 0.8737\nEpoch 189/200\n240/240 [==============================] - 0s 934us/step - loss: 0.0810 - accuracy: 0.9722 - val_loss: 0.6316 - val_accuracy: 0.8701\nEpoch 190/200\n240/240 [==============================] - 0s 899us/step - loss: 0.0763 - accuracy: 0.9735 - val_loss: 0.6246 - val_accuracy: 0.8758\nEpoch 191/200\n240/240 [==============================] - 0s 888us/step - loss: 0.0767 - accuracy: 0.9736 - val_loss: 0.6358 - val_accuracy: 0.8712\nEpoch 192/200\n240/240 [==============================] - 0s 867us/step - loss: 0.0792 - accuracy: 0.9728 - val_loss: 0.6281 - val_accuracy: 0.8749\nEpoch 193/200\n240/240 [==============================] - 0s 932us/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 0.6248 - val_accuracy: 0.8737\nEpoch 194/200\n240/240 [==============================] - 0s 919us/step - loss: 0.0765 - accuracy: 0.9733 - val_loss: 0.6223 - val_accuracy: 0.8734\nEpoch 195/200\n240/240 [==============================] - 0s 870us/step - loss: 0.0796 - accuracy: 0.9724 - val_loss: 0.6413 - val_accuracy: 0.8707\nEpoch 196/200\n240/240 [==============================] - 0s 903us/step - loss: 0.0750 - accuracy: 0.9742 - val_loss: 0.6315 - val_accuracy: 0.8737\nEpoch 197/200\n240/240 [==============================] - 0s 901us/step - loss: 0.0789 - accuracy: 0.9724 - val_loss: 0.6602 - val_accuracy: 0.8684\nEpoch 198/200\n240/240 [==============================] - 0s 915us/step - loss: 0.0793 - accuracy: 0.9720 - val_loss: 0.6615 - val_accuracy: 0.8698\nEpoch 199/200\n240/240 [==============================] - 0s 892us/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.6486 - val_accuracy: 0.8692\nEpoch 200/200\n240/240 [==============================] - 0s 937us/step - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.6474 - val_accuracy: 0.8723\n\n\n<keras.callbacks.History at 0x7f1b802e05b0>\n\n\n- 텐서보드 여는 방법1\n\n%load_ext tensorboard\n# 주피터노트북 (혹은 주피터랩)에서 텐서보드를 임베딩하여 넣을 수 있도록 도와주는 매직펑션\n\n\n#\n# !rm -rf logs\n# !kill 313799\n\n\n#\n# %tensorboard --logdir logs --host 0.0.0.0\n# %tensorboard --logdir logs # <-- 실습에서는 이렇게 하면됩니다.\n\n(참고사항) 파이썬 3.10의 경우 아래의 수정이 필요\n?/python3.10/site-packages/tensorboard/_vendor/html5lib/_trie/_base.py 을 열고\nfrom collections import Mapping ### 수정전\nfrom collections.abc import Mapping ### 수정후\n와 같이 수정한다.\n\n왜냐하면 파이썬 3.10부터 from collections import Mapping 가 동작하지 않고 from collections.abc import Mapping 가 동작하도록 문법이 바뀜\n\n- 텐서보드를 실행하는 방법2\n\n#\n# !tensorboard --logdir logs --host 0.0.0.0\n# !tensorboard --logdir logs # <-- 실습에서는 이렇게 하면됩니다.\n\n\n\n\n- 텐서보드를 살펴보니 특정에폭 이후에는 오히려 과적합이 진행되는 듯 하다 (학습할수록 손해인듯 하다) \\(\\to\\) 그 특정에폭까지만 학습해보자\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(5000,activation='relu')) ## 과적합좀 시키려고\nnet.add(tf.keras.layers.Dense(5000,activation='relu')) ## 레이어를 2장만듬 + 레이어하나당 노드수도 증가\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer='adam',loss=tf.losses.categorical_crossentropy,metrics='accuracy')\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=1) # val-loss가 1회증가하면 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 4ms/step - loss: 0.5483 - accuracy: 0.8134 - val_loss: 0.4027 - val_accuracy: 0.8546\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.3568 - accuracy: 0.8671 - val_loss: 0.3531 - val_accuracy: 0.8712\nEpoch 3/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.8799 - val_loss: 0.3477 - val_accuracy: 0.8733\nEpoch 4/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.8876 - val_loss: 0.3502 - val_accuracy: 0.8776\n\n\n<keras.callbacks.History at 0x7f1b80086650>\n\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=1) # val-loss가 1회증가하면 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2791 - accuracy: 0.8935 - val_loss: 0.3224 - val_accuracy: 0.8820\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.8999 - val_loss: 0.3498 - val_accuracy: 0.8779\n\n\n<keras.callbacks.History at 0x7f1b24290a90>\n\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=1) # val-loss가 1회증가하면 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.9043 - val_loss: 0.3641 - val_accuracy: 0.8711\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9110 - val_loss: 0.3282 - val_accuracy: 0.8848\nEpoch 3/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2254 - accuracy: 0.9151 - val_loss: 0.3280 - val_accuracy: 0.8843\nEpoch 4/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9177 - val_loss: 0.3191 - val_accuracy: 0.8925\nEpoch 5/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2074 - accuracy: 0.9223 - val_loss: 0.3152 - val_accuracy: 0.8949\nEpoch 6/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.3322 - val_accuracy: 0.8863\n\n\n<keras.callbacks.History at 0x7f1b242c1660>\n\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=1) # val-loss가 1회증가하면 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9257 - val_loss: 0.3513 - val_accuracy: 0.8836\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9304 - val_loss: 0.3376 - val_accuracy: 0.8901\nEpoch 3/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9346 - val_loss: 0.3568 - val_accuracy: 0.8894\n\n\n<keras.callbacks.History at 0x7f1b24302230>\n\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=1) # val-loss가 1회증가하면 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9367 - val_loss: 0.3995 - val_accuracy: 0.8780\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9398 - val_loss: 0.3469 - val_accuracy: 0.8917\nEpoch 3/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1481 - accuracy: 0.9423 - val_loss: 0.3726 - val_accuracy: 0.8853\n\n\n<keras.callbacks.History at 0x7f1b24136e00>\n\n\n- 몇 번 좀 참았다가 멈추면 좋겠다.\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(5000,activation='relu')) ## 과적합좀 시키려고\nnet.add(tf.keras.layers.Dense(5000,activation='relu')) ## 레이어를 2장만듬 + 레이어하나당 노드수도 증가\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer='adam',loss=tf.losses.categorical_crossentropy,metrics='accuracy')\n\n\n#\n#cb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=5) # 좀더 참다가 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=cb2,verbose=1)\n\nEpoch 1/200\n240/240 [==============================] - 1s 4ms/step - loss: 0.5475 - accuracy: 0.8139 - val_loss: 0.4219 - val_accuracy: 0.8453\nEpoch 2/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8676 - val_loss: 0.3647 - val_accuracy: 0.8712\nEpoch 3/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8792 - val_loss: 0.3559 - val_accuracy: 0.8710\nEpoch 4/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2990 - accuracy: 0.8883 - val_loss: 0.3448 - val_accuracy: 0.8808\nEpoch 5/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8966 - val_loss: 0.3337 - val_accuracy: 0.8792\nEpoch 6/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.9004 - val_loss: 0.3220 - val_accuracy: 0.8841\nEpoch 7/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2478 - accuracy: 0.9074 - val_loss: 0.3302 - val_accuracy: 0.8858\nEpoch 8/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2342 - accuracy: 0.9110 - val_loss: 0.3150 - val_accuracy: 0.8904\nEpoch 9/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2261 - accuracy: 0.9144 - val_loss: 0.3117 - val_accuracy: 0.8932\nEpoch 10/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9200 - val_loss: 0.3345 - val_accuracy: 0.8888\nEpoch 11/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.2081 - accuracy: 0.9207 - val_loss: 0.3344 - val_accuracy: 0.8867\nEpoch 12/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9255 - val_loss: 0.3158 - val_accuracy: 0.8975\nEpoch 13/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1863 - accuracy: 0.9275 - val_loss: 0.3302 - val_accuracy: 0.8934\nEpoch 14/200\n240/240 [==============================] - 1s 3ms/step - loss: 0.1764 - accuracy: 0.9324 - val_loss: 0.3717 - val_accuracy: 0.8859\n\n\n<keras.callbacks.History at 0x7f1b24301960>\n\n\n- 텐서보드로 그려보자?\n\n#\n# %tensorboard --logdir logs --host 0.0.0.0\n# 아무것도 안나온다 -> 왜? cb1을 써야 텐서보드가 나옴\n\n- 조기종료와 텐서보드를 같이 쓰려면?\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer='adam',loss=tf.losses.categorical_crossentropy,metrics='accuracy')\n\n\ncb1 = tf.keras.callbacks.TensorBoard()\ncb2 = tf.keras.callbacks.EarlyStopping(patience=7) # 좀더 참다가 멈추어라\nnet.fit(X,y,epochs=200,batch_size=200,validation_split=0.2,callbacks=[cb1,cb2])\n\nEpoch 1/200\n240/240 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.7581 - val_loss: 0.5077 - val_accuracy: 0.8276\nEpoch 2/200\n240/240 [==============================] - 0s 890us/step - loss: 0.4752 - accuracy: 0.8386 - val_loss: 0.4793 - val_accuracy: 0.8342\nEpoch 3/200\n240/240 [==============================] - 0s 899us/step - loss: 0.4304 - accuracy: 0.8517 - val_loss: 0.4386 - val_accuracy: 0.8497\nEpoch 4/200\n240/240 [==============================] - 0s 880us/step - loss: 0.4048 - accuracy: 0.8582 - val_loss: 0.4029 - val_accuracy: 0.8603\nEpoch 5/200\n240/240 [==============================] - 0s 923us/step - loss: 0.3832 - accuracy: 0.8669 - val_loss: 0.3932 - val_accuracy: 0.8619\nEpoch 6/200\n240/240 [==============================] - 0s 934us/step - loss: 0.3697 - accuracy: 0.8705 - val_loss: 0.3842 - val_accuracy: 0.8657\nEpoch 7/200\n240/240 [==============================] - 0s 900us/step - loss: 0.3569 - accuracy: 0.8759 - val_loss: 0.3844 - val_accuracy: 0.8668\nEpoch 8/200\n240/240 [==============================] - 0s 889us/step - loss: 0.3482 - accuracy: 0.8774 - val_loss: 0.3679 - val_accuracy: 0.8708\nEpoch 9/200\n240/240 [==============================] - 0s 912us/step - loss: 0.3387 - accuracy: 0.8799 - val_loss: 0.3602 - val_accuracy: 0.8719\nEpoch 10/200\n240/240 [==============================] - 0s 923us/step - loss: 0.3299 - accuracy: 0.8820 - val_loss: 0.3610 - val_accuracy: 0.8748\nEpoch 11/200\n240/240 [==============================] - 0s 853us/step - loss: 0.3229 - accuracy: 0.8858 - val_loss: 0.3574 - val_accuracy: 0.8717\nEpoch 12/200\n240/240 [==============================] - 0s 904us/step - loss: 0.3157 - accuracy: 0.8873 - val_loss: 0.3572 - val_accuracy: 0.8743\nEpoch 13/200\n240/240 [==============================] - 0s 890us/step - loss: 0.3106 - accuracy: 0.8899 - val_loss: 0.3545 - val_accuracy: 0.8761\nEpoch 14/200\n240/240 [==============================] - 0s 911us/step - loss: 0.3046 - accuracy: 0.8914 - val_loss: 0.3493 - val_accuracy: 0.8759\nEpoch 15/200\n240/240 [==============================] - 0s 921us/step - loss: 0.3011 - accuracy: 0.8928 - val_loss: 0.3483 - val_accuracy: 0.8776\nEpoch 16/200\n240/240 [==============================] - 0s 937us/step - loss: 0.2988 - accuracy: 0.8935 - val_loss: 0.3733 - val_accuracy: 0.8716\nEpoch 17/200\n240/240 [==============================] - 0s 892us/step - loss: 0.2925 - accuracy: 0.8947 - val_loss: 0.3481 - val_accuracy: 0.8768\nEpoch 18/200\n240/240 [==============================] - 0s 933us/step - loss: 0.2880 - accuracy: 0.8951 - val_loss: 0.3396 - val_accuracy: 0.8801\nEpoch 19/200\n240/240 [==============================] - 0s 957us/step - loss: 0.2827 - accuracy: 0.8982 - val_loss: 0.3439 - val_accuracy: 0.8798\nEpoch 20/200\n240/240 [==============================] - 0s 881us/step - loss: 0.2791 - accuracy: 0.8986 - val_loss: 0.3489 - val_accuracy: 0.8779\nEpoch 21/200\n240/240 [==============================] - 0s 886us/step - loss: 0.2765 - accuracy: 0.9007 - val_loss: 0.3350 - val_accuracy: 0.8823\nEpoch 22/200\n240/240 [==============================] - 0s 912us/step - loss: 0.2709 - accuracy: 0.9016 - val_loss: 0.3350 - val_accuracy: 0.8812\nEpoch 23/200\n240/240 [==============================] - 0s 908us/step - loss: 0.2688 - accuracy: 0.9029 - val_loss: 0.3374 - val_accuracy: 0.8820\nEpoch 24/200\n240/240 [==============================] - 0s 930us/step - loss: 0.2658 - accuracy: 0.9041 - val_loss: 0.3445 - val_accuracy: 0.8805\nEpoch 25/200\n240/240 [==============================] - 0s 872us/step - loss: 0.2607 - accuracy: 0.9058 - val_loss: 0.3383 - val_accuracy: 0.8822\nEpoch 26/200\n240/240 [==============================] - 0s 928us/step - loss: 0.2607 - accuracy: 0.9056 - val_loss: 0.3415 - val_accuracy: 0.8811\nEpoch 27/200\n240/240 [==============================] - 0s 927us/step - loss: 0.2576 - accuracy: 0.9068 - val_loss: 0.3402 - val_accuracy: 0.8814\nEpoch 28/200\n240/240 [==============================] - 0s 905us/step - loss: 0.2525 - accuracy: 0.9098 - val_loss: 0.3469 - val_accuracy: 0.8802\n\n\n<keras.callbacks.History at 0x7f1b24217a00>\n\n\n\n#\n# 조기종료가 구현된 그림이 출력\n# %tensorboard --logdir logs --host 0.0.0.0\n\n\n\n\n- 하이퍼파라메터 설정\n\nfrom tensorboard.plugins.hparams import api as hp\n\n\na=net.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 859us/step - loss: 0.3803 - accuracy: 0.8704\n\n\n\n!rm -rf logs\nfor u in [50,5000]:\n    for d in [0.0,0.5]:\n        for o in ['adam','sgd']:\n            logdir = 'logs/hpguebin_{}_{}_{}'.format(u,d,o)\n            with tf.summary.create_file_writer(logdir).as_default():\n                net = tf.keras.Sequential()\n                net.add(tf.keras.layers.Flatten())\n                net.add(tf.keras.layers.Dense(u,activation='relu'))\n                net.add(tf.keras.layers.Dropout(d))\n                net.add(tf.keras.layers.Dense(10,activation='softmax'))\n                net.compile(optimizer=o,loss=tf.losses.categorical_crossentropy,metrics=['accuracy','Recall'])\n                cb3 = hp.KerasCallback(logdir, {'유닛수':u, '드랍아웃비율':d, '옵티마이저':o})\n                net.fit(X,y,epochs=3,callbacks=cb3)\n                _rslt=net.evaluate(XX,yy)\n                _mymetric=_rslt[1]*0.8 + _rslt[2]*0.2\n                tf.summary.scalar('애큐러시와리컬의가중평균(테스트셋)', _mymetric, step=1)\n\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5255 - accuracy: 0.8180 - recall: 0.7546\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.3993 - accuracy: 0.8588 - recall: 0.8294\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.3648 - accuracy: 0.8698 - recall: 0.8443\n313/313 [==============================] - 0s 830us/step - loss: 0.4063 - accuracy: 0.8545 - recall: 0.8286\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.7744 - accuracy: 0.7503 - recall: 0.5797\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5204 - accuracy: 0.8223 - recall: 0.7565\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4742 - accuracy: 0.8369 - recall: 0.7859\n313/313 [==============================] - 0s 828us/step - loss: 0.4899 - accuracy: 0.8304 - recall: 0.7831\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.7502 - accuracy: 0.7356 - recall: 0.6115\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5738 - accuracy: 0.7923 - recall: 0.7133\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5473 - accuracy: 0.8037 - recall: 0.7321\n313/313 [==============================] - 0s 865us/step - loss: 0.4319 - accuracy: 0.8448 - recall: 0.7919\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 1.0932 - accuracy: 0.6228 - recall: 0.3971\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.7616 - accuracy: 0.7388 - recall: 0.5956\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.6828 - accuracy: 0.7684 - recall: 0.6478\n313/313 [==============================] - 0s 894us/step - loss: 0.5265 - accuracy: 0.8180 - recall: 0.7353\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4777 - accuracy: 0.8292 - recall: 0.7890\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.3603 - accuracy: 0.8682 - recall: 0.8427\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.3197 - accuracy: 0.8817 - recall: 0.8605\n313/313 [==============================] - 0s 846us/step - loss: 0.3803 - accuracy: 0.8628 - recall: 0.8428\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.6685 - accuracy: 0.7883 - recall: 0.6444\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4815 - accuracy: 0.8372 - recall: 0.7781\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4408 - accuracy: 0.8498 - recall: 0.8021\n313/313 [==============================] - 0s 859us/step - loss: 0.4634 - accuracy: 0.8390 - recall: 0.7962\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5708 - accuracy: 0.7991 - recall: 0.7556\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4418 - accuracy: 0.8393 - recall: 0.8057\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4091 - accuracy: 0.8514 - recall: 0.8211\n313/313 [==============================] - 0s 850us/step - loss: 0.3937 - accuracy: 0.8587 - recall: 0.8238\nEpoch 1/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.6930 - accuracy: 0.7752 - recall: 0.6338\nEpoch 2/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.5048 - accuracy: 0.8274 - recall: 0.7651\nEpoch 3/3\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4608 - accuracy: 0.8417 - recall: 0.7910\n313/313 [==============================] - 0s 854us/step - loss: 0.4625 - accuracy: 0.8396 - recall: 0.7957\n\n\n\n#\n#%tensorboard --logdir logs --host 0.0.0.0\n\n\n\n\n\n- 아래의 네트워크에서 옵티마이저를 adam, sgd를 선택하여 각각 적합시켜보고 testset의 loss를 성능비교를 하라. epoch은 5정도로 설정하라.\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(50,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(optimizer=???,loss=tf.losses.categorical_crossentropy,metrics=['accuracy','Recall'])"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_14_(2주차)_3월14일.html",
    "href": "posts/3_STBDA2022/2022_03_14_(2주차)_3월14일.html",
    "title": "[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)",
    "section": "",
    "text": "(2주차) 3월14일\n\n강의노트\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-z8oR8bQZHR0mpy_9OcsWOz\n\n\n\nimport\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[]\n\n\n\n\ntf.constant\n\n예비학습: 중첩리스트\n- 리스트\n\nlst = [1,2,4,5,6]\nlst \n\n[1, 2, 4, 5, 6]\n\n\n\nlst[1] # 두번쨰원소 \n\n2\n\n\n\nlst[-1] # 마지막원소 \n\n6\n\n\n- (2,2) matrix 느낌의 list\n\nlst= [[1,2],[3,4]]\nlst\n\n[[1, 2], [3, 4]]\n\n\n위를 아래와 같은 매트릭스로 생각할수 있다.\n1 2 \n3 4 \n\nprint(lst[0][0]) # (1,1) \nprint(lst[0][1]) # (1,2) \nprint(lst[1][0]) # (2,1) \nprint(lst[1][1]) # (2,2) \n\n1\n2\n3\n4\n\n\n- (4,1) matrix 느낌의 list\n\nlst=[[1],[2],[3],[4]] # (4,1) matrix = 길이가 4인 col-vector\nlst\n\n[[1], [2], [3], [4]]\n\n\n\nnp.array(lst), np.array(lst).shape\n\n(array([[1],\n        [2],\n        [3],\n        [4]]),\n (4, 1))\n\n\n- (1,4) matrix 느낌의 list\n\nlst=[[1,2,3,4]] # (1,4) matrix = 길이가 4인 row-vector \nlst\n\n[[1, 2, 3, 4]]\n\n\n\nnp.array(lst), np.array(lst).shape\n\n(array([[1, 2, 3, 4]]), (1, 4))\n\n\n\n\n선언 (변수 선언하는 법?)\n\n텐서플로우를 쓰려면 텐서로 바꿔줘야 한다.\n\n- 스칼라\n\ntf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n\n\n\ntf.constant(3.14)+tf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=6.28>\n\n\n- 벡터\n\ntype(1),type([1,2,3]), type(_vector) # int 혹은 list 타입 --> EagerTensor 타입으로 바꾸라는 뜻.\n\n(int, list, tensorflow.python.framework.ops.EagerTensor)\n\n\n\n_vector=tf.constant([1,2,3])\n\n\n_vector[-1]\n\n<tf.Tensor: shape=(), dtype=int32, numpy=3>\n\n\n- 매트릭스\n\n_matrix= tf.constant([[1,0],[0,1]])\n_matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 1]], dtype=int32)>\n\n\n- array\n\ntf.constant([[[0,1,1],[1,2,-1]],[[0,1,2],[1,2,-1]]])\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  1,  1],\n        [ 1,  2, -1]],\n\n       [[ 0,  1,  2],\n        [ 1,  2, -1]]], dtype=int32)>\n\n\n\n\n타입\n\ntype(tf.constant(3.14))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\nEagerTensor 타입이라는 것만 기억!\n\n\n\n인덱싱\n\n_matrix = tf.constant([[1,2],[3,4]])\n_matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n\n_matrix[0][0]\n\n<tf.Tensor: shape=(), dtype=int32, numpy=1>\n\n\n\n_matrix[0]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\n_matrix[0,:]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\n_matrix[:,0]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3], dtype=int32)>\n\n\n\n\ntf.constant는 불편하다.\n- 불편한점 1. 모든 원소가 같은 dtype을 가지고 있어야함. 2. 원소 수정이 불가능함. 3. 묵시적 형변환이 불가능하다.\n- 원소수정이 불가능함\n\na=tf.constant([1,22,33])\na\n\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 22, 33], dtype=int32)>\n\n\n\na[0]=11 \n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n- 묵시적 형변환이 불가능하다\n\n1 + 3.14 # 1(int), 3.14(float) --> 4.14(float)\n\n4.140000000000001\n\n\n\n1을 float으로 암묵적으로 바꿔서 계산함.\n\n\ntf.constant(1)+tf.constant(3.14) ## 에러!\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]\n\n\n\nint와 float이라 에러나는 것\n\n\ntf.constant(1.0)+tf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=4.1400003>\n\n\n- 같은 float도 안되는 경우가 있음\n\ntf.constant(1.0,dtype=tf.float64)\n\n<tf.Tensor: shape=(), dtype=float64, numpy=1.0>\n\n\n\ntf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n\n\n\ntf.constant(1.0,dtype=tf.float64)+tf.constant(3.14)\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:AddV2]\n\n\n\n조금만 틀리면 에러남..\n\n\n\ntf.constant \\(\\to\\) 넘파이\n\nnp.array(tf.constant(1)) # 방법1\n\narray(1, dtype=int32)\n\n\n\nnumpy로 연산을 다 해놓고 tensor로 바꾼다..\n\n\na=tf.constant([3.14,-3.14])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na.numpy() # numpy라는 메서드가 있음.\n\narray([ 3.14, -3.14], dtype=float32)\n\n\n\n\n연산\n- 더하기\n\na=tf.constant([1,2])\nb=tf.constant([3,4])\na+b\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>\n\n\n처음에 int로 선언했으면 나머지도 모두 int로 선언해야해..\n\ntf.add(a,b)\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>\n\n\n\n결과는 동일\n\n- 곱하기\n\na=tf.constant([[1,2],[3,4]])\nb=tf.constant([[5,6],[7,8]])\na*b # elementwise 하게 곱한하고 한다.\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)>\n\n\n\ntf.multiply(a,b) # 이게 먼저 나왔음.\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)>\n\n\n- 매트릭스의곱\n\na=tf.constant([[1,0],[0,1]]) # (2,2)\nb=tf.constant([[5],[7]]) # (2,1) \na@b\n\n<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)>\n\n\n\ntf.matmul(a,b)\n\n<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)>\n\n\n- 역행렬\n\na=tf.constant([[1,0],[0,2]])\na\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 2]], dtype=int32)>\n\n\n\ntf.linalg.inv(a)\n\nInvalidArgumentError: Value for attr 'T' of int32 is not in the list of allowed values: double, float, half, complex64, complex128\n    ; NodeDef: {{node MatrixInverse}}; Op<name=MatrixInverse; signature=input:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]> [Op:MatrixInverse]\n\n\n\n1/2을 계산하려면 애초에 float형이어야 했음.\n\n\na=tf.constant([[1.0,0.0],[0.0,2.0]])\ntf.linalg.inv(a)\n\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1. , 0. ],\n       [0. , 0.5]], dtype=float32)>\n\n\n- tf.linalg. + tab을 누르면 좋아보이는 연산들 많음\n\na=tf.constant([[1.0,2.0],[3.0,4.0]])\nprint(a)\ntf.linalg.det(a)\n\ntf.Tensor(\n[[1. 2.]\n [3. 4.]], shape=(2, 2), dtype=float32)\n\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>\n\n\n\ntf.linalg.trace(a)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=5.0>\n\n\n\n\n형태변환\n- 기본: tf.reshape() 를 이용\n\na=tf.constant([1,2,3,4]) #  길이가 4인 vector\na\n\n<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntf.reshape(a,(4,1)) # column-vec로 변환.\n\n<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2))\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,1))\n\n<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\narray([[[1],\n        [2]],\n\n       [[3],\n        [4]]], dtype=int32)>\n\n\n- 다차원\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12]) # 길이가 12인 vector\na\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,3)) # 2*2*3\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\ntf.reshape(a,(4,3)) # 4*3\n\n<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)>\n\n\n- tf.reshape\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12])\na\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\ntf.reshape(a,(4,-1)) # 원소 어짜피 12개 있으니까 4만 주면 나머지 3은 알아서 맞춰줌.\n\n<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,-1))\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\nb=tf.reshape(a,(2,2,-1))\nb\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\ntf.reshape(b,-1) # 길이가 12인 vector로 바꿔줌.\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\n\n선언고급\n뭔가를 초기화할 때 필요한 기능을 정리한 것입니다.\n- 다른 자료형 (리스트나 넘파이)로 만들고 바꾸는것도 좋다.\n\nnp.diag([1,2,3,4])\n\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])\n\n\n\ntf.constant(np.diag([1,2,3,4]))\n\n<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])>\n\n\n- tf.ones, tf.zeros\n\ntf.zeros([3,3])\n\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)>\n\n\n\ntf.reshape(tf.constant([0]*9),(3,3)) # tensor로 바꾸고 shape을 바꿔주는 방법도 있다.\n\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]], dtype=int32)>\n\n\n- range(10)\n\na=range(0,12)\ntype(a) # type이 range임!\n\nrange\n\n\n\nlist(a) # 타입을 list로 바꿀 수 있음.\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n\n\n\na=range(0,12)\ntf.constant(a)\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)>\n\n\n\ntf.constant(range(1,20,3)) \n\n<tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32)>\n\n\n- tf.linspace\n\ntf.linspace(0,1,10) # 0부터시작해서 1까지 총 10개 // 여기서는 1(마지막 숫자)이 포함됨\n\n<tf.Tensor: shape=(10,), dtype=float64, numpy=\narray([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])>\n\n\n\n\ntf.concat\n- (2,1) concat (2,1) => (2,2) - 두번째 축이 바뀌었다. => axis=1\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b # 2개의 col-vec\n\n(<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)>,\n <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=1) # 2col-vec -> matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 3],\n       [2, 4]], dtype=int32)>\n\n\n- (2,1) concat (2,1) => (4,1) - 첫번째 축이 바뀌었다. => axis=0\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b\n\n(<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)>,\n <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)>\n\n\n- (1,2) concat (1,2) => (2,2) - 첫번째 // axis=0\n\na=tf.constant([[1,2]])\nb=tf.constant([[3,4]])\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n- (1,2) concat (1,2) => (1,4) - 두번째 // axis=1\n- (2,3,4,5) concat (2,3,4,5) => (4,3,4,5) - 첫번째 // axis=0\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 3, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]]],\n\n\n       [[[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,6,4,5) - 두번째 // axis=1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=1)\n\n<tf.Tensor: shape=(2, 6, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]],\n\n        [[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]],\n\n        [[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,3,8,5) - 세번째 // axis=2\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=2)\n\n<tf.Tensor: shape=(2, 3, 8, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19],\n         [   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39],\n         [ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59],\n         [ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79],\n         [ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99],\n         [ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119],\n         [-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,3,4,10) - 네번째 // axis=3 # 0,1,2,3 // -4 -3 -2 -1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 10), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4,    0,   -1,   -2,   -3,   -4],\n         [   5,    6,    7,    8,    9,   -5,   -6,   -7,   -8,   -9],\n         [  10,   11,   12,   13,   14,  -10,  -11,  -12,  -13,  -14],\n         [  15,   16,   17,   18,   19,  -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24,  -20,  -21,  -22,  -23,  -24],\n         [  25,   26,   27,   28,   29,  -25,  -26,  -27,  -28,  -29],\n         [  30,   31,   32,   33,   34,  -30,  -31,  -32,  -33,  -34],\n         [  35,   36,   37,   38,   39,  -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44,  -40,  -41,  -42,  -43,  -44],\n         [  45,   46,   47,   48,   49,  -45,  -46,  -47,  -48,  -49],\n         [  50,   51,   52,   53,   54,  -50,  -51,  -52,  -53,  -54],\n         [  55,   56,   57,   58,   59,  -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64,  -60,  -61,  -62,  -63,  -64],\n         [  65,   66,   67,   68,   69,  -65,  -66,  -67,  -68,  -69],\n         [  70,   71,   72,   73,   74,  -70,  -71,  -72,  -73,  -74],\n         [  75,   76,   77,   78,   79,  -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84,  -80,  -81,  -82,  -83,  -84],\n         [  85,   86,   87,   88,   89,  -85,  -86,  -87,  -88,  -89],\n         [  90,   91,   92,   93,   94,  -90,  -91,  -92,  -93,  -94],\n         [  95,   96,   97,   98,   99,  -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104, -100, -101, -102, -103, -104],\n         [ 105,  106,  107,  108,  109, -105, -106, -107, -108, -109],\n         [ 110,  111,  112,  113,  114, -110, -111, -112, -113, -114],\n         [ 115,  116,  117,  118,  119, -115, -116, -117, -118, -119]]]],\n      dtype=int32)>\n\n\n- (4,) concat (4,) => (8,) - 첫번째축? // axis=0\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 1,  2,  3,  4, -1, -2, -3, -4], dtype=int32)>\n\n\n- (4,) concat (4,) => (4,2) - 두번째축? // axis=1 ==> 이런거없다..\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=1)\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat\n\n\n\n에러남! 이럴때는 tf.stack을 쓰면 된다.\n\n\n\ntf.stack\n\nstack은 차원이 늘어남!\n\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4]], dtype=int32)>\n\n\n\ntf.stack([a,b],axis=1)\n\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3],\n       [ 4, -4]], dtype=int32)>\n\n\n\n\n\ntnp\n- tf는 넘파이에 비하여 텐서만들기가 너무힘듬\n\nnp.diag([1,2,3])\n\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])\n\n\n\nnp.diag([1,2,3]).reshape(-1)\n\narray([1, 0, 0, 0, 2, 0, 0, 0, 3])\n\n\n\n넘파이는 이런식으로 np.diag()도 쓸수 있고 reshape을 메소드로 쓸 수도 있는데…\n\n\ntnp 사용방법 (불만해결방법)\ntensorflow에서 numpy처럼 동작하도록 할 수 있는 모듈이라고 생각 즉, np의 모방버전으로 생각하면 된다.\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\n\ntype(tnp.array([1,2,3]))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n이렇게 만들어도 된다.\n\n- int와 float을 더할 수 있음\n\ntnp.array([1,2,3])+tnp.array([1.0,2.0,3.0])\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])>\n\n\n\ntf.constant([1,2,3])+tf.constant([1.0,2.0,3.0]) # 이게 원래 에러났었음!\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])>\n\n\n\ntnp 모듈을 불러오는 순간 tf로 선언하는 모든 것들도 우리가 알고있는 넘파이처럼 동작합니다.\n\n\ntnp.array(1)+tnp.array([1.0,2.0,3.0])\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 3., 4.])>\n\n\n\ntnp.diag([1,2,3])\n\n<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])>\n\n\n\na=tnp.diag([1,2,3])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na=tf.constant([1,2,3])\na.reshape(3,1)\n\n<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3]], dtype=int32)>\n\n\n\n\n선언고급\n\nnp.random.randn(5) # random module\n\narray([1.12411749, 1.43127059, 0.61763568, 0.43586944, 0.33208259])\n\n\n\ntnp.random.randn(5) # 넘파이가 되면 나도 된다.\n\n<tf.Tensor: shape=(5,), dtype=float64, numpy=array([-0.64055227, -1.33606436, -0.71424816,  1.61243245, -2.07980232])>\n\n\n\n\n타입\n\ntype(tnp.random.randn(5))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n\ntf.contant로 만들어도 마치 넘파이인듯 쓰는 기능들\n- 묵시적형변환이 가능\nint랑 float을 계산할 수 있다는 것\n\ntf.constant([1,1])+tf.constant([2.2,3.3])\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([3.20000005, 4.29999995])>\n\n\n- 메소드를 쓸수 있음.\n사용가능한 메소드가 많아짐..\n\na= tnp.array([[1,2,3,4]])\na.T\n\n<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]])>\n\n\n\n\n그렇지만 np.array는 아님\n- 원소를 할당하는것은 불가능\n\na=tf.constant([1,2,3])\na\n\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n\n\n\na[0]=11\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n그냥 새로 만들어서 할당해야 함. (그래도 많이 개선된 것@)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-wvV9xuYHvx0Gn7KDGNJbwj"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#import",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#import",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "import",
    "text": "import\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow.experimental.numpy as tnp\n\n\ntf.config.experimental.list_physical_devices()\n\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+ s + ';}')\n\n\nbasis가 orthogonal하냐?\noverfitting 이슈는 변수가 많다고해서 무조건 발생하는 것은 아님! 변수가 많이 있어도 orthogonal하게 잘 넣으면 심지어 무한대의 basis를 갖고있어도 overfitting이슈가 발생하지 않는다. 이렇게 맞추는 것을 semi-parametric modeling 이라고 한다!\n\nex. 직선의 basis: 절편과 기울기"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#중간고사-관련-잡담",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#중간고사-관련-잡담",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "중간고사 관련 잡담",
    "text": "중간고사 관련 잡담\n\n중간고사 3번문제\n- 특이한모형: 오버핏이 일어날 수 없는 모형이다. - 유의미한 coef: 상수항(bias), \\(\\cos(t)\\)의 계수, \\(\\cos(2t)\\)의 계수, \\(\\cos(5t)\\)의 계수. - 유의미하지 않은 coef: \\(\\cos(3t)\\)의 계수, \\(\\cos(4t)\\)의 계수 - 유의미하지 않은 계수는 \\(n%\\)이 커질수록 0으로 추정된다 = \\(\\cos(3t)\\)와 \\(\\cos(5t)\\)는 사용자가 임의로 제외하지 않아도 결국 모형에서 알아서 제거된다 = overfit이 일어나지 않는다. 모형이 알아서 유의미한 변수만 뽑아서 fit하는 느낌\n- 3번문제는 overfit이 일어나지 않는다. 이러한 신기한 일이 일어나는 이유는 모든 설명변수가 직교하기 때문임. - 이런 모형의 장점: overfit이 일어날 위험이 없으므로 train/test로 나누어 학습할 이유가 없다. (샘플만 버리는 꼴, test에 빼둔 observation까지 모아서 학습해 \\(\\beta\\)를 좀 더 정확히 추론하는게 차라리 더 이득) - 이러한 모형에서 할일: 추정된 계수들이 0인지 아닌지만 test하면 된다. (이것을 유의성검정이라고 한다)\n- 직교기저의 예시 - 빨강과 파랑을 255,255만큼 섞으면 보라색이 된다. - 빨강과 파랑과 노랑을 각각 255,255,255만큼 섞으면 검은색이 된다. - 임의의 어떠한 색도 빨강,파랑,노랑의 조합으로 표현가능하다. 즉 \\(\\text{color}= \\text{red}*\\beta_1 + \\text{blue}*\\beta_2 + \\text{yellow}*\\beta_3\\) 이다. - (빨,파,노)는 색을 표현하는 basis이다. (적절한 \\(\\beta_1,\\beta_2,\\beta_3\\)을 구하기만 하면 임의의 색도 표현가능) - (빨,보,노)역시 색을 표현하는 basis라 볼 수 있다. (파란색이 필요할때 보라색-빨간색을 하면되니까) - (빨,보,검)역시 색을 표현하는 basis라 볼 수 있다. (파란색이 필요하면 보라색-빨간색을 하면되고, 노란색이 필요하면 검정색-보라색을 하면 되니까) - (빨,파,노)는 직교기저이다.\n- 3번에서 알아둘 것: (1) 직교기저의 개념 (추후 재설명) (2) 임의의 색을 표현하려면 3개의 basis가 필요함\n\n\n중간고사 1-(3)번 문제\n- 그림을 그려보자.\n\n_x= tf.constant(np.arange(1,10001)/10000)\n_y= tnp.random.randn(10000) + (0.5 + 2*_x)\nplt.plot(_x,_y,'.',alpha=0.1)\n\n\n\n\n- 저것 꼭 10000개 다 모아서 loss계산해야할까?\n\nplt.plot(_x,_y,'.',alpha=0.1)\nplt.plot(_x[::10],_y[::10],'.') # 10씩 jump해서 점이 찍힘.\n\n\n\n\n- 대충 이정도만 모아서 해도 비슷하지 않을까? \\(\\to\\) 해보자!\n\n주황색만가지고 기울기, 절편 추론을 해보자."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#경사하강법과-확률적경사하강법",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#경사하강법과-확률적경사하강법",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "경사하강법과 확률적경사하강법",
    "text": "경사하강법과 확률적경사하강법\n원래 확률적경사하강법이 딥러닝을 하려고 만든것이 아니다.(만들어진 의도와 사용이 다름) 그런데 거기에 맞게 진화를 한 것. 그래서 되게 헷갈린다…\n\nver1: 모든 샘플을 사용하여 slope계산 (gradient descent)\n- 단순회귀분석에서 샘플 10개 관측: \\((x_1,y_1),\\dots,(x_{10},y_{10})\\).\n(epoch1) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n(epoch2) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n…\nfor문 이 3번 돌아감.\n\n\nver2: 하나의 샘플만 사용하여 slope계산\n(epoch1) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n(epoch2) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n…\nfor문이 30번 돌아감.\n\n\nver3: \\(m(\\leq n)\\)개의 샘플만 사용하여 slope계산 (mini-batch)\n\\(m=3\\)이라고 하자.\n(epoch1) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n1,2,3번 observation들만 뽑아서 loss를 계산해서 그것만가지고 update \\(\\to\\) 4,5,6먼만 가지고 loss계산해서 update \\(\\to\\) 7,8,9를가지고 loss구하고 업데이트 \\(\\to\\) 남은 하나가지고 loss구하고 업데이트… // 한 에폭 끝!\n(epoch2) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\quad \\to \\quad slope \\quad \\to \\quad update\\)\n…\n\n\n용어의 정리\n\n옛날 (좀 더 엄밀)\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n\n\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n\n지금은 mini-batch가 포함된 방법을 stochastic gradient descent라고 부른다. 왜냐하면 1,2는 사장된 방법. 버전 3만 쓴다.(유명한 사람들이 학회에서 그렇게 부르기 시작했음.)\nnote: 이렇게 많이 쓰는 이유? ver1,2는 사실상 없는 방법이므로\n\n\n\nver1,2,3 이외에 좀 더 지저분한 것들이 있다.\n- ver2,3에서 샘플을 셔플할 수도 있다.\n- ver3에서 일부 샘플이 학습에 참여 안하는 버전도 있다.\n- 개인적 생각: 크게3개정도만 알면 괜찮고 나머지는 그렇게 유의미하지 않아보인다.\n\n\nDiscussion\n- 핵심개념\n\n메모리사용량1: ver1 > ver3 > ver2\n계산속도: ver1 > ver3 > ver2\nlocal-min에 갇힘: ver1 > ver3 > ver2\n\n로컬미니멈에 갇힌가는 건 로컬미니멈을 잘 찾는다라고 생각 (정신이 제대로 박힌애)\n대충대충 학습하면 로컬미니멈에서 딱 멈춰야하는데 대충대충 계산해서 기울기가 딱 \\(0\\)이 안나오는 것. (운 좋게 탈출하는 경우도 있음.)\n- 본질: GPU 메모리가 한정되어 있어서 ver1을 쓰지는 못한다. GPU 메모리를 가장 적게쓰는것은 ver2인데 이것은 너무 불안정하다.\n- 틀리진 않지만 어색한 블로그 정리 내용들\n\n경사하강법은 종종 국소최소점에 갇히는 문제가 있다. 이를 해결하기 위해서 등장한 방법이 확률적 경사하강법이다. –> 영 틀린말은 아니지만 그걸 의도하고 만든건 아님 (이건 side effect)\n경사하강법은 계산시간이 오래걸린다. 계산을 빠르게 하기 위해서 등장한 방법이 확률적 경사하강법이다. –> 1회 업데이트는 빠르게 계산함. 하지만 그것이 최적의 \\(\\beta\\)를 빠르게 얻을 수 있다는 의미는 아님\n\n원래 경사하강법은 local minimum에 빠지기 쉬운 알고리즘! 그런데 그나마 둘 중에 비교를 하자면 확률적으로 하면 로컬 미니멈에 빠졌다가 어쩌다 운좋아서 튀어 나가는 경우가 있다.\n동일한 컴퓨터 자원으로 수렴을 더 빨리 시킬 수 있냐? 그건 아님 (그건 모름).\n그럼 왜 쓰냐???\n메모리 사용량만 보면 됩니다!"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#fashion_mnist-모듈",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#fashion_mnist-모듈",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "fashion_mnist 모듈",
    "text": "fashion_mnist 모듈\n\ntf.keras.datasets.fashion_mnist.load_data()\n- tf.keras.datasets.fashion_mnist.load_data 의 리턴값 조사\n\ntf.keras.datasets.fashion_mnist.load_data??\n\n\nSignature: tf.keras.datasets.fashion_mnist.load_data()\nSource:   \n@keras_export(\"keras.datasets.fashion_mnist.load_data\")\ndef load_data():\n    \"\"\"Loads the Fashion-MNIST dataset.\n    This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\n    along with a test set of 10,000 images. This dataset can be used as\n    a drop-in replacement for MNIST.\n    The classes are:\n    | Label | Description |\n    |:-----:|-------------|\n    |   0   | T-shirt/top |\n    |   1   | Trouser     |\n    |   2   | Pullover    |\n    |   3   | Dress       |\n    |   4   | Coat        |\n    |   5   | Sandal      |\n    |   6   | Shirt       |\n    |   7   | Sneaker     |\n    |   8   | Bag         |\n    |   9   | Ankle boot  |\n    Returns:\n      Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n    **x_train**: uint8 NumPy array of grayscale image data with shapes\n      `(60000, 28, 28)`, containing the training data.\n    **y_train**: uint8 NumPy array of labels (integers in range 0-9)\n      with shape `(60000,)` for the training data.\n    **x_test**: uint8 NumPy array of grayscale image data with shapes\n      (10000, 28, 28), containing the test data.\n    **y_test**: uint8 NumPy array of labels (integers in range 0-9)\n      with shape `(10000,)` for the test data.\n    Example:\n    ```python\n    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n    assert x_train.shape == (60000, 28, 28)\n    assert x_test.shape == (10000, 28, 28)\n    assert y_train.shape == (60000,)\n    assert y_test.shape == (10000,)\n    ```\n    License:\n      The copyright for Fashion-MNIST is held by Zalando SE.\n      Fashion-MNIST is licensed under the [MIT license](\n      https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\n    \"\"\"\n    dirname = os.path.join(\"datasets\", \"fashion-mnist\")\n    base = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/\"\n    files = [\n        \"train-labels-idx1-ubyte.gz\",\n        \"train-images-idx3-ubyte.gz\",\n        \"t10k-labels-idx1-ubyte.gz\",\n        \"t10k-images-idx3-ubyte.gz\",\n    ]\n    paths = []\n    for fname in files:\n        paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))\n    with gzip.open(paths[0], \"rb\") as lbpath:\n        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n    with gzip.open(paths[1], \"rb\") as imgpath:\n        x_train = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(\n            len(y_train), 28, 28\n        )\n    with gzip.open(paths[2], \"rb\") as lbpath:\n        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n    with gzip.open(paths[3], \"rb\") as imgpath:\n        x_test = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(\n            len(y_test), 28, 28\n        )\n    return (x_train, y_train), (x_test, y_test)\nFile:      ~/anaconda3/envs/torch/lib/python3.8/site-packages/keras/datasets/fashion_mnist.py\nType:      function\n\n\n\n\n\n데이터생성 및 탐색\n- tf.keras.datasets.fashion_mnist.load_data()를 이용한 데이터 생성\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 [==============================] - 2s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 [==============================] - 0s 0us/step\n\n\n- 차원확인\n\nx_train.shape, y_train.shape, x_test.shape,y_test.shape\n\n((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n\n\n\n60000은 obs숫자인듯\n(28,28)은 28픽셀,28픽셀을 의미하는듯\ntrain/test는 6:1로 나눈것 같음\n\n- 첫번째 obs\n\nplt.imshow(x_train[0])\n\n<matplotlib.image.AxesImage at 0x7febf458eeb0>\n\n\n\n\n\n\ny_train[0]\n\n9\n\n\n\n첫번쨰 obs에 대응하는 라벨\n\n- 첫번째 obs와 동일한 라벨을 가지는 그림을 찾아보자.\n\nnp.where(y_train==9)\n\n(array([    0,    11,    15, ..., 59932, 59970, 59978]),)\n\n\n\ny_train[11]\n\n9\n\n\n\nplt.imshow(x_train[11])\n\n<matplotlib.image.AxesImage at 0x7f65219f9e80>\n\n\n\n\n\n\n\n데이터구조\n- \\({\\bf X}\\): (n,28,28)\n- \\({\\bf y}\\): (n,) , \\(y=0,1,2,3,\\dots,9\\)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#예제1",
    "href": "posts/3_STBDA2022/2022_05_02_(9주차)_5월2일(2).html#예제1",
    "title": "[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법",
    "section": "예제1",
    "text": "예제1\n\n데이터 정리\n- y=0,1에 대응하는 이미지만 정리하자. (우리가 배운건 로지스틱이니까)\n\ny= y_train[(y_train==0) | (y_train==1)].reshape(-1,1)\nX= x_train[(y_train==0) | (y_train==1)].reshape(-1,784)\nyy= y_test[(y_test==0) | (y_test==1)].reshape(-1,1)\nXX= x_test[(y_test==0) | (y_test==1)].reshape(-1,784)\n\n\nX.shape, y.shape, XX.shape, yy.shape\n\n((12000, 784), (12000, 1), (2000, 784), (2000, 1))\n\n\n\n\n풀이1: 은닉층을 포함한 신경망 // epochs=100\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n\n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n\n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node30\"\n    \"x2\" -> \"node30\"\n    \"..\" -> \"node30\"\n    \"x784\" -> \"node30\"\n\n\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"y\"\n    \"node2\" -> \"y\"\n    \"...\" -> \"y\"\n    \"node30\" -> \"y\"\n    label = \"Layer 2: sigmoid\"\n}\n''')\n\n\n\n\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(30,activation='relu'))\nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nnet.compile(optimizer='sgd',loss=tf.losses.binary_crossentropy)\nnet.fit(X,y,epochs=100,batch_size=12000)\n\nEpoch 1/100\n1/1 [==============================] - 0s 122ms/step - loss: 220.9145\nEpoch 2/100\n1/1 [==============================] - 0s 9ms/step - loss: 6800.3174\nEpoch 3/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7045\nEpoch 4/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7012\nEpoch 5/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7004\nEpoch 6/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6997\nEpoch 7/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6991\nEpoch 8/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6985\nEpoch 9/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6979\nEpoch 10/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6976\nEpoch 11/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6973\nEpoch 12/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6970\nEpoch 13/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6968\nEpoch 14/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6966\nEpoch 15/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6964\nEpoch 16/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6963\nEpoch 17/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6961\nEpoch 18/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6959\nEpoch 19/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6958\nEpoch 20/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6956\nEpoch 21/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6955\nEpoch 22/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6953\nEpoch 23/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6952\nEpoch 24/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6951\nEpoch 25/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6949\nEpoch 26/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6948\nEpoch 27/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6947\nEpoch 28/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6946\nEpoch 29/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6945\nEpoch 30/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6944\nEpoch 31/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6943\nEpoch 32/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6942\nEpoch 33/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6942\nEpoch 34/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6941\nEpoch 35/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6940\nEpoch 36/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6940\nEpoch 37/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6939\nEpoch 38/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6939\nEpoch 39/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6938\nEpoch 40/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6937\nEpoch 41/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6937\nEpoch 42/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6936\nEpoch 43/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6936\nEpoch 44/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6935\nEpoch 45/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6935\nEpoch 46/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6934\nEpoch 47/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6934\nEpoch 48/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6934\nEpoch 49/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 50/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 51/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 52/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 53/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 54/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 55/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 56/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 57/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 58/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 59/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 60/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 61/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 62/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6933\nEpoch 63/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 64/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 65/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 66/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 67/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6933\nEpoch 68/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 69/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 70/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 71/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 72/100\n1/1 [==============================] - 0s 10ms/step - loss: 0.6932\nEpoch 73/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 74/100\n1/1 [==============================] - 0s 10ms/step - loss: 0.6932\nEpoch 75/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 76/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 77/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 78/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 79/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 80/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 81/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 82/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 83/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 84/100\n1/1 [==============================] - 0s 10ms/step - loss: 0.6932\nEpoch 85/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 86/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6932\nEpoch 87/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 88/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 89/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 90/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 91/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 92/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 93/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 94/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 95/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 96/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 97/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 98/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 99/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\nEpoch 100/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6932\n\n\n<keras.callbacks.History at 0x7f640c5e9c40>\n\n\n\nnp.mean((net(X)>0.5) == y)\n\n0.5000833333333333\n\n\n\nnp.mean((net(XX)>0.5) == yy)\n\n0.5\n\n\n\n\n풀이2: 옵티마이저 개선\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(30,activation='relu'))\nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nnet.compile(optimizer='adam',loss=tf.losses.binary_crossentropy)\nnet.fit(X,y,epochs=100,batch_size=12000)\n\nEpoch 1/100\n1/1 [==============================] - 0s 138ms/step - loss: 220.9145\nEpoch 2/100\n1/1 [==============================] - 0s 10ms/step - loss: 88.9490\nEpoch 3/100\n1/1 [==============================] - 0s 10ms/step - loss: 7.5895\nEpoch 4/100\n1/1 [==============================] - 0s 9ms/step - loss: 33.7521\nEpoch 5/100\n1/1 [==============================] - 0s 9ms/step - loss: 40.2290\nEpoch 6/100\n1/1 [==============================] - 0s 9ms/step - loss: 28.9675\nEpoch 7/100\n1/1 [==============================] - 0s 9ms/step - loss: 16.5128\nEpoch 8/100\n1/1 [==============================] - 0s 10ms/step - loss: 9.4911\nEpoch 9/100\n1/1 [==============================] - 0s 10ms/step - loss: 6.2027\nEpoch 10/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.2417\nEpoch 11/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.5172\nEpoch 12/100\n1/1 [==============================] - 0s 9ms/step - loss: 6.5900\nEpoch 13/100\n1/1 [==============================] - 0s 9ms/step - loss: 7.8605\nEpoch 14/100\n1/1 [==============================] - 0s 9ms/step - loss: 8.5884\nEpoch 15/100\n1/1 [==============================] - 0s 9ms/step - loss: 8.3991\nEpoch 16/100\n1/1 [==============================] - 0s 9ms/step - loss: 7.4675\nEpoch 17/100\n1/1 [==============================] - 0s 9ms/step - loss: 6.2581\nEpoch 18/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.1274\nEpoch 19/100\n1/1 [==============================] - 0s 9ms/step - loss: 4.2382\nEpoch 20/100\n1/1 [==============================] - 0s 9ms/step - loss: 3.6033\nEpoch 21/100\n1/1 [==============================] - 0s 9ms/step - loss: 3.1860\nEpoch 22/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.9233\nEpoch 23/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.7560\nEpoch 24/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.6421\nEpoch 25/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.5490\nEpoch 26/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.4612\nEpoch 27/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.3617\nEpoch 28/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.2378\nEpoch 29/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.0874\nEpoch 30/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.9117\nEpoch 31/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.7239\nEpoch 32/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.5409\nEpoch 33/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.3663\nEpoch 34/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.2210\nEpoch 35/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.1035\nEpoch 36/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0208\nEpoch 37/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9766\nEpoch 38/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9628\nEpoch 39/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.9717\nEpoch 40/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9883\nEpoch 41/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0039\nEpoch 42/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0156\nEpoch 43/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0181\nEpoch 44/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0067\nEpoch 45/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9809\nEpoch 46/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9443\nEpoch 47/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9019\nEpoch 48/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.8571\nEpoch 49/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.8146\nEpoch 50/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7768\nEpoch 51/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7489\nEpoch 52/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7294\nEpoch 53/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7186\nEpoch 54/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7125\nEpoch 55/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7080\nEpoch 56/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7044\nEpoch 57/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7002\nEpoch 58/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6949\nEpoch 59/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6884\nEpoch 60/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6806\nEpoch 61/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6715\nEpoch 62/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6615\nEpoch 63/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6510\nEpoch 64/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6404\nEpoch 65/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6302\nEpoch 66/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6209\nEpoch 67/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6127\nEpoch 68/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6060\nEpoch 69/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6007\nEpoch 70/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5963\nEpoch 71/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5924\nEpoch 72/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5888\nEpoch 73/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5853\nEpoch 74/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5816\nEpoch 75/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5778\nEpoch 76/100\n1/1 [==============================] - 0s 10ms/step - loss: 0.5736\nEpoch 77/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5691\nEpoch 78/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5644\nEpoch 79/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5595\nEpoch 80/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5547\nEpoch 81/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5501\nEpoch 82/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5457\nEpoch 83/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5417\nEpoch 84/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5379\nEpoch 85/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5344\nEpoch 86/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5310\nEpoch 87/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5276\nEpoch 88/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5242\nEpoch 89/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5208\nEpoch 90/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5174\nEpoch 91/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5140\nEpoch 92/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5108\nEpoch 93/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5075\nEpoch 94/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5044\nEpoch 95/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5014\nEpoch 96/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4986\nEpoch 97/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4960\nEpoch 98/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.4935\nEpoch 99/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4909\nEpoch 100/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4885\n\n\n<keras.callbacks.History at 0x7f640c513e50>\n\n\n\nnp.mean((net(X)>0.5) == y)\n\n0.98125\n\n\n\nnp.mean((net(XX)>0.5) == yy)\n\n0.977\n\n\n\n\n풀이3: 컴파일시 metrics=[‘accuracy’] 추가\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(30,activation='relu'))\nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nnet.compile(optimizer='adam',loss=tf.losses.binary_crossentropy,metrics=['accuracy'])\nnet.fit(X,y,epochs=100,batch_size=12000)\n\nEpoch 1/100\n1/1 [==============================] - 0s 150ms/step - loss: 220.9145 - accuracy: 0.5000\nEpoch 2/100\n1/1 [==============================] - 0s 9ms/step - loss: 88.9490 - accuracy: 0.5073\nEpoch 3/100\n1/1 [==============================] - 0s 9ms/step - loss: 7.5895 - accuracy: 0.8208\nEpoch 4/100\n1/1 [==============================] - 0s 10ms/step - loss: 33.7521 - accuracy: 0.5972\nEpoch 5/100\n1/1 [==============================] - 0s 9ms/step - loss: 40.2290 - accuracy: 0.5723\nEpoch 6/100\n1/1 [==============================] - 0s 9ms/step - loss: 28.9675 - accuracy: 0.6442\nEpoch 7/100\n1/1 [==============================] - 0s 11ms/step - loss: 16.5128 - accuracy: 0.8061\nEpoch 8/100\n1/1 [==============================] - 0s 9ms/step - loss: 9.4911 - accuracy: 0.8947\nEpoch 9/100\n1/1 [==============================] - 0s 9ms/step - loss: 6.2027 - accuracy: 0.9355\nEpoch 10/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.2417 - accuracy: 0.9404\nEpoch 11/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.5172 - accuracy: 0.9270\nEpoch 12/100\n1/1 [==============================] - 0s 9ms/step - loss: 6.5900 - accuracy: 0.9021\nEpoch 13/100\n1/1 [==============================] - 0s 9ms/step - loss: 7.8605 - accuracy: 0.8788\nEpoch 14/100\n1/1 [==============================] - 0s 9ms/step - loss: 8.5884 - accuracy: 0.8647\nEpoch 15/100\n1/1 [==============================] - 0s 9ms/step - loss: 8.3991 - accuracy: 0.8664\nEpoch 16/100\n1/1 [==============================] - 0s 9ms/step - loss: 7.4675 - accuracy: 0.8793\nEpoch 17/100\n1/1 [==============================] - 0s 9ms/step - loss: 6.2581 - accuracy: 0.8982\nEpoch 18/100\n1/1 [==============================] - 0s 9ms/step - loss: 5.1274 - accuracy: 0.9156\nEpoch 19/100\n1/1 [==============================] - 0s 9ms/step - loss: 4.2382 - accuracy: 0.9302\nEpoch 20/100\n1/1 [==============================] - 0s 9ms/step - loss: 3.6033 - accuracy: 0.9426\nEpoch 21/100\n1/1 [==============================] - 0s 9ms/step - loss: 3.1860 - accuracy: 0.9509\nEpoch 22/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.9233 - accuracy: 0.9551\nEpoch 23/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.7560 - accuracy: 0.9574\nEpoch 24/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.6421 - accuracy: 0.9594\nEpoch 25/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.5490 - accuracy: 0.9599\nEpoch 26/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.4612 - accuracy: 0.9603\nEpoch 27/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.3617 - accuracy: 0.9608\nEpoch 28/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.2378 - accuracy: 0.9612\nEpoch 29/100\n1/1 [==============================] - 0s 9ms/step - loss: 2.0874 - accuracy: 0.9619\nEpoch 30/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.9117 - accuracy: 0.9630\nEpoch 31/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.7239 - accuracy: 0.9641\nEpoch 32/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.5409 - accuracy: 0.9657\nEpoch 33/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.3663 - accuracy: 0.9670\nEpoch 34/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.2210 - accuracy: 0.9685\nEpoch 35/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.1035 - accuracy: 0.9688\nEpoch 36/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0208 - accuracy: 0.9696\nEpoch 37/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9766 - accuracy: 0.9705\nEpoch 38/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9628 - accuracy: 0.9708\nEpoch 39/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9717 - accuracy: 0.9715\nEpoch 40/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9883 - accuracy: 0.9706\nEpoch 41/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0039 - accuracy: 0.9699\nEpoch 42/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0156 - accuracy: 0.9685\nEpoch 43/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0181 - accuracy: 0.9681\nEpoch 44/100\n1/1 [==============================] - 0s 9ms/step - loss: 1.0067 - accuracy: 0.9686\nEpoch 45/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9809 - accuracy: 0.9693\nEpoch 46/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9443 - accuracy: 0.9703\nEpoch 47/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.9019 - accuracy: 0.9711\nEpoch 48/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.8571 - accuracy: 0.9722\nEpoch 49/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.8146 - accuracy: 0.9737\nEpoch 50/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7768 - accuracy: 0.9743\nEpoch 51/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7489 - accuracy: 0.9753\nEpoch 52/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7294 - accuracy: 0.9759\nEpoch 53/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7186 - accuracy: 0.9767\nEpoch 54/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7125 - accuracy: 0.9774\nEpoch 55/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7080 - accuracy: 0.9776\nEpoch 56/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7044 - accuracy: 0.9777\nEpoch 57/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.7002 - accuracy: 0.9776\nEpoch 58/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6949 - accuracy: 0.9778\nEpoch 59/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6884 - accuracy: 0.9779\nEpoch 60/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6806 - accuracy: 0.9784\nEpoch 61/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.9786\nEpoch 62/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.9786\nEpoch 63/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6510 - accuracy: 0.9784\nEpoch 64/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6404 - accuracy: 0.9786\nEpoch 65/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6302 - accuracy: 0.9787\nEpoch 66/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6209 - accuracy: 0.9791\nEpoch 67/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.9787\nEpoch 68/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6060 - accuracy: 0.9791\nEpoch 69/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.9792\nEpoch 70/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5963 - accuracy: 0.9795\nEpoch 71/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5924 - accuracy: 0.9793\nEpoch 72/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5888 - accuracy: 0.9791\nEpoch 73/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5853 - accuracy: 0.9790\nEpoch 74/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5816 - accuracy: 0.9793\nEpoch 75/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5778 - accuracy: 0.9794\nEpoch 76/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.9795\nEpoch 77/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5691 - accuracy: 0.9794\nEpoch 78/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5644 - accuracy: 0.9794\nEpoch 79/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5595 - accuracy: 0.9796\nEpoch 80/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5547 - accuracy: 0.9796\nEpoch 81/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5501 - accuracy: 0.9798\nEpoch 82/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5457 - accuracy: 0.9800\nEpoch 83/100\n1/1 [==============================] - 0s 9ms/step - loss: 0.5417 - accuracy: 0.9800\nEpoch 84/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5379 - accuracy: 0.9804\nEpoch 85/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.9807\nEpoch 86/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.9807\nEpoch 87/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.9807\nEpoch 88/100\n1/1 [==============================] - 0s 7ms/step - loss: 0.5242 - accuracy: 0.9808\nEpoch 89/100\n1/1 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.9808\nEpoch 90/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.9811\nEpoch 91/100\n1/1 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.9812\nEpoch 92/100\n1/1 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.9812\nEpoch 93/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.9813\nEpoch 94/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.9814\nEpoch 95/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.9816\nEpoch 96/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.9815\nEpoch 97/100\n1/1 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.9815\nEpoch 98/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.9812\nEpoch 99/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.9812\nEpoch 100/100\n1/1 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.9812\n\n\n<keras.callbacks.History at 0x7f640c46bc70>\n\n\n\nnet.evaluate(X,y)\n\n375/375 [==============================] - 0s 349us/step - loss: 0.4860 - accuracy: 0.9812\n\n\n[0.48598653078079224, 0.981249988079071]\n\n\n\nnet.evaluate(XX,yy)\n\n63/63 [==============================] - 0s 617us/step - loss: 0.4294 - accuracy: 0.9770\n\n\n[0.42936256527900696, 0.9769999980926514]\n\n\n\n\n풀이4: 확률적경사하강법 이용 // epochs=10\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(30,activation='relu'))\nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nnet.compile(optimizer='adam',loss=tf.losses.binary_crossentropy,metrics=['accuracy'])\nnet.fit(X,y,epochs=10,batch_size=120)\n\nEpoch 1/10\n100/100 [==============================] - 0s 827us/step - loss: 5.6484 - accuracy: 0.9418\nEpoch 2/10\n100/100 [==============================] - 0s 747us/step - loss: 0.5078 - accuracy: 0.9793\nEpoch 3/10\n100/100 [==============================] - 0s 734us/step - loss: 0.3784 - accuracy: 0.9818\nEpoch 4/10\n100/100 [==============================] - 0s 765us/step - loss: 0.3390 - accuracy: 0.9828\nEpoch 5/10\n100/100 [==============================] - 0s 735us/step - loss: 0.2474 - accuracy: 0.9857\nEpoch 6/10\n100/100 [==============================] - 0s 717us/step - loss: 0.2116 - accuracy: 0.9870\nEpoch 7/10\n100/100 [==============================] - 0s 734us/step - loss: 0.1724 - accuracy: 0.9889\nEpoch 8/10\n100/100 [==============================] - 0s 784us/step - loss: 0.1711 - accuracy: 0.9880\nEpoch 9/10\n100/100 [==============================] - 0s 795us/step - loss: 0.1491 - accuracy: 0.9894\nEpoch 10/10\n100/100 [==============================] - 0s 723us/step - loss: 0.1550 - accuracy: 0.9896\n\n\n<keras.callbacks.History at 0x7f640c2d9fa0>\n\n\n\nnet.evaluate(X,y)\n\n375/375 [==============================] - 0s 339us/step - loss: 0.1124 - accuracy: 0.9923\n\n\n[0.11242959648370743, 0.9922500252723694]\n\n\n\nnet.evaluate(XX,yy)\n\n63/63 [==============================] - 0s 566us/step - loss: 0.2988 - accuracy: 0.9845\n\n\n[0.29883989691734314, 0.984499990940094]"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html",
    "href": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html",
    "title": "[STBDA] 10wk. 로지스틱 모형",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zvc1QWi-Li-2GAeW91oicn"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#imports",
    "href": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#imports",
    "title": "[STBDA] 10wk. 로지스틱 모형",
    "section": "imports",
    "text": "imports\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow.experimental.numpy as tnp\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\ntf.config.experimental.list_physical_devices()\n\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+ s + ';}')"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#softmax-function",
    "href": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#softmax-function",
    "title": "[STBDA] 10wk. 로지스틱 모형",
    "section": "softmax function",
    "text": "softmax function\n\n로지스틱 모형 (1): 활성화함수로 sigmoid 선택\n- 기본버전은 아래와 같다\n\\[y_i \\approx \\text{sigmoid}(b + w_1 x_{1,i} + \\dots + w_{784}x_{784,i})= \\frac{\\exp(b + w_1 x_{1,i} + \\dots + w_{784}x_{784,i})}{1+\\exp(b + w_1 x_{1,i} + \\dots + w_{784}x_{784,i})}\\]\n- 벡터버전은 아래와 같다.\n\\[{\\boldsymbol y} \\approx \\text{sigmoid}({\\bf X}{\\bf W} + b) = \\frac{\\exp({\\bf XW} +b)}{1+\\exp({\\bf XW} +b)}\\]\n- 벡터버전에 익숙해지도록 하자. 벡터버전에 사용된 차원 및 연산을 정리하면 아래와 같다.\n\n\\({\\bf X}\\): (n,784) matrix\n\\({\\boldsymbol y}\\): (n,1) matrix\n\\({\\bf W}\\): (784,1) matrix\n\\(b\\): (1,1) matrix\n+, exp 는 브로드캐스팅\n\n\n\n로지스틱 모형 (2): 활성화함수로 softmax 선택\n- \\(y_i=0 \\text{ or } 1\\) 대신에 \\(\\boldsymbol{y}_i=[y_{i1},y_{i2}]= [1,0] \\text { or } [0,1]\\)와 같이 코딩하면 어떠할까? (즉 원핫인코딩을 한다면?)\n- 활성화 함수를 취하기 전의 버전은 아래와 같이 볼 수 있다.\n\\[[{\\boldsymbol y}_1 ~ {\\boldsymbol y}_2] \\propto  [ {\\bf X}{\\bf W}_1  ~ {\\bf X}{\\bf W}_2] + [b_1 ~ b_2]= {\\bf X} [{\\bf W}_1 {\\bf W}_2] + [b_1 ~ b_2]= {\\bf X}{\\bf W} + {\\boldsymbol b}\\]\n여기에서 매트릭스 및 연산의 차원을 정리하면 아래와 같다.\n\n\\({\\bf X}\\): (n,784) matrix\n\\({\\boldsymbol y}_1,{\\boldsymbol y}_2\\): (n,1) matrix\n\\({\\boldsymbol y}:=[{\\boldsymbol y}_1~ {\\boldsymbol y}_2]\\): (n,2) matrix\n\\({\\bf W}_1\\), \\({\\bf W}_2\\): (784,1) matrix\n\\({\\bf W}:=[{\\bf W}_1~ {\\bf W}_2]\\): (784,2) matrix\n\\(b_1,b_2\\): (1,1) matrix\n$:= [b_1 ~b_2] $: (1,2) matrix\n+ 는 브로드캐스팅\n\n- 즉 로지스틱 모형 (1)의 형태를 겹쳐놓은 형태로 해석할 수 있음. 따라서 \\({\\bf X} {\\bf W}_1 + b_1\\)와 \\({\\bf X} {\\bf W}_2 + b_2\\)의 row값이 클수록 \\({\\boldsymbol y}_1\\)와 \\({\\boldsymbol y}_2\\)의 row값이 1이어야 함\n\n\\({\\boldsymbol y}_1 \\propto {\\bf X} {\\bf W}_1 + b_1\\) \\(\\to\\) \\({\\bf X} {\\bf W}_1 + b_1\\)의 row값이 클수록 \\(\\boldsymbol{y}_1\\)의 row 값이 1이라면 모형계수를 잘 추정한것\n\\({\\boldsymbol y}_2 \\propto {\\bf X} {\\bf W}_2 + b_2\\) \\(\\to\\) \\({\\bf X} {\\bf W}_2 + b_2\\)의 row값이 클수록 \\(\\boldsymbol{y}_2\\)의 row 값을 1이라면 모형계수를 잘 추정한것\n\n- (문제) \\({\\bf X}{\\bf W}_1 +b_1\\)의 값이 500, \\({\\bf X}{\\bf W}_2 +b_2\\)의 값이 200 인 row가 있다고 하자. 대응하는 \\(\\boldsymbol{y}_1, \\boldsymbol{y}_2\\)의 row값은 얼마로 적합되어야 하는가?\n\n\\([0,0]\\)\n\\([0,1]\\)\n\\([1,0]\\) <– 이게 답이다!\n\\([1,1]\\)\n\n\nnote: 둘다 0 혹은 둘다 1로 적합할수는 없으니까 (1), (4)는 제외한다. \\({\\bf X}{\\bf W}_1 +b_1\\)의 값이 \\({\\bf X}{\\bf W}_2 +b_2\\)의 값보다 크므로 (3)번이 합리적임\n\n- 목표: 위와 같은 문제의 답을 유도해주는 활성화함수를 설계하자. 즉 합리적인 \\(\\hat{\\boldsymbol{y}}_1,\\hat{\\boldsymbol{y}}_2\\)를 구해주는 활성화 함수를 설계해보자. 이를 위해서는 아래의 사항들이 충족되어야 한다.\n\n\\(\\hat{\\boldsymbol{y}}_1\\), \\(\\hat{\\boldsymbol{y}}_2\\)의 각 원소는 0보다 크고 1보다 작아야 한다. (확률을 의미해야 하니까)\n\\(\\hat{\\boldsymbol{y}}_1+\\hat{\\boldsymbol{y}}_2={\\bf 1}\\) 이어야 한다. (확률의 총합은 1이니까!)\n\\(\\hat{\\boldsymbol{y}}_1\\)와 \\(\\hat{\\boldsymbol{y}}_2\\)를 각각 따로해석하면 로지스틱처럼 되면 좋겠다.\n\n- 아래와 같은 활성화 함수를 도입하면 어떨까?\n\\[\\hat{\\boldsymbol{y}}=[\\hat{\\boldsymbol y}_1 ~ \\hat{\\boldsymbol y}_2] =  \\big[ \\frac{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)}{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)+\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}  ~~ \\frac{\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)+\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}  \\big]\\]\n- (1),(2)는 만족하는 듯 하다. (3)은 바로 이해되지는 않는다\n\n\\(\\hat{\\boldsymbol{y}}_1\\), \\(\\hat{\\boldsymbol{y}}_2\\)의 각 원소는 0보다 크고 1보다 작아야 한다. –> OK!\n\\(\\hat{\\boldsymbol{y}}_1+\\hat{\\boldsymbol{y}}_2={\\bf 1}\\) 이어야 한다. –> OK!\n\\(\\hat{\\boldsymbol{y}}_1\\)와 \\(\\hat{\\boldsymbol{y}}_2\\)를 각각 따로해석하면 로지스틱처럼 되면 좋겠다. –> ???\n\n- 그런데 조금 따져보면 (3)도 만족된다는 것을 알 수 있다. (sigmoid, softmax Section 참고)\n- 위와 같은 함수를 softmax라고 하자. 즉 아래와 같이 정의하자.\n\\[\n\\hat{\\boldsymbol y} = \\text{softmax}({\\bf X}\\hat{\\bf W} + {\\boldsymbol b})\n= \\big[ \\frac{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)}{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)+\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}  ~~ \\frac{\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}{\\exp({\\bf X}\\hat{\\bf W}_1+\\hat{b}_1)+\\exp({\\bf X}\\hat{\\bf W}_2+\\hat{b}_2)}  \\big]\n\\]\n\n\nsigmoid, softmax\n\nsoftmax는 sigmoid의 확장형\n- 아래의 수식을 관찰하자. \\[\\frac{\\exp(\\beta_0+\\beta_1 x_i)}{1+\\exp(\\beta_0+\\beta_1x_i)}=\\frac{\\exp(\\beta_0+\\beta_1 x_i)}{e^0+\\exp(\\beta_0+\\beta_1x_i)}\\]\n- 1을 \\(e^0\\)로 해석하면 모형2의 해석을 아래와 같이 모형1의 해석으로 적용할수 있다. - 모형2: \\({\\bf X}\\hat{\\bf W}_1 +\\hat{b}_1\\) 와 \\({\\bf X}\\hat{\\bf W}_2 +\\hat{b}_2\\) 의 크기를 비교하고 확률 결정 - 모형1: \\({\\bf X}\\hat{\\bf W} +\\hat{b}\\) 와 \\(0\\)의 크기를 비교하고 확률 결정 = \\({\\bf X}\\hat{\\bf W} +\\hat{b}\\)의 row값이 양수이면 1로 예측하고 음수이면 0으로 예측\n- 이항분포를 차원이 2인 다항분포로 해석가능한 것처럼 sigmoid는 차원이 2인 softmax로 해석가능하다. 즉 다항분포가 이항분포의 확장형으로 해석가능한 것처럼 softmax도 sigmoid의 확장형으로 해석가능하다.\n\n\n클래스의 수가 2인 경우 softmax vs sigmoid\n- 언뜻 생각하면 클래스가 2인 경우에도 sigmoid 대신 softmax로 활성화함수를 이용해도 될 듯 하다. 즉 \\(y=0 \\text{ or } 1\\)와 같이 정리하지 않고 \\(y=[0,1] \\text{ or } [1,0]\\) 와 같이 정리해도 무방할 듯 하다.\n- 하지만 sigmoid가 좀 더 좋은 선택이다. 즉 \\(y= 0 \\text{ or } 1\\)로 데이터를 정리하는 것이 더 좋은 선택이다. 왜냐하면 sigmoid는 softmax와 비교하여 파라메터의 수가 적지만 표현력은 동등하기 때문이다.\n- 표현력이 동등한 이유? 아래 수식을 관찰하자.\n\\[\\big(\\frac{e^{300}}{e^{300}+e^{500}},\\frac{e^{500}}{e^{300}+e^{500}}\\big) =\\big( \\frac{e^{0}}{e^{0}+e^{200}}, \\frac{e^{200}}{e^{0}+e^{200}}\\big)\\]\n\n\\(\\big(\\frac{e^{300}}{e^{300}+e^{500}},\\frac{e^{500}}{e^{300}+e^{500}}\\big)\\)를 표현하기 위해서 300, 500 이라는 2개의 숫자가 필요한것이 아니고 따지고보면 200이라는 하나의 숫자만 필요하다.\n\\((\\hat{\\boldsymbol{y}}_1,\\hat{\\boldsymbol{y}}_2)\\)의 표현에서도 \\({\\bf X}\\hat{\\bf W}_1 +\\hat{b}_1\\) 와 \\({\\bf X}\\hat{\\bf W}_2 +\\hat{b}_2\\) 라는 숫자 각각이 필요한 것이 아니고 \\(({\\bf X}\\hat{\\bf W}_1 +\\hat{b}_1)-({\\bf X}\\hat{\\bf W}_2 +\\hat{b}_2)\\)의 값만 알면 된다.\n\n- 클래스의 수가 2개일 경우는 softmax가 sigmoid에 비하여 장점이 없다. 하지만 softmax는 클래스의 수가 3개 이상일 경우로 쉽게 확장할 수 있다는 점에서 매력적인 활성화 함수이다.\n\n\n\n분류할 클래스가 3개 이상일 경우 신경망 모형의 설계\n- y의 모양: [0 1 0 0 0 0 0 0 0 0]\n- 활성화함수의 선택: softmax\n- 손실함수의 선택: cross entropy\n\n\nFashion_MNIST 여러클래스의 분류 (softmax의 실습)\n- 데이터정리\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n\nX= x_train.reshape(-1,784)\ny= tf.keras.utils.to_categorical(y_train)\nXX = x_test.reshape(-1,784)\nyy = tf.keras.utils.to_categorical(y_test)\n\n- 시도1: 간단한 신경망\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n\n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n\n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node30\"\n    \"x2\" -> \"node30\"\n    \"..\" -> \"node30\"\n    \"x784\" -> \"node30\"\n\n\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -> \"y10\"\n    \"node2\" -> \"y10\"\n    \"...\" -> \"y10\"\n    \"node30\" -> \"y10\"\n\n    \"node1\" -> \"y1\"\n    \"node2\" -> \"y1\"\n    \"...\" -> \"y1\"\n    \"node30\" -> \"y1\"\n\n    \"node1\" -> \".\"\n    \"node2\" -> \".\"\n    \"...\" -> \".\"\n    \"node30\" -> \".\"\n\n    label = \"Layer 2: softmax\"\n}\n''')\n\n\n\n\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(30,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(10,activation = 'softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\nnet.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 1s 485us/step - loss: 2.2998 - accuracy: 0.4233\nEpoch 2/5\n1875/1875 [==============================] - 1s 475us/step - loss: 1.2198 - accuracy: 0.5444\nEpoch 3/5\n1875/1875 [==============================] - 1s 498us/step - loss: 1.0499 - accuracy: 0.5938\nEpoch 4/5\n1875/1875 [==============================] - 1s 484us/step - loss: 0.9243 - accuracy: 0.6309\nEpoch 5/5\n1875/1875 [==============================] - 1s 484us/step - loss: 0.8560 - accuracy: 0.6506\n\n\n<keras.callbacks.History at 0x7f904d4618b0>\n\n\n\nnet.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 374us/step - loss: 0.8689 - accuracy: 0.6363\n\n\n[0.8688836693763733, 0.6363000273704529]\n\n\n\nnet.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 30)                23550     \n                                                                 \n dense_1 (Dense)             (None, 10)                310       \n                                                                 \n=================================================================\nTotal params: 23,860\nTrainable params: 23,860\nNon-trainable params: 0\n_________________________________________________________________\n\n\n- 시도2: 더 깊은 신경망\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n\n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n\n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node500\"\n    \"x2\" -> \"node500\"\n    \"..\" -> \"node500\"\n    \"x784\" -> \"node500\"\n\n\n    label = \"Layer 1: relu\"\n}\n\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -> \"node1(2)\"\n    \"node2\" -> \"node1(2)\"\n    \"...\" -> \"node1(2)\"\n    \"node500\" -> \"node1(2)\"\n\n    \"node1\" -> \"node2(2)\"\n    \"node2\" -> \"node2(2)\"\n    \"...\" -> \"node2(2)\"\n    \"node500\" -> \"node2(2)\"\n\n    \"node1\" -> \"....\"\n    \"node2\" -> \"....\"\n    \"...\" -> \"....\"\n    \"node500\" -> \"....\"\n\n    \"node1\" -> \"node500(2)\"\n    \"node2\" -> \"node500(2)\"\n    \"...\" -> \"node500(2)\"\n    \"node500\" -> \"node500(2)\"\n\n\n    label = \"Layer 2: relu\"\n}\n\nsubgraph cluster_4{\n    style=filled;\n    color=lightgrey;\n\n    \"node1(2)\" -> \"y10\"\n    \"node2(2)\" -> \"y10\"\n    \"....\" -> \"y10\"\n    \"node500(2)\" -> \"y10\"\n\n    \"node1(2)\" -> \"y1\"\n    \"node2(2)\" -> \"y1\"\n    \"....\" -> \"y1\"\n    \"node500(2)\" -> \"y1\"\n\n    \"node1(2)\" -> \".\"\n    \"node2(2)\" -> \".\"\n    \"....\" -> \".\"\n    \"node500(2)\" -> \".\"\n\n    label = \"Layer 3: softmax\"\n}\n''')\n\n\n\n\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(10,activation = 'softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy'])\nnet.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.3745 - accuracy: 0.7530\nEpoch 2/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.6109 - accuracy: 0.7965\nEpoch 3/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.5170 - accuracy: 0.8190\nEpoch 4/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4650 - accuracy: 0.8356\nEpoch 5/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4269 - accuracy: 0.8481\n\n\n<keras.callbacks.History at 0x7f8fa06980d0>\n\n\n\nnet.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 714us/step - loss: 0.4323 - accuracy: 0.8456\n\n\n[0.4322887063026428, 0.8456000089645386]\n\n\n\nnet.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_2 (Dense)             (None, 500)               392500    \n                                                                 \n dense_3 (Dense)             (None, 500)               250500    \n                                                                 \n dense_4 (Dense)             (None, 10)                5010      \n                                                                 \n=================================================================\nTotal params: 648,010\nTrainable params: 648,010\nNon-trainable params: 0\n_________________________________________________________________"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#평가지표",
    "href": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#평가지표",
    "title": "[STBDA] 10wk. 로지스틱 모형",
    "section": "평가지표",
    "text": "평가지표\n\n다양한 평가지표들\n- 의문: 왜 다양한 평가지표가 필요한가? (accuray면 끝나는거 아닌가? 더 이상 뭐가 필요해?)\n- 여러가지 평가지표들: https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values - 이걸 다 암기하는건 불가능함. - 몇 개만 뽑아서 암기하고 왜 쓰는지만 생각해보고 넘어가자!\n\n\nconfusion matrix의 이해\n- 표1\n\n\n\n\n퇴사(예측)\n안나감(예측)\n\n\n\n\n퇴사(실제)\nTP\nFN\n\n\n안나감(실제)\nFP\nTN\n\n\n\n- 표2 (책에없음)\n\n\n\n\n퇴사(예측)\n안나감(예측)\n\n\n\n\n퇴사(실제)\n$(y,)= $ (O,O)\n$(y,)= $(O,X)\n\n\n안나감(실제)\n$(y,)= $(X,O)\n$(y,)= $(X,X)\n\n\n\n- 표3 (책에없음)\n\n\n\n\n퇴사(예측)\n안나감(예측)\n\n\n\n\n퇴사(실제)\nTP, \\(\\# O/O\\)\nFN, \\(\\#O/X\\)\n\n\n안나감(실제)\nFP, \\(\\#X/O\\)\nTN, \\(\\#X/X\\)\n\n\n\n\n암기법, (1) 두번째 글자를 그대로 쓴다 (2) 첫글자가 T이면 분류를 제대로한것, 첫글자가 F이면 분류를 잘못한것\n\n- 표4 (위키등에 있음)\n\n\n\n\n\n\n\n\n\n\n퇴사(예측)\n안나감(예측)\n\n\n\n\n\n퇴사(실제)\nTP, \\(\\# O/O\\)\nFN, \\(\\# O/X\\)\nSensitivity(민감도)=Recall(재현율)=\\(\\frac{TP}{TP+FN}\\)=\\(\\frac{\\#O/O}{\\# O/O+ \\#O/X}\\)\n\n\n안나감(실제)\nFP, \\(\\# X/O\\)\nTN, \\(\\# X/X\\)\n\n\n\n\nPrecision(프리시즌)=\\(\\frac{TP}{TP+FP}\\)=\\(\\frac{\\# O/O}{\\# O/O+\\# X/O}\\)\n\nAccuracy(애큐러시)=\\(\\frac{TP+TN}{total}\\)=\\(\\frac{\\#O/O+\\# X/X}{total}\\)\n\n\n\n\n\n상황극\n- 최규빈은 입사하여 “퇴사자 예측시스템”의 개발에 들어갔다.\n- 자료의 특성상 대부분의 사람이 퇴사하지 않고 회사에 잘 다닌다. 즉 1000명이 있으면 10명정도 퇴사한다.\n\n\nAccuracy\n- 정의: Accuracy(애큐러시)=\\(\\frac{TP+TN}{total}\\)=\\(\\frac{\\#O/O+ \\#X/X}{total}\\) - 한국말로는 정확도, 정분류율이라고 한다. - 한국말이 헷갈리므로 그냥 영어를 외우는게 좋다. (어차피 Keras에서 옵션도 영어로 넣음)\n- (상확극 시점1) 왜 애큐러시는 불충분한가? - 회사: 퇴사자예측프로그램 개발해 - 최규빈: 귀찮은데 다 안나간다고 하자! -> 99퍼의 accuracy\n\n모델에 사용한 파라메터 = 0. 그런데 애큐러시 = 99! 이거 엄청 좋은 모형이다?\n\n\n\nSensitivity(민감도), Recall(재현율), True Positive Rate(TPR)\n- 정의: Sensitivity(민감도)=Recall(재현율)=\\(\\frac{TP}{TP+FN}\\)=\\(\\frac{\\# O/O}{\\# O/O+\\# O/X}\\) - 분모: 실제 O인 관측치 수 - 분자: 실제 O를 O라고 예측한 관측치 수 - 뜻: 실제 O를 O라고 예측한 비율\n- (상황극 시점2) recall을 봐야하는 이유 - 인사팀: 실제 퇴사자를 퇴사자로 예측해야 의미가 있음! 우리는 퇴사할것 같은 10명을 찍어달란 의미였어요! (그래야 면담을 하든 할거아냐!) - 최규빈: 가볍고(=파라메터 적고) 잘 맞추는 모형 만들어 달라면서요?\n\n인사팀: (고민중..) 사실 생각해보니까 이 경우는 애큐러시는 의미가 없네. 실제 나간 사람 중 최규빈이 나간다고 한 사람이 몇인지 카운트 하는게 더 의미가 있겠다. 우리는 앞으로 리컬(혹은 민감도)를 보겠다!\n\n\n예시1: 실제로 퇴사한 10명중 최규빈이 나간다고 찍은 사람이 5명이면 리컬이 50%\n\n\n예시2: 최규빈이 아무도 나가지 않는다고 예측해버린다? 실제 10명중에서 최규빈이 나간다고 적중시킨사람은 0명이므로 이 경우 리컬은 0%\n\n\n결론: 우리가 필요한건 recall이니까 앞으로 recall을 가져와! accuracy는 큰 의미없어. (그래도 명색이 모델인데 accuracy가 90은 되면 좋겠다)\n\n\n\nPrecision\n- 정의: Precision(프리시즌)=\\(\\frac{TP}{TP+FP}\\)=\\(\\frac{\\# O/O}{\\# O/O+\\# X/O}\\) - 분모: O라고 예측한 관측치 - 분자: O라고 예측한 관측치중 진짜 O인 관측치 - 뜻: O라고 예측한 관측치중 진짜 O인 비율\n- (상황극 시점3) recall 만으로 불충분한 이유\n\n최규빈: 에휴.. 귀찮은데 그냥 좀만 수틀리면 다 나갈것 같다고 해야겠다. -> 한 100명 나간다고 했음 -> 실제로 최규빈이 찍은 100명중에 10명이 다 나감!\n\n\n이 경우 애큐러시는 91%, 리컬은 100% (퇴사자 10명을 일단은 다 맞췄으므로).\n\n\n인사팀: (화가 많이 남) 멀쩡한 사람까지 다 퇴사할 것 같다고 하면 어떡해요? 최규빈 연구원이 나간다고 한 100명중에 실제로 10명만 나갔어요.\n인사팀: 마치 총으로 과녁중앙에 맞춰 달라고 했더니 기관총을 가져와서 한번 긁은것이랑 뭐가 달라요? 맞추는게 문제가 아니고 precision이 너무 낮아요.\n최규빈: accuracy 90% 이상, recall은 높을수록 좋다는게 주문 아니었나요?\n인사팀: (고민중..) 앞으로는 recall과 함께 precision도 같이 제출하세요. precision은 당신이 나간다고 한 사람중에 실제 나간사람의 비율을 의미해요. 이 경우는 \\(\\frac{10}{100}\\)이니까 precision이 10%입니다. (속마음: recall 올리겠다고 무작정 너무 많이 예측하지 말란 말이야!)\n\n\n\nF1 score\n- 정의: recall과 precision의 조화평균\n- (상황극 시점4) recall, precision을 모두 고려\n\n최규빈: recall/precision을 같이 내는건 좋은데요, 둘은 trade off의 관계에 있습니다. 물론 둘다 올리는 모형이 있다면 좋지만 그게 쉽지는 않아요. 보통은 precision을 올리려면 recall이 희생되는 면이 있고요, recall을 올리려고 하면 precision이 다소 떨어집니다.\n최규빈: 평가기준이 애매하다는 의미입니다. 모형1,2가 있는데 모형1은 모형2보다 precision이 약간 좋고 대신 recall이 떨어진다면 모형1이 좋은것입니까? 아니면 모형2가 좋은것입니까?\n인사팀: 그렇다면 둘을 평균내서 F1score를 계산해서 제출해주세요.\n\n\n\nSpecificity(특이도), False Positive Rate(FPR)\n- 정의:\n\nSpecificity(특이도)=\\(\\frac{TN}{FP+TN}\\)=\\(\\frac{\\# X/X}{\\# X/O+\\# X/X}\\)\nFalse Positive Rate (FPR) = 1-Specificity(특이도) = \\(\\frac{FP}{FP+TN}\\)=\\(\\frac{\\# X/O}{\\# X/O+\\# X/X}\\)\n\n- 의미: FPR = 오해해서 미안해, recall(=TPR)을 올리려고 보니 어쩔 수 없었어 ㅠㅠ - specificity는 안나간 사람을 안나갔다고 찾아낸 비율인데 별로 안중요하다. - FPR은 recall을 올리기 위해서 “실제로는 회사 잘 다니고 있는 사람 중 최규빈이 나갈것 같다고 찍은 사람들” 의 비율이다.\n\n즉 생사람잡은 비율.. 오해해서 미안한 사람의 비율..\n\n\n\nROC curve\n- 정의: \\(x\\)축=FPR, \\(y\\)축=TPR 을 그린 커브\n- 의미: - 결국 “오해해서 미안해 vs recall”을 그린 곡선이 ROC커브이다. - 생각해보면 오해하는 사람이 많을수록 당연히 recall은 올라간다. 따라서 우상향하는 곡선이다. - 오해한 사람이 매우 적은데 recall이 우수하면 매우 좋은 모형이다. 그래서 초반부터 ROC값이 급격하게 올라가면 좋은 모형이다.\n\n\nFashion MNIST 다양한 평가지표활용\n- data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n\nX= x_train.reshape(-1,784)\ny= tf.keras.utils.to_categorical(y_train)\nXX = x_test.reshape(-1,784)\nyy = tf.keras.utils.to_categorical(y_test)\n\n- 다양한 평가지표를 넣는 방법 (1)\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(10,activation = 'softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=['accuracy','Recall'])\nnet.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.1689 - accuracy: 0.7489 - recall: 0.7085\nEpoch 2/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.6779 - accuracy: 0.7775 - recall: 0.7104\nEpoch 3/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.6277 - accuracy: 0.7802 - recall: 0.7084\nEpoch 4/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7937 - recall: 0.7370\nEpoch 5/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.5308 - accuracy: 0.8032 - recall: 0.7394\n\n\n<keras.callbacks.History at 0x7f8fa054c2b0>\n\n\n\nnet.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 592us/step - loss: 0.6554 - accuracy: 0.7603 - recall: 0.7150\n\n\n[0.6554250717163086, 0.7602999806404114, 0.7149999737739563]\n\n\n- 다양한 평가지표를 넣는 방법 (2)\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(10,activation = 'softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=[tf.metrics.CategoricalAccuracy(),tf.metrics.Recall()])\nnet.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 1.9477 - categorical_accuracy: 0.7461 - recall: 0.7014\nEpoch 2/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.6755 - categorical_accuracy: 0.7792 - recall: 0.7217\nEpoch 3/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.5605 - categorical_accuracy: 0.8143 - recall: 0.7659\nEpoch 4/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.4762 - categorical_accuracy: 0.8356 - recall: 0.7929\nEpoch 5/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.4460 - categorical_accuracy: 0.8422 - recall: 0.8033\n\n\n<keras.callbacks.History at 0x7f904e1603d0>\n\n\n\nnet.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 590us/step - loss: 0.4699 - categorical_accuracy: 0.8353 - recall: 0.7885\n\n\n[0.46987518668174744, 0.8353000283241272, 0.7885000109672546]"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#flatten-layer",
    "href": "posts/3_STBDA2022/2022_05_09_(10주차)_5월9일.html#flatten-layer",
    "title": "[STBDA] 10wk. 로지스틱 모형",
    "section": "flatten layer",
    "text": "flatten layer\n- 이미지 데이터를 분류하기 좋은 형태로 자료를 재정리하자.\n\nx_train.shape\n\n(60000, 28, 28)\n\n\n\nX = tf.constant(x_train.reshape(-1,28,28,1),dtype=tf.float64)\ny = tf.keras.utils.to_categorical(y_train)\nXX = tf.constant(x_test.reshape(-1,28,28,1),dtype=tf.float64)\nyy = tf.keras.utils.to_categorical(y_test)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(TensorShape([60000, 28, 28, 1]),\n TensorShape([10000, 28, 28, 1]),\n (60000, 10),\n (10000, 10))\n\n\n- 일반적인 이미지 분석 모형을 적용하기 용이한 데이터 형태로 정리했다. -> 그런데 모형에 넣고 돌릴려면 다시 차원을 펼쳐야 하지 않을까?\n- 안펼치고 하고싶다.\n\nflttn = tf.keras.layers.Flatten()\n\n\nset(dir(flttn)) & {'__call__'}\n\n{'__call__'}\n\n\n\nX.shape, flttn(X).shape, X.reshape(-1,784).shape\n\n(TensorShape([60000, 28, 28, 1]),\n TensorShape([60000, 784]),\n TensorShape([60000, 784]))\n\n\n\n같은 기능\n다른건? \\(\\to\\) layers (layer로 넣을 수 있는 무기들 중 Flatten이 하나 추가됨!) \\(\\to\\) 네트워크에 넣을 수 있겠다!\n\n- flttn\n\\(X \\to \\text{Dense}(500, relu) \\to \\text{Dense}(500, relu) \\to \\text{Dense}(10,\\text{softmax}):=y\\)\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten()) ## dimension을 맞춰주는 것을 네트워크 안으로 넣은 것.\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(500,activation = 'relu'))\nnet.add(tf.keras.layers.Dense(10,activation = 'softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics=[tf.metrics.CategoricalAccuracy(),tf.metrics.Recall()])\nnet.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 2.5320 - categorical_accuracy: 0.7491 - recall_1: 0.7126\nEpoch 2/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.6705 - categorical_accuracy: 0.7844 - recall_1: 0.7238\nEpoch 3/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.5829 - categorical_accuracy: 0.8096 - recall_1: 0.7708\nEpoch 4/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.4954 - categorical_accuracy: 0.8318 - recall_1: 0.7970\nEpoch 5/5\n1875/1875 [==============================] - 3s 1ms/step - loss: 0.4676 - categorical_accuracy: 0.8383 - recall_1: 0.8020\n\n\n<keras.callbacks.History at 0x7f904e050940>\n\n\n\nnet.layers\n\n[<keras.layers.reshaping.flatten.Flatten at 0x7f904df61430>,\n <keras.layers.core.dense.Dense at 0x7f904df612e0>,\n <keras.layers.core.dense.Dense at 0x7f904deed700>,\n <keras.layers.core.dense.Dense at 0x7f904deed970>]\n\n\n\nDense layer는 activation이 합쳐진 layer.\n\n\nprint(X.shape)\nprint(net.layers[0](X).shape)\nprint(net.layers[1](net.layers[0](X)).shape)\nprint(net.layers[2](net.layers[1](net.layers[0](X))).shape)\nprint(net.layers[3](net.layers[2](net.layers[1](net.layers[0](X)))).shape)\n\n(60000, 28, 28, 1)\n(60000, 784)\n(60000, 500)\n(60000, 500)\n(60000, 10)\n\n\n\nnet.layers[1]\n\n<keras.layers.core.dense.Dense at 0x7f904df612e0>\n\n\n- 좀 더 복잡한 네트워크 -> 하지만 한계가 보인다 -> 좀 더 나은 아키텍처는 없을까\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Flatten())\nnet.add(tf.keras.layers.Dense(500,activation='relu'))\nnet.add(tf.keras.layers.Dense(500,activation='relu'))\nnet.add(tf.keras.layers.Dense(500,activation='relu'))\nnet.add(tf.keras.layers.Dense(500,activation='relu'))\nnet.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet.compile(loss=tf.losses.categorical_crossentropy, optimizer='adam',metrics='accuracy')\nnet.fit(X,y,epochs=10)\n\nEpoch 1/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 1.1550 - accuracy: 0.7911\nEpoch 2/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.4523 - accuracy: 0.8377\nEpoch 3/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.4129 - accuracy: 0.8532\nEpoch 4/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3926 - accuracy: 0.8610\nEpoch 5/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.3748 - accuracy: 0.8680\nEpoch 6/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3645 - accuracy: 0.8718\nEpoch 7/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3461 - accuracy: 0.8773\nEpoch 8/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3381 - accuracy: 0.8788\nEpoch 9/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3372 - accuracy: 0.8810\nEpoch 10/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.3240 - accuracy: 0.8844\n\n\n<keras.callbacks.History at 0x7f904e1d9d00>\n\n\n\nnet.summary()\n\nModel: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten_3 (Flatten)         (None, 784)               0         \n                                                                 \n dense_20 (Dense)            (None, 500)               392500    \n                                                                 \n dense_21 (Dense)            (None, 500)               250500    \n                                                                 \n dense_22 (Dense)            (None, 500)               250500    \n                                                                 \n dense_23 (Dense)            (None, 500)               250500    \n                                                                 \n dense_24 (Dense)            (None, 10)                5010      \n                                                                 \n=================================================================\nTotal params: 1,149,010\nTrainable params: 1,149,010\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nnet.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 752us/step - loss: 0.4136 - accuracy: 0.8566\n\n\n[0.4136269986629486, 0.8565999865531921]\n\n\n- layer중에 우리는 끽해야 Dense정도 쓰고있었음. \\(\\to\\) flatten과 같은 다른 layer도 많음. \\(\\to\\) 이런것도 써보자"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_01_(9주차)_5월2일(1).html",
    "href": "posts/3_STBDA2022/2022_05_01_(9주차)_5월2일(1).html",
    "title": "[STBDA] 9wk. Likelihood function",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wrJ6CivKKBuJUN7ukm5OHr\n\n\n\nimports\n\nimport numpy as np\nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport matplotlib.pyplot as plt \n\n\n\n우도함수와 최대우도추정량\n(예제)\n\\(X_i \\overset{iid}{\\sim} Ber(p)\\)에서 얻은 샘플이 아래와 같다고 하자.\n\nx=[0,1,0,1] \nx\n\n[0, 1, 0, 1]\n\n\n\\(p\\)는 얼마라고 볼 수 있는가? –> 0.5\n왜?? \\(p\\)가 0.5라고 주장할 수 있는 이론적 근거, 혹은 논리체계가 무엇인가?\n- suppose: \\(p=0.1\\) 이라고 하자.\n그렇다면 \\((x_1,x_2,x_3,x_4)=(0,1,0,1)\\)와 같은 샘플이 얻어질 확률이 아래와 같다.\n\n0.9 * 0.1 * 0.9 * 0.1\n\n0.008100000000000001\n\n\n- suppose: \\(p=0.2\\) 이라고 하자.\n그렇다면 \\((x_1,x_2,x_3,x_4)=(0,1,0,1)\\)와 같은 샘플이 얻어질 확률이 아래와 같다.\n\n0.8 * 0.2 * 0.8 * 0.2\n\n0.025600000000000008\n\n\n- 질문1: \\(p=0.1\\)인것 같냐? 아니면 \\(p=0.2\\)인것 같냐? -> \\(p=0.2\\)\n\n왜?? \\(p=0.2\\)일 확률이 더 크다! \\(\\to\\) \\(p=0.2\\)일 가능도가 더 크다!\n\n\n(여기서 잠깐 중요한것) 확률이라는 말을 함부로 쓸 수 없다.\n- 0.0256은 “\\(p=0.2\\)일 경우 샘플 (0,1,0,1)이 얻어질 확률”이지 “\\(p=0.2\\)일 확률”은 아니다.\n“\\(p=0.2\\)인 확률” 이라는 개념이 성립하려면 아래코드에서 sum([(1-p)*p*(1-p)*p for p in _plist])이 1보다는 작아야 한다. (그런데 1보다 크다)\n\n_plist = np.linspace(0.499,0.501,1000) \nsum([(1-p)*p*(1-p)*p for p in _plist])\n\n62.49983299986714\n\n\n\n확률은 다 더하면 \\(1\\)이어야 하는데 가뿐히 넘어버림..\n\n- 확률이라는 말을 쓸 수 없지만 확률의 느낌은 있음 -> 가능도라는 말을 쓰자.\n\n0.0256 \\(=\\) \\(p\\)가 0.2일 경우 샘플 (0,1,0,1)이 얻어질 확률 \\(=\\) \\(p\\)가 0.2일 가능도\n\n\n- 다시 질문1로 돌아가자!\n\n질문1: \\(p=0.1\\)인 것 같냐? 아니면 \\(p=0.2\\)인 것 같냐? -> 답 \\(p=0.2\\) -> 왜? \\(p=0.2\\)인 가능도가 더 크니까!\n질문2: \\(p=0.2\\)인 것 같냐? 아니면 \\(p=0.3\\)인 것 같냐? -> 답 \\(p=0.3\\) -> 왜? \\(p=0.3\\)인 가능도가 더 크니까!\n질문3: …\n\n- 궁극의 질문: \\(p\\)가 뭐일 것 같아?\n\n\\(p\\)가 입력으로 들어가면 가능도가 계산되는 함수를 만들자.\n그 함수를 최대화하는 \\(p\\)를 찾자.\n그 \\(p\\)가 궁극의 질문에 대한 대답이 된다.\n\n- 잠깐 용어정리\n\n가능도함수 \\(=\\) 우도함수 \\(=\\) likelihood function \\(:=\\) \\(L(p)\\)\n\\(p\\)의 maximum likelihood estimator \\(=\\) p의 MLE \\(:=\\) \\(\\hat{p}^{mle}\\) \\(=\\) \\(\\text{argmax}_p L(p)\\) \\(=\\) \\(\\hat{p}\\)\n\n(예제의 풀이)\n- 이 예제의 경우 가능도함수를 정의하자.\n\n\\(L(p)\\): \\(p\\)의 가능도함수 = \\(p\\)가 모수일때 샘플 (0,1,0,1)이 얻어질 확률 = \\(p\\)가 모수일때 \\(x_1\\)이 0일 확률 \\(\\times \\dots \\times\\) \\(p\\)가 모수일때 \\(x_4\\)가 1일 확률\n\\(L(p)=\\prod_{i=1}^{4} f(x_i;p)= \\prod_{i=1}^{4}p^{x_i}(1-p)^{1-x_i}\\)\n\n\nnote: 참고로 이 과정을 일반화 하면 \\(X_1,\\dots,X_n \\overset{iid}{\\sim} Ber(p)\\) 일때 \\(p\\)의 likelihood function은 \\(\\prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}\\) 라고 볼 수 있다.\n\n\nnote: 더 일반화: \\(x_1,\\dots,x_n\\)이 pdf가 \\(f(x)\\)인 분포에서 뽑힌 서로 독립인 샘플일때 likelihood function은 \\(\\prod_{i=1}^{n}f(x_i)\\)라고 볼 수 있다.\n\n- 이 예제의 경우 \\(p\\)의 최대우도추정량을 구하면\n\\[\\hat{p}^{mle} = \\text{argmax}_p L(p) = \\text{argmax}_p  \\big\\{ p^2(1-p)^2 \\big\\}= \\frac{1}{2}\\]\n\n\n중간고사 1번\n(1) \\(N(\\mu,\\sigma)\\)에서 얻은 샘플이 아래와 같다고 할때 \\(\\mu,\\sigma\\)의 MLE를 구하여라.\n<tf.Tensor: shape=(10000,), dtype=float64, numpy=\narray([ 4.12539849,  5.46696729,  5.27243374, ...,  2.89712332,\n        5.01072291, -1.13050477])>\n(2) \\(Ber(p)\\)에서 얻은 샘플이 아래와 같다고 할 때 \\(p\\)의 MLE를 구하여라.\n<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([1, 1, 1, ..., 0, 0, 1])>\n(3) \\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\), \\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\) 일때 \\((\\beta_0,\\beta_1)\\)의 MLE를 구하여라. (회귀모형)\n(풀이) 가능도함수\n\\[L(\\beta_0,\\beta_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(y_i)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(y_i-\\mu_i)^2}, \\quad \\mu_i=\\beta_0+\\beta_1 x_i\\]\n를 최대화하는 \\(\\beta_0,\\beta_1\\)을 구하면된다. 그런데 이것은 아래를 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하는 것과 같다.\n\\[-\\log L(\\beta_0,\\beta_1) = \\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2\\]\n위의 식은 SSE와 같다. 결국 오차항이 정규분포를 따르는 회귀모형의 MLE는 MSE를 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하면 된다.\n중간고사 1-(3)의 다른 풀이\nstep1: 생성\n\nx= tf.constant(np.arange(1,10001)/10000)\ny= tnp.random.randn(10000) + (0.5 + 2*x) \n\nstep2: minimize MSEloss (원래는 maximize log-likelihood)\n\nmaximize likelihood였던 문제를 minimize MSEloss로 바꾸어도 되는근거? 주어진 함수(=가능도함수)를 최대화하는 \\(\\beta_0,\\beta_1\\)은 MSE를 최소화하는 \\(\\beta_0,\\beta_1\\)과 동일하므로\n\n\nbeta0= tf.Variable(1.0)\nbeta1= tf.Variable(1.0) \nfor i in range(2000):\n    with tf.GradientTape() as tape: \n        #minus_log_likelihood = tf.reduce_sum((y-beta0-beta1*x)**2)\n        loss =  tf.reduce_sum((y-beta0-beta1*x)**2)\n    slope1, slope2 = tape.gradient(loss,[beta0,beta1]) \n    beta0.assign_sub(slope1* 0.1/10000) # N=10000 \n    beta1.assign_sub(slope2* 0.1/10000) \n\n\nbeta0,beta1\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.52694947>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.956429>)\n\n\n\n\\(\\beta_0 = 0.5, \\beta_1 = 2\\) 가 true값임.\n\n- 문제를 풀면서 생각해보니 손실함수는 -로그가능도함수로 선택하면 될 것 같다?\n\n손실함수를 선택하는 기준이 -로그가능도함수만 존재하는 것은 아니나 대부분 그러하긴함\n\n(4) 출제하지 못한 중간고사 문제\n아래의 모형을 생각하자. - \\(Y_i \\overset{iid}{\\sim} Ber(\\pi_i)\\) - \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}=\\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\)\n아래는 위의 모형에서 얻은 샘플이다.\n\nx = tnp.linspace(-1,1,2000) # sample\npi = tnp.exp(-1+5*x) / (1+tnp.exp(-1+5*x)) # sample이 나올 확률\ny = np.random.binomial(1,pi)\ny = tf.constant(y)\n\n함수 \\(L(w_0,w_1)\\)을 최대화하는 \\((w_0,w_1)\\)를 tf.GradeintTape()를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 \\((w_0,w_1)\\)의 초기값은 모두 0.1로 설정할 것)\n\\[L(w_0,w_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(x_i)={\\pi_i}^{y_i}(1-\\pi_i)^{1-y_i},\\quad \\pi_i=\\text{sigmoid}(w_0+w_1x_i)\\]\n(풀이1)\n\nw0hat = tf.Variable(1.0) \nw1hat = tf.Variable(1.0) \n\n\nfor i in range(1000): \n    with tf.GradientTape() as tape: \n        pihat = tnp.exp(w0hat+w1hat *x) / (1+tnp.exp(w0hat+w1hat *x))\n        pdf = pihat**y * (1-pihat)**(1-y) \n        logL = tf.reduce_mean(tnp.log(pdf)) \n    slope1,slope2 = tape.gradient(logL,[w0hat,w1hat])\n    w0hat.assign_add(slope1*0.1) \n    w1hat.assign_add(slope2*0.1) \n\n\nw0hat,w1hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.88308984>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.144893>)\n\n\n\ntrue값인 \\(-1\\)과 \\(5\\)에 근접한 값이 나와 적합이 잘 되었다.\n\n(해석) - 로지스틱에서 가능도함수와 BCEloss의 관계\n\\(L(w_0,w_1)\\)를 최대화하는 \\(w_0,w_1\\)은 아래를 최소화하는 \\(w_0,w_1\\)와 같다.\n\\[-\\log L(w_0,w_1) = - \\sum_{i=1}^{n}\\big(y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\big)\\]\n이것은 최적의 \\(w_0,w_1\\)을 \\(\\hat{w}_0,\\hat{w}_1\\)이라고 하면 \\(\\hat{\\pi}_i=\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\hat{y}_i\\)이 되고 따라서 위의 식은 \\(n\\times\\)BCEloss의 형태임을 쉽게 알 수 있다.\n결국 로지스틱 모형에서 \\((w_0,w_1)\\)의 MLE를 구하기 위해서는 BCEloss를 최소화하는 \\((w_0,w_1)\\)을 구하면 된다!\n결국 BCE Loss는 -로그가능도함수를 \\(n\\)으로 나눈 것과 같다.\nlikelihood라는 개념이없다면 회귀모형일 경우에는 MSELoss를 쓰고, 로지스틱일 경우에는 BCELoss를 쓴다고 외워야하는 문제였지만, Likelihood라는 개념이 있다면 로지스틱이든 회귀모형이든 손실함수는 -loglikelihood로 잡는군! 이렇게 넘어갈 수 있다.\n(풀이2)\n\nw0hat = tf.Variable(1.0) \nw1hat = tf.Variable(1.0) \n\n\nfor i in range(1000): \n    with tf.GradientTape() as tape: \n        yhat = tnp.exp(w0hat+w1hat *x) / (1+tnp.exp(w0hat+w1hat *x))\n        loss = tf.losses.binary_crossentropy(y,yhat)\n    slope1,slope2 = tape.gradient(loss,[w0hat,w1hat])\n    w0hat.assign_sub(slope1*0.1) \n    w1hat.assign_sub(slope2*0.1) \n\n\nw0hat,w1hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.8830899>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.144893>)\n\n\n\n\n손실함수의 설계 (선택)\n- 회귀분석이든 로지스틱이든 손실함수는 minus_log_likelihood 로 선택한다. - 그런데 (오차항이 정규분포인) 회귀분석 일때는 minus_log_likelihood 가 MSEloss가 되고 - 로지스틱일때는 minus_log_likelihood 가 BCEloss가 된다\n- minus_log_likelihood가 손실함수를 선택하는 유일한 기준은 아니다. <— 참고만하세요, 이 수업에서는 안중요합니다. - 오차항이 대칭이고 서로독립이며 등분산 가정을 만족하는 어떠한 분포에서의 회귀모형이 있다고 하자. 이 회귀모형에서 \\(\\hat{\\beta}\\)은 여전히 MSEloss를 최소화하는 \\(\\beta\\)를 구함으로써 얻을 수 있다. - 이 경우 MSEloss를 쓰는 이론적근거? \\(\\hat{\\beta}\\)이 BLUE가 되기 때문임 (가우스-마코프정리)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html",
    "href": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html",
    "title": "[STBDA] 4wk. 미분 / 경사하강법",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xGxAT-3Sq_jpD-eBxpsT8L"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html#경사하강법",
    "href": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html#경사하강법",
    "title": "[STBDA] 4wk. 미분 / 경사하강법",
    "section": "경사하강법",
    "text": "경사하강법\n\n최적화문제\n- \\(loss=(\\frac{1}{2}\\beta-1)^2\\)를 최소하는 \\(\\beta\\)를 컴퓨터를 활용하여 구하는 문제를 생각해보자. - 답은 \\(\\beta=2\\)임을 알고 있다.\n\n\n방법1: grid search\n\n알고리즘\n\nbeta = [-10.00,-9.99,…,10.00] 와 같은 리스트를 만든다.\n(1)의 리스트의 각원소에 해당하는 loss를 구한다.\n(2)에서 구한 loss를 제일 작게 만드는 beta를 찾는다.\n\n\n\n구현코드\n\nbeta = np.linspace(-10,10,100) \nloss = (beta/2 -1)**2 \n\n\n# argmin()\ntnp.argmin([1,2,-3,3,4]) # 가장작은 인덱스 리턴\n\n<tf.Tensor: shape=(), dtype=int64, numpy=2>\n\n\n\ntnp.argmin([1,2,3,-3,4])\n\n<tf.Tensor: shape=(), dtype=int64, numpy=3>\n\n\n\ntnp.argmin(loss)\n\n<tf.Tensor: shape=(), dtype=int64, numpy=59>\n\n\n\nbeta[59]\n\n1.9191919191919187\n\n\n\n\n그리드서치의 문제점\n- 비판1: [-10,10]이외에 해가 존재하면? - 이 예제의 경우는 운좋게 [-10,10]에서 해가 존재했음 - 하지만 임의의 고정된 \\(x,y\\)에 대하여 \\(loss(\\beta)=(x\\beta-y)^2\\) 의 형태의 해가 항상 [-10,10]에서 존재한다는 보장은 없음 - 해결책: 더 넓게 많은 범위를 탐색하자?\n- 비판2: 효율적이지 않음 - 알고리즘을 요약하면 결국 -10부터 10까지 작은 간격으로 조금씩 이동하며 loss를 조사하는 것이 grid search의 아이디어 - \\(\\to\\) 생각해보니까 \\(\\beta=2\\)인 순간 \\(loss=(\\frac{1}{2}\\beta-1)^2=0\\)이 되어서 이것보다 작은 최소값은 존재하지 않는다(제곱은 항상 양수이어야 하므로) - \\(\\to\\) 따라서 \\(\\beta=2\\) 이후로는 탐색할 필요가 없다\n\n\n\n방법2: gradient descent\n\\(loss=(\\frac{1}{2}\\beta-1)^2\\)\n\n알고리즘!\n\nbeta = -5 로 셋팅한다.\n\n\n(-5/2-1)**2 # 아무거나 던지면 됨..\n\n12.25\n\n\n\nbeta=-5 근처에서 조금씩 이동하여 loss를 조사해본다.\n\n\n(-4.99/2-1)**2 ## 오른쪽으로 0.01 이동하고 loss조사\n\n12.215025\n\n\n\n(-5.01/2-1)**2 ## 왼쪽으로 0.01 이동하고 loss조사\n\n12.285025\n\n\n\n(2)의 결과를 잘 해석하고 더 유리한 쪽으로 이동\n위의 과정을 반복하고 왼쪽, 오른쪽 어느쪽으로 움직여도 이득이 없다면 멈춘다.\n\n\n\n알고리즘 분석\n- (2)-(3)의 과정은 beta=-5 에서 미분계수를 구하고 미분계수가 양수이면 왼쪽으로 움직이고 음수이면 오른쪽으로 움직인다고 해석가능. 아래그림을 보면 더 잘 이해가 된다.\n\nplt.plot(beta,loss)\n\n\n\n\n\n\n왼쪽/오른쪽중에 어디로 갈지 어떻게 판단하는 과정을 수식화?\n- 아래와 같이 해석가능\n\n오른쪽으로 0.01 간다 = beta_old에 0.01을 더함. (if, 미분계수가 음수)\n왼쪽으로 0.01 간다. = beta_old에 0.01을 뺀다. (if, 미분계수가 양수)\n\n- 그렇다면 $_{new} =\n\\[\\begin{cases}\n\\beta_{old} + 0.01, & loss'(\\beta_{old})< 0  \\\\\n\\beta_{old} - 0.01, & loss'(\\beta_{old})> 0\n\\end{cases}\\]\n$\n\n\n혹시 알고리즘을 좀 개선할수 있을까?\n- 항상 0.01씩 움직여야 하는가?\n\nplt.plot(beta,loss)\n\n\n\n\n- \\(\\beta=-10\\) 일 경우의 접선의 기울기? \\(\\beta=-4\\) 일때 접선의 기울기?\n\n\\(\\beta=-10\\) => 기울기는 -6\n\\(\\beta=-4\\) => 기울기는 -3\n\n\n(-10/2-1), (-4/2-1)\n\n(-6.0, -3.0)\n\n\n- 실제로 6,3씩 이동할순 없으니 적당한 \\(\\alpha\\) (예를들면 \\(\\alpha=0.01\\)) 를 잡아서 곱한만큼 이동하자.\n- 수식화하면\n\n\\(\\beta_{new} = \\beta_{old} - \\alpha~ loss'(\\beta_{old})\\)\n\\(\\beta_{new} = \\beta_{old} - \\alpha~ \\left[\\frac{\\partial}{\\partial \\beta }loss(\\beta)\\right]_{\\beta=\\beta_{old}}\\)\n\n- \\(\\alpha\\)의 의미 - \\(\\alpha\\)가 크면 크게크게 움직이고 작으면 작게작게 움직인다. - \\(\\alpha>0\\) 이어야 한다.\n\n\n구현코드\n- iter 1\n\\(\\beta=-10\\)이라고 하자.\n\nbeta = tf.Variable(-10.0) \n\n\nwith tf.GradientTape(persistent=True) as tape: \n    loss = (beta/2-1)**2 \n\n\ntape.gradient(loss,beta)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-6.0>\n\n\n\\(\\beta = -10\\) 에서 0.01만큼 움직이고 싶음\n\nalpha= 0.01/6\n\n\nalpha * tape.gradient(loss,beta)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-0.01>\n\n\n\nbeta.assign_sub(alpha * tape.gradient(loss,beta))\n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.99>\n\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n\n한번 더 움직이자.\n\n- iter2\n\nwith tf.GradientTape(persistent=True) as tape: \n    loss = (beta/2-1)**2 \n\n\nbeta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.980008>\n\n\n\n더 나은 \\(\\beta\\)가 되었음! 이렇게 가다보면 \\(2\\)까지 잘 갈 수 있을 것 같다!\n\n- for 문을 이용하자.\n(강의용)\n\nbeta = tf.Variable(-10.0) \n\n\nfor k in range(10000): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9971251>\n\n\n\n잘 찾았네!\n\n(시도1) beta 다시 초기화 해서 iter 100번 돌려보자.\n\nbeta = tf.Variable(-10.0) \n\n\nfor k in range(100): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-8.157076>\n\n\n(시도2) beta 다시 초기화 해서 iter 1000번 돌려보자.\n\nbeta = tf.Variable(-10.0)  # 초기화\n\n\nfor k in range(1000): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-3.2133684>\n\n\n\n10000번 돌렸을 때는 답과 근사했는데 iter 수를 줄였더니 잘 못맞추네… 그럼 이건 알고리즘상 문제가 아니라 보폭이 너무 작아서..느린 것 뿐..\n\n- 너무 느린 것 같다? \\(\\to\\) \\(\\alpha\\)를 키워보자!\n\n\n학습률\n- 목표: \\(\\alpha\\)에 따라서 수렴과정이 어떻게 달라지는 시각화해보자.\n\n[시각화 코드 예비학습]\n\nfig = plt.figure() # 도화지가 만들어지고 fig라는 이름을 붙인다. \n\n<Figure size 432x288 with 0 Axes>\n\n\n\nax = fig.add_subplot() # fig는 ax라는 물체를 만든다. \n\n\nid(fig.axes[0])\n\n140572441475776\n\n\n\nid(ax)\n\n140572441475776\n\n\n\npnts, = ax.plot([1,2,3],[4,5,6],'or')\npnts\n\n<matplotlib.lines.Line2D at 0x7fd9926c52e0>\n\n\n\npnts.get_xdata()\n\narray([1, 2, 3])\n\n\n\npnts.get_ydata()\n\narray([4, 5, 6])\n\n\n\nfig\n\n\n\n\n\npnts.set_ydata([5,5,5])\n\n\npnts.get_ydata() # 값이 수정됨!\n\n[5, 5, 5]\n\n\n\nfig\n\n\n\n\n- 응용\n\nplt.rcParams[\"animation.html\"]=\"jshtml\"\nfrom matplotlib import animation \n\n\ndef animate(i): \n    if i%2 == 0: \n        pnts.set_ydata([4,5,6]) # 4,5,6으로 셋팅\n    else: \n        pnts.set_ydata([5,5,5]) # 5,5,5로 셋팅\n\n\nani = animation.FuncAnimation(fig,animate,frames=10)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n예비학습 끝\n- beta_lst=[-10,-9,-8] 로 이동한다고 하자.\n\nbeta_lst = [-10,-9,-8]\nloss_lst = [(-10/2-1)**2,(-9/2-1)**2,(-8/2-1)**2] \n\n\nfig = plt.figure() \n\n<Figure size 432x288 with 0 Axes>\n\n\n\nax= fig.add_subplot()\n\n\n_beta = np.linspace(-15,19,100) \n\n\nax.plot(_beta,(_beta/2-1)**2)\n\n\nfig\n\n\n\n\n\npnts, = ax.plot(beta_lst[0],loss_lst[0],'ro')\nfig\n\n\n\n\n\ndef animate(i): \n    pnts.set_xdata(beta_lst[:(i+1)])\n    pnts.set_ydata(loss_lst[:(i+1)])\n\n\nani =animation.FuncAnimation(fig, animate, frames=3)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 최종아웃풋\n\nbeta = tf.Variable(-10.0) \nalpha = 0.01/6\n\n\nbeta_lst=[]\nloss_lst=[]\n\n\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\n\n\nwith tf.GradientTape(persistent=True) as tape: \n    tape.watch(beta)  # beta에 대해 미분.\n    loss = (beta/2-1)**2\n\n\nbeta.assign_sub(tape.gradient(loss,beta)*alpha) \n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.99>\n\n\n\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\n\n\nbeta_lst, loss_lst\n\n([-10.0, -9.99], [36.0, 35.94002362785341])\n\n\n\nbeta값과 그에 대응되는 loss값\n\n- for\n\nbeta = tf.Variable(-10.0) \nalpha = 0.01/6\nbeta_lst=[]\nloss_lst=[]\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\nfor k in range(100): \n    with tf.GradientTape(persistent=True) as tape: \n        tape.watch(beta) \n        loss = (beta/2-1)**2\n    beta.assign_sub(tape.gradient(loss,beta)*alpha)  # beta update\n    beta_lst.append(beta.numpy()) # update된 beta 추가\n    loss_lst.append((beta.numpy()/2-1)**2) # loss 계산\n\n\nfig = plt.figure() \nax = fig.add_subplot() \nax.plot(_beta,(_beta/2-1)**2) \npnts, = ax.plot(beta_lst[0],loss_lst[0],'or')\n\n\n\n\n\nani = animation.FuncAnimation(fig,animate,frames=100) \nani \n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n너무 느려… 왜 \\(\\alpha\\) 를 바꿔야할지 알듯하다..\n\n\n\n\n\n숙제\n\\(y=(x-1)^2\\)를 최소화 하는 \\(x\\)를 경사하강법을 이용하여 찾아라. 수렴과정을 animation으로 시각화하라.\n- x의 초기값은 -3으로 설정한다. - 적당한 \\(\\alpha\\)를 골라서 100번의 반복안에 수렴하도록 하라."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_18_(7주차)_4월18일.html",
    "href": "posts/3_STBDA2022/2022_04_18_(7주차)_4월18일.html",
    "title": "[STBDA] 7wk. Piece-wise LR / Logistic Regression",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-ws3T1xD-bBU46dtduUlwmP\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\npiece-wise linear regression\nmodel: \\(y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x>0 \\end{cases}\\)\n\nnp.random.seed(43052)\nN=100\nx = np.linspace(-1,1,N)\nlamb = lambda x: x*1+np.random.normal()*0.3 if x<0 else x*3.5+np.random.normal()*0.3 \ny= np.array(list(map(lamb,x)))\ny\n\narray([-0.88497385, -0.65454563, -0.61676249, -0.84702584, -0.84785569,\n       -0.79220455, -1.3777105 , -1.27341781, -1.41643729, -1.26404671,\n       -0.79590224, -0.78824395, -0.86064773, -0.52468679, -1.18247354,\n       -0.29327295, -0.69373049, -0.90561768, -1.07554911, -0.7225404 ,\n       -0.69867774, -0.34811037,  0.11188474, -1.05046296, -0.03840085,\n       -0.38356861, -0.24299798, -0.58403161, -0.20344022, -0.13872303,\n       -0.529586  , -0.27814478, -0.10852781, -0.38294596,  0.02669763,\n       -0.23042603, -0.77720364, -0.34287396, -0.04512022, -0.30180793,\n       -0.26711438, -0.51880349, -0.53939672, -0.32052379, -0.32080763,\n        0.28917092,  0.18175206, -0.48988124, -0.08084459,  0.37706178,\n        0.14478908,  0.07621827, -0.071864  ,  0.05143365,  0.33932009,\n       -0.35071776,  0.87742867,  0.51370399,  0.34863976,  0.55855514,\n        1.14196717,  0.86421076,  0.72957843,  0.57342304,  1.54803332,\n        0.98840018,  1.11129366,  1.42410801,  1.44322465,  1.25926455,\n        1.12940772,  1.46516829,  1.16365096,  1.45560853,  1.9530553 ,\n        2.45940445,  1.52921129,  1.8606463 ,  1.86406718,  1.5866523 ,\n        1.49033473,  2.35242686,  2.12246412,  2.41951931,  2.43615052,\n        1.96024441,  2.65843789,  2.46854394,  2.76381882,  2.78547462,\n        2.56568465,  3.15212157,  3.11482949,  3.17901774,  3.31268904,\n        3.60977818,  3.40949166,  3.30306495,  3.74590922,  3.85610433])\n\n\n\nplt.plot(x,y,'.')\n\n\n\n\n\n풀이1: 단순회귀모형\n\nx= x.reshape(N,1)\ny= y.reshape(N,1) \n\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(1)) \nnet.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\nnet.fit(x,y,batch_size=N,epochs=1000,verbose=0) # numpy로 해도 돌아감\n\n<keras.callbacks.History at 0x7f88c01c7820>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[2.2616348]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.6069048], dtype=float32)>]\n\n\n\nyhat = x * 2.2616348 + 0.6069048\nyhat = net.predict(x)\n\n4/4 [==============================] - 0s 470us/step\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n- 실패: 이 모형은 epoch을 10억번 돌려도 실패할 모형임 - 왜? 아키텍처 설계자체가 틀렸음 - 꺽인부분을 표현하기에는 아키텍처의 표현력이 너무 부족하다 -> under fit의 문제\n\n\n풀이2: 비선형 활성화 함수의 도입\n- 여기에서 비선형 활성화 함수는 relu\n- 네트워크를 아래와 같이 수정하자.\n(수정전) hat은 생략\n\n#collapse\ngv('''\n\"x\" -> \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -> \"y\"[label=\"indentity\"] ''')\n\n\n\n\n(수정후) hat은 생략\n\n#collapse\ngv('''\n\"x\" -> \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -> \"y\"[label=\"relu\"] ''')\n\n\n\n\n\n마지막에 \\(f(x)=x\\) 라는 함수대신에 relu 를 취하는 것으로 구조를 약간 변경\n활성화함수(acitivation function)를 indentity에서 relu로 변경\n\n- relu함수란?\n\n_x = np.linspace(-1,1,100)\ntf.nn.relu(_x)\n\n<tf.Tensor: shape=(100,), dtype=float64, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.01010101, 0.03030303, 0.05050505, 0.07070707, 0.09090909,\n       0.11111111, 0.13131313, 0.15151515, 0.17171717, 0.19191919,\n       0.21212121, 0.23232323, 0.25252525, 0.27272727, 0.29292929,\n       0.31313131, 0.33333333, 0.35353535, 0.37373737, 0.39393939,\n       0.41414141, 0.43434343, 0.45454545, 0.47474747, 0.49494949,\n       0.51515152, 0.53535354, 0.55555556, 0.57575758, 0.5959596 ,\n       0.61616162, 0.63636364, 0.65656566, 0.67676768, 0.6969697 ,\n       0.71717172, 0.73737374, 0.75757576, 0.77777778, 0.7979798 ,\n       0.81818182, 0.83838384, 0.85858586, 0.87878788, 0.8989899 ,\n       0.91919192, 0.93939394, 0.95959596, 0.97979798, 1.        ])>\n\n\n\nplt.plot(_x,_x)\nplt.plot(_x,tf.nn.relu(_x))\n\n\n\n\n\n파란색을 주황색으로 바꿔주는 것이 렐루함수임\n\\(f(x)=\\max(0,x)=\\begin{cases} 0 & x\\leq 0 \\\\ x & x>0 \\end{cases}\\)\n\n- 아키텍처: \\(\\hat{y}_i=relu(\\hat{w}_0+\\hat{w}_1x_i)\\), \\(relu(x)=\\max(0,x)\\)\n- 풀이시작\n1단계\n\nnet2 = tf.keras.Sequential() \n\n2단계\n\ntf.random.set_seed(43053)\nl1 = tf.keras.layers.Dense(1, input_shape=(1,)) \na1 = tf.keras.layers.Activation(tf.nn.relu) \n\n\nnet2.add(l1)\n\n\nnet2.layers\n\n[<keras.layers.core.dense.Dense at 0x7f888c109820>]\n\n\n\nnet2.add(a1)\n\n\nnet2.layers\n\n[<keras.layers.core.dense.Dense at 0x7f888c109820>,\n <keras.layers.core.activation.Activation at 0x7f888c109250>]\n\n\n\nl1.get_weights()\n\n[array([[0.3830086]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nnet2.get_weights()\n\n[array([[0.3830086]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nl1에 있는 weight가 net2에 그대로 들어가게 된다.\n왜 시드고정이 안되는거지??\n\n(네트워크 상황 확인)\n\nu1= l1(x)\n#u1= x@l1.weights[0] + l1.weights[1]\n\n\nv1= a1(u1)\n#v1= tf.nn.relu(u1) \n\n\nplt.plot(x,x)\nplt.plot(x,u1,'--r')\nplt.plot(x,v1,'--b')\n\n\n\n\n3단계\n\nnet2.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\n\n4단계\n\nnet2.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f888c0b6d90>\n\n\n- result\n\n# 다 똑같은 코드.\nyhat = tf.nn.relu(x@l1.weights[0] + l1.weights[1]) \nyhat = net2.predict(x)\nyhat = net2(x)\nyhat = a1(l1(x))\nyhat = net2.layers[1](net2.layers[0](x))\n\n4/4 [==============================] - 0s 438us/step\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n- discussion - 이것 역시 수백억번 에폭을 반복해도 이 이상 적합이 힘들다 \\(\\to\\) 모형의 표현력이 떨어진다. - 해결책: 주황색점선이 2개 있다면 어떨까?\n\n\n풀이3: 노드수추가 + 레이어추가\n목표: 2개의 주황색 점선을 만들자.\n1단계\n\nnet3 = tf.keras.Sequential()\n\n2단계\n\n# tf.random.set_seed(43053)\ntf.keras.utils.set_random_seed(43053)\nl1 = tf.keras.layers.Dense(2,input_shape=(1,)) # 출력을 2로 하면 직선이 2개 만들어짐.\na1 = tf.keras.layers.Activation(tf.nn.relu)\n\n\nnet3.add(l1)\nnet3.add(a1) \n\n\nnet3.layers # 2개가 들어가있음!\n\n[<keras.layers.core.dense.Dense at 0x7f8840271d60>,\n <keras.layers.core.activation.Activation at 0x7f888c268c40>]\n\n\n(네트워크 상황 확인)\n\nl1(x).shape\n# l1(x) : (100,1) -> (100,2) \n\nTensorShape([100, 2])\n\n\n\n출력차원이 2라고 했으니까!\n\n\nplt.plot(x,x) # 입력 (파란)\nplt.plot(x,l1(x),'--') # 출력 (주황, 초록)\n\n\n\n\n\nplt.plot(x,x)\nplt.plot(x,a1(l1(x)),'--')\n\n\n\n\n- 이 상태에서는 yhat이 안나온다. 왜? - 차원이 안맞음. a1(l1(x))의 차원은 (N,2)인데 최종적인 yhat의 차원은 (N,1)이어야 함. (선이 하나여야 하잖아..) - 차원이 어찌저찌 맞다고 쳐도 relu를 통과하면 항상 yhat>0 임. 따라서 음수값을 가지는 y는 0으로 밖에 맞출 수 없음.\n- 해결책: a1(l1(x))에 연속으로(Sequential하게!) 또 다른 레이어를 설계! (N,2) -> (N,1) 이 되도록! - yhat= bias + weight1 * a1(l1(x))[0] + weight2 * a1(l1(x))[1]\n- 즉 a1(l1(x)) 를 새로운 입력으로 해석하고 출력을 만들어주는 선형모형을 다시태우면 된다. - 입력차원: 2 - 출력차원: 1\n\nnet3.layers\n\n[<keras.layers.core.dense.Dense at 0x7f8840271d60>,\n <keras.layers.core.activation.Activation at 0x7f888c268c40>]\n\n\n\n# tf.random.set_seed(43053) \ntf.keras.utils.set_random_seed(43053)\nl2 = tf.keras.layers.Dense(1, input_shape=(2,)) # 출력차원은 1, 입력차원은 2\n\n\nnet3.add(l2) \n\n\nnet3.layers\n\n[<keras.layers.core.dense.Dense at 0x7f8840271d60>,\n <keras.layers.core.activation.Activation at 0x7f888c268c40>,\n <keras.layers.core.dense.Dense at 0x7f88401fdaf0>]\n\n\n\nnet3.summary()\n\nModel: \"sequential_32\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_39 (Dense)            (None, 2)                 4         \n                                                                 \n activation_37 (Activation)  (None, 2)                 0         \n                                                                 \n dense_40 (Dense)            (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 7\nTrainable params: 7\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nDense layer \\(\\to\\) activation \\(\\to\\) Dense layer\n\n- 추정해야할 파라메터수가 4,0,3으로 나온다.\n- 수식표현: \\(X \\to X@W^{(1)}+b^{(1)} \\to relu(X@W^{(1)}+b^{(1)}) \\to relu(X@W^{(1)}+b^{(1)})@W^{(2)}+b^{(2)}=yhat\\)\n\n\\(X\\): (N,1)\n\\(W^{(1)}\\): (1,2) ==> 파라메터 2개 추정\n\\(b^{(1)}\\): (2,) ==> 파라메터 2개가 추가 // 여기까지 추정할 파라메터는 4개\n\\(W^{(2)}\\): (2,1) ==> 파라메터 2개 추정\n\\(b^{(2)}\\): (1,) ==> 파라메터 1개가 추가 // 따라서 3개\n\n- 참고: 추정할 파라메터수가 많다 = 복잡한 모형이다. - 초거대AI: 추정할 파라메터수가 엄청 많은..\n\nnet3.weights\n\n[<tf.Variable 'dense_39/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.8359591, -0.8971499]], dtype=float32)>,\n <tf.Variable 'dense_39/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_40/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.8359591],\n        [-0.8971499]], dtype=float32)>,\n <tf.Variable 'dense_40/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n\nl1.weights\n\n[<tf.Variable 'dense_39/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.8359591, -0.8971499]], dtype=float32)>,\n <tf.Variable 'dense_39/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n\n\n\nl2.weights\n\n[<tf.Variable 'dense_40/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.8359591],\n        [-0.8971499]], dtype=float32)>,\n <tf.Variable 'dense_40/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n- 좀 더 간단한 수식표현: \\(X \\to (u_1 \\to v_1) \\to (u_2 \\to v_2) = yhat\\) - \\(u_1= X@W^{(1)}+b^{(1)}\\) - \\(v_1= relu(u_1)\\) - \\(u_2= v_1@W^{(2)}+b^{(2)}\\) - \\(v_2= indentity(u_2):=yhat\\)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"u1[:,0]\"[label=\"*W1[0,0]\"]\n    \"X\" -> \"u1[:,1]\"[label=\"*W1[0,1]\"]\n    \"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -> \"yhat\"[label=\"*W2[0,0]\"]\n    \"v1[:,1]\" -> \"yhat\"[label=\"*W2[1,0]\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n하나는 주황색선, 하나는 초록색선이 만들어진다.\n너무 복잡한데..?\n\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n좀 더 간단한 형태의 아키텍쳐\n\n3단계\n\nnet3.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1))\n\n4단계\n\nnet3.fit(x,y,epochs=1000,verbose=0, batch_size=N) \n\n<keras.callbacks.History at 0x7f88400fba30>\n\n\n- 결과확인\n\nnet3.weights\n\n[<tf.Variable 'dense_39/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 1.6574922, -0.8332077]], dtype=float32)>,\n <tf.Variable 'dense_39/bias:0' shape=(2,) dtype=float32, numpy=array([-0.0729818,  0.8324026], dtype=float32)>,\n <tf.Variable 'dense_40/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6503255],\n        [-1.1728343]], dtype=float32)>,\n <tf.Variable 'dense_40/bias:0' shape=(1,) dtype=float32, numpy=array([0.95030355], dtype=float32)>]\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,net3(x),'--')\n\n\n\n\n\n잘 맞춤!\n\n- 분석\n\nplt.plot(x,y,'.') \nplt.plot(x,l1(x),'--')\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,a1(l1(x)),'--')\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,l2(a1(l1(x))),'--')\n\n\n\n\n- 마지막 2개의 그림을 분석\n\nl2.weights\n\n[<tf.Variable 'dense_40/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6503255],\n        [-1.1728343]], dtype=float32)>,\n <tf.Variable 'dense_40/bias:0' shape=(1,) dtype=float32, numpy=array([0.95030355], dtype=float32)>]\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \nfig.set_figwidth(12) \nax1.plot(x,y,'.')\nax1.plot(x,a1(l1(x))[:,0],'--r')\nax1.plot(x,a1(l1(x))[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0]*1.6328746,'--r')\nax2.plot(x,a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*1.6328746+a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--')\n\n\n\n\n\n\n풀이3의 실패\n\n# tf.random.set_seed(43054) \ntf.keras.utils.set_random_seed(43052)\n## 1단계\nnet3 = tf.keras.Sequential() \n## 2단계\nnet3.add(tf.keras.layers.Dense(2))\nnet3.add(tf.keras.layers.Activation('relu')) \nnet3.add(tf.keras.layers.Dense(1)) # 출력 1\n## 3단계 \nnet3.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\n## 4단계 \nnet3.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f8821a15c70>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n- 엥? 에폭이 부족한가?\n\nnet3.fit(x,y,epochs=10000,verbose=0,batch_size=N)\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n\n똑같은데…? 결국 에폭문제가 아니였음.\n\n- 실패분석\n\nl1,a1,l2 = net3.layers\n\n\nl2.weights\n\n[<tf.Variable 'dense_46/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.5306579],\n        [1.7407396]], dtype=float32)>,\n <tf.Variable 'dense_46/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)>]\n\n\n\nfig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nfig.set_figwidth(16) \nax1.plot(x,y,'.')\nax1.plot(x,l1(x)[:,0],'--r')\nax1.plot(x,l1(x)[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0],'--r')\nax2.plot(x,a1(l1(x))[:,1],'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*0.5306579,'--r')\nax3.plot(x,a1(l1(x))[:,1]*(1.7407396)+(-0.60076195),'--b')\nax4.plot(x,y,'.')\nax4.plot(x,a1(l1(x))[:,0]*0.5306579+a1(l1(x))[:,1]*(1.7407396)+(-0.60076195),'--')\n\n\n\n\n\n보니까 빨간색선이 하는 역할을 없음\n그런데 생각해보니까 이 상황에서는 빨간색선이 할수 있는 일이 별로 없음\n왜? 지금은 나름 파란색선에 의해서 최적화가 된 상태임 \\(\\to\\) 빨간선이 뭔가 하려고하면 최적화된 상태가 깨질 수 있음 (loss 증가)\n즉 이 상황 자체가 나름 최적화된 상태이다. 이러한 현상을 “global minimum을 찾지 못하고 local minimum에 빠졌다” 라고 표현한다.\n\n확인:\n\nnet3.weights\n\n[<tf.Variable 'dense_45/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[-0.3914748,  1.9987504]], dtype=float32)>,\n <tf.Variable 'dense_45/bias:0' shape=(2,) dtype=float32, numpy=array([-0.392621,  0.34811 ], dtype=float32)>,\n <tf.Variable 'dense_46/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.5306579],\n        [1.7407396]], dtype=float32)>,\n <tf.Variable 'dense_46/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)>]\n\n\n\nW1= tf.Variable(tnp.array([[-0.03077251,  1.8713338 ]]))\nb1= tf.Variable(tnp.array([-0.04834982,  0.3259186 ]))\nW2= tf.Variable(tnp.array([[0.65121335],[1.8592643 ]]))\nb2= tf.Variable(tnp.array([-0.60076195])) \n\n\nwith tf.GradientTape() as tape: \n    u = tf.constant(x) @ W1 + b1 \n    v = tf.nn.relu(u) \n    yhat = v@W2 + b2 \n    loss = tf.losses.mse(y,yhat) \n\n\ntape.gradient(loss,[W1,b1,W2,b2])\n\n[<tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[ 0.00000000e+00, -4.77330119e-05]])>,\n <tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.0000000e+00, 3.1478608e-06])>,\n <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n array([[ 0.00000000e+00],\n        [-4.74910706e-05]])>,\n <tf.Tensor: shape=(1,), dtype=float64, numpy=array([-2.43031263e-05])>]\n\n\n예상대로 계수값이 거의 다 0이다.\n\n\n풀이4: 노드수를 더 추가한다면?\n- 노드수를 더 추가해보면 어떻게 될까? (주황색 점선이 더 여러개 있다면?)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    \"X\" -> \"...\"\n    \"X\" -> \"node512\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    \"...\" -> \"yhat\"\n    \"node512\" -> \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\ntf.random.set_seed(43056)\nnet4= tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu')) # 이렇게 해도됩니다. \nnet4.add(tf.keras.layers.Dense(1))         \nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1)) \nnet4.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f8821327160>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net4(x),'--')\n\n\n\n\n\n잘된다..\n한두개의 노드가 역할을 못해도 다른노드들이 잘 보완해주는듯!\n\n- 노드수가 많으면 무조건 좋다? -> 대부분 나쁘지 않음. 그런데 종종 맞추지 말아야할것도 맞춤.. (overfit)\n\nnp.random.seed(43052)\nN=100 \n_x = np.linspace(0,1,N).reshape(N,1) \n_y = np.random.normal(loc=0,scale=0.001,size=(N,1))\nplt.plot(_x,_y)\n\n\n\n\n\ntf.random.set_seed(43052) \nnet4 = tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu'))\nnet4.add(tf.keras.layers.Dense(1))\nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.5))\nnet4.fit(_x,_y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f88210403a0>\n\n\n\nplt.plot(_x,_y)\nplt.plot(_x,net4(_x),'--')\n\n\n\n\n\n맞추지 말아야 할 것까지 맞춘다..\n가장 좋은 fit은 직선으로 맞추는것.\n이 예제는 추후 다시 공부할 예정\n\n\n\n\nLogistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 올라간다.\nex) 전자제품에 열을 많이 가할수록 불량률일 증가한다.\nex) 성적이 좋을수록 합격률이 증가한다.\n- 이러한 모형은 아래와 같이 설계할 수 있음 <– 외우세요!! - \\(y_i \\sim Ber(\\pi_i)\\), where \\(\\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\n\\(\\hat{y}_i =\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n- 위와 같은 손실함수를 BCEloss라고 부른다. (BCE는 Binary Cross Entropy의 약자)\n\n\n예제\n\nN = 2000\n\n\nx = tnp.linspace(-1,1,N).reshape(N,1)\nw0 = -1 \nw1 = 5 \nu = w0 + x*w1 \n#v = tf.constant(np.exp(u)/(1+np.exp(u))) # v=πi \nv = tf.nn.sigmoid(u) \ny = tf.constant(np.random.binomial(1,v),dtype=tf.float64) \n\n\nplt.plot(x,y,'.',alpha=0.02)\nplt.plot(x,v,'--r')\n\n\n\n\n- 이 아키텍처(yhat을 얻어내는 과정)를 다어어그램으로 나타내면 아래와 같다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x\" -> \"x*w, bias=True\"[label=\"*w\"]\n    \"x*w, bias=True\" -> \"yhat\"[label=\"sigmoid\"]\n    label = \"Layer 1\"\n}\n''')\n\n\n\n\n- 또는 간단하게 아래와 같이 쓸 수 있다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    x\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    x -> \"node1=yhat\"\n    label = \"Layer 1: sigmoid\"\n}\n''')\n\n\n\n\n- 케라스를 이용하여 적합을 해보면\n\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nbceloss_fn = lambda y,yhat: -tf.reduce_mean(y*tnp.log(yhat) + (1-y)*tnp.log(1-yhat))\nnet.compile(loss=bceloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f8820868070>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_55/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[4.4220047]], dtype=float32)>,\n <tf.Variable 'dense_55/bias:0' shape=(1,) dtype=float32, numpy=array([-0.84613276], dtype=float32)>]\n\n\n\nplt.plot(x,y,'.',alpha=0.1) # 관측데이터\nplt.plot(x,v,'--r') # 추정하고 싶은 확률\nplt.plot(x,net(x),'--b')  # 네트워크에 의한 추정 결과.\n\n\n\n\n\n거의 비슷하게 잘 추정되었다.\n\n\n\nMSE loss?\n- mse loss를 쓰면 왜 안되는지?\nMSE loss를 써서 다시 돌려보자.\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nmseloss_fn = lambda y,yhat: tf.reduce_mean((y-yhat)**2)\nnet.compile(loss=mseloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f88201c2580>\n\n\n\nplt.plot(x,y,'.',alpha=0.1)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x),'--b')\n\n\n\n\n\n일단 BCE loss와 비교해보니까 동일 초기값, 동일 epochs에서 적합이 별로임\n\n\n\nMSE loss vs BCE loss\n- MSEloss, BCEloss의 시각화\n\nw0, w1 = np.meshgrid(np.arange(-10,3,0.2), np.arange(-1,10,0.2), indexing='ij')\nw0, w1 = w0.reshape(-1), w1.reshape(-1)\n\ndef loss_fn1(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return mseloss_fn(y,yhat) \n\ndef loss_fn2(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return bceloss_fn(y,yhat) \n\nloss1 = list(map(loss_fn1,w0,w1))\nloss2 = list(map(loss_fn2,w0,w1))\n\n\nfig = plt.figure()\nfig.set_figwidth(9)\nfig.set_figheight(9)\nax1=fig.add_subplot(1,2,1,projection='3d')\nax2=fig.add_subplot(1,2,2,projection='3d')\nax1.elev=15\nax2.elev=15\nax1.azim=75\nax2.azim=75\nax1.scatter(w0,w1,loss1,s=0.1)\nax2.scatter(w0,w1,loss2,s=0.1) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f8803ecb910>\n\n\n\n\n\n\n왼쪽곡면(MSEloss)보다 오른쪽곡면(BCEloss)이 좀더 예쁘게 생김 -> 오른쪽 곡면에서 더 학습이 잘될것 같음\n\n\n\n학습과정 시각화예시1\n- 파라메터학습과정 시각화 // 옵티마이저: SGD, 초기값: (w0,w1) = (-3.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.SGD(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 75ms/step - loss: 0.2461\n\n\n<keras.callbacks.History at 0x7f8803dd3940>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.SGD(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 85ms/step - loss: 1.1333\n\n\n<keras.callbacks.History at 0x7f882080f0d0>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[0.40601483],\n         [0.3624403 ]], dtype=float32)],\n [array([[ 1.363407  ],\n         [-0.33031225]], dtype=float32)])\n\n\n\n둘이 weight이 다르니까 강제로 맞춰놓자.\n\n\nnet_mse.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-3.],\n         [-1.]], dtype=float32)],\n [array([[-3.],\n         [-1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"SGD, Winit=(-3,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n왼쪽 MSE, 오른쪽 BCE\nMSE의 경우 너무 천천히 수렴을 한다.\n동일 학습조건에서 오른쪽이 학습이 더 잘된다.\n\n\n\n학습과정 시각화예시2\n이번에는 똑같은 초깃값에 다른 옵티마이저(Adam)를 써보자.\n- 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-3.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.Adam(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 92ms/step - loss: 0.2902\n\n\n<keras.callbacks.History at 0x7f88211b1430>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.Adam(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 98ms/step - loss: 0.8690\n\n\n<keras.callbacks.History at 0x7f88402718b0>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[1.1395919],\n         [1.3250527]], dtype=float32)],\n [array([[-0.77553874],\n         [-0.59953135]], dtype=float32)])\n\n\n\nnet_mse.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-3.],\n         [-1.]], dtype=float32)],\n [array([[-3.],\n         [-1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"Adam, Winit=(-3,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nAdam을 쓴게 확실히 학습을 효율적으로 빨리함!\n\n동일한 loss function에 동일한 초깃값이라 해도 Adam을 쓰면 학습이 더 빠르다.\n그럼 MSE+Adam 조합으로 하면 적합이 잘 되겠구나? 라고 생각할 수 있는데 그건 아님.\n\n\n\n학습과정 시각화예시3\n이번에는 Adam을 쓸건데 다른 초깃값에서 시작해보자.\n- 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-10.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.Adam(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 93ms/step - loss: 0.1645\n\n\n<keras.callbacks.History at 0x7f87f3edb880>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.Adam(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 101ms/step - loss: 0.5978\n\n\n<keras.callbacks.History at 0x7f87f1ce8400>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-0.9448344],\n         [ 1.4777311]], dtype=float32)],\n [array([[0.47022673],\n         [1.2034082 ]], dtype=float32)])\n\n\n\nnet_mse.set_weights([tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-10.],\n         [ -1.]], dtype=float32)],\n [array([[-10.],\n         [ -1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"Adam, Winit=(-10,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n아무리 아담이라고 해도 이건 힘듬\n\n학습을 잘 되게 하기 위해서 옵티마이저를 개선하는 것은 되게 좋은 방법이지만 그것보다 근본적으로 loss function을 좀 더 예쁘게 만드려는 노력이 훨씬 더 좋은 생각..\n\n\ndiscussion / Summary\n- discussion - mse_loss는 경우에 따라서 엄청 수렴속도가 느릴수도 있음. - 근본적인 문제점: mse_loss일 경우 loss function의 곡면이 예쁘지 않음. (전문용어로 convex가 아니라고 말함) - 좋은 옵티마지어를 이용하면 mse_loss일 경우에도 수렴속도를 올릴 수 있음 (학습과정 시각화예시2). 그렇지만 이는 근본적인 해결책은 아님. (학습과정 시각화예시3)\n- 요약: 왜 logistic regression에서 mse loss를 쓰면 안되는가? - mse loss를 사용하면 손실함수가 convex하지 않으니까! - 그리고 bce loss를 사용하면 손실함수가 convex하니까!"
  },
  {
    "objectID": "posts/3_STBDA2022/2023-01-01.html",
    "href": "posts/3_STBDA2022/2023-01-01.html",
    "title": "Jupyter",
    "section": "",
    "text": "ref: STBDA 10주차 (2번째 동영상)\n- 파이썬 / 주피터 설치\nconda create -n test python=3.9\n\nconda env list\n\nconda activate test\n\n# conda라는 앱스토어에서 jupyterlab을 깐다. (conda-forge라는 커뮤니티에서 검증이 된 (추천목록) 패키지들을 깔겠다..)\n# 여러 솔루션 중 하나\nconda install -c conda-forge jupyterlab \n\njupyter lab\n\n주피터 설치 완료\n\n- 주피터에서 슬라이드 쇼\n\n## test 환경 활성화\nconda activte test\n\n## jupyter notebook slide show\nconda install -c conda-forge rise\njupyter notebook"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_16_(11주차)_5월16일.html",
    "href": "posts/3_STBDA2022/2022_05_16_(11주차)_5월16일.html",
    "title": "[STBDA] 11wk. MaxPool2D, Conv2D",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wlEuWT75L4hqGNEwoPpjWw\n\n\n\nimports\n\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n\nX = tf.constant(x_train.reshape(-1,28,28,1),dtype=tf.float64)\ny = tf.keras.utils.to_categorical(y_train)\nXX = tf.constant(x_test.reshape(-1,28,28,1),dtype=tf.float64)\nyy = tf.keras.utils.to_categorical(y_test)\n\n- 첫시도\n\nnet1 = tf.keras.Sequential()\nnet1.add(tf.keras.layers.Flatten())\nnet1.add(tf.keras.layers.Dense(500,activation='relu'))\nnet1.add(tf.keras.layers.Dense(500,activation='relu'))\nnet1.add(tf.keras.layers.Dense(500,activation='relu'))\nnet1.add(tf.keras.layers.Dense(500,activation='relu'))\nnet1.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet1.compile(optimizer='adam', loss=tf.losses.categorical_crossentropy,metrics='accuracy')\nnet1.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 1.2243 - accuracy: 0.7894\nEpoch 2/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4534 - accuracy: 0.8388\nEpoch 3/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.4161 - accuracy: 0.8502\nEpoch 4/5\n1875/1875 [==============================] - 2s 907us/step - loss: 0.4019 - accuracy: 0.8569\nEpoch 5/5\n1875/1875 [==============================] - 2s 973us/step - loss: 0.3873 - accuracy: 0.8622\n\n\n<keras.callbacks.History at 0x7f38111302b0>\n\n\n\nnet1.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 835us/step - loss: 0.4163 - accuracy: 0.8504\n\n\n[0.41634100675582886, 0.8503999710083008]\n\n\n\nnet1.summary()\n\nModel: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten_6 (Flatten)         (None, 784)               0         \n                                                                 \n dense_22 (Dense)            (None, 500)               392500    \n                                                                 \n dense_23 (Dense)            (None, 500)               250500    \n                                                                 \n dense_24 (Dense)            (None, 500)               250500    \n                                                                 \n dense_25 (Dense)            (None, 500)               250500    \n                                                                 \n dense_26 (Dense)            (None, 10)                5010      \n                                                                 \n=================================================================\nTotal params: 1,149,010\nTrainable params: 1,149,010\nNon-trainable params: 0\n_________________________________________________________________\n\n\n- 두번째 시도\n\nnet2 = tf.keras.Sequential()\nnet2.add(tf.keras.layers.Conv2D(30,(2,2),activation='relu'))\nnet2.add(tf.keras.layers.MaxPool2D())\nnet2.add(tf.keras.layers.Conv2D(30,(2,2),activation='relu'))\nnet2.add(tf.keras.layers.MaxPool2D())\nnet2.add(tf.keras.layers.Flatten())\n#net2.add(tf.keras.layers.Dense(500,activation='relu'))\nnet2.add(tf.keras.layers.Dense(10,activation='softmax'))\nnet2.compile(optimizer='adam', loss=tf.losses.categorical_crossentropy,metrics='accuracy')\nnet2.fit(X,y,epochs=5)\n\nEpoch 1/5\n1875/1875 [==============================] - 2s 1ms/step - loss: 0.8787 - accuracy: 0.8044\nEpoch 2/5\n1875/1875 [==============================] - 2s 994us/step - loss: 0.3843 - accuracy: 0.8618\nEpoch 3/5\n1875/1875 [==============================] - 2s 994us/step - loss: 0.3454 - accuracy: 0.8755\nEpoch 4/5\n1875/1875 [==============================] - 2s 989us/step - loss: 0.3217 - accuracy: 0.8838\nEpoch 5/5\n1875/1875 [==============================] - 2s 901us/step - loss: 0.3053 - accuracy: 0.8878\n\n\n<keras.callbacks.History at 0x7f3234110fd0>\n\n\n\nnet2.evaluate(XX,yy)\n\n313/313 [==============================] - 0s 837us/step - loss: 0.3438 - accuracy: 0.8736\n\n\n[0.3437994122505188, 0.8736000061035156]\n\n\n\nnet2.summary()\n\nModel: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_2 (Conv2D)           (None, 27, 27, 30)        150       \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 13, 13, 30)       0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 12, 12, 30)        3630      \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 6, 6, 30)         0         \n 2D)                                                             \n                                                                 \n flatten_8 (Flatten)         (None, 1080)              0         \n                                                                 \n dense_28 (Dense)            (None, 10)                10810     \n                                                                 \n=================================================================\nTotal params: 14,590\nTrainable params: 14,590\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n14590/ 1149010\n\n0.012697887746842934\n\n\n\nc1, m1, c2, m2, flttn, dns = net2.layers\n\n\nprint(X.shape) # 입력이미지 = 2D\nprint(c1(X).shape) #2D\nprint(m1(c1(X)).shape)  #2D\nprint(c2(m1(c1(X))).shape) #2D\nprint(m2(c2(m1(c1(X)))).shape) #2D\nprint(flttn(m2(c2(m1(c1(X))))).shape)# 1D\nprint(dns(flttn(m2(c2(m1(c1(X)))))).shape)# 1D\n\n(60000, 28, 28, 1)\n(60000, 27, 27, 30)\n(60000, 13, 13, 30)\n(60000, 12, 12, 30)\n(60000, 6, 6, 30)\n(60000, 1080)\n(60000, 10)\n\n\n\n\nMaxPool2D\n\n테스트1\n- 레이어생성\n\nm=tf.keras.layers.MaxPool2D()\n\n- 입력데이터\n\nXXX = tnp.arange(1*4*4*1).reshape(1,4,4,1)\nXXX.reshape(1,4,4)\n\n<tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]]])>\n\n\n- 입력데이터가 레이어를 통과한 모습\n\nm(XXX).reshape(1,2,2)\n\n<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\narray([[[ 5,  7],\n        [13, 15]]])>\n\n\n- MaxPool2D layer의 역할: (2,2)윈도우를 만들고 (2,2)윈도우에서 max를 뽑아 값을 기록, 윈도우를 움직이면서 반복\n\n\n테스트2\n\nXXX = tnp.arange(1*6*6*1).reshape(1,6,6,1)\nXXX.reshape(1,6,6)\n\n<tf.Tensor: shape=(1, 6, 6), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11],\n        [12, 13, 14, 15, 16, 17],\n        [18, 19, 20, 21, 22, 23],\n        [24, 25, 26, 27, 28, 29],\n        [30, 31, 32, 33, 34, 35]]])>\n\n\n\nm(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=int64, numpy=\narray([[[ 7,  9, 11],\n        [19, 21, 23],\n        [31, 33, 35]]])>\n\n\n\n\n테스트3\n\nm=tf.keras.layers.MaxPool2D(pool_size=(3, 3))\n\n\nXXX = tnp.arange(1*6*6*1).reshape(1,6,6,1)\nXXX.reshape(1,6,6)\n\n<tf.Tensor: shape=(1, 6, 6), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11],\n        [12, 13, 14, 15, 16, 17],\n        [18, 19, 20, 21, 22, 23],\n        [24, 25, 26, 27, 28, 29],\n        [30, 31, 32, 33, 34, 35]]])>\n\n\n\nm(XXX).reshape(1,2,2)\n\n<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\narray([[[14, 17],\n        [32, 35]]])>\n\n\n\n\n테스트4\n\nm=tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n\n\nXXX = tnp.arange(1*5*5*1).reshape(1,5,5,1)\nXXX.reshape(1,5,5)\n\n<tf.Tensor: shape=(1, 5, 5), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24]]])>\n\n\n\nm(XXX).reshape(1,2,2)\n\n<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\narray([[[ 6,  8],\n        [16, 18]]])>\n\n\n\nm=tf.keras.layers.MaxPool2D(pool_size=(2, 2),padding=\"same\")\n\n\nXXX = tnp.arange(1*5*5*1).reshape(1,5,5,1)\nXXX.reshape(1,5,5)\n\n<tf.Tensor: shape=(1, 5, 5), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24]]])>\n\n\n\nm(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=int64, numpy=\narray([[[ 6,  8,  9],\n        [16, 18, 19],\n        [21, 23, 24]]])>\n\n\n\n\n테스트5\n\nXXX = tnp.arange(2*4*4*1).reshape(2,4,4,1)\nXXX.reshape(2,4,4)\n\n<tf.Tensor: shape=(2, 4, 4), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]],\n\n       [[16, 17, 18, 19],\n        [20, 21, 22, 23],\n        [24, 25, 26, 27],\n        [28, 29, 30, 31]]])>\n\n\n\nm(XXX).reshape(2,2,2)\n\n<tf.Tensor: shape=(2, 2, 2), dtype=int64, numpy=\narray([[[ 5,  7],\n        [13, 15]],\n\n       [[21, 23],\n        [29, 31]]])>\n\n\n\n\n테스트6\n\nXXX = tnp.arange(1*4*4*3).reshape(1,4,4,3)\n\n\nXXX[...,0]\n\n<tf.Tensor: shape=(1, 4, 4), dtype=int64, numpy=\narray([[[ 0,  3,  6,  9],\n        [12, 15, 18, 21],\n        [24, 27, 30, 33],\n        [36, 39, 42, 45]]])>\n\n\n\nm(XXX)[...,0]\n\n<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\narray([[[15, 21],\n        [39, 45]]])>\n\n\n\n\n\nConv2D\n\n테스트1\n- 레이어생성\n\ncnv = tf.keras.layers.Conv2D(1,(2,2))\n\n- XXX생성\n\nXXX = tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\nXXX.reshape(1,4,4)\n\n<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\narray([[[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]]])>\n\n\n\ncnv(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[ 4.0450797,  5.7349434,  7.4248075],\n        [10.804535 , 12.494399 , 14.184262 ],\n        [17.56399  , 19.253855 , 20.943718 ]]], dtype=float32)>\n\n\n\nXXX에서 cnv(XXX)로 가는 맵핑을 찾는건 쉽지 않아보인다.\n심지어 랜덤으로 결정되는 부분도 있어보임\n\n- 코드정리 + 시드통일\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(1,(2,2))\nXXX = tnp.arange(1*4*4*1,dtype=tf.float64).reshape(1,4,4,1)\n\n- conv의 입출력\n\nprint(XXX.reshape(1,4,4))\nprint(cnv(XXX).reshape(1,3,3))\n\ntf.Tensor(\n[[[ 0.  1.  2.  3.]\n  [ 4.  5.  6.  7.]\n  [ 8.  9. 10. 11.]\n  [12. 13. 14. 15.]]], shape=(1, 4, 4), dtype=float64)\ntf.Tensor(\n[[[ -4.125754   -5.312817   -6.4998803]\n  [ -8.874006  -10.0610695 -11.248133 ]\n  [-13.622259  -14.809322  -15.996386 ]]], shape=(1, 3, 3), dtype=float32)\n\n\n- conv연산 추론\n\ntf.reshape(cnv.weights[0],(2,2))\n\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-0.13014299, -0.23927206],\n       [-0.20175874, -0.6158894 ]], dtype=float32)>\n\n\n\n0 * -0.13014299 + 1 * -0.23927206 + 4 * -0.20175874 + 5 * -0.6158894 + 0\n\n-4.1257540200000005\n\n\n- 내가 정의한 weights를 대입하여 conv 연산 확인\n\ncnv.get_weights()[0].shape\n\n(2, 2, 1, 1)\n\n\n\nw = np.array([1/4,1/4,1/4,1/4],dtype=np.float32).reshape(2, 2, 1, 1)\nb = np.array([3],dtype=np.float32)\n\n\ncnv.set_weights([w,b])\n\n\nXXX.reshape(1,4,4)\n\n<tf.Tensor: shape=(1, 4, 4), dtype=float64, numpy=\narray([[[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]]])>\n\n\n\ncnv(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[ 5.5,  6.5,  7.5],\n        [ 9.5, 10.5, 11.5],\n        [13.5, 14.5, 15.5]]], dtype=float32)>\n\n\n\nnp.mean([0,1,4,5])+3, np.mean([1,2,5,6])+3, np.mean([2,3,6,7])+3\n\n(5.5, 6.5, 7.5)\n\n\n\n\ntf.keras.layers.Conv2D(1,kernel_size=(2,2)) 요약\n- 요약\n\nsize=(2,2)인 윈도우를 만듬.\nXXX에 윈도우를 통과시켜서 (2,2)크기의 sub XXX 를 얻음. sub XXX의 각 원소에 conv2d.weights[0]의 각 원소를 element-wise하게 곱한다.\n(2)의 결과를 모두 더한다. 그리고 그 결과에 다시 conv2d.weights[1]을 수행\n윈도우를 이동시키면서 반복!\n\n\n\n테스트2\n- 레이어와 XXX생성\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(1,(3,3))\nXXX = tnp.arange(1*5*5*1,dtype=tf.float64).reshape(1,5,5,1)\n\n\nXXX.reshape(1,5,5) ## 입력: XXX\n\n<tf.Tensor: shape=(1, 5, 5), dtype=float64, numpy=\narray([[[ 0.,  1.,  2.,  3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.],\n        [10., 11., 12., 13., 14.],\n        [15., 16., 17., 18., 19.],\n        [20., 21., 22., 23., 24.]]])>\n\n\n\ntf.reshape(cnv.weights[0],(3,3)) ## 커널의 가중치\n\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[-0.08676198, -0.1595147 , -0.13450584],\n       [-0.4105929 , -0.38366908,  0.07744962],\n       [-0.09255642,  0.4915564 ,  0.20828158]], dtype=float32)>\n\n\n\ncnv(XXX).reshape(1,3,3) ## 출력: conv(XXX)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[ 2.7395768 ,  2.2492635 ,  1.7589504 ],\n        [ 0.28801066, -0.20230258, -0.6926158 ],\n        [-2.1635566 , -2.6538715 , -3.1441827 ]]], dtype=float32)>\n\n\n\ntf.reduce_sum(XXX.reshape(1,5,5)[0,:3,:3] * tf.reshape(cnv.weights[0],(3,3)))\n\n<tf.Tensor: shape=(), dtype=float64, numpy=2.739577144384384>\n\n\n\n\n테스트3\n\n\nXXX = tf.constant([[3,3,2,1,0],[0,0,1,3,1],[3,1,2,2,3],[2,0,0,2,2],[2,0,0,0,1]],dtype=tf.float64).reshape(1,5,5,1)\nXXX.reshape(1,5,5)\n\n<tf.Tensor: shape=(1, 5, 5), dtype=float64, numpy=\narray([[[3., 3., 2., 1., 0.],\n        [0., 0., 1., 3., 1.],\n        [3., 1., 2., 2., 3.],\n        [2., 0., 0., 2., 2.],\n        [2., 0., 0., 0., 1.]]])>\n\n\n\ncnv = tf.keras.layers.Conv2D(1,(3,3))\n\n\ncnv.weights\n\n[]\n\n\n\ncnv(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[1.7157198, 2.9689512, 2.7728844],\n        [2.4162836, 1.8230928, 2.9890852],\n        [1.9408667, 1.2231059, 2.2712555]]], dtype=float32)>\n\n\n\ncnv.weights[0]\n\n<tf.Variable 'conv2d_13/kernel:0' shape=(3, 3, 1, 1) dtype=float32, numpy=\narray([[[[ 0.28270614]],\n\n        [[-0.13318631]],\n\n        [[ 0.21818542]]],\n\n\n       [[[ 0.23769057]],\n\n        [[ 0.40044254]],\n\n        [[ 0.38520074]]],\n\n\n       [[[ 0.15709132]],\n\n        [[ 0.48156905]],\n\n        [[-0.25362712]]]], dtype=float32)>\n\n\n\n_w = tf.constant([[0,1,2],[2,2,0],[0,1,2]],dtype=tf.float64).reshape(3,3,1,1)\n_b = tf.constant([0],dtype=tf.float64)\n\n\ncnv.set_weights([_w,_b])\n\n\ncnv(XXX).reshape(1,3,3)\n\n<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\narray([[[12., 12., 17.],\n        [10., 17., 19.],\n        [ 9.,  6., 14.]]], dtype=float32)>\n\n\n\n\n테스트4\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(1,(2,2))\nXXX = tnp.arange(2*5*5*1,dtype=tf.float64).reshape(2,5,5,1)\n\n\nprint(XXX.reshape(2,5,5))\ncnv(XXX) # weights를 초기화 시키기 위해서 레이어를 1회 통과\ncnv.set_weights([w,b])\nprint(cnv(XXX).reshape(2,4,4))\n\ntf.Tensor(\n[[[ 0.  1.  2.  3.  4.]\n  [ 5.  6.  7.  8.  9.]\n  [10. 11. 12. 13. 14.]\n  [15. 16. 17. 18. 19.]\n  [20. 21. 22. 23. 24.]]\n\n [[25. 26. 27. 28. 29.]\n  [30. 31. 32. 33. 34.]\n  [35. 36. 37. 38. 39.]\n  [40. 41. 42. 43. 44.]\n  [45. 46. 47. 48. 49.]]], shape=(2, 5, 5), dtype=float64)\ntf.Tensor(\n[[[ 6.  7.  8.  9.]\n  [11. 12. 13. 14.]\n  [16. 17. 18. 19.]\n  [21. 22. 23. 24.]]\n\n [[31. 32. 33. 34.]\n  [36. 37. 38. 39.]\n  [41. 42. 43. 44.]\n  [46. 47. 48. 49.]]], shape=(2, 4, 4), dtype=float32)\n\n\n\nnp.mean([0,1,5,6])+3,np.mean([25,26,30,31])+3,\n\n(6.0, 31.0)\n\n\n\n\n테스트5\n-\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(4,(2,2),activation='relu')\nXXX = tnp.arange(1*2*2*1,dtype=tf.float64).reshape(1,2,2,1)\n\n\nprint(XXX.reshape(1,2,2))\n\ntf.Tensor(\n[[[0. 1.]\n  [2. 3.]]], shape=(1, 2, 2), dtype=float64)\n\n\n\ncnv(XXX)\n\n<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=array([[[[1.048703, 0.      , 0.      , 0.      ]]]], dtype=float32)>\n\n\n\ncnv.weights[0] # (2,2) 커널의 크기 // 1은 XXX의 채널수 // 4는 conv(XXX)의 채널수\n\n<tf.Variable 'conv2d_27/kernel:0' shape=(2, 2, 1, 4) dtype=float32, numpy=\narray([[[[-0.08230966, -0.15132892, -0.12760344, -0.38952267]],\n\n        [[-0.36398047,  0.07347518, -0.08780673,  0.46633136]]],\n\n\n       [[[ 0.19759327, -0.46042526, -0.15406173, -0.34838456]],\n\n        [[ 0.33916563, -0.08248386,  0.11705655, -0.49948823]]]],\n      dtype=float32)>\n\n\n\ncnv.weights[0][...,0].reshape(2,2) ## conv(XXX)의 첫번째채널 출력을 얻기 위해 곱해지는 w\n\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-0.08230966, -0.36398047],\n       [ 0.19759327,  0.33916563]], dtype=float32)>\n\n\n\ntf.reduce_sum(XXX.reshape(1,2,2) * cnv.weights[0][...,0].reshape(2,2)) ### conv(XXX)의 첫번째 채널 출력결과\n\n<tf.Tensor: shape=(), dtype=float64, numpy=1.0487029552459717>\n\n\n- 계산결과를 확인하기 쉽게 하기 위한 약간의 트릭\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(4,(2,2))\nXXX = tnp.array([1]*1*2*2*1,dtype=tf.float64).reshape(1,2,2,1)\n\n\nprint(XXX.reshape(1,2,2))\n\ntf.Tensor(\n[[[1. 1.]\n  [1. 1.]]], shape=(1, 2, 2), dtype=float64)\n\n\n\n이렇게 XXX를 설정하면 cnv(XXX)의 결과는 단지 cnv의 weight들의 sum이 된다.\n\n\ncnv(XXX)\n\n<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=\narray([[[[ 0.09046876, -0.6207629 , -0.25241536, -0.7710641 ]]]],\n      dtype=float32)>\n\n\n\ncnv.weights[0] # (2,2) 커널의 크기 // 1은 XXX의 채널수 // 4는 conv(XXX)의 채널수\n\n<tf.Variable 'conv2d_24/kernel:0' shape=(2, 2, 1, 4) dtype=float32, numpy=\narray([[[[-0.08230966, -0.15132892, -0.12760344, -0.38952267]],\n\n        [[-0.36398047,  0.07347518, -0.08780673,  0.46633136]]],\n\n\n       [[[ 0.19759327, -0.46042526, -0.15406173, -0.34838456]],\n\n        [[ 0.33916563, -0.08248386,  0.11705655, -0.49948823]]]],\n      dtype=float32)>\n\n\n\ncnv.weights[0][...,0].reshape(2,2) ## conv(XXX)의 첫번째채널 출력을 얻기 위해 곱해지는 w\n\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-0.08230966, -0.36398047],\n       [ 0.19759327,  0.33916563]], dtype=float32)>\n\n\n\ntf.reduce_sum(cnv.weights[0][...,0])\n#tf.reduce_sum(XXX.reshape(1,2,2) * cnv.weights[0][...,0].reshape(2,2)) ### conv(XXX)의 첫번째 채널 출력결과\n\n<tf.Tensor: shape=(), dtype=float32, numpy=0.090468764>\n\n\n\n\n테스트6\n- 결과확인을 쉽게하기 위해서 XXX를 1로 통일\n\ntf.random.set_seed(43052)\ncnv = tf.keras.layers.Conv2D(4,(2,2))\nXXX = tnp.array([1]*1*2*2*3,dtype=tf.float64).reshape(1,2,2,3)\n\n\ncnv(XXX)\n\n<tf.Tensor: shape=(1, 1, 1, 4), dtype=float32, numpy=\narray([[[[ 0.3297621, -0.4498347, -1.0487393, -1.580095 ]]]],\n      dtype=float32)>\n\n\n\ncnv.weights[0] ## (2,2)는 커널의 사이즈 // 3은 XXX의채널 // 4는 cnv(XXX)의 채널\n\n<tf.Variable 'conv2d_33/kernel:0' shape=(2, 2, 3, 4) dtype=float32, numpy=\narray([[[[-0.06956434, -0.12789628, -0.10784459, -0.32920673],\n         [-0.30761963,  0.06209785, -0.07421023,  0.3941219 ],\n         [ 0.16699678, -0.38913035, -0.13020593, -0.29443866]],\n\n        [[ 0.28664726, -0.0697116 ,  0.09893084, -0.4221446 ],\n         [-0.23161241, -0.16410837, -0.36420006,  0.12424195],\n         [-0.14245945,  0.36286396, -0.10751781,  0.1733647 ]]],\n\n\n       [[[ 0.02764335,  0.15547717, -0.42024496, -0.31893867],\n         [ 0.22414821,  0.3619454 , -0.00282967, -0.3503708 ],\n         [ 0.4610079 , -0.17417148,  0.00401336, -0.29777044]],\n\n        [[-0.1620284 , -0.42066965, -0.01578814, -0.4240524 ],\n         [ 0.37925082,  0.24236053,  0.3949356 , -0.20996472],\n         [-0.30264795, -0.28889188, -0.3237777 ,  0.37506342]]]],\n      dtype=float32)>\n\n\n\ncnv.weights[0][...,0] ## cnv(XXX)의 첫번째 채널결과를 얻기 위해서 사용하는 w\n\n<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\narray([[[-0.06956434, -0.30761963,  0.16699678],\n        [ 0.28664726, -0.23161241, -0.14245945]],\n\n       [[ 0.02764335,  0.22414821,  0.4610079 ],\n        [-0.1620284 ,  0.37925082, -0.30264795]]], dtype=float32)>\n\n\n\ntf.reduce_sum(cnv.weights[0][...,0]) ### cnv(XXX)의 첫번째 채널의 결과\n\n<tf.Tensor: shape=(), dtype=float32, numpy=0.32976213>\n\n\n\nprint(tf.reduce_sum(cnv.weights[0][...,0]))\nprint(tf.reduce_sum(cnv.weights[0][...,1]))\nprint(tf.reduce_sum(cnv.weights[0][...,2]))\nprint(tf.reduce_sum(cnv.weights[0][...,3])) ### cnv(XXX)의 결과\n\ntf.Tensor(0.32976213, shape=(), dtype=float32)\ntf.Tensor(-0.44983464, shape=(), dtype=float32)\ntf.Tensor(-1.0487392, shape=(), dtype=float32)\ntf.Tensor(-1.5800952, shape=(), dtype=float32)\n\n\n\nw_red = cnv.weights[0][...,0][...,0]\nw_green = cnv.weights[0][...,0][...,1]\nw_blue = cnv.weights[0][...,0][...,2]\n\n\ntf.reduce_sum(XXX[...,0] * w_red + XXX[...,1] * w_green + XXX[...,2] * w_blue) ## cnv(XXX)의 첫채널 출력결과\n\n<tf.Tensor: shape=(), dtype=float64, numpy=0.32976213097572327>\n\n\n\n\n\nhw\n아래와 같은 흑백이미지가 있다고 하자.\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n위의 이미지에 아래와 같은 weight를 가진 필터를 적용하여 convolution한 결과를 계산하라. (bias는 0으로 가정한다)\n-1 1\n-1 1"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_11_(6주차)_4월11일.html",
    "href": "posts/3_STBDA2022/2022_04_11_(6주차)_4월11일.html",
    "title": "[STBDA] 6wk. 회귀모형 적합 with keras",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zueMdNhXiDTIMD-Dz5sbBD\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\n\\(x \\to \\hat{y}\\) 가 되는 과정을 그림으로 그리기\n- 단순회귀분석의 예시 - \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i, \\quad i=1,2,\\dots,n\\)\n(표현1)\n\n#collapse\ngv(''' \n    \"1\" -> \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xₙ\" -> \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xₙ*β̂₁,    bias=False\" -> \"ŷₙ\"[label=\"identity\"]\n\n    \".\" -> \"....................................\"[label=\"* β̂₀\"]\n    \"..\" -> \"....................................\"[label=\"* β̂₁\"]\n    \"....................................\" -> \"...\"[label=\" \"]\n\n    \"1 \" -> \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₂\" -> \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₂*β̂₁,    bias=False\" -> \"ŷ₂\"[label=\"identity\"]\n    \n    \"1  \" -> \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₁\" -> \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₁*β̂₁,    bias=False\" -> \"ŷ₁\"[label=\"identity\"]\n''')\n\n\n\n\n- 표현1의 소감? - 교수님이 고생해서 만든것 같음 - 그런데 그냥 다 똑같은 그림의 반복이라 사실 고생한 의미가 없음.\n(표현2)\n- 그냥 아래와 같이 그리고 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다”고 하면 될것 같다.\n\n#collapse\ngv(''' \n    \"1\" -> \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xᵢ\" -> \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xᵢ*β̂₁,    bias=False\" -> \"ŷᵢ\"[label=\"identity\"]\n\n''')\n\n\n\n\n(표현3)\n- 그런데 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다” 라는 언급자체도 반복할 필요가 없을 것 같다. (어차피 당연히 그럴테니까) 그래서 단순히 아래와 같이 그려도 무방할듯 하다.\n\ngv(''' \n    \"1\" -> \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x\" -> \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x*β̂₁,    bias=False\" -> \"ŷ\"[label=\"identity\"]\n\n''')\n\n\n\n\n(표현4)\n- 위의 모델은 아래와 같이 쓸 수 있다. (\\(\\beta_0\\)를 바이어스로 표현)\n\n#collapse\ngv('''\n\"x\" -> \"x*β̂₁,    bias=True\"[label=\"*β̂₁\"] ;\n\"x*β̂₁,    bias=True\" -> \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n실제로는 이 표현을 많이 사용함\n\n(표현5)\n- 벡터버전으로 표현하면 아래와 같다. 이 경우에는 \\({\\bf X}=[1,x]\\)에 포함된 1이 bias의 역할을 해주므로 bias = False 임.\n\n#collapse\ngv('''\n\"X\" -> \"X@β̂,    bias=False\"[label=\"@β̂\"] ;\n\"X@β̂,    bias=False\" -> \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n저는 이걸 좋아해요\n\n(표현5)’\n- 딥러닝에서는 \\(\\hat{\\boldsymbol{\\beta}}\\) 대신에 \\(\\hat{{\\bf W}}\\)을 라고 표현한다.\n\n#collapse\ngv('''\n\"X\" -> \"X@Ŵ,    bias=False\"[label=\"@Ŵ\"] ;\n\"X@Ŵ,    bias=False\" -> \"ŷ\"[label=\"identity\"] ''')\n\n\n\n\n- 실제로는 표현4 혹은 표현5를 외우면 된다.\n\n\nLayer의 개념\n- (표현4) 혹은 (표현5)의 그림은 레이어로 설명할 수 있다.\n- 레이어는 항상 아래와 같은 규칙을 가진다. - 첫 동그라미는 레이어의 입력이다. - 첫번째 화살표는 선형변환을 의미한다. - 두번째 동그라미는 선형변환의 결과이다. (이때 bias가 false인지 true인지에 따라서 실제 수식이 조금 다름) - 두번째 화살표는 두번째 동그라미에 어떠한 함수 \\(f\\)를 취하는 과정을 의미한다. (우리의 그림에서는 \\(f(x)=x\\)) - 세번째 동그라미는 레이어의 최종출력이다.\n- 엄청 복잡한데, 결국 레이어를 만들때 위의 그림들을 의미하도록 하려면 아래의 4개의 요소만 필요하다. 1. 레이어의 입력차원 2. 선형변환의 결과로 얻어지는 차원 3. 선형변환에서 바이어스를 쓸지? 안쓸지? 4. 함수 \\(f\\)\n- 주목: 1,2가 결정되면 자동으로 \\(\\hat{{\\bf W}}\\)의 차원이 결정된다.\n(예시) - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=1: \\(\\hat{\\bf W}\\)는 (2,1) 매트릭스 - 레이어의 입력차원=20, 선형변환의 결과로 얻어지는 차원=5: \\(\\hat{\\bf W}\\)는 (20,5) 매트릭스 - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=50: \\(\\hat{\\bf W}\\)는 (2,50) 매트릭스\n- 주목2: 이중에서 절대 생략불가능 것은 “2. 선형변환의 결과로 얻어지는 차원” 이다. - 레이어의 입력차원: 실제 레이어에 데이터가 들어올 때 데이터의 입력차원을 컴퓨터 스스로 체크하여 \\(\\hat{\\bf W}\\)의 차원을 결정할 수 있음. - 바이어스를 쓸지? 안쓸지? 기본적으로 쓴다고 가정한다. - 함수 \\(f\\): 기본적으로 항등함수를 가정하면 된다.\n\n\nKeras를 이용한 풀이\n- 기본뼈대: net생성 \\(\\to\\) add(layer) \\(\\to\\) compile(opt,loss) \\(\\to\\) fit(data,epochs)\n- 데이터정리\n\\[{\\bf y}\\approx 2.5 +4*x\\]\n\ntnp.random.seed(43052)\nN= 200 \nx= tnp.linspace(0,1,N)\nepsilon= tnp.random.randn(N)*0.5 \ny= 2.5+4*x +epsilon\n\n\nX=tf.stack([tf.ones(N,dtype='float64'),x],axis=1)\n\n\n풀이1: 스칼라버전\n(0단계) 데이터정리\n\ny=y.reshape(N,1)\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1)  \n# 입력차원? 데이터를 넣어보고 결정, 바이어스=디폴드값을 쓰겠음 (use_bias=true), 함수도 디폴트값을 쓰겠음 (f(x)=x)\nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE) \n\n\n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용 \n\n<keras.callbacks.History at 0x7fb265125b20>\n\n\n\nbatch_size=N : 경사하강법\nbatch_size!=N : 확률적 경사하강법\n\n(결과확인)\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.9330256]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([2.583672], dtype=float32)>]\n\n\n\n스칼라버전 끝!\n\n\n\n풀이2: 벡터버전\n(0단계) 데이터정리\n\nX.shape,y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False) ## 주의!  use_bias=False\nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE) \n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용 \n\n<keras.callbacks.History at 0x7fb2650ead00>\n\n\n(결과확인)\n\nnet.weights\n\n[<tf.Variable 'dense_1/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n\n\n\n\n\n잠시문법정리\n\n\n\n- 잠깐 Dense layer를 만드는 코드를 정리해보자.\n\n아래는 모두 같은 코드이다.\n\n\ntf.keras.layers.Dense(1)\ntf.keras.layers.Dense(units=1)\ntf.keras.layers.Dense(units=1,activation=‘linear’) // identity 가 더 맞는것 같은데..\ntf.keras.layers.Dense(units=1,activation=‘linear’,use_bias=True)\n\n\n아래의 코드1,2는 (1)의 코드들과 살짝 다른코드이다. (코드1과 코드2는 같은코드임)\n\n\ntf.keras.layers.Dense(1,input_dim=2) # 코드1\ntf.keras.layers.Dense(1,input_shape=(2,)) # 코드2\n\n\n아래는 사용불가능한 코드이다.\n\n\ntf.keras.layers.Dense(1,input_dim=(2,)) # 코드1\ntf.keras.layers.Dense(1,input_shape=2) # 코드2\n\n\n\n- 왜 input_dim이 필요한가?\n\nnet1 = tf.keras.Sequential()\nnet1.add(tf.keras.layers.Dense(1,use_bias=False)) \n\n\nnet2 = tf.keras.Sequential()\nnet2.add(tf.keras.layers.Dense(1,use_bias=False,input_dim=2))\n\n\nnet1.weights\n\nValueError: Weights for model 'sequential_3' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`.\n\n\n\nnet2.weights\n\n[<tf.Variable 'dense_4/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-1.4113412],\n        [-1.3562037]], dtype=float32)>]\n\n\n\nnet1.summary()\n\nValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n\n\n\nnet2.summary()\n\nModel: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_4 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\n풀이3: 스칼라버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\ny=y.reshape(N,1)\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,input_dim=1)\n\n\nnet.add(layer)\n\n\nnet.get_weights()\n\n[array([[-0.80770403]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nweight, bias 순으로 출력\n\n\n초기값을 설정\n\nnet.weights\n\n[<tf.Variable 'dense_8/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.80770403]], dtype=float32)>,\n <tf.Variable 'dense_8/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n\nnet.get_weights()\n\n[array([[-0.80770403]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nweight, bias순으로 출력\n\n\nnet.set_weights?\n\n\nSignature: net.set_weights(weights)\nDocstring:\nSets the weights of the layer, from NumPy arrays.\nThe weights of a layer represent the state of the layer. This function\nsets the weight values from numpy arrays. The weight values should be\npassed in the order they are created by the layer. Note that the layer's\nweights must be instantiated before calling this function, by calling\nthe layer.\nFor example, a `Dense` layer returns a list of two values: the kernel\nmatrix and the bias vector. These can be used to set the weights of\nanother `Dense` layer:\n>>> layer_a = tf.keras.layers.Dense(1,\n...   kernel_initializer=tf.constant_initializer(1.))\n>>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n>>> layer_a.get_weights()\n[array([[1.],\n       [1.],\n       [1.]], dtype=float32), array([0.], dtype=float32)]\n>>> layer_b = tf.keras.layers.Dense(1,\n...   kernel_initializer=tf.constant_initializer(2.))\n>>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n>>> layer_b.get_weights()\n[array([[2.],\n       [2.],\n       [2.]], dtype=float32), array([0.], dtype=float32)]\n>>> layer_b.set_weights(layer_a.get_weights())\n>>> layer_b.get_weights()\n[array([[1.],\n       [1.],\n       [1.]], dtype=float32), array([0.], dtype=float32)]\nArgs:\n  weights: a list of NumPy arrays. The number\n    of arrays and their shape must match\n    number of the dimensions of the weights\n    of the layer (i.e. it should match the\n    output of `get_weights`).\nRaises:\n  ValueError: If the provided weights list does not match the\n    layer's specifications.\nFile:      ~/anaconda3/envs/torch/lib/python3.8/site-packages/keras/engine/base_layer.py\nType:      method\n\n\n\n\nlayer_b.set_weights(layer_a.get_weights()) 와 같은방식으로 쓴다는 것이군?\n\n- 한번따라해보자.\n\n_w = net.get_weights()\n_w\n\n[array([[-0.80770403]], dtype=float32), array([0.], dtype=float32)]\n\n\n\n길이가 2인 리스트이고, 각 원소는 numpy array 임\n\n\nnet.set_weights(\n    [np.array([[10.0]],dtype=np.float32), # weight, β1_hat\n     np.array([-5.0],dtype=np.float32)] # bias, β0_hat \n)\n\n\nnet.weights\n\n[<tf.Variable 'dense_8/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[10.]], dtype=float32)>,\n <tf.Variable 'dense_8/bias:0' shape=(1,) dtype=float32, numpy=array([-5.], dtype=float32)>]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1),tf.losses.MSE) \n\n(4단계) net.fit()\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7fb26550b130>\n\n\n결과확인\n\nnet.weights\n\n[<tf.Variable 'dense_8/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.933048]], dtype=float32)>,\n <tf.Variable 'dense_8/bias:0' shape=(1,) dtype=float32, numpy=array([2.58366], dtype=float32)>]\n\n\n\n\n풀이4: 벡터버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False,input_dim=2) \n\n\nnet.add(layer)\n\n\nnet.summary()\n\nModel: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_9 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n초기값을 설정하자\n\nnet.set_weights([np.array([[-5.0],[10.0]], dtype=np.float32)])\n\n\nnet.get_weights()\n\n[array([[-5.],\n        [10.]], dtype=float32)]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.losses.MSE) # optimizer, loss 전달하여 compile \n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) # verbose=0: 귀찮은 메시지X, batch_size=N: 경사하강법\n\n<keras.callbacks.History at 0x7fb28c5bf550>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_9/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.58366 ],\n        [3.933048]], dtype=float32)>]\n\n\n\n똑같이 잘 나옴.\n\n- 사실 실전에서는 초기값을 설정할 필요가 별로 없음.\n\n\n풀이5: 벡터버전 사용자정의 손실함수\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False)  # 출력1, bias사용X\n\n\nnet.add(layer)\n\n(3단계) net.compile()\n\nloss_fn = lambda y,yhat: (y-yhat).T @ (y-yhat) / N\n\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss_fn)\n\n\n사용자가 직접 loss function을 정의해서 컴파일해도 상관없다.\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7fb26591f4c0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n잘 수렴한다…\n\n\n\n풀이6: 벡터버전, net.compile의 옵션으로 손실함수 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss='mse')  # 알아서 내장되어있는 mse 찾아서 컴파일해줌. \n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7fb265183d60>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n\n풀이7: 벡터버전, net.compile의 옵션으로 손실함수 지정 + 옵티마이저 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(optimizer='sgd', loss='mse') \n#net.optimizer.lr = tf.Variable(0.1,dtype=tf.float32)\n#net.optimizer.lr = 0.1\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=5000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7fb2645af7c0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_15/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5849245],\n        [3.9306912]], dtype=float32)>]\n\n\n\n아까보다 에폭을 좀 더 늘리면 \\(2.58, 3.93\\)으로 수렴!\n\n\n\n\n여러가지 회귀모형의 적합과 학습과정의 모니터링\n\n예제1\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 x_i\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.random.randn(N) \nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*x +epsilon\n\n\nX= np.stack([np.ones(N),x],axis=1)\ny= y.reshape(N,1)\n\n\nplt.plot(x,y,'o') # 관측한 자료 \n\n\n\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\n\n\nyhat = X@beta_hat \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-') \n\n\n\n\n더 좋은 적합선을 얻기위해서!\n\n\\(loss'(\\beta)=-2X'y +2X'X\\beta\\)\n\n\nslope = (2*X.T@X@beta_hat - 2*X.T@y)/ N \nbeta_hat2 = beta_hat - 0.1*slope  \nyhat2 = X@beta_hat2\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-') \nplt.plot(x,yhat2.reshape(-1),'-') \n\n\n\n\n초록색이 좀 더 나아보인다.\n\nbeta_hat = np.array([-3,-2]).reshape(2,1) \nbeta_hats = beta_hat # beta_hats = beta_hat.copy() 가 더 안전한 코드입니다. \nfor i in range(1,30):\n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat - 2*X.T@y) / N \n    beta_hat = beta_hat - 0.1*slope # 0.1은 적당, 0.3은 쪼금빠르지만 그래도 적당, 0.9는 너무 나간것같음, 1.0 은 수렴안함, 1.2 \n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) \n\n\n좀 안정적인 건 \\(0.1\\)\n\\(0.3, 0.9\\)는 수렴은 하는데 좀 더 안전한건 \\(0.1\\)\n\\(1\\sim\\) 는 수렴하는척하면서 터짐…\n\n\nbeta_hats\n\narray([[-3.        , -1.98776175, -1.16054651, -0.48448286,  0.06808892,\n         0.51975837,  0.88897604,  1.19081334,  1.43758253,  1.63934274,\n         1.80431301,  1.93920945,  2.04952049,  2.13973166,  2.2135091 ,\n         2.27384947,  2.32320238,  2.36357035,  2.39659058,  2.42360161,\n         2.44569792,  2.46377445,  2.47856304,  2.49066214,  2.50056123,\n         2.5086606 ,  2.51528766,  2.52071021,  2.52514732,  2.52877816],\n       [-2.        , -0.929175  , -0.05089843,  0.66940348,  1.26010705,\n         1.74449975,  2.14169103,  2.46736052,  2.73437247,  2.95328049,\n         3.13274182,  3.27985761,  3.40045219,  3.4993023 ,  3.58032529,\n         3.64673351,  3.70116104,  3.74576767,  3.78232418,  3.81228235,\n         3.83683236,  3.85694989,  3.87343472,  3.88694243,  3.89801039,\n         3.90707901,  3.91450928,  3.92059703,  3.92558472,  3.92967104]])\n\n\n\nbeta_hats[0]\n\narray([-3.        , -1.98776175, -1.16054651, -0.48448286,  0.06808892,\n        0.51975837,  0.88897604,  1.19081334,  1.43758253,  1.63934274,\n        1.80431301,  1.93920945,  2.04952049,  2.13973166,  2.2135091 ,\n        2.27384947,  2.32320238,  2.36357035,  2.39659058,  2.42360161,\n        2.44569792,  2.46377445,  2.47856304,  2.49066214,  2.50056123,\n        2.5086606 ,  2.51528766,  2.52071021,  2.52514732,  2.52877816])\n\n\n\nb0hats = beta_hats[0].tolist()\nb1hats = beta_hats[1].tolist()\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.5451404 ],\n       [3.94818596]])\n\n\n\nfrom matplotlib import animation \nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 (data, 적합된 직선)\nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*x) \n# ax2: 오른쪽그림 (loss function)\nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*x)**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02) \nax2.scatter(2.5451404,3.94818596,loss_fn(2.5451404,3.94818596),s=200,marker='*') # loss값이 제일 작은 지점. \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*x) \n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 참고\n\nβ0,β1 = np.meshgrid(np.array([0,1,2]), np.array([4,5,6]), indexing='ij')\nβ0 = β0.reshape(-1)\nβ1 = β1.reshape(-1)\n\n\nβ0, β1\n\n(array([0, 0, 0, 1, 1, 1, 2, 2, 2]), array([4, 5, 6, 4, 5, 6, 4, 5, 6]))\n\n\n\n_a=list(map(lambda x,y: x*y, β0, β1))\n\n\n_a\n\n[0, 0, 0, 4, 5, 6, 8, 10, 12]\n\n\n\n\n예제2\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) +epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nX= np.stack([np.ones(N),np.exp(-x)],axis=1)\ny= y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\nbeta_hats = beta_hat.copy() # shallow copy, deep copy <--- 여름 방학 특강 \nfor i in range(1,30): \n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat - 2*X.T@y) /N \n    beta_hat = beta_hat - 0.05*slope\n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) \n\n\nbeta_hats\n\narray([[-3.        , -1.74671631, -0.82428979, -0.14453919,  0.35720029,\n         0.72834869,  1.0036803 ,  1.20869624,  1.36209751,  1.47759851,\n         1.56525696,  1.63244908,  1.68458472,  1.72563174,  1.75850062,\n         1.78532638,  1.80767543,  1.82669717,  1.84323521,  1.85790889,\n         1.8711731 ,  1.88336212,  1.89472176,  1.90543297,  1.91562909,\n         1.92540859,  1.93484428,  1.94399023,  1.9528867 ,  1.96156382],\n       [-2.        , -0.25663415,  1.01939241,  1.95275596,  2.63488171,\n         3.13281171,  3.49570765,  3.75961951,  3.95098231,  4.08918044,\n         4.18842797,  4.2591476 ,  4.30898175,  4.34353413,  4.36691339,\n         4.38213187,  4.39139801,  4.39633075,  4.39811673,  4.3976256 ,\n         4.3954946 ,  4.3921905 ,  4.38805511,  4.3833386 ,  4.37822393,\n         4.37284482,  4.36729887,  4.36165718,  4.35597148,  4.35027923]])\n\n\n\nb0hats= beta_hats[0].tolist()\nb1hats= beta_hats[1].tolist()\n\n\nnp.linalg.inv(X.T@X)@X.T@y\n\narray([2.46307644, 3.99681332])\n\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 \nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x))\n# ax2: 오른쪽그림 \nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02) \nax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*') \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x))\n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) \ny=y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2,-1]).reshape(3,1) \nbeta_hats = beta_hat.copy()\nfor i in range(1,30):\n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat -2*X.T@y) /N \n    beta_hat = beta_hat - 0.1 * slope \n    beta_hats= np.concatenate([beta_hats,beta_hat],axis=1)\n\n\nbeta_hats\n\narray([[-3.        , -0.71767532,  0.36255782,  0.89072137,  1.16423101,\n         1.31925078,  1.41819551,  1.48974454,  1.54713983,  1.59655416,\n         1.64091846,  1.68167278,  1.71956758,  1.75503084,  1.78833646,\n         1.81968188,  1.84922398,  1.877096  ,  1.90341567,  1.92828934,\n         1.95181415,  1.97407943,  1.99516755,  2.01515463,  2.0341111 ,\n         2.05210214,  2.06918818,  2.08542523,  2.10086524,  2.11555643],\n       [-2.        ,  1.16947474,  2.64116513,  3.33411605,  3.66880042,\n         3.83768856,  3.92897389,  3.98315095,  4.01888831,  4.04486085,\n         4.06516144,  4.08177665,  4.09571971,  4.10754954,  4.1176088 ,\n         4.12613352,  4.13330391,  4.13926816,  4.14415391,  4.14807403,\n         4.15112966,  4.1534121 ,  4.15500404,  4.15598045,  4.15640936,\n         4.15635249,  4.15586584,  4.15500014,  4.15380139,  4.1523112 ],\n       [-1.        , -0.95492718, -0.66119313, -0.27681968,  0.12788212,\n         0.52254445,  0.89491388,  1.24088224,  1.55993978,  1.85310654,\n         2.12199631,  2.36839745,  2.59408948,  2.8007666 ,  2.99000967,\n         3.16327964,  3.32192026,  3.46716468,  3.60014318,  3.72189116,\n         3.83335689,  3.93540864,  4.02884144,  4.11438316,  4.19270026,\n         4.26440288,  4.33004965,  4.39015202,  4.44517824,  4.49555703]])\n\n\n\nb0hats,b1hats,b2hats = beta_hats # unpacking\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.46597526],\n       [4.00095138],\n       [5.04161877]])\n\n\n\ntrue가 잘 찾아짐.\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 \nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x) + b2hats[0]*np.cos(5*x))\n# ax2: 오른쪽그림 \n# β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\n# β0=β0.reshape(-1)\n# β1=β1.reshape(-1)\n# loss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\n# loss = list(map(loss_fn, β0,β1))\n# ax2.scatter(β0,β1,loss,alpha=0.02) \n# ax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*') \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x) + b2hats[i]*np.cos(5*x))\n    # ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3: 케라스로 해보자!\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) \ny=y.reshape(N,1)\n\n\nnet = tf.keras.Sequential() # 1: 네트워크 생성\nnet.add(tf.keras.layers.Dense(1,use_bias=False)) # 2: add layer \nnet.compile(tf.optimizers.SGD(0.1), loss='mse') # 3: compile\nnet.fit(X,y,epochs=30, batch_size=N) # 4: fit \n\nEpoch 1/30\n1/1 [==============================] - 0s 77ms/step - loss: 45.8620\nEpoch 2/30\n1/1 [==============================] - 0s 1ms/step - loss: 20.5386\nEpoch 3/30\n1/1 [==============================] - 0s 1ms/step - loss: 13.5033\nEpoch 4/30\n1/1 [==============================] - 0s 1ms/step - loss: 10.5736\nEpoch 5/30\n1/1 [==============================] - 0s 1ms/step - loss: 8.7382\nEpoch 6/30\n1/1 [==============================] - 0s 1ms/step - loss: 7.3295\nEpoch 7/30\n1/1 [==============================] - 0s 1ms/step - loss: 6.1758\nEpoch 8/30\n1/1 [==============================] - 0s 1ms/step - loss: 5.2144\nEpoch 9/30\n1/1 [==============================] - 0s 1ms/step - loss: 4.4098\nEpoch 10/30\n1/1 [==============================] - 0s 1ms/step - loss: 3.7355\nEpoch 11/30\n1/1 [==============================] - 0s 1ms/step - loss: 3.1704\nEpoch 12/30\n1/1 [==============================] - 0s 1ms/step - loss: 2.6967\nEpoch 13/30\n1/1 [==============================] - 0s 1ms/step - loss: 2.2996\nEpoch 14/30\n1/1 [==============================] - 0s 1ms/step - loss: 1.9667\nEpoch 15/30\n1/1 [==============================] - 0s 1ms/step - loss: 1.6877\nEpoch 16/30\n1/1 [==============================] - 0s 1ms/step - loss: 1.4539\nEpoch 17/30\n1/1 [==============================] - 0s 1ms/step - loss: 1.2578\nEpoch 18/30\n1/1 [==============================] - 0s 1ms/step - loss: 1.0935\nEpoch 19/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.9557\nEpoch 20/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.8403\nEpoch 21/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.7435\nEpoch 22/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.6623\nEpoch 23/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.5943\nEpoch 24/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.5373\nEpoch 25/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.4895\nEpoch 26/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.4494\nEpoch 27/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.4158\nEpoch 28/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.3877\nEpoch 29/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.3641\nEpoch 30/30\n1/1 [==============================] - 0s 1ms/step - loss: 0.3443\n\n\n<keras.callbacks.History at 0x7fb265509dc0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_16/kernel:0' shape=(3, 1) dtype=float32, numpy=\n array([[2.4614503],\n        [3.925311 ],\n        [4.5953326]], dtype=float32)>]\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,(X@net.weights).reshape(-1),'--')\n\n\n\n\n\n\n\n숙제\n\n예제2: 케라스를 이용하여 아래를 만족하는 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 구하라. 적합결과를 시각화하라. (애니메이션 시각화 X)\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) +epsilon\n\n\nX = np.stack([np.ones(N), np.exp(-x)],axis=1)\ny = y.reshape(N,1)\n\n\nX.shape, y.shape\n\n((100, 2), (100, 1))\n\n\n\nnet = tf.keras.Sequential() # 1. 네트워크 생성\nnet.add(tf.keras.layers.Dense(1,use_bias=False)) # 2. add layer\nnet.compile(tf.optimizers.SGD(0.1), loss='mse') # 3. compile\nnet.fit(X,y,epochs=100, batch_size=N, verbose=0) # 4. fit\n\n<keras.callbacks.History at 0x7fb1ef048940>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_21/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5061626],\n        [3.966341 ]], dtype=float32)>]\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@net.weights).reshape(-1),'--')"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_25_중간고사.html",
    "href": "posts/3_STBDA2022/2022_04_25_중간고사.html",
    "title": "[STBDA] 중간고사",
    "section": "",
    "text": "import numpy as np\nimport tensorflow as tf\nimport tensorflow.experimental.numpy as tnp\n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport matplotlib.pyplot as plt\n\n\n\n(1) 아래는 \\(X_i \\overset{iid}{\\sim} N(3,2^2)\\) 를 생성하는 코드이다.\n\ntf.random.set_seed(43052)\nx= tnp.random.randn(10000)*2+3\nx\n\n<tf.Tensor: shape=(10000,), dtype=float64, numpy=\narray([ 4.12539849,  5.46696729,  5.27243374, ...,  2.89712332,\n        5.01072291, -1.13050477])>\n\n\n함수 \\(L(\\mu,\\sigma)\\)을 최대화하는 \\((\\mu,\\sigma)\\)를 tf.GradeintTape()를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 \\(\\mu\\)의 초기값은 2로 \\(\\sigma\\)의 초기값은 3으로 설정할 것)\n\\[L(\\mu,\\sigma)=\\prod_{i=1}^{n}f(x_i), \\quad f(x_i)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(\\frac{x_i-\\mu}{\\sigma})^2}\\]\n(2) 아래는 \\(X_i \\overset{iid}{\\sim} Ber(0.8)\\)을 생성하는 코드이다.\n\ntf.random.set_seed(43052)\nx= tf.constant(np.random.binomial(1,0.8,(10000,)))\nx\n\n<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([0, 0, 1, ..., 1, 1, 1])>\n\n\n함수 \\(L(p)\\)을 최대화하는 \\(p\\)를 tf.GradeintTape()를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 \\(p\\)의 초기값은 0.3으로 설정할 것)\n\\[L(\\mu,\\sigma)=\\prod_{i=1}^{n}f(x_i), \\quad f(x_i)=p^{x_i}(1-p)^{1-x_i}\\]\n(3) 아래의 모형에 따라서 \\(\\{Y_i\\}_{i=1}^{10000}\\)를 생성하는 코드를 작성하라. - \\(Y_i \\overset{iid}{\\sim} N(\\mu_i,1)\\) - \\(\\mu_i = \\beta_0 + \\beta_1 x_i = 0.5 + 2 x_i\\) , where \\(x_i = \\frac{i}{10000}\\)\n함수 \\(L(\\beta_0,\\beta_1)\\)을 최대화하는 \\((\\beta_0,\\beta_1)\\)를 tf.GradeintTape()를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 \\(\\beta_0,\\beta_1\\)의 초기값은 모두 1로 설정할 것)\n\\[L(\\beta_0,\\beta_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(y_i)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(y_i-\\mu_i)^2}, \\quad \\mu_i=\\beta_0+\\beta_1 x_i\\]\n\n\n\n아래와 같은 선형모형을 고려하자.\n\\[y_i = \\beta_0 + \\beta_1 x_i +\\epsilon_i.\\]\n이때 오차항은 정규분포로 가정한다. 즉 \\(\\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)\\)라고 가정한다.\n관측데이터가 아래와 같을때 아래의 물음에 답하라.\n\nx= tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4])\ny= tnp.array([55.4183651 , 58.19427589, 61.23082496, 62.31255873, 63.1070028 ,\n              63.69569103, 67.24704918, 71.43650092, 73.10130336, 77.84988286])\n# X= tnp.array([[1.0, 20.1], [1.0, 22.2], [1.0, 22.7], [1.0, 23.3], [1.0, 24.4],\n#               [1.0, 25.1], [1.0, 26.2], [1.0, 27.3], [1.0, 28.4], [1.0, 30.4]])\n\n(1) MSE loss를 최소화 하는 \\(\\beta_0,\\beta_1\\)의 해석해를 구하라.\n(2) 경사하강법과 MSE loss의 도함수를 이용하여 \\(\\beta_0,\\beta_1\\)을 추정하라.\n주의 tf.GradeintTape()를 이용하지 말고 MSE loss의 해석적 도함수를 사용할 것.\n(3) tf.keras.optimizers의 apply_gradients()를 이용하여 \\(\\beta_0,\\beta_1\\)을 추정하라.\n(4) tf.keras.optimizers의 minimize()를 이용하여 \\(\\beta_0,\\beta_1\\)을 추정하라.\n\n\n\n(1) 아래와 같은 모형을 고려하자.\n\\[y_i= \\beta_0 + \\sum_{k=1}^{5} \\beta_k \\cos(k t_i)+\\epsilon_i, \\quad i=0,1,\\dots, 999\\]\n여기에서 \\(t_i=\\frac{2\\pi i}{1000}\\) 이다. 그리고 \\(\\epsilon_i \\sim i.i.d~ N(0,\\sigma^2)\\), 즉 서로 독립인 표준정규분포에서 추출된 샘플이다. 위의 모형에서 아래와 같은 데이터를 관측했다고 가정하자.\n\nnp.random.seed(43052)\nt= np.array(range(1000))* np.pi/1000\ny = -2+ 3*np.cos(t) + 1*np.cos(2*t) + 0.5*np.cos(5*t) + np.random.randn(1000)*0.2\nplt.plot(t,y,'.',alpha=0.2)\n\n\n\n\ntf.keras를 이용하여 \\(\\beta_0,\\dots,\\beta_5\\)를 추정하라. (\\(\\beta_0,\\dots,\\beta_5\\)의 참값은 각각 -2,3,1,0,0,0.5 이다)\n(2) 아래와 같은 모형을 고려하자.\n\\[y_i \\sim Ber(\\pi_i), ~ \\text{where} ~ \\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\]\n위의 모형에서 관측한 데이터는 아래와 같다.\n\ntf.random.set_seed(43052)\nx = tnp.linspace(-1,1,2000)\ny = tf.constant(np.random.binomial(1, tf.nn.sigmoid(-1+5*x)),dtype=tf.float64)\nplt.plot(x,y,'.',alpha=0.05)\n\n\n\n\ntf.keras를 이용하여 \\(w_0,w_1\\)을 추정하라. (참고: \\(w_0, w_1\\)에 대한 참값은 -1과 5이다.)\n\n\n\n아래의 모형을 고려하자.\nmodel: \\(y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x>0 \\end{cases}\\)\n아래는 위의 모형에서 생성한 샘플이다.\n\n## data\nnp.random.seed(43052)\nN=100\nx= np.linspace(-1,1,N).reshape(N,1)\ny= np.array(list(map(lambda x: x*1+np.random.normal()*0.3 if x<0 else x*3.5+np.random.normal()*0.3,x))).reshape(N,1)\n\n(1) 다음은 \\((x_i,y_i)\\)를 아래와 같은 아키텍처로 적합시키는 코드이다.\n\n$ = _0+_1x $\n\n\ntf.random.set_seed(43054)\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(1))\nnet.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\nnet.fit(x,y,batch_size=N,epochs=1000,verbose=0) # numpy로 해도 돌아감\n\n<keras.callbacks.History at 0x7f6b142800d0>\n\n\n케라스에 의해 추정된 \\(\\hat{\\beta}_0,\\hat{\\beta}_1\\)을 구하라.\n(2) 다음은 \\((x_i,y_i)\\)를 아래와 같은 아키텍처로 적합시키는 코드이다.\n\n\\(\\boldsymbol{u}= x\\boldsymbol{W}^{(1)}+\\boldsymbol{b}^{(1)}\\)\n\\(\\boldsymbol{v}= \\text{relu}(u)\\)\n\\(y= \\boldsymbol{v}\\boldsymbol{W}^{(2)}+b^{(2)}\\)\n\n\ntf.random.set_seed(43056)\n## 1단계\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(2))\nnet.add(tf.keras.layers.Activation('relu'))\nnet.add(tf.keras.layers.Dense(1))\nnet.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f6af6c39f30>\n\n\n\\({\\boldsymbol u}\\)를 이용하여 \\({\\boldsymbol v}\\)를 만드는 코드와 \\({\\boldsymbol v}\\)를 이용하여 \\(y\\)를 만드는 코드를 작성하라.\n(3) 아래는 (1)-(2)번 모형에 대한 discussion이다. 올바른 것을 모두 골라라.\n(곤이) (2) 모형은 활성화함수로 relu를 사용하였다.\n(철용) (1) 모형에서 추정해야할 파라메터의 수는 2개이다.\n(아귀) (2) 모형이 (1) 모형보다 복잡한 모형이다.\n(짝귀) (1) 의 모형은 오버피팅의 위험이 있다.\n\n\n\n(1) 적절한 학습률이 선택된다면, 경사하강법은 손실함수가 convex일때 언제 전역최소해를 찾을 수 있다.\n(2) tf.GradeintTape()는 경사하강법을 이용하여 최적점을 찾아주는 tool이다.\n(3) 학습률이 크다는 것은 파라메터는 1회 업데이트 하는 양이 크다는 것을 의미한다.\n(4) 학습률이 크면 학습파라메터의 수렴속도가 빨라지지만 때때로 과적합에 빠질 수도 있다.\n(5) 단순회귀분석에서 MSE loss를 최소화 하는 해는 경사하강법을 이용하지 않아도 해석적으로 구할 수 있다."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_04_(5주차)_4월4일.html",
    "href": "posts/3_STBDA2022/2022_04_04_(5주차)_4월4일.html",
    "title": "[STBDA] 5wk. optimizer를 이용한 최적화",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wVWUAZ5xT35INvWbNOXpBx\n\n옵티마이저를 이용하면 이전의 그 수식들을 다 기억하고 있지 않아도 된다는 장점!\n\n\nimports\n\n#\n#!conda install -c conda-forge python-graphviz -y\n\n\nimport tensorflow as tf \nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior() \n\n\n\n최적화의 문제\n- \\(loss=(\\frac{1}{2}\\beta-1)^2\\)\n- 기존에 했던 방법은 수식을 알고 있어야 한다는 단점이 있음\n\n\ntf.keras.optimizers를 이용한 최적화방법\n\n방법1: opt.apply_gradients()를 이용\n\nalpha= 0.01/6 # 학습률설정\n\n\nbeta= tf.Variable(-10.0)  # 초깃값 설정\n\n\nopt = tf.keras.optimizers.SGD(alpha)\n\n- iter1\n\nwith tf.GradientTape() as tape:  # 미분을 위한 tape object 생성\n    tape.watch(beta) \n    loss=(beta/2-1)**2 \nslope = tape.gradient(loss,beta)\n\n\n# 얠 안하고 싶다는 거임.\n# beta.assign_sub(slope*alpha) # beta update\n# beta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.969999>\n\n\n\nopt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n\n\n\n\n\n\nWarning\n\n\n\nopt.apply_gradients()의 입력은 pair의 list\n\n\n- iter2\n\nwith tf.GradientTape() as tape: \n    tape.watch(beta) \n    loss=(beta/2-1)**2 \nslope = tape.gradient(loss,beta)\nopt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.980008>\n\n\n\n\\(-10 \\to -9.99 \\to -9.98\\to \\dots\\)\n\n- for문으로 정리\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0) \nopt = tf.keras.optimizers.SGD(alpha)\n\n\nfor epoc in range(10000): \n    with tf.GradientTape() as tape: \n        tape.watch(beta) \n        loss=(beta/2-1)**2 \n    slope = tape.gradient(loss,beta)\n    opt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \n    beta\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9971251>\n\n\n\nopt.lr\n\n<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0016666667>\n\n\n\nopt.learning_rate\n\n<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0016666667>\n\n\n\nid(opt.lr), id(opt.learning_rate) # 똑같음...\n\n(140176929947312, 140176929947312)\n\n\n\nopt.apply_gradients()의 입력은 pair 의 list\n지난시간에 했던 것이 optimizer로 완벽히 구현되었다!\n\n\n\n방법2: opt.minimize()\n\n방법2는 GradientTape()를 안써도 된다.\n\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0)\nopt = tf.keras.optimizers.SGD(alpha)\n\n\nloss_fn = lambda: (beta/2-1)**2\n\n\nlambda x: x**2 <=> lambda(x)=x^2\nlambda x,y: x+y <=> lambda(x,y)=x+y\nlambda: y <=> lambda()=y, 입력이 없으며 출력은 항상 y인 함수\n\n\nloss_fn() # 입력은 없고 출력은 뭔가 계산되는 함수 \n\n<tf.Tensor: shape=(), dtype=float32, numpy=36.0>\n\n\n- iter 1\n\nopt.minimize(loss_fn, [beta])\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n- iter2\n\nopt.minimize(loss_fn, [beta])\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.980008>\n\n\n- for문으로 정리하면\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0) \nopt = tf.keras.optimizers.SGD(alpha)\nloss_fn = lambda: (beta/2-1)**2\nfor epoc in range(10000): \n    opt.minimize(loss_fn, [beta])\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9971251>\n\n\n\n\n\n회귀분석 문제\n- \\({\\bf y} \\approx 2.5 + 4.0 {\\bf x}\\)\n\ntnp.random.seed(43052)\nN = 200\nx = tnp.linspace(0,1,N) \nepsilon = tnp.random.randn(N)*0.5 # 오차항.\ny = 2.5+4*x + epsilon\ny_true = 2.5+4*x\n\n\nplt.plot(x,y,'.')\nplt.plot(x,y_true,'r--')\n\n\n\n\n\n\n이론적 풀이\n\n풀이1: 스칼라버전\n- 포인트 - \\(S_{xx}=\\), \\(S_{xy}=\\) - \\(\\hat{\\beta}_0=\\), \\(\\hat{\\beta}_1=\\)\n- 풀이\n\nSxx = sum((x-x.mean())**2)\nSxy = sum((x-x.mean())*(y-y.mean()))\n\n\nbeta1_hat = Sxy/Sxx \nbeta1_hat # true: 4.0\n\n<tf.Tensor: shape=(), dtype=float64, numpy=3.9330345167331697>\n\n\n\nbeta0_hat = y.mean() - x.mean()*beta1_hat\nbeta0_hat # true: 2.5\n\n<tf.Tensor: shape=(), dtype=float64, numpy=2.583667211565867>\n\n\n\n\n풀이2: 벡터버전\n- 포인트 - \\(\\hat{\\beta}=(X'X)^{-1}X'y\\)\n- 풀이\n\ny=y.reshape(N,1)\nX=tf.stack([tf.ones(N,dtype=tf.float64),x],axis=1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\ntf.linalg.inv(X.T @ X ) @ X.T @ y \n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[2.58366721],\n       [3.93303452]])>\n\n\n\n\n풀이3: 벡터버전, 손실함수의 도함수이용\n- 포인트\n\n\\(loss'(\\beta)=-2X'y +2X'X\\beta\\)\n\\(\\beta_{new} = \\beta_{old} - \\alpha \\times loss'(\\beta_{old})\\)\n\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tnp.array([-5,10]).reshape(2,1)\nbeta_hat\n\n<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\narray([[-5],\n       [10]])>\n\n\n\n# slope = (-2*X.T @ y + 2*X.T @ X @ beta_hat) / N # SSE\nslope = (-2*X.T @ y + 2*X.T @ X @ beta_hat) / N   # MSE \nslope\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[-9.10036894],\n       [-3.52886113]])>\n\n\n\n앞으로는 MSE 버전으로 할 것임. (sample 수가 커질때마다 alpha 값을 조정하기가 너무 귀찮으니까..)\n\n\nalpha= 0.1 \n\n\nstep = slope*alpha\nstep\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[-0.91003689],\n       [-0.35288611]])>\n\n\n\nfor epoc in range(1000): \n    slope = (-2*X.T @ y + 2*X.T @ X @ beta_hat)/N \n    beta_hat = beta_hat - alpha* slope\n\n\nbeta_hat\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n\nGradientTape를 이용\n\n풀이1: 벡터버전\n- 포인트\n## 포인트코드1: 그레디언트 테입  \nwith tf.GradientTape() as tape: \n    loss = \n## 포인트코드2: 미분 \nslope = tape.gradient(loss,beta_hat) \n## 포인트코드3: update \nbeta_hat.assign_sub(slope*alph) \n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\nalpha=0.1\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= X@beta_hat\n        loss= (y-yhat).T @ (y-yhat) / N\n    slope = tape.gradient(loss,beta_hat) \n    beta_hat.assign_sub(alpha*slope) \n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n위에서 구한것과 같음!\n\n\n\n풀이2: 스칼라버전\n- 포인트\n## 포인트코드: 미분\nslope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat])\n- 풀이\n\ny=y.reshape(-1) # 길이가 200인 벡터.\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0)\n\n\nalpha=0.1\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= beta0_hat + x*beta1_hat \n        loss= tf.reduce_sum((y-yhat)**2)/N #loss= sum((y-yhat)**2)/N\n    slope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat]) \n    beta0_hat.assign_sub(alpha*slope0)\n    beta1_hat.assign_sub(alpha*slope1)\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\nloss를 tf.reduce_sum((y-yhat)**2)/N 이렇게 해야 속도가 훨씬 빠름..\nloss= sum((y-yhat)**2)/N 얘와 같지만 속도는 다름!\n\n\n\n\nGradientTape + opt.apply_gradients\n\n풀이1: 벡터버전\n- 포인트\n## 포인트코드: 업데이트\nopt.apply_gradients([(slope,beta_hat)])  ## pair의 list가 입력 \n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\n# tf.keras.optimizers       ## tf.optimizers와 동일..\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= X@beta_hat\n        loss= (y-yhat).T @ (y-yhat) / N\n    slope = tape.gradient(loss,beta_hat)\n    opt.apply_gradients([(slope,beta_hat)])\n    #beta_hat.assign_sub(alpha*slope) \n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이2: 스칼라버전\n- 포인트\n## 포인트코드: 업데이트 \nopt.apply_gradients([(slope0,beta0_hat),(slope1,beta1_hat)]) ## pair의 list가 입력 \n- 풀이\n\ny=y.reshape(-1)\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0)\n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= beta0_hat + beta1_hat*x #X@beta_hat\n        loss= tf.reduce_sum((y-yhat)**2) / N\n    slope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat])\n    opt.apply_gradients([(slope0,beta0_hat),(slope1,beta1_hat)])\n\n\npair의 list [(slope0,beta0_hat),(slope1,beta1_hat)]이런 형태가 필요함.\n미분하는 애들이 여러개 있을 때는 리스트로 전달함으로써 연산을 용이하게 함. (리스트로 전달하는 이유.)\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\n\n\nopt.minimize\n\n풀이1: 벡터버전, 사용자정의 손실함수 with lambda\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\n# 손실함수 정의\nloss_fn = lambda: (y-X@beta_hat).T @ (y-X@beta_hat) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta_hat])\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366721],\n       [3.93303452]])>\n\n\n\n\\(\\hat{\\beta}\\)이 적절히 잘 추론됨.\n\n\n\n풀이2: 스칼라버전, 사용자정의 손실함수 with lambda\n- 포인트\n## 포인트코드: 미분 & 업데이트 = minimize \nopt.minimize(loss_fn,[beta0_hat,beta1_hat])\n- 풀이\n\ny=y.reshape(-1)\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0) \n\n\nloss_fn = lambda: tf.reduce_sum((y-beta0_hat-beta1_hat*x )**2) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta0_hat,beta1_hat])\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\n결과는 동일.\n\n\n\n풀이3: 벡터버전, 사용자정의 (짧은) 손실함수\n- 포인트\n## 포인트코드: 손실함수정의 \ndef loss_fn():\n    return ??\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    return (y-X@beta_hat).T @ (y-X@beta_hat) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn, [beta_hat])\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이4: 벡터버전, 사용자정의 (긴) 손실함수\n- 포인트\n## 포인트코드: 손실함수정의 \ndef loss_fn():\n    ??\n    ??\n    return ??\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = (y-yhat).T @ (y-yhat) / N # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta_hat])\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이5: 벡터버전, 사용자정의 손실함수 <- tf.losses.MSE\n- 포인트\n## 포인트코드: 미리구현되어있는 손실함수 이용 \ntf.losses.MSE(y,yhat)\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\n# 알아서 MSE 잘 구해줌.\ntf.keras.losses.MSE(tnp.array([0.0,0.0,0.0]),tnp.array([1.0,2.0,3.0]))\n\n<tf.Tensor: shape=(), dtype=float64, numpy=4.666666666666667>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = tf.keras.losses.MSE(y.reshape(-1),yhat.reshape(-1)) # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta_hat])\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이6: 벡터버전, 사용자정의 손실함수 <- tf.losses.MeaSquaredError\n- 포인트\n## 포인트코드: 클래스로부터 손실함수 오브젝트 생성 (함수를 찍어내는 클래스) \nmse_fn = tf.losses.MeanSquaredError()\nmse_fn(y,yhat)\n- 풀이\n\nmseloss_fn = tf.losses.MeanSquaredError()\n\n\nmseloss_fn = tf.keras.losses.MSE 라고 보면된다.\n\n\nmseloss_fn(tnp.array([0.0,0.0]), tnp.array([1.0,2.0]))\n\n<tf.Tensor: shape=(), dtype=float64, numpy=2.5>\n\n\n\ndir(mseloss_fn) # callable object.\n\n['__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_allow_sum_over_batch_size',\n '_fn_kwargs',\n '_get_reduction',\n '_keras_api_names',\n '_keras_api_names_v1',\n '_name_scope',\n '_set_name_scope',\n 'call',\n 'fn',\n 'from_config',\n 'get_config',\n 'name',\n 'reduction']\n\n\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = mseloss_fn(y.reshape(-1),yhat.reshape(-1)) # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta_hat])\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n\ntf.keras.Sequential\n- \\(\\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1x_i\\) 의 서로다른 표현\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\ngv(''' \n    \"1\" -> \"beta0_hat + x*beta1_hat,    bias=False\"[label=\"* beta0_hat\"]\n    \"x\" -> \"beta0_hat + x*beta1_hat,    bias=False\"[label=\"* beta1_hat\"]\n    \"beta0_hat + x*beta1_hat,    bias=False\" -> \"yhat\"[label=\"indentity\"]\n    ''')\n\n\n\n\n\ngv('''\n\"x\" -> \"x*beta1_hat,    bias=True\"[label=\"*beta1_hat\"] ;\n\"x*beta1_hat,    bias=True\" -> \"yhat\"[label=\"indentity\"] ''')\n\n\n\n\n\ngv('''\n\"X=[1 x]\" -> \"X@beta_hat,    bias=False\"[label=\"@beta_hat\"] ;\n\"X@beta_hat,    bias=False\" -> \"yhat\"[label=\"indentity\"] ''')\n\n\n\n\n\n풀이1: 벡터버전, 사용자정의 손실함수\n- 포인트\n## 포인트코드1: 네트워크 생성 \nnet = tf.keras.Sequential()\n\n## 포인트코드2: 네트워크의 아키텍처 설계 \nnet.add(tf.keras.layers.Dense(1,input_shape=(2,),use_bias=False)) \n\n## 포인트코드3: 네트워크 컴파일 = 아키텍처 + 손실함수 + 옵티마이저\nnet.compile(opt,loss=loss_fn2)\n\n## 포인트코드4: 미분 & update \nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n- 레이어: 입력 -> 레이어 -> 출력\n- 네트워크: 레이어들의 집합\n- 풀이\n\nnet = tf.keras.Sequential() # 아무것도 없음..\n\n\nnetwork 안에 layer를 설계를 해야함.\n\n\nnet.add(tf.keras.layers.Dense(units=1,input_shape=(2,),use_bias=False)) ## yhat을 구하는 방법정의 = 아키텍처가 설계 \n\n\nunits는 layer의 출력의 차원, 이 경우는 yhat의 차원, yhat은 (200,1) 이므로 1임.\ninput_shape는 layer의 입력의 차원, 이 경우는 X의 차원, X는 (200,2) 이므로 2임.\n\n\nnet.summary() # 뭔가 만들어짐.\n\nModel: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n네트워크 안에 레이어가 만들어졌다.\n\n\nnet.weights # 뭔가 weight도 만들어져 있음!\n\n[<tf.Variable 'dense/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.2421309 ],\n        [-0.71216303]], dtype=float32)>]\n\n\n\ndef loss_fn2(y,yhat):\n    return (y-yhat).T @ (y-yhat) / N \n\n\nalpha=0.1\nopt =tf.optimizers.SGD(alpha)\n\n\n[np.array([[-5.0],[10.0]],dtype=np.float32)]\n\n[array([[-5.],\n        [10.]], dtype=float32)]\n\n\n\nnet.set_weights([np.array([[-5.0],[10.0]],dtype=np.float32)])\n\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-5.],\n        [10.]], dtype=float32)>]\n\n\n\nnet.compile(opt,loss=tf.losses.MSE)\n# 아키텍처 + 손실함수 + 옵티마이저 => 네트워크에 다 합치자 => 네트워크를 컴파일한다. \n\n\nnet.fit(X,y,epochs=1000,batch_size=N,verbose=0) # 미분 + 파라메터업데이트 = net.fit \n\n<keras.callbacks.History at 0x7f7d0bd6cc70>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.58366 ],\n        [3.933048]], dtype=float32)>]"
  },
  {
    "objectID": "posts/5_study/2023-05-13-추정 for JY.html",
    "href": "posts/5_study/2023-05-13-추정 for JY.html",
    "title": "[Essays] 추정 for JY",
    "section": "",
    "text": "- 비편향추정량(UB)란 \\(\\theta\\)의 추정량 중\n\\[\\forall \\theta\\in \\Theta:~ E(\\hat{\\theta})=\\theta\\]\n를 만족하는 추정량 \\(\\hat{\\theta}\\)을 의미한다.\n- (예시) 아래와 같은 상황을 가정하자.\n\\[X_n \\overset{iid}{\\sim} N(\\theta,1)\\]\n여기에서\n\n\\(\\hat{\\theta}_1=0\\) 은 \\(\\theta=0\\) 일 경우에는 \\(E(\\hat{\\theta})=\\theta\\) 를 만족하지만 그 외의 경우에는 \\(E(\\hat{\\theta})\\neq\\theta\\) 이므로 UB가 아니다.\n\\(\\hat{\\theta}_2=X_1\\) 은 UB이다.\n\\(\\hat{\\theta}_3=\\frac{X_1+X_2}{2}\\) 역시 UB이다.\n\\(\\hat{\\theta}_4=X_1+X_2-X_3\\) 역시 UB이다.\n\\(\\hat{\\theta}_5=-99X_1+100X_2\\) 역시 UB이다.\n\\(\\hat{\\theta}_6=\\frac{X_1+0}{2}\\) 은 1과 동일한 이유로 UB가 아니다.\n\\(\\hat{\\theta}_7=\\bar{X}\\)는 UB이다.\n\\(\\hat{\\theta}_8=w_1X_1+\\dots+w_nX_n\\) ,where \\(\\sum_{i=1}^{n}w_i=1\\) 형태의 estimator는 모두 UB이다.\n\n- 최소분산비편향추정량(MVUE)란 \\(\\theta\\)에 대한 비편향추정량을 모아놓은 집합 \\(\\hat{\\Theta}_{UB}\\) 에서 최소분산을 가지는 추정량을 의미한다. MVUE를 구하는 방법은 아래와 같다.\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n예를들어 위의 예제에서 \\(V(\\hat{\\theta}_2)=1\\) 이고 \\(V(\\hat{\\theta}_3)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}\\) 이므로 \\(\\hat{\\theta}_3\\) 이 더 좋은 추정량이라 볼 수 있다.\n- (의문) 왜 비편향추정량만 모아서 그중에서 최소분산을 구할까?\n\n\\(\\hat{\\theta}_1\\)와 같은 추정량은 \\(V(\\hat{\\theta}_1)=0\\) 이므로 그냥 최소분산을 만족한다. 따라서 이러한 추정량은 제외해야지 게임이 성립함.\n\n- 불만: 아래의 방법으로 구하는건 거의 불가능하지 않나?\n\n\\(\\theta\\)에 대한 모든 비편향추정량을 구한다. 즉 집합 \\(\\hat{\\Theta}_{UB}\\)를 구한다. 그리고 \\(\\forall \\hat{\\theta} \\in \\hat{\\Theta}_{UB}\\) 에 대하여 \\(V(\\hat{\\theta})\\) 를 구한 뒤 \\(V(\\hat{\\theta})\\)가 가장 작은 \\(\\hat{\\theta}\\)를 선택한다.\n\n- 이론: 크래머라오 하한값(편의상 \\(L^\\star\\)이라고 하자)이라고 있는데, 이는 \\({\\Theta}_{UB}\\)에 존재하는 모든 추정량에 대한 분산의 하한값을 제공한다.1 즉 아래가 성립한다.\n\n\\(L^\\star\\) is Cramer-Rao lower bound \\(\\Rightarrow\\) \\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L^\\star\\)\n\n역은 성립하지 않음을 주의하자. 즉 아래를 만족하는 \\(L\\)이 존재할 수 있다.\n\n\\(V(\\hat{\\theta}) \\geq L > L^\\star\\) for some \\(\\hat{\\theta} \\in \\Theta_{UB}\\)\n\n- 위의 이론을 이용하면 아래의 논리전개를 펼 수 있다.\n\n\\(L^\\star\\)를 구한다.\n왠지 MVUE가 될 것 같은 \\(\\hat{\\theta}\\)을 하나 찍고 그것의 분산 \\(V(\\hat{\\theta})\\)를 구한다.\n만약에 \\(V(\\hat{\\theta})=L^\\star\\)를 만족하면 그 \\(\\hat{\\theta}\\)이 MVUE라고 주장할 수 있다.\n\n- 위의 논리전개에 대한 불만 [@ p.212]\n\n\\(V(\\hat{\\theta})=L^\\star\\) 이길 기도해야함.\n\\(\\forall \\hat{\\theta} \\in {\\Theta}_{UB}:~ V(\\hat{\\theta}) \\geq L > L^\\star\\) 와 같은 \\(L\\)이 존재하는 경우는 쓸 수 없음.\n\n- 또 다른 방법: 완비충분통계량을 이용함\n\n\n아래와 같은 상황을 가정하자.\n\\[ X_1,\\dots,X_n \\overset{iid}{\\sim} P_{\\theta}\\]\n- 충분통계량(SS)의 느낌: “이 값만 기억하면 \\(\\theta\\)를 추정하는데 무난할듯”\n- 예시1: \\(X_1 \\sim N(\\theta,1)\\)\n\n\\(X_1\\)은 \\(\\theta_1\\) 의 SS. (하나밖에 없으니 그거라도 기억해야지)\n즉 \\(\\hat{\\theta}=X_1\\)은 \\(\\theta\\)의 SS\n\n- 예시2: \\(X_1,X_2 \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)는 \\(\\theta\\)의 SS (둘다 기억하면 당연히 \\(\\theta\\)를 추정함에 있어서 충분함)\n그렇지만 좀 더 생각해보면 굳이 값 두개를 기억하기보다 \\(\\frac{1}{2}(X_1+X_2)\\)의 값만 기억해도 왠지 충분할것 같음. 따라서 \\(\\hat{\\theta} = \\frac{1}{2}(X_1+X_2)\\) 역시 \\(\\theta\\)의 SS 일듯\n그런데 좀 더 생각해보니까 \\(X_1+X_2\\)의 값만 기억해도 \\(\\frac{1}{2}(X_1+X_2)\\)를 나중에 만들 수 있음 (1/2만 곱하면 되니까) 따라서 \\(X_1+X_2\\)만 기억해도 왠지 충분할 것 같음. 따라서 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- 예시3: \\(X_1,\\dots,X_n \\sim N(\\theta,1)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2,\\dots,X_n)\\)은 \\(\\theta\\)의 SS.\n하지만 \\(n\\)개의 숫자를 기억할 필요 없이 \\(\\sum_{i=1}^{n} X_i\\) 하나의 숫자만 기억해도 왠지 충분할듯. 그래서 \\(\\hat{\\theta} = \\sum_{i=1}^{n} X_i\\) 역시 \\(\\theta\\)의 SS 일듯\n\n- SS에 대한 직관1\n\n기억할 숫자가 적을수록 유리 -> MSS의 개념\n충분통계량의 1:1은 충분통계량 (\\(\\frac{1}{2}(X_1+X_2)\\)을 기억하면 충분한 상황이라면, \\(X_1+X_2\\)를 기억해도 충분하니까..)\n\n- 예시4: \\(X_1,X_2 \\sim {\\cal B}er(\\theta)\\)\n\n당연히 \\(\\hat{\\boldsymbol \\theta}=(X_1,X_2)\\)은 \\(\\theta\\)의 SS.\n그리고 \\(\\hat{\\theta}=X_1+X_2\\) 역시 \\(\\theta\\) SS 일듯.\n두개보다 한개가 유리하니까 둘다 SS이면 \\((X_1,X_2)\\)보다 \\(X_1+X_2\\)가 더 좋은 SS.\n\\(X_1\\)은 SS가 아닐듯. \\(p\\)를 추정함에 있어서 \\(X_1\\)만 가지고서는 충분하지 않아보임\n\\(X_2\\)도 SS가 아닐듯.\n\n왠지 충분할 것 같은 느낌의 정의\n아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n- 일반적으로\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=\\theta(1-\\theta)\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=(1-\\theta)^2\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=\\theta^2\\)\n\n와 같은 확률들은 \\(\\theta\\)가 unknown일 때 하나의 숫자로 정할 수 없다. 예를들어 \\(\\theta=0\\) 이라면 아래와 같을 것이고\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=0\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=0\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=0\\)\n\n\\(\\theta=1/2\\) 이라면 아래와 같을 것이다.\n\n\\(P((X_1,X_2)=(0,0))=P(X_1=0,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(0,1))=P(X_1=0,X_2=1)=1/4\\)\n\\(P((X_1,X_2)=(1,0))=P(X_1=1,X_2=0)=1/4\\)\n\\(P((X_1,X_2)=(1,1))=P(X_1=1,X_2=1)=1/4\\)\n\n즉 \\(X_1,X_2\\)의 결합확률분포는 \\(\\theta\\)가 변함에 따라 같이 변화한다. 이를 이용해 우리는 \\(X_1,X_2\\)의 결합확률분포에서 관찰한 샘플들을 이용하여 \\(\\theta\\)의 값을 역으로 추론한다.\n- 만약에 어떠한 “특수한 정보를 알고 있을 경우” \\(X_1,X_2\\)의 결합확률분포를 완벽하게 기술할 수 있을 때를 가정해보자.\n- 경우1: \\(\\theta\\)를 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(\\theta=1/2\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=0,X_2=1 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=0 | \\theta=1/2)=1/4\\)\n\\(P(X_1=1,X_2=1 | \\theta=1/2)=1/4\\)\n\n- 경우2: \\(X_1,X_2\\)의 realization을 알고 있을 경우. \\((X_1,X_2)\\)의 조인트를 완벽하게 기술할 수 있다. 예를들어 \\(X_1=0,X_2=1\\)일 경우는 아래와 같다.\n\n\\(P(X_1=0,X_2=0 | X_1=0,X_2=0)=0\\)\n\\(P(X_1=0,X_2=1| X_1=0,X_2=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1,X_2=0)=1\\)\n\\(P(X_1=1,X_2=1| X_1=1,X_2=1)=0\\)\n\n- 경우3: \\((X_1+X_2)(\\omega)\\)의 realization을 알고 있을 경우. 이때도 매우 특이하게 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 있다.\ncase1: \\(X_1+X_2=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=0)=1\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=0)=0\\)\n\ncase2: \\(X_1+X_2=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=1)=1/2\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=1)=0\\)\n\ncase3: \\(X_1+X_2=2\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=0,X_2=1| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=0| X_1+X_2=2)=0\\)\n\\(P(X_1=1,X_2=1| X_1+X_2=2)=1\\)\n\n- 경우4: \\(X_1\\)의 realization만 알고 있을 경우. 이때는 \\((X_1,X_2)\\) 의 조인트를 완벽하게 기술할 수 없다.\ncase1: \\(X_1=0\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=0)=1-\\theta\\)\n\\(P(X_1=0,X_2=1| X_1=0)=\\theta\\)\n\\(P(X_1=1,X_2=0| X_1=0)=0\\)\n\\(P(X_1=1,X_2=1| X_1=0)=0\\)\n\ncase2: \\(X_1=1\\)일 경우\n\n\\(P(X_1=0,X_2=0| X_1=1)=0\\)\n\\(P(X_1=0,X_2=1| X_1=1)=0\\)\n\\(P(X_1=1,X_2=0| X_1=1)=1-\\theta\\)\n\\(P(X_1=1,X_2=1| X_1=1)=\\theta\\)\n\n- 종합해보면 경우1,경우2,경우3은 경우4와 구분되는 어떠한 공통점을 가지고 있다 볼 수 있다. 특징은 결합확률분포가 \\(\\theta\\)에 대한 함수로 표현되지 않는다는 것이다. 하나씩 살펴보면\n\n경우1: 당연히 \\(\\theta\\)를 줬으니까 \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우2: \\(X_1,X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n경우3: \\(X_1+X_2\\)를 줬음. \\((X_1,X_2)\\)의 조인트는 \\(\\theta\\)에 의존하지 않음.\n\n이렇게보면 경우1과 경우2,3은 또 다시 구분된다. 경우1은 \\(\\theta\\)에 대한 완전한 정보를 준 상황이므로 당연히 조인트는 \\(\\theta\\)에 의존하지 않는다. 경우2-3은 \\(\\theta\\)를 주지 않았음에도 조인트가 \\(\\theta\\)에 의존하지 않는 매우 특별해보이는 상황이다. 따라서 이를 통해서 유추하면\n\n경우2에서는 \\((X_1,X_2)\\) 가 경우3에서는 \\(X_1+X_2\\)가 \\(\\theta\\)에 대한 완전한 정보를 대신하고 있는것 아닐까?\n\n라는 생각이 든다. 정리하면\n\n경우2: \\((X_1,X_2)\\)을 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n경우3: \\(X_1+X_2\\)를 주는 것은 \\(\\theta\\)의 값을 그냥 알려주는 것과 대등한 효과\n\n라고 해석할 수 있는데 이를 수식화 하면 아래와 같다.\n- 대충정의: 어떠한 통계량 \\(S\\)의 값을 줬을때, \\((X_1,X_2\\dots,X_n)\\)의 조인트가 \\(\\theta\\)에 의존하지 않으면 그 통계량 \\(S\\)를 \\(\\theta\\)의 충분통계량이라고 한다.\n- 충분통계량 구하는 방법\n\n지수족일때 구하는 방식이 있음! <– 외우세여\n분해정리를 쓰는 경우. <– 거의 안쓰는거같은데..\n1-2로도 잘 모르겠으면 충분통계량일듯한 애를 잡아와서 정의에 넣고 노가다로 때려맞춤. (문제가 디스크릿할때만 쓸것)\n\n\n\n\n- 충분통계량에 대한 realization을 알려주면 \\(\\theta\\)의 값을 그냥 알려주는 효과임. 그래서 충분통계량은 좋은 것임\n- 그런데 충분통계량에도 급이 있음. 아래와 같은 상황을 가정하자.\n\\[X_1,X_2 \\sim {\\cal B}er(\\theta)\\]\n이 경우\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n이지만 1은 두개의 숫자를 기억해야하고 2는 하나의 숫자만 기억하면 되니까 2가 더 좋음\n- 예비개념: 상태1과 상태2가 있다고 하자. 상태1에서 상태2로 가는 변화는 쉽지만, 상태2에서 상태1로 가는 변화는 어렵다고 할때, 상태1이 더 좋은 상태이다.\n\n두가지 상태 “500원을 가지고 있음”, “1000원을 가지고 있음” 을 고려하자. 1000원을 500원을 만드는 것은 쉽지만 500원을 1000원으로 만들기는 어렵다. 따라서 1000원이 더 좋은 상태이다.\n\n- 충분통계량의 급을 어떻게 구분할까? 아래의 상황에서\n\n\\((X_1,X_2)\\)는 SS\n\\(X_1+X_2\\)는 SS\n\n1을 이용하면 2를 만들 수 있지만, 2를 이용해서 1을 만들 수는 없음. 즉 \\(1\\to 2\\) 인 변환(=함수)는 가능하지만 \\(2\\to 1\\)로 만드는 변환(=함수)는 가능하지 않음. 예비개념을 잘 이해했다면 2가 더 좋은 상태라고 볼 수 있다.\n- 이를 확장하자. 어떠한 충분 통계량 \\(S^\\star\\)가 있다고 가정하자. 다른 모든 충분통계량 \\(S_1,S_2,S_3 \\dots\\)에서 \\(S^\\star\\)로 만드는 변환은 존재하는데 (함수는 존재하는데) 그 반대는 \\(S^\\star\\)의 전단사인 충분통계량만 가능하다고 하자. 그렇다면 \\(S^\\star\\)는 가장 좋은 충분통계량이라고 하며, 가장 적은 숫자만 기억하면 되는 충분통계량이라 볼 수 있다. 이러한 충분통계량을 MSS 라고 하자.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, @Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다.\n\n\n\n- 충분통계량 \\(S\\)을 알려주면 (기븐하면) \\(\\theta\\)에 대한 완벽한 정보를 알려주는 셈이다. 따라서 \\(\\theta\\)를 추정하는 어떠한 추정량 \\(\\hat{\\theta}\\)도 충분통계량의 정보 \\(S\\)가 있다면 \\(\\hat{\\theta}\\)를 업그레이드할 수 있다고 볼 수 있다. (뭐 수틀리면 정보야 안쓰면 그만이니까 나빠질것은 없다)\n- 충분통계량을 줬을때 \\(\\hat{\\theta}\\)의 업그레이드 방법은\n\\[\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\]\n와 같이 할 수 있는데 이는 충분통계량 \\(S\\)의 정보를 받아서 어떠한 방식으로 업데이트된 \\(\\hat{\\theta}\\) 이므로 \\(S\\)의 함수라 해석할 수 있다.\n- 이론 (라오블랙웰, @Thm, 4.5): \\(\\hat{\\theta}\\)가 UB일때 충분통계량의 값을 알려주면 \\(\\hat{\\theta}^{new}:=E(\\hat{\\theta}|S)\\)와 같이 \\(\\hat{\\theta}\\)를 업그레이드 할 수 있다."
  },
  {
    "objectID": "posts/5_study/2023-02-20-ts1.html",
    "href": "posts/5_study/2023-02-20-ts1.html",
    "title": "ts1",
    "section": "",
    "text": "The classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\n\nlibrary(forecast)\nlibrary(tseries)\nlibrary(tidyverse)\n\n\nap <- AirPassengers\nap\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n\n\nap %>% glimpse()\n\n Time-Series [1:144] from 1949 to 1961: 112 118 132 129 121 135 148 148 136 119 ...\n\n\n\nclass(ap)\n\n[1] \"ts\"\n\n\n\nts 객체는 시계열 데이터를 처리하기 위한 속성\n\n\nstart(ap)\n\n[1] 1949    1\n\nend(ap)\n\n[1] 1960   12\n\nfrequency(ap)\n\n[1] 12\n\n\n\nplot(ap)\n\n\n\n\n\ncycle(ap)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949   1   2   3   4   5   6   7   8   9  10  11  12\n1950   1   2   3   4   5   6   7   8   9  10  11  12\n1951   1   2   3   4   5   6   7   8   9  10  11  12\n1952   1   2   3   4   5   6   7   8   9  10  11  12\n1953   1   2   3   4   5   6   7   8   9  10  11  12\n1954   1   2   3   4   5   6   7   8   9  10  11  12\n1955   1   2   3   4   5   6   7   8   9  10  11  12\n1956   1   2   3   4   5   6   7   8   9  10  11  12\n1957   1   2   3   4   5   6   7   8   9  10  11  12\n1958   1   2   3   4   5   6   7   8   9  10  11  12\n1959   1   2   3   4   5   6   7   8   9  10  11  12\n1960   1   2   3   4   5   6   7   8   9  10  11  12\n\n\n\nboxplot(ap~cycle(ap))"
  },
  {
    "objectID": "posts/5_study/2023-06-22-퓨리에변환공부.html",
    "href": "posts/5_study/2023-06-22-퓨리에변환공부.html",
    "title": "푸리에변환",
    "section": "",
    "text": "Chap1. 인트로\n전파나 음파는 모두 시간과 함께 변화하는 [파형] 이라고 할 수 있다. 보통 자연계에 존재하는 파형은 단순한 파형이 아니라 복잡한 파형으로 나타나고 있다.\n여기서 복잡하다는 것은 몇 개의 단순한 파형들이 합성돼서 만들어진다고 생각하면 된다. 단순한 파형들의 합성으로 복잡한 파형이 만들어진다는 개념이 [푸리에 변환] 의 기저를 이루고 있는 것.\n달리 말하면, 단순한 파형들의 합성이 어떤 주파수나 세기로 성립되어 있는지를 수학적으로 구하는 방법이 [푸리에 변환].\n푸리에 변환을 실행하려면, 원칙적으로는 파형이 일정 주기를 가져야한다. 그래서 복잡한 파형을 짧은 부분들로 나눠서 그 구간에서 파형이 반복된다고 가정하는 것이다.\n\n\n\n푸리에 변환의 이미지\n\n\n\n\nChap6. 푸리에 변환의 이해를 위한 준비\n\n1. 삼각함수의 합으로 파형 만들기\n직교하는 함수의 합을 이용해서 다양한 파형을 만들어보자.\n- \\(y=a\\cos x + b\\sin x\\)\n같은 주기를 가지는 \\(\\sin mx\\)와 \\(\\cos mx\\)을 더하는 것으로 시작해보자. (\\(m=1\\))\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef sin_wave(amp, freq, time):\n    return amp*np.sin(np.pi*freq*time)\n\ndef cos_wave(amp, freq, time):\n    return amp*np.cos(np.pi*freq*time)\n\n- \\(a=1, b=1\\)\n\ntime = np.arange(0,2,0.001)\ncos1 = cos_wave(1,1,time)\nsin1 = sin_wave(1,1,time)\nplt.plot(time, cos1, label='cosx')\nplt.plot(time, sin1, label='sinx')\nplt.plot(time, cos1+sin1, label='cosx + sinx')\nplt.axhline(y=0, color='grey', linestyle='--')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fe65f0982e0>\n\n\n\n\n\n\n모양은 별로 안변함..\n진폭이 커진다.\n\n- \\(a=1, b=-1\\)\n\ntime = np.arange(0,2,0.001)\ncos1 = cos_wave(-1,1,time)\nsin1 = sin_wave(1,1, time)\nplt.plot(time, cos1, label='-cosx')\nplt.plot(time, sin1, label='sinx')\nplt.plot(time, sin1+cos1, label='-cosx+sinx')\nplt.axhline(y=0, color='grey', linestyle='--')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fe65f2180a0>\n\n\n\n\n\n\n덧셈의 값은 진폭이 합성된 크기가 된다.\n위상1이 변한다.\n\n\n\n2. \\(a\\cos x\\)와 \\(b\\sin x\\)의 합성\n함수들을 그대로의 형태로 다루는 것이 아니라 어떤 [직교하는 함수의 조합] 으로 다룬다고 생각해야 한다. 실제로는 \\(\\sin x\\)와 \\(\\cos x\\)라는 단 2개의 함수로 다양한 위상의 \\(\\sin(x+\\theta)\\)를 만들 수 있다.\n\ntime = np.arange(0,2,0.001)\ncos1 = cos_wave(1/2,1,time)\nsin1 = sin_wave(1,1, time)\ncos2 = cos_wave(1,1,time)\nsin2 = sin_wave(1/2,1,time)\nplt.plot(time, sin1+cos1, label='0.5cosx+sinx')\nplt.plot(time, cos2+sin2, label='cosx+0.5sinx')\nplt.axhline(y=0, color='grey', linestyle='--')\nplt.axhline(y=1, color='grey', linestyle='--')\nplt.axhline(y=-1, color='grey', linestyle='--')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fe65eda0430>\n\n\n\n\n\n\n\\(\\sin\\)과 \\(\\cos\\) 만으로 나타낼 수 있다는 것은 이 \\(2\\)개가 [직교]라는 성질을 가지고 있다는 것과 같다.\n[직교하고 있다] = [다른 방법을 통해서는 나타낼 수 없다.] 라는 성질도 가지고 있음.\n\n- 다른 방법을 통해서는 나타낼수 없다??\n아래와 같은 \\(x\\)축과 \\(y\\)축이 교차된 직각으로 교차된 그래프를 생각해보자.\n\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\nplt.annotate(\"\", xy=(10, 0), xytext=(-10, 0), arrowprops=dict(arrowstyle=\"->\", linewidth=1.5, color='black'))\nplt.annotate(\"\", xy=(0, 10), xytext=(0, -10), arrowprops=dict(arrowstyle=\"->\", linewidth=1.5, color='black'))\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.show()\n\n\n\n\n이 그래프도 관점만 바꾸면 \\(y=0\\)이란 상수식이 \\(x\\)축을 나타내고, \\(x=0\\)이라는 상수식이 \\(y\\)축을 나타낸다고도 할 수 있다. 즉, \\(x\\)축과 \\(y\\)축의 기본 그래프는 상수식 \\(x=0\\)과 \\(y=0\\)의 그래프가 직교하는 그래프라는 것이다.\n\\(x\\)축은 \\(y\\)축을 아무리 정수배해도 나타낼 수 없다. \\(0\\)은 몇 배를 해도 \\(0\\) 밖에 되지 않으니까!\n\\(x\\)축 위의 적당한 값은 \\(x=0\\) (\\(y\\)축)을 몇배해도 만들 수 없다. \\(y\\)축도 마찬가지이다. 이것은 곧 [직교한다] 라는 말이 [다른 방법으로는 나타낼 수 없다] 라는 뜻.\n- 이것을 \\(\\sin, \\cos\\)함수에 적용시켜보자.\n\n위와 동일한 논리로 \\(\\cos x\\)라는 함수는 \\(b\\sin x\\)의 \\(b\\)를 아무리 변화시켜도 만들어 낼 수 없다.\n마찬가지로 \\(\\sin x\\)는 \\(a\\cos x\\)의 \\(a\\)를 아무리 변화시켜도 만들어 낼 수 없다.\n\\(\\sin 3x\\)도 \\(\\sin x\\)로부터는 만들어 낼 수 없다. 왜냐? 이것은 \\(\\sin x\\)와 \\(\\sin 3x\\)가 직교하고 있기 때문!\n\\(x\\)축과 \\(y\\)축의 경우, 직교하는 것이 단 둘뿐이었지만 \\(\\sin x\\)나 \\(\\sin 2x\\)나 \\(\\sin 3x\\) 등등은 모두 서로에게 직교하는 함수인 것.\n\\(\\cos x\\)와 \\(\\cos 2x, \\cos 3, \\dots\\)와 \\(\\cos\\)도 주기가 다른 것들끼리는 서로 직교하고 있다.\n\\(\\cos nx\\)와 \\(\\cos nx\\)는 주기가 같아도 직교하고 있다.\n\n이렇게 서로 직교하는 함수를 조합함으로써 다양한 형태의 함수를 만들어 낼 수 있다. 다른 삼각함수로는 만들어 낼 수 없는, 서로 직교하는 각각의 삼각함수는 다양한 파형을 만들어 내는 기준단위로서 존재 의의가 있는 것이다.\n- 합성된 파형은 진폭이 바뀐다.\n다시 처음으로 돌아가서 \\(\\sin x\\)와 \\(\\cos x\\)의 크기(\\(a\\)와 \\(b\\))에 따라 합성된 파형은 진폭도 바뀌게 된다.\n이것은 \\(\\sin x\\)와 \\(\\cos x\\)의 합성을 원주 위를 회전하는 벡터로 바꿔서 생각하면 이해하기 쉽다.\n피타고라스 정리를 적용시켜보면\n\\(a^2+b^2=r^2\\) 이므로 \\(r=\\sqrt{a^2+b^2},\\quad (r>0)\\)\n합성된 \\((a+b)\\)라는 벡터를 반지름이 \\(r\\)인 원에 대입해보면,\n\\(a^2+b^2=r^2\\) 이라는 관계가 있다는 것을 알 수 있음. 이 식을 \\(r\\)에 대해서 정리하면\n\\(r=\\sqrt{a^2+b^2}\\) 이 된다.\n결국 \\(a\\cos x + b\\sin x\\)의 크기가 \\(\\sqrt{a^2+b^2}\\) 이 된다는 말.\n- 예제 : \\(a=2, b=2\\)의 파형의 크기는?\n\\(2\\cos x+2\\sin x\\)의 파형의 크기(진폭)는\n\\(\\therefore r=\\sqrt{2^2+2^2}=\\sqrt{8}=2.82842712\\dots\\)\n이처럼 \\(a\\)와 \\(b\\)를 적당하게 조합하면 주기는 바꿀 수 없지만 진폭과 위상은 자유자재로 바꿀 수 있다.\n즉, 주기는 같아도 여러가지 형태의 파형을 만들 수 있다.\n\n\n4. 푸리에 급수\n- 푸리에 급수\n\\(\\sin\\) 이나 \\(\\cos\\)을 개수와 상관없이 여러 개를 더하면 더 복잡한 함수를 만들어 낼 수 있다.\n\\(\\begin{align*}F(x) &= \\frac{1}{2}a_0 + a_1\\cos x + a_2\\cos 2x + a_3\\cos 3x + \\dots + a_n\\cos nx + \\dots \\\\ &+b_1\\sin x + b_2\\sin 2x + b_3 \\sin 3x + \\dots b_n\\sin nx+ \\dots \\\\ &= \\frac{1}{2}a_0 + \\sum_{n=1}^\\infty (a_n\\cos nx + b_n \\sin nx)\\end{align*}\\)\n\n\\(\\frac{1}{2}a_0\\) : 삼각함수에 의해 함성된 파형 전체를 상하로 이동시킬 수 있도록 하기 위해 있는 것이라 생각하자.\n[푸리에 급수 전개]는 함수 \\(F(x)\\)가 어떤 주기를 가지고 있을 때, 즉 [주기함수]일 때 합성에 이용되는 것이 전제되어 있어햐 한다.2\n\\(a_1,a_2,a_3,\\dots, b_1,b_2,\\dots\\)은 푸리에 계수\n푸리에 계수 값을 알면 \\(F(x)\\)의 파형의 형태를 결정할 수 있다.\n\n\\(\\cos nx\\) 나 \\(\\sin nx\\)의 앞에 붙는 \\(n\\) \\(\\to\\) 주파수\n\\(\\sin, \\cos\\)의 크기를 결정하는 계수 \\(a_n, b_n\\) \\(\\to\\) 푸리에 계수\n\n\n삼각함수의 주기와 푸리에 계수를 조합하면 다양한 파형을 만들어 낼 수 있다. 이 공식이 푸리에 급수..\n\n여러 개의 함수를 조합해서 만들어 내는 것이 “합성”\n한 함수가 어떤 조합으로 이루어졌는지를 알아보는 것이 “변환”\n합성과 변환은 서로 역의 관계\n\n푸리에 급수를 역으로 하면 푸리에 변환을 이용하여 파형을 해석하는 푸리에 해석이 가능하다.\n원래의 파형 \\(F(x)\\)에서 푸리에 계수에 등장한 \\(a_0, a_n, b_n\\)을 구하는 일을 푸리에 계수를 구한다 라고 한다.\n\n\n\nChap 7. 푸리에 해석\n- 푸리에 계수\n\\(a_n = \\frac{1}{\\pi}\\int_{0}^{2\\pi} F(x) \\cos nx dx\\)\n\\(b_n = \\frac{1}{\\pi}\\int_0^{2\\pi}F(x)\\sin nx dx\\)\n\\(a_0 = \\frac{1}{2\\pi}\\int_0^{2\\pi}F(x)dx\\)\n하나의 주파 성분에는 \\(\\sin\\)함수의 성분과 \\(\\cos\\)함수의 성분이 들어있고, 그것들에 대응하는 푸리에 계수는 \\(b_n\\)과 \\(a_n\\)으로 표시하고 있다. 그러나 스펙트럼에는 각각의 성분의 계수가 아닌 그 주파수의 크기에 주목해야한다.\n4번째 단계에서 계산된 \\(r_n\\)을 \\(n\\)이 작은 순서부터 오른쪽으로 일렬로 늘어놓아 그래프로 그린 것이 스펙트럼 이다.\n푸리에 변환으로 주파수 분석을 할 경우엔 변수를 시간함수로 생각하기 때문에 변수를 \\(t\\)로 바꿔서 \\(F(t)\\)로 쓰기도 한다. 이렇게 하면 함수의 변수가 시간인 것을 강하게 나타내주기 때문.\n정현파…..\n\n세미, 넌, 파라메트릭….이 뭔지???\n\n\n\n\n\n\nFootnotes\n\n\n그래프의 출발점↩︎\n주기함수가 아닌 경웅는 어떤 구간으로 잘라내서 이 구간이 반복되고 있다고 가정함으로써 파형을 합성.↩︎"
  },
  {
    "objectID": "posts/5_study/2023-02-25-jt-test.html",
    "href": "posts/5_study/2023-02-25-jt-test.html",
    "title": "JT test",
    "section": "",
    "text": "JT-test\n\nEx1\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.2.0     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\ngroup <- c(rep(3,8), rep(2,7), rep(1,7))\nspace <- c(54.0,67.0,47.2,71.1,62.7,44.8,67.4,80.2,\n           79.8,82.0,88.8,79.6,85.7,81.7,88.5,\n          98.6,99.5,95.8,93.3,98.9,91.1,94.5)\n\n\n# H0: m_N = m_U = m_S\n# H1: m_N >= m_U >= m_s (at least one strict inequality)\nlibrary(clinfun)\njonckheere.test(space, \n                group,\n                alternative = 'decreasing')\n\n\n    Jonckheere-Terpstra test\n\ndata:  \nJT = 2, p-value = 7.29e-09\nalternative hypothesis: decreasing\n\n\n\n\nLarge-Sample Approximation\nFor large sample sizes, J is approximately normally distributed with mean 0 and variance 1. When we use the normal approximation, we compute.\n\\[\nz = \\frac{J-[(N^2 - \\sum_{i=1}^kn_i^2)/4]}{\\sqrt{[N^2(2N+3)-\\sum_{k=1}^kn_i^2(2n_i+3)]/72}}\n\\] ### Ex2\n\njonckheere.test(mtcars$mpg,\n                as.integer(mtcars$cyl),\n                alternative = 'decreasing')\n\nWarning in jonckheere.test(mtcars$mpg, as.integer(mtcars$cyl), alternative = \"decreasing\"): Sample size > 100 or data with ties \n p-value based on normal approximation. Specify nperm for permutation p-value\n\n\n\n    Jonckheere-Terpstra test\n\ndata:  \nJT = 5, p-value = 1.153e-08\nalternative hypothesis: decreasing\n\n\n\nN <- nrow(mtcars)\nn1 <- filter(mtcars, mtcars$cyl == 4) %>% nrow()\nn2 <- filter(mtcars, mtcars$cyl == 6) %>% nrow()\nn3 <- filter(mtcars, mtcars$cyl == 8) %>% nrow()\n\n\nmu <- ((N^2 - (n1^2+n2^2+n3^2))/4)\nvar_ <- (N^2*(2*N+3)-((n1^2*(2*n1+3) + n2^2*(2*n2+3) + n3^2*(2*n3 + 3))))/72\nmu; var_\n\n[1] 164.5\n\n\n[1] 814.9167\n\n\n\npnorm(5, mu, sqrt(var_), lower.tail = TRUE)\n\n[1] 1.152957e-08\n\n\n\nz_ = (5 - mu) / sqrt(var_)\npnorm(z_,  lower.tail = TRUE)\n\n[1] 1.152957e-08"
  },
  {
    "objectID": "posts/5_study/2023-06-24-파라메트릭.html",
    "href": "posts/5_study/2023-06-24-파라메트릭.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "비선형 입출력 함수도 표현할 수 있도록 확장한 것이 파라미터에 대한 선형 모델이다.\n\\[f_{\\theta}(x) = \\sum_{j=1}^b \\theta_j \\phi_j (x) = \\theta^\\top \\phi(x)\\]\n이때, \\(\\phi_j(x)\\)는 기저 함수(basis function) 벡터 \\(\\phi(x) = (\\phi_1(x), \\dots, \\phi_b(x))^\\top\\)의 \\(j\\)번째 요소, \\(\\theta_j\\)는 파라미터 벡터 \\(\\theta = (\\theta_1, \\dots, \\theta_b)^\\top\\)의 \\(j\\)번째 요소를 나타낸다. 또, \\(b\\)는 기저 함수의 수를, \\(\\top\\)는 전치행렬을 나타낸다.이 모델은 파라미터 벡터 \\(\\theta\\)에 대해서는 여전히 선형이지만, 예를들어 기저 함수로써 다음의 다항식이나,\n\\[\\phi(x) = (1,x,x^2,\\dots,x^{b-1})^\\top\\]\n\\(b=2m+1\\)에 대한 다음의 삼각 다항식 등을 선택하면 복잡한 비선형 함수도 나타낼 수 있게 된다.\n\\[\\phi(x) = (1, \\sin x, \\cos x, \\sin 2x, \\cos 2x, \\dots, \\sin ms, \\cos mx)^\\top\\]\n이 모델은 \\(d\\)차원의 입력벡터 \\({\\bf x} = (x^{(1)}, \\dots, x^{(d)})^\\top\\)로도 자연스럽게 확장할 수 있다.\n\\[f_{\\theta}(x) = \\sum_{j=1}^b \\theta_j \\phi_j (x) = \\theta^\\top \\phi(x)\\]\n다차원 입력 벡터 \\(\\bf x\\)에 대하여 어떤 기저 함수를 택해야 할까?\n\n\n1차원 기저 함수의 곱으로 다차원 기저 함수를 구성한다.\n\\[f_{\\theta}(x)=\\sum_{j_1=1}^{b'}\\cdots \\sum_{j_d=1}^{b'} \\theta_{j1,\\dots, jd}\\phi_{j1}(x^{(1)})\\cdots \\phi_{jd}(x^{d})\\]\n\n\\(b'\\) : 각 차원의 파라미터 수\n승법모델에서는 모든 1차원 기저함수의 조합을 따지므로 복잡한 함수를 표현할 수 있다.\n그러나 전체 파라미터 수가 \\((b')^d\\)가 되므로 입력차원 \\(d\\)에 대하여 지수적으로 증가한다.\n\n이렇게 차원에 대해 파라미터 수가 지수적으로 증가하는 현상을 차원의 저주 라 부른다.\n\n\n\n1차원 기저 함수의 합으로 다차원 기저 함수를 구성한다.\n\\[f_{\\theta}(x) = \\sum_{k=1}^d\\sum_{j=1}^{b'} \\theta_{k,j} \\phi_j (x^{(k)}) \\tag{2.1}\\]\n가법모델에서는 전체 파라미터 수가 \\(b'd\\)개가 되므로 입력 차원 \\(d\\)에 대하여 선형으로만 증가한다. 예를들면, \\(b'=10\\)이고, 입력차원 \\(d=100\\)일 때 전체 하라미터 수는 \\(10\\times 100 = 1000\\)이 되어 컴퓨터로 쉽게 다룰 수 있는 범위를 유지한다.그러나 가법 모델에서는 1차원 기저 함수의 합밖에 표현할 수 밖에 없기 때문에 승법모델만큼의 표현력은 가지지 못한다."
  },
  {
    "objectID": "posts/5_study/2023-06-24-파라메트릭.html#커널모델",
    "href": "posts/5_study/2023-06-24-파라메트릭.html#커널모델",
    "title": "Quarto-Blog",
    "section": "2.2 커널모델",
    "text": "2.2 커널모델\n선형모델에서는 다항식이나 삼각다항식 등 기저 함수를 훈련 표본 \\(\\{(x_i, y_i)\\}_{i=1}^n\\)과 관계없이 결정해 왔다.\n기저함수의 설계에 입력 표본 \\(\\{x_i\\}_{i=1}^n\\)을 이용하는 커널 모델(kernel models) 을 소개한다.\n커널모델은 이항 함수 \\(K( , )\\)로 나타낼 수 있는 커널함수를 써서 \\(\\{K(x,x_j)\\}_{j=1}^n\\)의 선형결합으로 정의된다.\n\\[f_{\\theta}(x) = \\sum_{j=1}^n \\theta_j K(x,x_j) \\tag{2.2}\\]\n커널함수로는 가우스 커널(Gaussian kernel) 이 자주 쓰인다.\n\\[K(x,c) = \\exp \\left(-\\frac{||x-c||^2}{2h^2}\\right)\\]\n\n\\(||\\cdot||\\) : \\(l_2\\) 노름(norm) // ex. \\(||x|| = \\sqrt{x^\\top x}\\)\n\\(h\\): 가우스 커널의 밴드 폭\n\\(c\\): 가우스 커널의 밴드 중심\n\n가우스 커널 모델은 각 입력 표본 \\(\\{x_i\\}_{i=1}^n\\)에 가우스 커널을 배치하고, 각각의 높이 \\(\\{\\theta_i\\}_{i=1}^n\\)을 파라미터로써 학습한다. 따라서 가우스 커널 모델은 훈련 입력 표본이 있는 위치의 근처에서만 함수를 근사한다. 승법 모델로는 입력공간 전체에서 함수를 근사하는 데 비해, 가우스 커널 모델로는 입력 표본 \\(\\{x_i\\}_{i=1}^n\\) 가까이에서만 함수를 근사하므로 차원의 저주로부터 영향을 줄일 수 있다.\n각 입력 표본 \\(\\{x_i\\}_{i=1}^n\\)에 가우스 커널을 배치하고, 그 높이를 파라미터 \\(\\{\\theta_i\\}_{i=1}^n\\)으로써 학습하는 것.\n입력 표본 근처에서만 함수를 근사하면 되니까, 차원의 저주로부터 오는 어려움이 줄어드는 것이다.\n실제로, 커널 모델의 파라미터 수는 입력 변수 \\(x\\)의 차원 \\(d\\)에 의존하지 않으며, 훈련 표본 수 \\(n\\)만으로 결정된다. 따라서 입력차원 \\(d\\)가 큰 경우에도 표본 수 \\(n\\)이 그렇게 많지 않으면 컴퓨터로 어렵지 않게 다룰 수 있다.\n매우 많은 훈련 표본을 다루는 경우에도 입력 표본 \\(\\{x_i\\}_{i=1}^n\\)의 (이를테면 무작위로 선택한) 부분집합 \\(\\{c_j\\}_{j=1}^b\\)만을 커널 중심으로 사용하여 계산 부하를 줄일 수 있다.\n\\[f_{\\theta}(x) = \\sum_{j=1}^b \\theta_j K(x,c_j)\\]\n커널 모델은 파라미터 벡터 \\({\\bf\\theta}=(\\theta_1, \\dots, \\theta_n)^\\top\\) 에 대해 선형인 성질 때문에 식 (2.1)의 파라미터에 대한 선형모델의 한 종류로 볼 수 있다.\n그러나 기저 함수가 입력 표본에 의존적이기 때문에 커널 모델의 거동은 파라미터에 대한 선형모델과는 크게 달라진다. 이 때문에 통계학에서는 파라미터에 대한 선형 모델을 파라메트릭 모델(parametric models), 커널 모델을 넌파라메트릭 모델(non-parametric models) 로 구분하고 있다.\n커널 모델의 또 다른 특징은 입력 \\(\\bf x\\)가 벡터가 아닌 경우에도 비교적 쉽게 확장이 가능하다는 점이다.\n커널모델 식 (2.2)의 경우, 입력 \\(x\\)는 커널 함수 \\(K(x,x')\\)에서 \\(x\\)와 \\(x'\\) 사이에만 존재하므로 두 개의 입력 \\(x\\)와 \\(x'\\)에 대한 커널 함수만 정의되어 있다면, 입력 \\(\\bf x\\)는 어떤 값을 취해도 상관없다. 예를 들면, 입력 \\(\\bf x\\)가 문자열, 트리, 그래프 등인 경우에대한 커널 함수가 제안된 바가 있다.\n이렇듯 커널함수를 사용한 머신러닝 알고리즘은 커널법 이라 불리며 활발히 연구되고 있다."
  },
  {
    "objectID": "posts/5_study/2023-06-23-퓨리에변환4jy.html",
    "href": "posts/5_study/2023-06-23-퓨리에변환4jy.html",
    "title": "[Essays] 퓨리에변환4jy",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\n회귀모형 (1)\n\nx = np.linspace(-10,10,1000)\nx0 = x*0+1\nx1 = x \nbeta0 = 3 \nbeta1 = 2\ny = x0*beta0+x1*beta1+np.random.randn(1000)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n회귀모형 (2)\n- 관측한자료\n\nN=1000\nx=np.linspace(0,1,N)\neps = np.random.randn(N)\nX0 = np.sin(x*0*np.pi)\nX1 = np.sin(x*2*np.pi)\nX2 = np.sin(x*4*np.pi)\nX3 = np.sin(x*6*np.pi)\n\ny=2*X1+1*X2+3*X3+eps\n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\nobserved signal\n\n- 위의 자료를 해석하는 방법\n\ndef spec(y):\n    N= len(y)\n    return abs(np.fft.fft(y)/N)*2 \n\n\ny=2*X1+1*X2+3*X3+eps\nyfft =spec(y) \ny1=2*X1\ny2=1*X2\ny3=3*X3\nyfft1=spec(y1)\nyfft2=spec(y2)\nyfft3=spec(y3)\nepsfft=spec(eps)\n\n\nplt.plot(yfft[:20],'o',alpha=0.5)\nplt.plot(yfft1[:20],'x',alpha=1,)\nplt.plot(yfft2[:20],'x',alpha=1)\nplt.plot(yfft3[:20],'x',alpha=1)\nplt.plot(epsfft[:20],'x',alpha=1)\n\n\n\n\n- 퓨리에변환 -> threshold -> 역퓨리에변환을 이용한 스킬\n\nyfft=np.fft.fft(y)\n\n\nplt.plot(abs(yfft[1:50]),'o')\n\n\n\n\n\nyfft[abs(yfft)<100] = 0\n\n\nplt.plot(y,'o',alpha=0.1)\nyhat=np.fft.ifft(yfft)\nplt.plot(yhat,'--')\nplt.plot(y-eps,'-')\n\n\n\n\n\nplt.plot(spec(y)[:50],'o')\nplt.plot(spec(yhat)[:50],'x')\n\n\n\n\n\n\n삼성전자 주가자료를 스무딩해보기\n- 삼성전자 자료\n\nimport yfinance as yf\n\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ny = yf.download(\"005930.KS\", start=start_date, end=end_date)['Adj Close'].to_numpy()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nplt.plot(y)\n\n\n\n\n- 스펙트럼\n\nyfft = np.fft.fft(y)\n\n\nplt.plot(abs(yfft))\n\n\n\n\n- 처음 50개정도만 관찰\n\nplt.plot(abs(yfft[:50]),'o')\n\n\n\n\n\n첫값이 너무커서 나머지는 잘안보임\n\n- 2번째부터 50번째까지만 관찰\n\nplt.plot(abs(yfft)[2:50],'o')\nplt.axhline(y=22500, color='r', linestyle='--')\n\n<matplotlib.lines.Line2D at 0x7f85162b57c0>\n\n\n\n\n\n\n대충 이정도 짜르면 될것같음\n\n- thresholded value\n\ntresh_value = 22500\n\n\nyfft[abs(yfft)<tresh_value] =0 \n\n- 퓨리에역변환\n\nyhat = np.fft.ifft(yfft)\nyhat[:5]\n\narray([59664.72193044+8.87311904e-14j, 58572.98839934+8.87311904e-14j,\n       58066.07369126+3.39894326e-14j, 58169.18671667-6.87747670e-14j,\n       58706.41986821-1.14383435e-13j])\n\n\n실수화\n\nyhat = np.real(yhat)\nyhat[:5]\n\narray([59664.72193044, 58572.98839934, 58066.07369126, 58169.18671667,\n       58706.41986821])\n\n\n- 적합결과 시각화\n\nplt.plot(y)\nplt.plot(yhat,'--')\n\n\n\n\n\n- 숙제: treshold value를 관찰하며 시각화해볼것\n\n# 스펙트럼\nyfft1 = yfft.copy()\nyfft2 = yfft.copy()\nyfft3 = yfft.copy()\n\n\nplt.plot(abs(yfft)[2:50],'o')\nplt.axhline(y=30000, color='r', linestyle='--')\nplt.axhline(y=50000, color='g', linestyle='--')\nplt.axhline(y=100000, color='y', linestyle='--')\nplt.show()\n\n\n\n\n- thresholded value\n\ntresh_value1 = 30000\ntresh_value2 = 50000\ntresh_value3 = 100000\n\n\nyfft1[abs(yfft)<tresh_value1] =0 \nyfft2[abs(yfft)<tresh_value2] =0 \nyfft3[abs(yfft)<tresh_value3] =0 \n\n- 퓨리에역변환\n\nyhat1 = np.real(np.fft.ifft(yfft1))\nyhat2 = np.real(np.fft.ifft(yfft2))\nyhat3 = np.real(np.fft.ifft(yfft3))\nyhat1[:5], yhat2[:5], yhat3[:5] \n\n(array([60302.63175219, 59674.04944237, 59176.52517726, 58830.97854078,\n        58648.54453033]),\n array([60610.76706766, 60334.04540323, 60094.64069051, 59898.16437304,\n        59749.22168918]),\n array([61926.12309451, 61926.12309451, 61926.12309451, 61926.12309451,\n        61926.12309451]))\n\n\n- 적합결과 시각화\n\nplt.plot(y)\nplt.plot(yhat1, color='r', linestyle='--', label='thresh=30000')\nplt.plot(yhat2,color='g', linestyle='--', label='thresh=50000')\nplt.plot(yhat3, color='y', linestyle='--', label='thresh=100000')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nminor topics\n- y의 FFT 결과는 항상 y와 같은길이임\n\nlen(y)\n\n82\n\n\n\nlen(np.fft.fft(y))\n\n82\n\n\n- 에일리어싱: number of observation은 얼마나 세밀한 주파수까지 측정가능하냐를 결정함\n예시1: 에일리어싱\n\nx = np.linspace(-3.14,3.14,10)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.        , -0.99975131],\n       [-0.99975131,  1.        ]])\n\n\n\nplt.plot(x1,label='x1')\nplt.plot(x2,label='x2')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f8514838190>\n\n\n\n\n\n\n실제로는 x2가 더 고주파인데, 같은 주파수처럼 보임\n\n예시2: 에일리어싱이 없는 경우\n\nx = np.linspace(-3.14,3.14,100000)\n\n\nx1 = np.sin(8*x)\nx2 = np.sin(10*x)\n\n\nnp.corrcoef([x1,x2])\n\narray([[ 1.00000000e+00, -6.45767105e-08],\n       [-6.45767105e-08,  1.00000000e+00]])\n\n\n\nplt.plot(x1)\nplt.plot(x2)\n\n\n\n\n\n주파수 왜곡떄문에 실제로는 corr ceof = 0 일지라도 관측되는건 corr coef >0 일 수 있음"
  },
  {
    "objectID": "posts/5_study/2023-02-20-simul_eq.html",
    "href": "posts/5_study/2023-02-20-simul_eq.html",
    "title": "simultaneous equation",
    "section": "",
    "text": "파이썬에서 Numpy는 행렬 계산을 쉽게하기 위해 사용하는 패키지이다. R로도 행렬과 매트릭스를 구현해보자.\n- 예를 들어 아래와 같은 문제가 있다고 하자.\n\\[\\begin{cases}w+2x+ey+4z = 1 \\\\2w+2x+y=9 \\\\x-y = 4 \\\\3w+x-y+3y=7\\end{cases}\\]\n- 매트릭스 형태로 위의 식을 표현하면 아래와 같다.\n\\[\n\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\nw \\\\ x \\\\ y \\\\z\n\\end{bmatrix}=\\begin{bmatrix}\n1 \\\\ 9 \\\\ 4 \\\\7\n\\end{bmatrix}\n\\]\n- 양변에\n\\[\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}\\]\n의 역행렬을 취하면\n\\[\\begin{bmatrix}\nw \\\\ x \\\\ y \\\\z\n\\end{bmatrix}=\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}^{-1}\\begin{bmatrix}\n1 \\\\ 9 \\\\ 4 \\\\7\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/5_study/2023-02-20-simul_eq.html#r로-구현",
    "href": "posts/5_study/2023-02-20-simul_eq.html#r로-구현",
    "title": "simultaneous equation",
    "section": "R로 구현",
    "text": "R로 구현\n\n- 방법1\n\nA=rbind(c(1,2,3,4),c(2,2,1,0),c(0,1,-1,0),c(3,1,-1,3))\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    2    2    1    0\n[3,]    0    1   -1    0\n[4,]    3    1   -1    3\n\n\n\nb=c(1,9,4,7)\ndim(b)=c(4,1)\nb\n\n     [,1]\n[1,]    1\n[2,]    9\n[3,]    4\n[4,]    7\n\n\n\nsolve(A) %*% b \n\n     [,1]\n[1,]    2\n[2,]    3\n[3,]   -1\n[4,]   -1\n\n\n따라서 \\((w,x,y,z) = (2,3,-1,-1)\\) 이다.\n\n\n- 방법2\n\nA = rbind(c(1,2,3,4),c(2,2,1,0),c(0,1,-1,0),c(3,1,-1,3))\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    2    2    1    0\n[3,]    0    1   -1    0\n[4,]    3    1   -1    3\n\n\n\nb = c(1,9,4,7)\nb\n\n[1] 1 9 4 7\n\n\n\nsolve(A) %*% b\n\n     [,1]\n[1,]    2\n[2,]    3\n[3,]   -1\n[4,]   -1"
  },
  {
    "objectID": "posts/5_study/2023-06-18-chap2.html",
    "href": "posts/5_study/2023-06-18-chap2.html",
    "title": "Chap2. 신경망의 수학적 구성요소",
    "section": "",
    "text": "케라스 파이썬 라이브러리를 사용하여 손글씨 숫자 분류를 학습하는 구체적인 신경망 예제를 살펴보겠습니다.\n흑백 손글씨 숫자 이미지 (\\(28 \\times 28\\) 픽셀)를 10개의 범주(0에서 9까지)로 분류하는 것입니다. 1980년대 미국 국립표준기술연구소(NIST)에서 수집한 6만개의 훈련 이미지와 1만개의 테스트 이미지로 구성되어 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n머신러닝에서 분류 문제의 범주(category) 를 클래스(class) 라고 합니다. 데이터 포인트는 샘플(sample) 이라고 합니다. 특정 샘플의 클래스는 레이블(label) 이라고 합니다.\n\n\n\n\n- 케라스에서 MNIST 데이터셋 적재\nMNIST 데이터셋은 Numpy 배열 형태로 케라스에 이미 포함되어 있습니다.\n\nfrom keras.datasets import mnist\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 1s 0us/step\n\n\n\ntrain_images.shape, test_images.shape\n\n((60000, 28, 28), (10000, 28, 28))\n\n\n\nlen(train_labels), len(test_labels)\n\n(60000, 10000)\n\n\n\ntrain_labels\n\narray([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\n\n\n\ntest_labels\n\narray([7, 2, 1, ..., 4, 5, 6], dtype=uint8)\n\n\n- 신경망 구조\n\nfrom keras import models\nfrom keras import layers\n\n\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\nnetwork.add(layers.Dense(10, activation='softmax'))\n\n신경망이 준비를 마치기 위해서 컴파일 단계에 포함될 세가지가 더 필요합니다.\n\n손실함수(loss function) : 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습할 수 있도록 도와줍니다.\n옵티마이저(optimizer) : 입력된 데이터와 손실함수를 기반으로 네트워크를 업데이트하는 메커니즘입니다.\n훈련과 테스트 과정을 모니터링할 지표 : 여기에서는 정확도(정확히 분류된 이미지의 비율)만 고려하겠습니다.\n\n- 컴파일 단계\n\nnetwork.compile(optimizer='rmsprop',\n                loss = 'categorical_crossentropy',\n                metrics= ['accuracy'])\n\n훈련 시작 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 \\(0\\) 과 \\(1\\) 사이로 스케일을 조정합니다.1\n- 이미지 데이터 준비\n\ntrain_images = train_images.reshape((60000, 28*28))\ntrain_images = train_images.astype('float32')/255\n\ntest_images = test_images.reshape((10000, 28*28))\ntest_images = test_images.astype('float32')/255\n\n- 레이블 준비\n\nfrom keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n\ntrain_labels\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)\n\n\n\ntest_labels\n\narray([[0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n\n\n\n신경망 훈련준비 완료!\n\n\nnetwork.fit(train_images, train_labels, epochs=5, batch_size=128)\n\nEpoch 1/5\n469/469 [==============================] - 1s 1ms/step - loss: 0.2646 - accuracy: 0.9231\nEpoch 2/5\n469/469 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9679\nEpoch 3/5\n469/469 [==============================] - 1s 1ms/step - loss: 0.0707 - accuracy: 0.9790\nEpoch 4/5\n469/469 [==============================] - 1s 1ms/step - loss: 0.0512 - accuracy: 0.9849\nEpoch 5/5\n469/469 [==============================] - 1s 1ms/step - loss: 0.0377 - accuracy: 0.9885\n\n\n<keras.callbacks.History at 0x7f02cc03f880>\n\n\n훈련하는동안 2개의 정보가 출력도비니다. 훈련 데이터에 댛나 네트워크 손실과 정확도!\n테스트 세트에서도 모델이 잘 작동하는지 확인해봅시다.\n\ntest_loss, test_acc = network.evaluate(test_images, test_labels)\n\n313/313 [==============================] - 0s 470us/step - loss: 0.0605 - accuracy: 0.9815\n\n\n\n\n\n최근의 모든 머신러닝 시스템은 일반적으로 텐서를 기본 데이터 구조로 사용합니다.\n핵심적으로 텐서는 데이터를 위한 컨테이너(container)입니다. 거의 항상 수치형 데이터를 다루므로 숫자를 위한 컨테이너입니다. 텐서는 임의의 차원 개수를 가지는 행렬의 일반화된 모습입니다.\n\n\n하나의 숫자만 담고있는 텐서를 스칼라 또는 (스칼라 텐서, 0차원 텐서, 0D텐서) 라고 부릅니다. 넘파이에서는 float32나 float64 타입의 숫자가 스칼라 텐서(또는 배열 스칼라) 입니다. 스칼라 텐서의 축 개수는 \\(0\\)개 입니다. 텐서의 축 개수를 랭크(rank) 라고도 부릅니다.\n\nimport numpy as np\nx = np.array(12)\nx\n\narray(12)\n\n\n\nx.ndim\n\n0\n\n\n\n\n\n숫자의 배열을 벡터(vector) 또는 1D 텐서라고 부릅니다.\n\nx = np.array([12,3,6,14,7])\nx\n\narray([12,  3,  6, 14,  7])\n\n\n\nx.ndim\n\n1\n\n\n\n5개의 원소를 가지고 있으므로 이 벡터는 5D 벡터.\n5D벡터와 5D텐서 혼동하지 말기! (5D벡터는 하나의 축을따라 5개의 차원을 가진것이고, 5D텐서는 5개의 축을 가진 것!)\n\n\n\n\n벡터의 배열이 행렬(matrix) 또는 2D텐서 입니다. 행렬에는 2개의 축이 있습니다.\n\nx = np.array([[1,2,3,4,5],[6,7,8,9,0],[4,5,6,7,8]])\nx\n\narray([[1, 2, 3, 4, 5],\n       [6, 7, 8, 9, 0],\n       [4, 5, 6, 7, 8]])\n\n\n\nx.ndim\n\n2\n\n\n\n\n\n이런 행렬들을 하나의 새로운 배열로 합치면 숫자가 채워진 직육면체 형태로 해석할 수 있는 3D텐서가 만들어집니다.\n\n# 넘파이에서 3D 텐서\nx = np.array([[[1,2,3,4,5],[6,7,8,9,0],[4,5,6,7,8]],[[1,2,3,4,5],[6,7,8,9,0],[4,5,6,7,8]],[[1,2,3,4,5],[6,7,8,9,0],[4,5,6,7,8]]])\n\n\nx\n\narray([[[1, 2, 3, 4, 5],\n        [6, 7, 8, 9, 0],\n        [4, 5, 6, 7, 8]],\n\n       [[1, 2, 3, 4, 5],\n        [6, 7, 8, 9, 0],\n        [4, 5, 6, 7, 8]],\n\n       [[1, 2, 3, 4, 5],\n        [6, 7, 8, 9, 0],\n        [4, 5, 6, 7, 8]]])\n\n\n\nx.ndim\n\n3\n\n\n3D 텐서들을 하나의 배열로 합치면 4D 텐서를 만드는 식\n딥러닝에서는 보통 0D에서 4D까지의 텐서를 다룹니다. 동영상 데이터는 5D까지..\n\n\n\n텐서는 3개의 핵심속성으로 정의됩니다.\n\n축의 개수(랭크) : 예를들어 3D 텐서에는 3개의 축, 행렬에는 2개의 축이 있다.\n\n넘파이 라이브러리에 ndim 속성에 저장되어있음.\n\n크기 (shape): 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플(tuple).\n\n벡터의 크기는 (5,) 처럼 1개의 원소로 이루어진 튜플. 배열스칼라는 ()처럼 크기 가 없다.\n\n데이터 타입: 넘파이에서는 dtype에 저장됨.\n\nex. float32, uint8, float64 등.\n\n\n\nfrom keras.datasets import mnist\n(train_images, train_labels), (test_images, tset_labels) = mnist.load_data()\n\n\n# 축의 개수\nprint(train_images.ndim)\n\n3\n\n\n\n# 배열의 크기\nprint(train_images.shape)\n\n(60000, 28, 28)\n\n\n\n# 데이터 타입\nprint(train_images.dtype)\n\nuint8\n\n\n\n이 배열은 8비트 정수형 3D 텐서.\n정확히는 \\(28\\times 28\\) 크기의 정수 행렬 6만개가 있는 배열\n\n- 다섯번째 샘플 확인\n\ndigit = train_images[4]\nimport matplotlib.pyplot as plt\n\nplt.imshow(digit, cmap=plt.cm.binary)\nplt.show()\n\n\n\n\n\n\n\n이전 예제에서는 train_images[i] 같은 형식으로 첫번째 축을 따라 특정 숫자를 선택했었다. 배열에 있는 특정 원소들을 선택하는 것을 슬라이싱 이라고 한다. 넘파이 배열에서 할 수 있는 슬라이싱 연산을 살펴보자.\n\nmy_slice = train_images[10:100]\nprint(my_slice.shape)\n\n(90, 28, 28)\n\n\n\nmy_slice = train_images[10:100, :, :]\nmy_slice.shape\n\n(90, 28, 28)\n\n\n\nmy_slice = train_images[10:100, 0:28, 0:28]\nmy_slice.shape\n\n(90, 28, 28)\n\n\n\n# 14x14 픽셀\nmy_slice = train_images[10:100, 0:14, 0:14]\nmy_slice.shape\n\n(90, 14, 14)\n\n\n\n\n\n일반적으로 딥러닝에서 사용하는 모든 데이터 텐서의 첫번째 축은 샘플 축(sample axis)이다.2 MNIST 예제에서는 숫자 이미지가 샘플이다.\n딥러닝 모델은 한 번에 전체 데이터셋을 처리하지 않습니다. 그 대신 데이터를 작은 배치(batch)로 나눕니다.\n# 첫번째 배치\nbatch = train_images[:128]\n\n# 2번째 배치\nbatch = train_images[128:256]\n\n# n 번째 배치\nbatch = train_images[128 * n:128 * (n + 1)]\n\n\n\n우리가 앞으로 사용할 데이터는 대부분 다음 중 하나에 속할 것이다.\n\n벡터 데이터 : (samples, features) 크기의 2D 텐서\n시계열 데이터 또는 시퀀스(sequence) 데이터: (samples, timesteps, features) 크기의 3D 텐서\n이미지: (samples, height, width, channels) 또는 (samples, channels, height, width)\n동영상: (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서\n\n\n\n\n\n\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n\n\ntrain_images = train_images.reshape((60000, 28*28))\ntrain_images = train_images.astype('float32') / 255\n\ntest_images = test_images.reshape((10000, 28*28))\ntest_images = test_images.astype('float32') / 255\n\n\nfrom keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n\nnetwork = models.Sequential()\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\nnetwork.add(layers.Dense(10, activation='softmax'))\n\n\n이 네트워크는 2개의 Dense 층이 연결되어 있고 각 층은 가중치 텐서를 포함하여 입력 데이터에 대한 몇 개의 간단한 텐서 연산을 적용.\n경사하강법을 적용하는 구체적인 방식은 첫번째 매개변수로 전달된 rmsprop 옵티마이저에 의해 결정.\n\n\n# 네트워크 컴파일\nnetwork.compile(optimizer='rmsprop',\n                loss = 'categorical_crossentropy',\n                metrics=['accuracy'])\n\n\ncategorical_crossentropy : 손실함수, 가중치 텐서를 학습하기 위한 피드백 신호로 사용되며 훈련하는 동안 최소화 된다.\n\n\nnetwork.fit(train_images, train_labels, epochs=5, batch_size=128)\n\nEpoch 1/5\n469/469 [==============================] - 1s 1ms/step - loss: 2.3015 - accuracy: 0.1120\nEpoch 2/5\n469/469 [==============================] - 1s 1ms/step - loss: 2.3014 - accuracy: 0.1124\nEpoch 3/5\n469/469 [==============================] - 1s 1ms/step - loss: 2.3014 - accuracy: 0.1124\nEpoch 4/5\n469/469 [==============================] - 1s 1ms/step - loss: 2.3014 - accuracy: 0.1124\nEpoch 5/5\n469/469 [==============================] - 1s 1ms/step - loss: 2.3014 - accuracy: 0.1124\n\n\n<keras.callbacks.History at 0x7f025d247850>\n\n\n- fit 메서드 호출 결과\n\n네트워크가 128개 샘플씩 미니배치로 훈련 데이터를 5번 반복. (전체 훈련 데이터에 수행되는 각 반복을 에포크(epoch) 라고 한다.\n각 반복마다 네트워크가 배치에서 손실에 대한 가중치의 그래디언트를 계산하고 그에 맞추어 가중치를 업데이트.\n다섯번의 에포크 동안 네트워크는 \\(2,345\\)번의 크래디언트 업데이트 수행. (에폭마다 469번)\n\n\n60000/128 # 1에폭당 업데이트 횟수\n\n468.75\n\n\n\n60000/128*5 # 5에폭 업데이트 횟수\n\n2343.75"
  },
  {
    "objectID": "posts/4_TS2023/2023-06-16-begas-수정본.html",
    "href": "posts/4_TS2023/2023-06-16-begas-수정본.html",
    "title": "0616 시계열 실습 (수정본)",
    "section": "",
    "text": "패키지 설치 및 로드\nEDA\n시계열 분해 및 회귀분석 이용 예측\n지수 평활을 이용한 예측 (Holt-Winters)\nARIMA를 이용한 예측\n모형 평가 및 진단\n\n시간의 흐름에 따라서 관측된 데이터를 시계열 자료라고 한다. 시게열 분석을 위해서는 정상성을 만족해야한다. 정상성은 시점에 상관없이 시계열의 특성이 일정하다는 것을 의미하며, 이를 만족한 다는 것은 다음과 같은 것을 말한다.\n정상성 - 평균이 일정하다. - 분산이 시점에 의존하지 않는다. - 공분산은 단지 시차에만 의존하고 시점 자체에는 의존하지 않는다.\n\n# install.packages('forecast')\n# install.packages('tseries')\n# install.packages('ggplot2')\n# install.packages('reshape')\n# install.packages('zoo')\n\nlibrary(forecast)\nlibrary(tseries)\nlibrary(ggplot2)\nlibrary(reshape)\nlibrary(zoo)"
  },
  {
    "objectID": "posts/4_TS2023/2023-06-15-ts-begas-study-new.html",
    "href": "posts/4_TS2023/2023-06-15-ts-begas-study-new.html",
    "title": "0616 TS 공부",
    "section": "",
    "text": "library(forecast)\nlibrary(tseries)\nlibrary(ggplot2) \nlibrary(reshape) # 데이터 재구조화\nlibrary(zoo)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nAttaching package: ‘zoo’\n\n\nThe following objects are masked from ‘package:base’:\n\n    as.Date, as.Date.numeric"
  },
  {
    "objectID": "posts/4_TS2023/2023-06-15-ts-begas-study-new.html#시계열분석-방법",
    "href": "posts/4_TS2023/2023-06-15-ts-begas-study-new.html#시계열분석-방법",
    "title": "0616 TS 공부",
    "section": "시계열분석 방법",
    "text": "시계열분석 방법\n\nSTL (Seasonal Trend Decomposition Using Loess)\n\n\nSeasonal과 Trend를 분해하고 다항식을 이용하여 예측\n\n\n지수평활\n\n\n단순 지수 평활\n이중 지수 평활\nHolt-Winters\n\n\nARIMA"
  },
  {
    "objectID": "posts/4_TS2023/2023-06-14-ts-begas.html",
    "href": "posts/4_TS2023/2023-06-14-ts-begas.html",
    "title": "0616 TS 공부 (origin)",
    "section": "",
    "text": "library(forecast)\nlibrary(tseries)\nlibrary(ggplot2)\nlibrary(reshape)\nlibrary(zoo)\n\n\nData Load\n\n#============================================================\n# Data Load\n# - 1949년 ~ 1960년 까지의 월별 비행기 탑승 고객 수\n#============================================================ \norigin <- AirPassengers\norigin\n\n\n\nA Time Series: 12 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1949112118132129121135148148136119104118\n    1950115126141135125149170170158133114140\n    1951145150178163172178199199184162146166\n    1952171180193181183218230242209191172194\n    1953196196236235229243264272237211180201\n    1954204188235227234264302293259229203229\n    1955242233267269270315364347312274237278\n    1956284277317313318374413405355306271306\n    1957315301356348355422465467404347305336\n    1958340318362348363435491505404359310337\n    1959360342406396420472548559463407362405\n    1960417391419461472535622606508461390432\n\n\n\n\n\nclass(origin) # ts 객체\n\n'ts'\n\n\n\nstart(origin)\nend(origin)\nfrequency(origin)\n\n\n19491\n\n\n\n196012\n\n\n12\n\n\n\n\nEDA\n\n# 시도표\nplot(origin)\n# 데이터에 이분산이 존재함을 확인일 수 있음\n# 분산 안정화를 위한 데이터 변환 필요\n\n\n\n\n\nBoxcox먼저 (등분산) , seasonal, 차분, 계절차분 순서 중요!\n차분, 계절차분 순서모를때\n\n시즈널, 트렌드, 분산이상한데 분산맞춰주는게 우산.\n\n#분산 안정화를 위한 BoxCox 변환\nlambda <- BoxCox.lambda(origin)\ntran_org <- BoxCox(origin, BoxCox.lambda(origin))\nplot(tran_org)\n# BoxCox 변환 이후 이분산의 효과가 줄어 든것을 확인\n\n\n\n\n\nBoxCox.lambda(origin)\n\n-0.294715585559316\n\n\n\n## 질문?\n# 정규성 및 Corr\n# Hist Plot\nhist(tran_org,prob=TRUE,12)\nlines(density(tran_org))\n\n\n\n\nQQ Plot, 정규성 검정 \\(\\to\\) 왜하는지?\n\n# Q-Q PLOT\nqqnorm(tran_org)\nqqline(tran_org)\n\n\n\n\n\n# 상관관계 확인\nlag.plot(tran_org,12,do.lines=FALSE)\n#전반적으로 데이터는 정규분포를 따르고 시차가 12일때 상관관계가 높음\n\n\n\n\n\nacf 확인\nlag=12\n\n\n\n시계열 분해 및 회귀분석 이용 예측\n\nstl_tran_org <- stl(tran_org, s.window = 12)\n\nplot(stl_tran_org)\n# 1차 Trend와 Seasonality 존재\n# 잔차는 White Noise로 판단\n\n\n\n\n\n# 계절형 Dummy 변수 생성\nM <- factor(cycle(tran_org))\nstl_tran_org_df <- as.data.frame(stl_tran_org$time.series)\n\n\n# 회귀 모형 생성\n# 모형식 : tran_org=trend∗β1+M1∗d1+...+M11∗d11+ϵ\nmodel_stl <- lm(formula = tran_org~ 0+stl_tran_org_df$trend+M, na.action = NULL)\nsummary(model_stl)\n\n\nCall:\nlm(formula = tran_org ~ 0 + stl_tran_org_df$trend + M, na.action = NULL)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0208982 -0.0030056  0.0003675  0.0032375  0.0186285 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \nstl_tran_org_df$trend  1.003132   0.006557 152.982  < 2e-16 ***\nM1                    -0.025890   0.017899  -1.446  0.15043    \nM2                    -0.029141   0.017911  -1.627  0.10614    \nM3                    -0.002850   0.017923  -0.159  0.87389    \nM4                    -0.009503   0.017936  -0.530  0.59713    \nM5                    -0.010617   0.017948  -0.592  0.55519    \nM6                     0.012901   0.017961   0.718  0.47386    \nM7                     0.032071   0.017974   1.784  0.07669 .  \nM8                     0.030402   0.017986   1.690  0.09335 .  \nM9                     0.004045   0.017998   0.225  0.82255    \nM10                   -0.023032   0.018011  -1.279  0.20322    \nM11                   -0.052048   0.018023  -2.888  0.00454 ** \nM12                   -0.028326   0.018036  -1.571  0.11870    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.006548 on 131 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.92e+06 on 13 and 131 DF,  p-value: < 2.2e-16\n\n\n\ncycle(tran_org) # gives the positions in the cycle of each observation.\n\n\n\nA Time Series: 12 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1949 1 2 3 4 5 6 7 8 9101112\n    1950 1 2 3 4 5 6 7 8 9101112\n    1951 1 2 3 4 5 6 7 8 9101112\n    1952 1 2 3 4 5 6 7 8 9101112\n    1953 1 2 3 4 5 6 7 8 9101112\n    1954 1 2 3 4 5 6 7 8 9101112\n    1955 1 2 3 4 5 6 7 8 9101112\n    1956 1 2 3 4 5 6 7 8 9101112\n    1957 1 2 3 4 5 6 7 8 9101112\n    1958 1 2 3 4 5 6 7 8 9101112\n    1959 1 2 3 4 5 6 7 8 9101112\n    1960 1 2 3 4 5 6 7 8 9101112\n\n\n\n\n\n# 잔차 검정\n\npar(mfrow=c(3,1))\n# time Plot\nplot(resid(model_stl))\n# Hist Plot\nhist(resid(model_stl),prob=TRUE,12)\nlines(density(resid(model_stl)))\n# Q-Q PLOT\nqqnorm(resid(model_stl))\nqqline(resid(model_stl))\n# Q-Q Plot과 Histogram을 확인하면 양쪽 끝이 두텁지만 White Noise라고 판단하기 어려움이 없음\n\n\n\n\n\n트렌드 분산 같이 잡고싶을 때\n\n\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\n\n# 원 데이터 및 fitted 데이터의 비교\n# BoxCox 역변환 필요 함\nlines(InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)), col='red')\nmean((origin - InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)))^2, na.rm = TRUE)\n\n81.1421060592885\n\n\n\n\n\n\n\n지수평활을 이용한 예측\n\n단순 지수 평활: 추세나 계절적 변동이 없는 시계열 예측에 사용\n이중 지수 평활: 추세만 존재하는 시계열 예측에 사용\nHoltWinters: 추세와 계절 요인이 있는 시계열 예측에 사용\n\n이중 지수 평활을 확장한 개념으로 특정 기간 내의 계절성을 함께 고려 가능\n\n#============================================================\n# 지수평활을 이용한 예측\n#============================================================\n\nplot(stl(origin, s.window=12))\n# Trend 및 Seasonality 존재\n# Holt-Winter 지수평활 모형이 적합\n\n\n\n\n\n#HoltWinters 모형 생성\nmodel_es <- HoltWinters(origin, seasonal = \"multiplicative\")\n\n# 원 데이터 및 fitted 데이터의 비교\n# plot\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\nlines(model_es$fitted[,1], col='red')\n# mse 125.5\nmean((origin-model_es$fitted[,1])^2)\n\n125.536195962121\n\n\n\n\n\n\n\nARIMA를 이용한 예측\n\nSeasonality 제거/ 차분인데 시즈널리티가 뚜렷하면 시즈널 제거…\n\n\n# 데이터 탐색 및 모형식별\n# 시도표\nplot(origin)\n# 데이터의 이분산과 1차 추세가 존재함\n# 분산 안정화를 위한 Box Cox 변환과 1차 차분 필요\n\n\n\n\n\n# 분산 안정화 및 차분\ntran_org <- BoxCox(origin, BoxCox.lambda(origin))\nplot(tran_org)\ntran_diff_org <- diff(tran_org)\nplot(tran_diff_org)\n\n\n\n\n\n\n\n\n계절성을 먼저 제거하고 차분을 해야하는 케이스가 존재.\n일반적으로는 차분을 먼저한다.\n\n\n# ACF, PACF를 통한 탐색\nlayout(1:2)\nacf(tran_diff_org, lag.max = 24)\npacf(tran_diff_org, lag.max=24)\n\n\n\n\n\n# 계절 차분 및 ACF, PACF를 통한 탐색\ntran_sdiff_org <- diff(tran_diff_org, lag = 12)\n\n\nacf(tran_sdiff_org, lag.max = 24)\n# acf는 lag=1,3,12에서 0이 아닌값 가짐  비계절 시차 4부터 절단 -> MA(3), 계절 -> 시차 2부터 절단 SMA(1)\n\n\n\n\n\npacf(tran_sdiff_org, lag.max = 24)\n# 시차 2와 8에서 0보다 큰 값을 가지지만 정확한 모형을 찾기 위해 auto.arima를 통해 aic가 최소가 되는 order 값 구함\n\n\n\n\n\nauto.arima(tran_sdiff_org, max.p = 3, max.q=3, max.Q=1)\nauto.arima(tran_org, max.p = 3, max.q=3, max.Q=1)\n# 모형 구축\n\nSeries: tran_sdiff_org \nARIMA(0,0,1)(0,0,1)[12] with zero mean \n\nCoefficients:\n          ma1     sma1\n      -0.4355  -0.5847\ns.e.   0.0908   0.0725\n\nsigma^2 = 5.789e-05:  log likelihood = 451.59\nAIC=-897.18   AICc=-896.99   BIC=-888.55\n\n\nSeries: tran_org \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.4355  -0.5847\ns.e.   0.0908   0.0725\n\nsigma^2 = 5.855e-05:  log likelihood = 451.6\nAIC=-897.19   AICc=-897.01   BIC=-888.57\n\n\n\nmodel_arima <- arima(tran_sdiff_org, order=c(0,0,1), seasonal = list(order = c(0,0,1), period = 12))\nmodel_arima <- arima(tran_org, order=c(0,1,1), seasonal = list(order = c(0,1,1), period = 12))\n\n\n# 모형 검진\n# 잔차 검정\ntsdiag(model_arima)\n# 독립성 검정\n\n\n\n\n\nBox.test(model_arima$residuals, type=\"Ljung-Box\")\n# 잔차의 독립성, 등분산성, 정규성 만족\n\n\n    Box-Ljung test\n\ndata:  model_arima$residuals\nX-squared = 0.15595, df = 1, p-value = 0.6929\n\n\nplot(spline(time(origin), origin),type=‘l’,xlab=‘Time’,ylab=‘Pop’)\n\n# spline ? underline function을 부드럽게 만드는 함수...\n\n\n# 원 데이터 및 fitted 데이터의 비교\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\nlines(InvBoxCox(fitted(model_arima), BoxCox.lambda(origin)), col='red')\nmean((origin - InvBoxCox(fitted(model_arima), BoxCox.lambda(origin)))^2)\n\n107.241415231708\n\n\n\n\n\n\n# 12개월 예측\narima_fit <- predict(model_arima, n.ahead=12) #BoxCox 변환 데이터 사용\nlambda <- BoxCox.lambda(origin)\n\n\nts.plot(origin, xlim=c(1950,1965), ylim = c(0, 1000))\nlines(InvBoxCox(arima_fit$pred, lambda),col=\"red\")\nlines(InvBoxCox(arima_fit$pred+1.96*arima_fit$se, lambda),col=\"blue\",lty=1)\nlines(InvBoxCox(arima_fit$pred-1.96*arima_fit$se, lambda),col=\"blue\",lty=1)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html",
    "href": "posts/4_TS2023/2023-05-12-2wk.html",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "",
    "text": "정의역: \\(\\Omega\\)\n치역: \\(\\mathbb{R}\\)의 부분집합\n\n\n\n\\(\\Omega = \\{H,T\\}\\)\n\\(X: \\Omega \\to \\mathbb{R}\\)\n\n- 기호\n집합: \\(\\Omega\\), 원소: \\(w\\), \\(\\quad w\\in \\Omega\\)\n\\(\\Omega = \\{H,T\\} = \\{w_1,w_2\\}\\)\n\\(X(w_1) = X(H)=0, X(w_2) = X(T)=1\\)\n- 주의\n\n\\(X: \\Omega \\to \\mathbb{R}\\)\n\\(P: \\cal{F} \\to [0,1]\\) (set function)\n\n(참고) \\(\\cal{F}\\): \\(\\Omega\\)의 부분집합 중 잴 수 있는 집합의 모임.\n\n\n\n\n“확률변수는 (특별한 성질을 가진) 함수다!”\n함수: \\(\\begin{align*}&y=f(x), \\quad f: \\text{function}, x: \\text{input}, y:\\text{outcome}\\\\ & x=X(w) \\quad X: \\text{random variable}, w: \\text{outcome}, x: \\text{realization}\\end{align*}\\)\n보통 \\(X(w)\\)에서 \\((w)\\)를 생략하고, 간단히 \\(X\\)로 표시 \\(\\to\\) 혼란의 이유!\n“확률변수는 결과가 랜덤으로 변한다.”\n1 맵핑규칙은 변화없음.\n\n\\(H\\to 0 \\quad w_1 \\to 0\\)\n\\(T\\to 1 \\quad w_2 \\to 1\\)\n\n2 입력. 즉, outcome은 실험결과에 따라 랜덤으로 변한다.\n\n\n\n\nw.p는 with probability를 의미.\n\n확률변수 \\(X = \\begin{cases} 0, & \\text{w.p. } \\frac{1}{2} \\\\ 1 & \\text{w.p. } \\frac{1}{2}\\end{cases}\\)\n(i) \\(X\\)는 변수처럼 보임.\n(ii) 변수의 값이 랜덤으로 변하는 것 같음\n\\(X(w) = \\begin{cases} 0, & w\\in \\{H\\} \\\\ 1, & w\\in \\{T\\} \\end{cases}\\)\n\n\n\n\n확률변수는 확률과 관련 없다.\n간접적으로는 관련있다. (\\(\\therefore\\) \\(X\\)의 역상 \\(= \\Omega\\)의 부분집합 \\(=P\\)의 정의역)\n\n\n\n\n- 시계예제\n\\(\\Omega=[0,2\\pi) \\qquad X: [0,2\\pi)\\to [0,2\\pi)\\)인 항등함수.\n\\(X\\)는 항등함수 \\(\\Rightarrow\\) 비탈리 집합의 역상은 비탈리집합 \\(\\Rightarrow\\) 확률을 정의할 수 X\n\n\n\n“확률변수 \\(X\\)를 그냥 함수가 아니라, 역상이 measurable set이 되는 함수라 하자.” \\(\\Leftrightarrow\\) \\(X\\)를 가측함수1라고 하자."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro1",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro1",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "시계열 intro1",
    "text": "시계열 intro1\n\n확률변수 \\(X\\): \\(\\Omega\\to \\mathbb{R}\\)인 특별한 함수.\n확률벡터 \\(\\bf{X}: \\Omega\\to \\mathbb{R}^m\\)인 특별한 함수\n\n- 기호\n확률변수: \\(X(w) = x\\)\n확률벡터: \\(\\bf{X}(w) = (x_1,\\dots, x_m)\\) \\(\\to\\) 출력이 벡터임을 강조!\n확률변수: \\(X\\)\n확률벡터: \\(\\mathbf{X} = (X_1,\\dots,X_m), \\quad X_1,\\dots,X_m\\)은 \\(r.v.\\)\n\\(\\therefore \\bf{X} = (X_1,\\dots, X_m)(w) = (X_1(w),\\dots,X_m(w))=(x_1,\\dots,x_m)\\)\n\\(x_1 = \\text{2019-03-20} \\\\ x_2 = \\text{2019-03-21} \\\\ \\qquad \\vdots\\)\n\\(\\therefore x_1,\\dots, x_m \\Rightarrow \\text{2019-03-20}\\) 부터 순서대로 \\(m\\)개의 삼전주식값을 나열\nNote! : \\(w\\)만 알면 \\(x_1,\\dots,x_m\\)의 값이 저절로 결정.\n\\(X_1(w) = x_1 \\\\ X_2(w) = x_2,\\\\ \\qquad \\vdots\\)\n- 가능한 설명모형\n\n\\(14,000,605\\) 개의 평행세계\n우리는 이 중 하나의 세계에 \\(\\frac{1}{14,000,605}\\)의 “확률”로 선택되어져 살고있음.\n\n\\(\\Rightarrow \\Omega=\\{w_1,w_2,\\dots, w_{14,000,605}\\}\\)\n\\(P(\\{w_1\\})=P(\\{w_2\\})=\\dots=P(\\{w_{14,000,605}\\})=\\frac{1}{14,000,605}\\)\n\n하나의 평행세계가 선택 \\(\\Rightarrow\\) 그 평행세계의 모든 사건이 이미 결정.\n\n우리의 우주 \\(=\\) \\(777\\)번째 평행세계 \\(\\Rightarrow w=w_{777}\\)\n\n- 반론 : 미래는 고정되지 않음.\n\\(m+1\\) 시점은 총 \\(52,210-38,590=13,620\\)개의 미래가 가능!\n- 반론의 반론 : 처음부터 \\(14,000,605 \\times 13,620\\) 의 미래를 고려.\n\n\\(m\\)개의 삼전 주가 \\(\\Rightarrow 14,000,605\\)\n\\(m+1\\)개의 삼전주가 \\(\\Rightarrow 14,000,605 \\times 13,620\\)\n\n- 동전 2회\n\\(\\Omega = \\{\\{H,H\\}, \\{H,T\\}\\,\\{T,H\\}, \\{T,T\\}\\}\\)\n\\(\\{H,H\\}: w_1 \\\\ \\{H,T\\}:w_2 \\\\ \\{T,H\\}: w_3 \\\\ \\{T,T\\}:w_4\\)\n\n복습: 확률변수\n\n\n\n기호정리\n\n확률변수: \\(X(w) = x\\).\n확률벡터: \\(\\bf{X}(w) = \\left(X_1(w),\\dots,X_m(w)\\right)=(x_1,\\dots,x_m)\\)\n확률과정: \\(X(w,t) = x_t = x(t)\\)\n\n확률과정은 \\(w\\)와 \\(t\\)의 함수.\n\\(X(w,t)\\)를 \\(X_t(w)\\)로 표기하기도 함.\n고정된 \\(w \\Rightarrow\\) relization이 시간에 따른 함수\n고정된 \\(t \\Rightarrow\\) random variable이 함수\n\n\n(참고) : 고정된 \\(w\\)에 대한 \\(X(w,t)\\)의 relization을 sample path 혹은 sample function이라고 부른다.\n\n\n용어정리1 (\\(\\star\\star\\star\\))\n\\(\\Omega = \\{w_1,\\dots, w_{14,000,605}\\}\\) 이런 평행세계가 있다…\n\n각각의 \\(\\omega\\)에 매핑되는 함수(무한 개의 값들)가 있을 것이고, 시점을 \\(t_0\\)로 고정하면, 첫번째 평행세계에 대해서는 \\(X(w_1, t_0)\\), 두번째 평행세계에 대해서는 \\(X(w_2, t_0)\\), 세번째 평행세계에 대해서는 \\(X(w_3, t_0)\\)가 된다.\n\n\n용어정리2\n모든 \\(\\omega\\)에 대하여 가능한 sample path를 모두 모은 뭉치. \\(\\Rightarrow\\) 앙상블(ensemble)\n\n\n\n앙상블(ensemble)\n\n\n\n앙상블 mean: 1번 timeseries, \\(\\dots\\) 14,000,605번 timeseries를 다 더해서 평균을 낸 것\n\n앙상블 mean : \\(\\sum_{i=1}^{14,000,605}\\frac{1}{14,000,605}\\times(w_i,t) \\Rightarrow \\sim\\)어떤 함수값 (mean function이라고 표현을 많이 함.)\n\n\n\n\nTime Average: 하나의 평행세계의 모든 시점에 대해 평균낸 것.\n\n\n결국 확률변수 \\(X(w)\\)를 줄여서 \\(X\\)로 쓰고, 확률벡터 \\(\\bf{X}(w)\\)를 줄여서 \\(\\bf{X}\\)라 쓰고, 확률과정 \\(X(w,t)\\)를 줄여서 \\(X(t)\\)라고 쓴다.\n\n\\(X(w) \\to X\\)\n\\(\\bf{X}(w) \\to \\bf{X}\\)\n\\(X(w,t) \\to X(t)\\) 또는 \\(X_t\\)\n\n연속 시계열은 확률과정 그 자체이고, 이산 시계열은 원소의 수가 무한한 확률벡터라고 생각할 수 있다.우리가 많이 다루는 것은 이산 시계열이다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro2",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro2",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "시계열 intro2",
    "text": "시계열 intro2\n시계열: 무한차원의 확률벡터 or. 확률과정의 smaple 버전이라고 생각할 수 있다. \\((x_1, x_2, \\dots, \\dots)\\)\n\\(\\{Z_t(w), \\quad t=1,2,\\dots\\}, \\quad\\) \\(\\omega\\): 평행세계의 인덱스\n\n교재의 표현정리\n\n확률과정: \\(X(t)\\)\n확률법칙: \\(P\\)\n확률공간: \\((\\Omega,\\cal{F}, P)\\)\n확률변수: \\(X\\)\n확률변수의 모임: \\(\\bf{X}, X(t)\\) \\(\\leftarrow\\) 확률벡터나 확률과정 모두 의미.\n집합 T: index set of random element2\n\nT의 원소가 1개이면 확률변수\nT의 원소가 유한개이면 확률벡터\nT의 원소가 무한개이면 확률과정\n\n연속형 확률과정 \\(= \\{X(t), \\quad t\\in (0,\\infty)\\}\\)\n\n집합 T가 \\((0,\\infty)\\)와 같이 구간으로 표현된 경우.\n\n이산형 확률과정: (\\(X_1,X_2,X_3,\\dots), (\\dots, X_{-1},X_0,X_1,X_2,\\dots)\\)\n\n집합T가 \\(\\{1,2,3,\\dots\\}, \\{\\dots,-1,0,1,2,\\dots\\}\\)\n\n실현값 (realization)\n\n\\(x\\) : 확률변수의 relization\n\\((x_1,\\dots, x_m)\\) : 확률벡터의 relization\n\\(x(t)\\) : 확률과정의 relization\n\n표본통로 (sample path): \\(x(t)\\)\n\n\n\n확률과정 노테이션 정리\n\n\n\n정상성\n\n정상성 가정이 안되면 시계열분석의 의미가 없다.\n\n\n\n\nensemble\n\n\n\n\n\n예제1. 동전 3번던지기\n동전을 3번 던지면 나올 수 있는 모든 경우의 수는 8가지. 따라서 평행세계가 8개 있다고 하자.\n\\(\\Omega = \\{w_1,\\dots,w_8\\} = \\{HHH,\\dots, TTT\\}\\)\n\\(P(w_1) = P(w_2) = \\dots = P(w_8)=\\frac{1}{8}\\)\n\n\\(\\bf{X}(HHH) = (X_1(HHH),X_2(HHH),X_3(HHH)) = (0,0,0) \\leftarrow\\)확률벡터\n\\(\\bf{X}(TTT) = (X_1(TTT),X_2(TTT),X_3(TTT)) = (1,1,1) \\leftarrow\\)확률벡터\n\n- 동전을 무한번 던진다? \\(\\to\\) 무한 개의 평행세계\n\\(X_t = (X_1,X_2,X_3,X_4,\\dots) \\leftarrow\\) 이산형확률과정 (베르누이 과정)\n\\(x_t = (x_1,x_2,x_3,x_4,\\dots) \\leftarrow\\) relization\n동전을 평생던져야 함.\n현실적인 관측 : \\((x_1,\\dots, x_{t^*-1})\\leftarrow t^*-1\\)\n질문 : \\(E(X+t^*)=\\frac{1}{2}\\times 0 + \\frac{1}{2}\\times 1 = \\frac{1}{2}\\)\n디펜스 : 니가 동전이 공평한 동전인지 어떻게 아느냐?\n\n\n\n큰수의 법칙: 동전을 계속던지다보면 1/2로 수렴하지 않느냐?\n\n\n계속 던지다 보니까 1/2이 나오잖아?\n하지만 시계열 문제에서는 이런식으로 대답을 못한다. 왜냐? \\(n\\)이 하나밖에 없잖아..(반복실험 자체가 불가능하다.3)\n시계열 문제 : \\(n=1\\)\n대안: \\(\\sum_{t=1}^{t^*-1}x_t/(t^*-1)\\)로 ensemble average를 추론.\n\n\\(\\sum_{t=1}^{t^*-1}x_t/(t^*-1)\\)를 time average라고 함.\n\n\niid 일경우 : time average로 ensemble average를 추론. (주황선)\n\\(\\Rightarrow\\) iid의 가정을 약화시키기 위한 노력이 필요함.\n\\(\\Rightarrow\\) 이러한 노력의 결과물이 stationary 가정임.\nstationary 가정은 관측치끼리 독립일 필요도 없고 uncorrelated 되어야할 필요도 없다.\n\\(\\Rightarrow\\) 정상성가정이 없다면 \\(\\Rightarrow\\) 시계열 분석을 할 이유가 없다.\n\n에르고딕..\n\niid일 경우 단점 : 쓸모가 없다. iid를 가정할 수 있으면, 회귀분석을 돌리면 되는데 시계열을 돌릴 필요가 없다. iid가 안되기 때문에 시계열을 돌리는 것. > 과거의 사건이 현재의 사건과 correlation이 있다고 믿고, 독립이 아니라고 믿기 때문에 분석이 어려운 것..\n결국 iid 보다 약한 가정을 찾다보니 stationary라는 가정이 생기게 됨."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#stationary-종류",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#stationary-종류",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "Stationary 종류",
    "text": "Stationary 종류\nStationary 과정은 크게 2가지 버전이 있습니다. Strictly Stationary 버전과 Weak Stationary 버전.\nStrictly Stationary가 더 엄밀한 의미에서의 정상성인데 다루기 힘들다. 어떤 시계열이 strictly stationary하다는 것을 밝히기 쉽지 않다. 그래서 약화된 버전인 Weak Stationary를 많이 사용한다.\n에러텀이 normal 일 경우에는 strictly stationary와 weak stationary의 정의가 같아진다.\n\nStrictly Stationary\n\nDefinition: 시계열 \\(\\{X_t\\}\\) is strictly stationary.4\n\\(\\Leftrightarrow \\forall t_1,\\dots,t_n \\in T\\) & \\(h\\in \\mathbb{Z}\\): \\(\\quad (X_{t_1},\\dots,X_{t_n}) \\overset{d}{=}(X_{t_1+h}, \\dots, X_{t_n+h})\\)\n시계열 \\(X_t\\)의 모든 finite한 샘플에 대해 어떤 임의의 lag에 대해서 확률벡터가 뽑히게 될텐데 확률벡터의 결합분포는 확률벡터를 \\(h\\)만큼 민 또 다른 확률벡터의 결합분포와 동일하다는 의미입니다.\n\n예제\n\\(\\{X_t\\},\\quad t\\in \\cal{T}=\\{0,1,2,3,\\dots\\}\\) \\(\\Rightarrow X_0, X_1, X_2,X_3,X_4,X_5,X_6,X_7,X_8,X_9,X_{10}\\)\n다음의 6개의 샘플을 뽑았다고 하자. \\(h=3\\)이라고 하자.\n\\((X_1,X_3,X_5,X_7,X_9,X_{10}) \\overset{d}{=}(X_{1+3},X_{3+3},X_{5+3},X_{7+3},X_{9+3},X_{10+3})\\)\n이는 시간 축을 \\(h\\) 만큼 이동하여도 결합확률밀도함수가 동일하다는 것을 의미하며, “strictly stationary” 라고 합니다.\n\nlag이 3이든, 4이든 결합분포가 다 똑같아야 합니다. \\(\\to\\) 되게 강한 조건\nfinite sample을 예제 처럼 안뽑고 다르게 뽑더라도 어떤 lag에 관해서도 결합분포가 다 똑같아야 합니다.\n\n\n\nWeak Stationary\n\nDefinition: 시계열 \\(\\{X_t\\}\\) is weak stationary.5\n\\(\\Leftrightarrow E(X_t), \\text{Cov}(X_t, X_{t+h})\\) is not depend on \\(t\\).\n\n평균과 공분산이 \\(t\\)에 의존하지 않는다는 의미이고 그래서 당연히 strictly stationary 하면 weak stationary 하게 됩니다.\n\\(\\bf{X}=\\bf{X}_t = (o,o,\\dots, o,o,\\dots) \\to\\) 무한차원 확률벡터\n\\(E\\bf{X}_t = (o,o,\\dots, o,o,\\dots) \\to\\) 무한차원의 벡터\n\\(\\text{Cov}(\\bf{X}) = \\begin{bmatrix} Cov(X_0,X_0)&Cov(X_0,X_1)&Cov(X_0,X_2)&Cov(X_0,X_3)&\\dots \\\\ Cov(X_1,X_1)&Cov(X_1,X_1)&Cov(X_1,X_2)&Cov(X_1,X_3)&\\dots\\\\ Cov(X_2,X_1)&Cov(X_2,X_1)&Cov(X_2,X_2)&Cov(X_2,X_3)&\\dots\\\\ \\vdots&\\vdots&\\vdots&\\vdots&\\dots \\end{bmatrix}\\to\\) 무한차원의 매트릭스\n\\(t\\)에 디펜드 하지 않다는 것은 \\(t\\)에 따라 값이 일정하다는 의미. 즉, 분산이 일정하다는 의미!6\n\n\n\n색이 같은 부분은 값이 동일함을 나타냅니다.\n\n\n정의상 lag을 임의로 밀어도 평균이나 공분산은 바뀌지 않음을 말하고 있다. 강스테이셔너리에서는 lag을 임의로 밀어도 분포가 같은것을 의미하고 여기서는 lag을 임의로 밀어도 평균이나 공분산이 같음을 말함.\n\\[Cov(X_0,X_1) \\overset{lag1}{=}Cov(X_1,X_2)\\]\n\\[Cov(X_0,X_1) \\overset{lag2}{=}Cov(X_2,X_3)\\]"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html",
    "href": "posts/4_TS2023/2023-05-14-3wk.html",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "",
    "text": "\\(\\{\\epsilon_t\\}\\) is white noise iff1. \\(\\epsilon_t \\overset{\\text{i.i.d.}}{\\sim}(\\mu,\\sigma^2)\\) for all \\(t\\).\n회귀분석에서는 보통 normal 가정을 하는데2 여기서는 normal 가정이 필요 없다. (uniform이나 다른 가정 가능)\n- 특징\nfor all \\(t\\) \\(\\quad E(\\epsilon_t)=\\mu, V(\\epsilon_t)=\\sigma^2\\)\nfor all \\(l\\geq 0\\) \\(\\quad \\text{Cov}(\\epsilon_{t-l},\\epsilon_t)=0\\) 여기서 \\(l\\)은 lag의 약자.\n\\(\\Rightarrow\\) Stationary Process3\n히스토리를 보면 왜 당연한건지 알 수 있다. i.i.d.인 경우에는 에르고딕 성질이 있다..iid는 너무 강한 조건이니까 약한 조건을 찾다 약화시키고 약화시키다보니 Stationary Process가 되었다. 그러니까 당연히 iid는 stationary가 된다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#motive1-과거의-값에-계수값-반영",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#motive1-과거의-값에-계수값-반영",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "motive1 : 과거의 값에 계수값 반영",
    "text": "motive1 : 과거의 값에 계수값 반영\n랜덤워크 방식이 너무 아까움.. 분산이 안터지는 방법이 없을까?\n\\(Z_t = 0.999Z_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim (0,\\sigma^2)\\)\n\n현재=과거+오차\n\n\\(\\begin{align*}Z_t &= \\epsilon_t + 0.999 Z_{t-1}\\\\ &=\\epsilon_t + 0.999(0.999Z_{t-2} + \\epsilon_{t-1}) \\\\ &=\\epsilon_t + 0.999\\epsilon_{t-1} + 0.999^2Z_{t-2}\\\\ &\\vdots \\\\ &=\\epsilon_t + 0.999\\epsilon_{t-1} + 0.999^2 \\epsilon_{t-2} + \\dots \\end{align*}\\)\n\\(\\begin{align*}V(Z_t) &= \\sigma^2 + 0.999^2\\sigma^2 + 0.999^4\\sigma^2 + \\dots\\\\ &= \\sigma^2(1+0.999^2+0.999^4+\\dots) \\quad \\text{<- 무한등비급수}\\\\ &= \\sigma^2\\frac{1}{1-0.999^2} < \\infty \\Rightarrow \\text{t에 depend하지 X} \\end{align*}\\)\n\nCovariance 구하는 것은 생략.. 결과는 \\(t\\)에 depend하지 않습니다.\n\n따라서 Stationary 하다!"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#motive2-기울기-텀-추가",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#motive2-기울기-텀-추가",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "motive2 : 기울기 텀 추가",
    "text": "motive2 : 기울기 텀 추가\n좀 더 좋은 모델을 만들고 싶은 욕심이 생긴다..\n이런 모델을 생각해본다.\n\n\n\nmotive2: 현재 = 과거 + 오차 + 기울기\n\n\n모델 : 현재 = 과거 + 오차 + 기세(기울기)5\n\\(Z_t = \\frac{0.9}{2}Z_{t-1} + \\frac{(Z_{t-1} -Z_{t-2})}{2} + \\epsilon_t\\)\n\\(\\quad\\space = 0.45Z_{t-1} + \\frac{1}{2}Z_{t-1} -\\frac{1}{2}Z_{t-2} + \\epsilon_t\\)\n\\(\\quad\\space = 0.95Z_{t-1} - 0.5Z_{t-2} + \\epsilon_t\\)\n\\(\\quad\\space =\\phi_1 Z_{t-1} + \\phi_2Z_{t-2} + \\phi_3Z_{t-3} + \\dots + \\phi_pZ_{t-p} + \\epsilon_t\\)\n위의 두 모티브에 따라 Stationary를 만들기 위해 계수를 고려하고, 기울기를 적당히 추가해 고려하면 좀 더 일반적이고 설명이 잘 되는 모델을 만들 수 있을 것 같다.\n근데 결국 Stationary가 안되면 쓸모가 없으니까 모티브2의 모델이 Stationary를 만족하는지 확인해 볼 필요가 있다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar모델의-정상성-확인",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar모델의-정상성-확인",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "AR모델의 정상성 확인",
    "text": "AR모델의 정상성 확인\n- AR Process\n\\(\\{Z_t\\}\\) is AR process iff.\n\\(Z_t = \\phi_1Z_{t-1} + \\phi_2Z_{t-2} + \\dots + \\phi_pZ_{t-p} + \\epsilon_t\\)\n\\(BZ_t = Z_{t-1}\\)를 만족하는 \\(B\\)6를 생각하자.\n\\(BZ_{t-1} = Z_{t-2}\\)\n\\(BBZ_{t} = Z_{t-2}\\)\n\\(B^2Z_t = Z_{t-2}\\)\n\\(\\therefore Z_t = \\phi_1BZ_t + \\phi_2B^2Z_t + \\dots \\phi_pB^pZ_t + \\epsilon_t\\)\n\\(Z_t - \\phi_1BZ_t - \\phi_2B^2Z_t - \\dots - \\phi_pB^pZ_t = \\epsilon_t\\)\n\\((1-\\phi_1B-\\phi_2B^2-\\dots-\\phi_pB^p)Z_t = \\epsilon_t\\)\n여기에서 \\((1-\\phi_1B-\\phi_2B^2-\\dots-\\phi_pB^p)=0\\)으로 놓은 식을 특성방정식 이라고 합니다.\n\nAR process의 정상성을 체크하는 법 (교재 p215, p246): 1. 특성방정식을 구한다. 2. 특성방정식을 \\(B\\)에 대하여 푼다. 3. 모든 근의 절댓값이 1보다 큰지 조사한다.\n\n\n연습문제 5.1 (h)\n다음 모형에 의해 설명되는 확률과정 \\(\\{Z_t\\}\\)는 정상성을 갖는지 조사하라.\n\\(Z_t=100+0.5Z_{t-1}+\\epsilon_t, \\quad \\{\\epsilon_t\\}\\)는 \\(WN(0,5)\\) 이다.\n(sol)\n\\(Z_t = 100 + 0.5Z_{t-1} + \\epsilon_t.\\)7\n\\(\\Leftrightarrow Z_t-200 = 0.5(Z_{t-1}-200) + \\epsilon_t.\\)\n여기서 \\(Z_t - 200 = Y_t\\)로 놓고, \\(Z_{t-1}-200=Y_{t-1}\\)로 놓으면,\n\\(Y_t = 0.5Y_{t-1} + \\epsilon_t.\\)8\n\\(\\{Z_t\\}\\)의 정상성을 파악하는 일은 \\(\\{Y_t\\}\\)의 정상성을 파악하기만 하면 충분함.\n(참고) 절편은 생략해도 됩니다. 절편이 있든 없든 AR모델의 정상성을 체크하고 AR모델의 성질을 파악하는 것은 차이가 없어요.\n\\(Y_t = 0.5Y_{t-1} + \\epsilon_t.\\)에서 \\(\\{Y_t\\}\\)가 정상인지만 판단하면 됩니다.\n\\(\\Leftrightarrow Y_t = 0.5BY_t +\\epsilon_t\\)\n\\(\\Leftrightarrow Y_t-0.5BY_t = \\epsilon_t\\)\n\\(\\Leftrightarrow (1-0.5B)Y_t = \\epsilon_t\\)\n\\(\\therefore\\) 특성방정식: \\(1-0.5B=0 \\Rightarrow B=2 \\Rightarrow |B|>1 \\Rightarrow \\{Y_t\\}\\)는 정상.\n\\(\\Rightarrow \\{Z_t\\}\\)도 정상\n(다른 풀이) – 결과는 특성방정식을 이용해 푼 결과와 동일.\n관점1 (t: 시작, \\(-\\infty\\): 끝)\n\\(E(Z_t) = E(Y_t+200) = 200\\)\n\\(Y_t = 0.5Y_{t-1} +\\epsilon_t\\)\n\\(\\quad = \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\dots + Y_{-\\infty}.\\)9\n\\(E(Y_t) = 0 + 0 + \\dots + 0 = 0\\)\n관점2 (0: 시작, \\(\\infty\\): 끝)\n\\(Z_t = 100 + 0.5Z_{t-1}+\\epsilon_t\\)\n\n\\(Z_0 = 0\\)\n\\(Z_1 = 100 + 1\\cdot\\frac{1}{2}+\\epsilon_1\\)\n\\(Z_2 = 100 + (100+\\epsilon_1)\\frac{1}{2}+\\epsilon_2\\)\n\\(Z_3 = 100 + (100+(100+\\epsilon_1)\\frac{1}{2} + \\epsilon_2) + \\epsilon_3\\)\n\\(Z_t = 100 + 100\\times\\frac{1}{2}+ 100\\times \\frac{1}{4} + \\dots\\)\n\n\\(\\therefore E(Z_t) = \\frac{100}{1-\\frac{1}{2}}=200\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\n관점1과 2의 결과는 동일하다.\n\\(Y_t = \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots\\)\n\\(V(Y_t) = 1 + 0.5^2 + 0.5^4 + \\dots = \\frac{1}{1-0.5^2}=\\frac{4}{3}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=1: \\(\\quad Cov(Y_t, Y_{t-1})\\)\n\\(Cov(Y_t, Y_{t-1}) = Cov( \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots, 0 +\\epsilon_{t-1} + 0.5\\epsilon_{t-2} + 0.5^2\\epsilon_{t-3} + \\cdots)\\)\n\\(\\begin{align*}\\therefore Cov(Y_t, Y_{t-1}) &= 0+ 0.5\\sigma^2 + 0.5^3\\sigma^2 + 0.5^5\\sigma^2 + \\cdots \\\\ &= \\left(\\frac{0.5}{1-0.5^2}\\right)\\sigma^2\\end{align*}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=2: \\(\\quad Cov(Y_t, Y_{t-2})\\)\n\\(Cov(Y_t, Y_{t-2}) = Cov( \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots, 0 + 0 +\\epsilon_{t-2} + 0.5\\epsilon_{t-3} + 0.5^2\\epsilon_{t-4} + \\cdots)\\)\n\\(\\begin{align*}\\therefore Cov(Y_t, Y_{t-2}) &= 0+ 0+ 0.5^2\\sigma^2 + 0.5^4\\sigma^2 + 0.5^6\\sigma^2 + \\cdots \\\\ &= \\left(\\frac{0.5^2}{1-0.5^2}\\right)\\sigma^2\\end{align*}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=k: \\(\\quad Cov(Y_t, Y_{t-k})\\)\n\\(Cov(Y_t, Y_{t-k}) = \\sigma^2\\cdot\\frac{0.5^k}{1-0.5^2} \\quad \\leftarrow \\text{not depend on t}\\)\n\\(\\Rightarrow \\{Y_t\\} \\text{ is stationary!}\\)\n특성방정식을 이용해 푼 결과와 동일하다. 특성방정식 매우 좋은 방법이였음..\n\n\n연습문제 5.1 (i)\n\\(Z_t = 1.3Z_{t-1}+\\epsilon_t, \\quad \\epsilon_t \\overset{iid}{\\sim}(0,1)\\)\n(sol1)\n특성방정식: \\(1-1.3B = 0 \\Rightarrow B = \\frac{1}{1.3}\\)\n\\(\\Rightarrow\\) “비정상시계열”\n(sol2)\n\\(Z_t = \\epsilon_t + 1.3\\epsilon_{t-1} + 1.3^2\\epsilon_{t-2}+\\dots\\)\n$V(Z_t)=$ “비정상시계열”"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar1-특성방정식보다-쉽게-정상성-판단하는-법",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar1-특성방정식보다-쉽게-정상성-판단하는-법",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "AR(1): 특성방정식보다 쉽게 정상성 판단하는 법",
    "text": "AR(1): 특성방정식보다 쉽게 정상성 판단하는 법\n\n단, AR(1) 모델 한정해서 정상성 체크. (p191, p218)\n\n\\(\\begin{align*}AR(1): Z_t &= \\phi Z_{t-1} + \\epsilon_t\\\\ \\Rightarrow Z_t &= \\phi BZ_t + \\epsilon\\end{align*}\\)\n\\(\\therefore\\) 특성방정식\\(=1-\\phi B = 0 \\to B=\\frac{1}{\\phi}\\)\n따라서 \\(|\\frac{1}{\\phi}| > 1\\)인지만 체크하면 됨. \\(\\Leftrightarrow |\\phi| < 1\\)\n\n교재: 절편 무시/ 분산 & Cov 유한\n\n결국 AR(1): 현재 = \\(\\phi\\)과거 + 오차10 에서\n\n\\(|\\phi| < 1 \\Rightarrow\\) 과거의 효과가 점차 사라진다.\n랜덤워크와의 차이점은 계수를 적당히 조절해서 수렴시키게 만들 수 있다는 것. 즉, 정상성을 만족하도록 만들 수 있다는 특징이 있다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar2과정이-정상일-조건",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar2과정이-정상일-조건",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "AR(2)과정이 정상일 조건",
    "text": "AR(2)과정이 정상일 조건\n\\(Z_t = \\phi_1 Z_{t-1} + \\phi_2Z_{t-2} + \\epsilon_t\\)\n\\(Z_t = \\phi+1BZ_t + \\phi_2B^2Z_t + \\epsilon_t\\)\n특성방정식: \\(1-\\phi_2B - \\phi_2B^2 = 0\\)\n근11 : \\(\\frac{\\phi_1\\pm \\sqrt{\\phi_1^2+4\\phi_2}}{-2\\phi_2}\\quad\\) 근의 절댓값이 1보다 클 조건.\n\nAR(2) 모델한정 정상성 쉽게 판단하는 법: 1. \\(\\phi_1 + \\phi_2 < 1\\) 2. \\(\\phi_2 - \\phi_1 < 1\\) 3. \\(|\\phi_2| < 1\\) \n다음 조건과 같은 조건을 만족하는 AR(2) 과정을 정상이라고 하며, 특성방정식의 근의 절대값이 1보다 커야한다는 조건과 동치이다.\n\n\n연습문제 5.1 (h)\n\\(Z_t = 100 + 0.5Z_{t-1} + \\epsilon_t\\)\n절편무시, \\(0.5 < 1 \\Rightarrow\\) “정상”\n\n\n연습문제 5.1 (i)\n\\(Z_t = 1.3Z_{t-t} + \\epsilon_t\\)\n\\(1.3 > 1 \\Rightarrow\\) “비정상”\n\n\n연습문제 5.1 (l)\n\\(Z_t = 0.12 + Z_{t-1} + \\epsilon_t\\)\n절편무시 \\(\\phi=1 \\Rightarrow\\) “비정상”\n\n\n\n\n자기공분산함수와 자기상관함수"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar1-acf를-구하자.-교재-6.1.1",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar1-acf를-구하자.-교재-6.1.1",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "# AR(1) acf를 구하자. (교재 6.1.1)",
    "text": "# AR(1) acf를 구하자. (교재 6.1.1)\nLeg \\(\\{Z_t\\}\\) be \\(AR(1)\\) with \\(\\phi\\). i.e\n\\(\\begin{align*}Z_t &= \\phi Z_{t-1} +\\epsilon_t, \\quad \\epsilon_t\\sim (0,\\sigma^2) \\\\ &=\\epsilon_t + \\phi \\epsilon_{t-1} + \\phi^2\\epsilon_{t-2}+\\dots\\end{align*}\\)\n\n\n\n$Cov(Z_t, Z_{t-h})\n\n\n\\(\\therefore Cov(Z_t, Z_{t-h}) = \\frac{\\phi^h}{1-\\phi^2}\\sigma^2=\\gamma(h)\\)\n\\(acf(h)=\\frac{\\gamma(h)}{\\gamma(0)}=\\frac{\\frac{\\phi^h}{1-\\phi^2}}{\\frac{1}{1-\\phi^2}}=\\phi^h\\)12\n\n\n\nacf를 쉽게 계산하는 방법 따윈 없어.. 정석대로 하자."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#gammah와-textacfh의-성질-교재-5.3",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#gammah와-textacfh의-성질-교재-5.3",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "\\(\\gamma(h)\\)와 \\(\\text{acf}(h)\\)의 성질 (교재 5.3)",
    "text": "\\(\\gamma(h)\\)와 \\(\\text{acf}(h)\\)의 성질 (교재 5.3)\n\n\n\n성질1. 분산은 시간에 depend 하지 않으니까~\n\n\n\n\n\n성질2.\n\n\n\n\n\n성질3.\n\n\n\n\n\n성질4. 코쉬-슈바르츠로 증명 가능"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar2-textacf를-구하라.",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar2-textacf를-구하라.",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "# \\(AR(2)\\) \\(\\text{ACF}\\)를 구하라.",
    "text": "# \\(AR(2)\\) \\(\\text{ACF}\\)를 구하라."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#교재6.1.2-ar2의-acf-형태.",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#교재6.1.2-ar2의-acf-형태.",
    "title": "[TS] 3wk. 여러가지 확률과정 (random walk, AR)",
    "section": "교재6.1.2 AR(2)의 ACF 형태.",
    "text": "교재6.1.2 AR(2)의 ACF 형태.\n\n\n\nAR(2)의 ACF 형태\n\n\n\n\n\nType1. 지수적으로 감소, Type2. 점차 소멸하는 sin 함수"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-13-5장연습.html",
    "href": "posts/4_TS2023/2023-05-13-5장연습.html",
    "title": "[TS] 2wk-2. 연습문제 5.1",
    "section": "",
    "text": "다음의 모형들에 의해 설명되는 확률과정 \\(\\{Z_t\\}\\)는 정상성을 갖는가? 이를 논하라.\n\n\n\\(Z_t = A\\sin(\\frac{2}{3}\\pi t + U)\\), \\(A\\)는 평균이 \\(0\\)이고, 분산이 \\(1\\)인 확률변수이고 \\(U\\)는 상수이다.\n\n\n\n5.1 (c)\n\n\n\n\n\n\\(Z_t=A\\sin(\\pi t+U)\\), \\(A\\)는 평균이 \\(0\\)이고 분산이 \\(1\\)인 확률변수이고 \\(U\\)는 구간 \\([-\\pi, \\pi]\\)에서 일양분포를 따르는 확률변수이다. 또한 \\(A\\)와 \\(U\\)는 서로 독립이다.\n\n\n\n5.1 (d)\n\n\n\n\n\n5.1 (d) lag=2\n\n\n\n\n\n5.1 (d) lag=3,4,…\n\n\n\n\n\n\\(Z_t = A\\cos(\\frac{1}{2}\\pi t) + B\\sin(\\frac{1}{2}\\pi t)\\), \\(A\\)와 \\(B\\)는 서로 독립이고 각각 평균 \\(0\\), 분산 \\(1\\)을 갖는 확률변수들이다.\n\n\n\n5.1 (e)\n\n\n\n\n\n\n\n\n5.1 (f), (k)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-22-6kw-2.html#wold의-관찰",
    "href": "posts/4_TS2023/2023-05-22-6kw-2.html#wold의-관찰",
    "title": "[TS] 6wk. wold의 관찰 / MA / ARMA",
    "section": "Wold의 관찰",
    "text": "Wold의 관찰\n\\(\\begin{cases}X_t = p_t + z_t \\\\ z_t = \\epsilon_t + \\psi_1\\epsilon_{t-1} + \\psi \\epsilon_{t-2} + \\dots\\end{cases}\\)\n\\(\\begin{align*}z_t &= 0.5z_{t-1} + \\epsilon_t\\\\ &=\\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2 \\epsilon_{t-2} + \\dots \\\\ &= \\sum_{i=1}^\\infty \\psi_j \\epsilon_{t-j}\\end{align*}\\)\n이를 \\(MA(\\infty)\\), 무한 MA가정이라고 합니다.\n\n\\(MA(1) : Z_t = \\epsilon_t -\\theta_1\\epsilon_{t-1}\\)\n\\(MA(2) : Z_t = \\epsilon_t -\\theta_1\\epsilon_{t-1}-\\theta_2\\epsilon_{t-2}\\)\n\\(\\vdots\\)\n\\(MA(\\infty)\\) : \\(Z_t = \\epsilon_t -\\theta_1\\epsilon_{t-1} -\\theta_2\\epsilon_{t-2}-\\dots\\)\n\n\\(\\psi_1 = -\\theta_1 , \\psi_2 =-\\theta_2 \\cdots\\)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-22-6kw-2.html#ar1",
    "href": "posts/4_TS2023/2023-05-22-6kw-2.html#ar1",
    "title": "[TS] 6wk. wold의 관찰 / MA / ARMA",
    "section": "AR(1)",
    "text": "AR(1)\n\n- \\(|\\phi|<1\\)\n\\(AR(1):\\)\n\\(Z_t = \\phi Z_{t-1} + \\epsilon_t \\\\ =\\phi^2Z_{t-2} + \\phi\\epsilon_{t-1} + \\epsilon_t\\\\ = \\epsilon_t + \\phi\\epsilon_{t-1} +\\phi^2\\epsilon_{t-2} + \\phi^3Z_{t-3}\\\\ = \\epsilon_t + \\phi\\epsilon_{t-1} +\\phi^2\\epsilon_{t-2} + \\phi^3Z_{t-3} + \\phi^4Z_{t-4} \\\\ = \\epsilon_t + \\phi\\epsilon_{t-1} +\\phi^2\\epsilon_{t-2} + \\phi^3Z_{t-3} + \\phi^4Z_{t-4} + \\dots\\\\ \\vdots\\\\ =\\epsilon_t + \\phi\\epsilon_{t-1}+\\phi^2\\epsilon_{t-2}+\\dots\\)\n\n\\(Z_{t-1}, Z_{t-2}, \\dots, Z_{t-4},\\dots\\)가 안없어지잖아? 없어져야 의미가 있을 것 같은데\n\n\\(Z_t = \\phi^2Z_{t-2} + \\sum_{h=0}^{L-1}\\phi^h\\epsilon_{t-h}\\)\n\\(Z_t = \\sum_{h=0}^\\infty \\phi^h\\epsilon_{t-h}\\)\n결국 \\(\\lim_{L\\to\\infty} \\phi^LZ_{t-L} =0\\) 이어야함.\n\\(|\\phi| < 1, |Z_{t-2}|<M,\\quad \\phi^2M\\underset{L\\to\\infty}{\\to} 0\\) 이럼 되는거 야니야 라고 생각할 수 있지만\n\\(Z_t\\)가 연속적인 분포에서 뽑힌다면, 이론적으로 정규분포 같은애들은 무한히 큰 값이 나올 수 있잖아?\n그런데 보이지 못함.. 좀 바꿔서 확률개념을 좀 섞어서\n\\(Z_t\\)가 연속적으로 큰 값이 뽑힐 수는 있겠으나 그렇게 뽑히는 확률이 매우 적으니까\n평균적인 값은 \\(0\\)으로 간다!\n\\(\\lim_{L\\to\\infty}E[Z_t-\\sum_{h=0}^L \\phi^h \\epsilon_{t-h}]^2 =0\\)\n평균적으로 \\(0\\)이라는 것은 \\(Z_t \\overset{L_2}{=} \\sum_{h=0}^\\infty \\phi^h\\epsilon_{t-h}\\)1\n결론은 \\(Z_t=\\sim\\sim\\sim\\)에 있는 등호는 사실 진짜 등호가 아니라는 것을 이해하면 된다.\n\n\n\n- \\(|\\phi|>1\\)\n이번에는 \\(|\\phi|>1\\)인 AR(1) 모형을 생각해보자.\n\\(AR(1): Z_t = \\phi Z_{t-1} + \\epsilon_t, \\quad |\\phi|>1.\\\\ \\lim_{L\\to\\infty} \\phi^2 Z_{t-L}\\)\n\\(\\Rightarrow\\)수렴하지 않는다.\n\\(Z_t = \\sum_{h=0}^\\infty \\phi^h\\epsilon_{t-h}.\\) 이런식으로 표현할 수 없다.\n\\(Z_t = 2Z_{t-1} + \\epsilon_t\\\\ \\quad =\\epsilon_t + 2\\epsilon_{t-1} + 4\\epsilon_{t-2} + 8\\epsilon_{t-3} + \\dots\\)\n이게 \\(0\\)으로 안가.. (분산이 터지잖아!)\n\\(Z_t = 2Z_{t-1}+\\epsilon_t.\\) 이 식을\n\\(Z_{t+1} = 2Z_t + \\epsilon_{t+1}\\) 이렇게 생각해보자.\n$Z_t = Z_{t+1} + {t+1} \\ ={t+1}+(Z_{t+2} + _{t+2})\\ $\n\\(\\quad Z_{t+1}=\\frac{1}{2}Z_{t+2}+\\frac{1}{2}\\epsilon_{t+2}\\) 얘를 대입한 것임.\n\\(\\quad = \\frac{1}{2}\\epsilon_{t+1} + \\frac{1}{4}Z_{t+2}+\\frac{1}{4}\\epsilon_{t+2}\\)\n\\(\\quad \\overset{L_2}{=}\\frac{1}{2}\\epsilon_{t+1} + \\frac{1}{4}\\epsilon_{t+2} + \\frac{1}{8}\\epsilon_{t+3}+\\dots\\)\n\\(\\phi=\\frac{1}{2}\\)인 정상시계열이랑 비슷한데?\n \\(Z_t = \\epsilon_t + 0.5\\epsilon_{t-1} + \\dots\\) 이 식은 지금 현재시점을 과거에서부터 이어온 시점으로 표현한 것인데\n\\(Z_t = \\frac{1}{2}\\epsilon_{t+1} + \\frac{1}{4}\\epsilon_{t+2} + \\frac{1}{8}\\epsilon_{t+3}+\\dots\\) 이런식으로 미래의 시점으로도 표현 가능하다.\n결국 정상이라고 주장할 수 있는 상태가 됩니다!\n\n\n- 현재시점을 미래시점으로 표현 (Stationary future dependent)\n\\(Z_t = 2Z_{t-1} + \\epsilon_t, \\quad \\epsilon_t\\overset{iid}{\\sim} N(0,1)\\)\n\\(\\quad \\overset{L_2}{=} \\frac{1}{2}\\epsilon_{t+1} + \\frac{1}{4}\\epsilon_{t+2} + \\dots\\)\n Stationary 한데 미래값에 의존하여 stationary하다고 해서 Stationary future dependent AR(1) 모델이라고 합니다. \n\n\n- 현재시점을 과거에서부터 이어온 시점으로 표현 (우리가 배우던 것)\n\\(Y_t = 0.5Y_{t-1} + \\eta t, \\quad \\eta_t\\overset{iid}{\\sim} N(0,\\frac{1}{4})\\)\n\\(\\quad \\overset{L_2}{=}\\eta_t + \\frac{1}{2}\\eta_{t-1} + \\frac{1}{4}\\eta_{t-2} + \\dots\\)\n이건 그냥 stationary하다고 표현\n\n\n- 이상한점과 새로운 관점\n\\(Z_t\\)와 \\(Y_t\\)는 분포가 똑같게 된다.\n그런데 \\(Z_t\\)는 비정상시계열이고 \\(Y_t\\)는 정상시계열이다. 이상한데?\n\\(Z_t, Y_t\\)의 분포는 같은데 하나는 정상 하나는 비정상 이거 이상하다\n여기서 새로운 개념이 등장하게 되는데\n\\(Z_t\\)도 정상으로 보자는 것이다.\n \\(\\overset{L_2}{=}\\) 이런식으로 표현이 되면 정상으로 보자는 얘기다.\n그렇게 되면 다 정상으로 되는 거 아닌가요? \\(\\to\\) 아님. \\(\\phi=1\\)일 때는 안됩니다!\n\\(\\phi=1: \\quad Z_t = \\epsilon_t + \\epsilon_{t-1} + \\dots\\)\n그래서 \\(\\phi=1\\)일 때를 제외하고는 AR을 다 stationary하다고 보는 사람들도 있음..\n\n\n미래에서부터 시계열을 관찰한다면 정상시계열의 개념이 달라지지 않을까?\n\n\n\n(분홍):현재시점에서부터 삼전주식 관찰 (검정): 벤자민버튼이 뒤(미래)에서부터 삼전주식을 관찰\n\n\n\n[분홍] 갈수록 분산이 커져서 이건 비정상 시계열이네\n검정: 뒤로갈수록 안정화되는 시계열로 보임.\n\n그래서 미래에서보면 정상시계열로 보일 수 있다.\n그래서 관점이 2개이다.\n관점1에서는 \\(Z_t = 2Z_{t-1} + \\epsilon_t\\)가 없는시계열\n관점2에서는 \\(Z_t = 2Z_{t-1} + \\epsilon_t\\) 쓸모가 없는 시계열.. (실제로는 미래를 예측하고 싶은거잖아..) - 인과성이 없다. (causality가 없다.) 과거에서 미래로 가야 원인/결과가 있을 건데..이건 그럴수가 없지\n관점1 : 정상시계열 (과거에서부터 오는 정상만 인정) 에 관심\n관점2 : causal & stationary. (미래에서부터 오는 정상도 인정) 에 관심\n(참고) \\(Y_t = 0.5Y_{t-1} + \\eta t\\) 이런걸 causal하다라고 한다.\n결국 말은 다르지만 관심있는 건 같다라는 소리.\nㅇ아아아아아ㅏ악"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-22-6kw-2.html#invertable-ma",
    "href": "posts/4_TS2023/2023-05-22-6kw-2.html#invertable-ma",
    "title": "[TS] 6wk. wold의 관찰 / MA / ARMA",
    "section": "invertable MA",
    "text": "invertable MA\n\\(Z_t = \\epsilon_t -\\theta_1\\epsilon_{t-1} -\\theta_2\\epsilon_{t-2} -\\dots -\\theta_q\\epsilon_{t-q}\\)\n\\(MA(q)\\) : 유한차수 MA는 정상시계열이 된다.\n임의의 정상시계열 \\(Z_t\\)는\n\\(\\begin{cases}Z_t=\\psi_0\\epsilon_t + \\psi_1\\epsilon_{t-1} + \\dots\\\\ \\sum|\\psi_j|<\\infty\\end{cases}\\)\n유한 차수 MA니까 위와 같은 식으로 표현이 되고, 유한차수니까 절댓값을 취해서 다 더해봤자 \\(\\infty\\)보다 작으니까 정상시계열\n사실 MA모델과 AR모델은 표현상의 차이일 뿐!\n\n\\(Z_t = \\phi_1Z_{t-1} + \\phi_2Z_{t-2} + \\dots + \\phi_pZ_{t-p}+\\epsilon_t\\) (MA식 표현)\n\\(Z_t - \\phi_1Z_{t-1} - \\phi_2Z_{t-2} - \\dots - \\phi_pZ_{t-p}=\\epsilon_t\\) (AR식 표현)\n\n- 예제\n\\(Z_t = \\epsilon_t + 0.2\\epsilon_{t-1}, \\quad \\epsilon_t \\overset{iid}{\\sim} N(0,25)\\)\n\\(Y_t = \\eta_t + 5\\epsilon_{t-1}, \\quad \\eta_t \\overset{iid}{\\sim} N(0,1)\\)\n\\(\\gamma(h)=\\begin{cases} 26 & h=0 \\\\ 5 & h=1 \\\\ 0 & h>1\\end{cases}\\)\n여기서 \\(\\gamma(h)\\) 는 covariance\n\\(cov(Z_t, Z_t) = cov(\\epsilon_t + 0.2\\epsilon_{t-1},\\epsilon_t+0.2\\epsilon_{t-1})\\\\ \\qquad=V(\\epsilon_t) + 0.2^2V(\\epsilon_{t-1}) = 25 + 1\\)\n\\(cov(Y_t,Y_t) = 25 + 1 = 26\\)\n둘 다 노말분포이고, 평균은 \\(0\\)으로 똑같으니까 covariance가 같으면 같은 분포를 갖는 것이므로 \\(Z_t\\) 와 \\(Y_t\\)는 같은 분포를 갖음.\n유한차수 MA모델이니까 당연히 정상 모델인데 ACF가 똑같은 모델이 존재한다는 것.\n정상이면서 ACF가 같은 모델이 2개있으니까 하나 버려!\n결론적으로는 \\(Y_t\\)를 버린다. (두 정상시계열을 AR식 표현으로 나타냈을 때 \\(Z_t\\)는 causal하지만 \\(Y_t\\)는 그렇지 않다.)\n즉, \\(Y_t\\)는 정상시계열이긴 한데 causal하지 않은 정상시계열인 것이죠.\n이건 이제 AR식 표현이고,\nMA식표현하면 invertable한 것에만 관심이 있는데, \\(Z_t\\)는 invertable, \\(Y_t\\)는 invertable 하지 않음을 의미.\n즉, 버려진 \\(Y_t\\)는 invertable 하지 않은 애!"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-22-6kw-2.html#summary",
    "href": "posts/4_TS2023/2023-05-22-6kw-2.html#summary",
    "title": "[TS] 6wk. wold의 관찰 / MA / ARMA",
    "section": "Summary",
    "text": "Summary\n유한차수 MA모델은 항상 정상이다.\n그런데 유한차수 MA모델은 무한차수 AR모델로 바꿀 수 있다. (이항하면 됨) 등호를 의미있게 만들려다 보니 어떤 것은 표현식이 causal한데 어떤건 causal하지 않다. causal하지 않다는 것은 invertable하지 않다라고 표현을 한다.\nAR모델에서 causal한 것만 다루듯이 MA모델에서도 invertable 한것만 다룬다.\nMA모델에서 가역성을 보이려면\n\\(Z_t = \\epsilon_t - \\theta_1\\epsilon_{t-1} -\\theta_2\\epsilon_{t-2}-\\dots -\\theta_q\\epsilon_{t-q}\\\\ \\quad= (1-\\mathbb{B}\\theta_1 - \\mathbb{B}^2\\theta_2-\\dots -\\mathbb{B}^q\\theta_q)\\epsilon_t\\)\n위 식을 \\(\\mathbb{B}\\) 에 대하여 풀고, \\(\\mathbb{B}\\)의 모든 근의 절댓값이 \\(1\\)보다 큼을 보이면 됨. (=모든 근이 단위원 밖에 있다.)\nMA모델은 AR모델의 거울같은 존재(duality)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-22-6kw-2.html#arma",
    "href": "posts/4_TS2023/2023-05-22-6kw-2.html#arma",
    "title": "[TS] 6wk. wold의 관찰 / MA / ARMA",
    "section": "ARMA",
    "text": "ARMA\n\n\\(Z_t - \\phi_1Z_{t-1} -\\dots -\\phi_pZ_{t-p} \\\\ = \\epsilon_t-\\theta_1\\epsilon_{t-1} - \\dots -\\theta_q\\epsilon_{t-q}\\)\n\n\nARMA(1,1)\n\nAR식, MA식 표현 모두 가능\n\n\\(Z_t -\\phi Z_{t-1} = \\epsilon_t-\\theta_1\\epsilon_{t-1}.\\)\n\\(Z_t = \\phi Z_{t-1} + \\epsilon_t - \\theta_1\\epsilon_{t-1}.\\)\n\n\n우리가 관심있는 ARMA 모델: Stationary & intertable\n- AR part만 봤을 때: Stationary (Causal Stationary)\n- MA part만 봤을 때: invertable"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-19-5wk.html",
    "href": "posts/4_TS2023/2023-05-19-5wk.html",
    "title": "[TS] 5wk. PACF",
    "section": "",
    "text": "PACF\nsuppose \\(Y_t = \\phi Y_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim \\begin{cases} 1 & wp \\frac{1}{2} \\\\ -1 & wp \\frac{1}{2}\\end{cases}, \\text{with } \\phi=0.5\\)\n\n\n\n\\(Y_0\\)\n\\(Y_1\\)\n\\(Y_2\\)\n\n\n\n\n2\n2\n2\n\n\n2\n2\n0\n\n\n2\n0\n1\n\n\n2\n0\n-1\n\n\n6\n4\n3\n\n\n6\n4\n1\n\n\n6\n2\n2\n\n\n6\n2\n0\n\n\n10\n6\n4\n\n\n10\n6\n2\n\n\n10\n4\n3\n\n\n10\n4\n1\n\n\n\n- 관찰1\n\\(Y_0, Y_2\\) : 선형관계가 있어보인다.1\n- 관찰2:\n\\(Y_1\\)을 given2 하면 \\(Y_0, Y_2\\)는 선형관계가 없어보인다.\n\n\\(Y_1=0\\)\n\n\n\n\n\\(Y_0\\)\n\\(Y_2\\)\n\n\n\n\n2\n1\n\n\n2\n-1\n\n\n\n\n\\(Y_1 =2\\)\n\n\n\n\n\\(Y_0\\)\n\\(Y_2\\)\n\n\n\n\n2\n2\n\n\n2\n0\n\n\n6\n2\n\n\n6\n0\n\n\n\n(iii)$ Y_1=4$\n\n\n\n\\(Y_0\\)\n\\(Y_2\\)\n\n\n\n\n6\n3\n\n\n6\n1\n\n\n10\n3\n\n\n10\n1\n\n\n\n- 관찰3\n\\(Y_0\\)를 given해도 \\(Y_1,Y_2\\)는 선형관계가 있다.\n- 관찰4\n\\(Y_2\\)를 given해도 \\(Y_0, Y_1\\)은 선형관계가 있다.\n- 결론\n\\(Y_0\\)와 \\(Y_2\\)의 순수한 선형관계(=부분자기상관계수) 를 구하려면 \\(Y_1\\)을 통제3해야함.\n(예시)\n\\(Y_0\\): 교회의수, \\(Y_1\\): 인구 수, \\(Y_2\\): 범죄 수\n교회의 수와 인구 수는 직접적인 관련이 있는데 교회의 수와 범죄 수는 직접적인 관련이 없다.\n그런데 만약 “인구” 라는 요인을 통제 하지않고 단순히 교회 수(\\(Y_0\\))와 인구 수(\\(Y_2\\))만 봤을 때 교회의 수가 증가할 수록 범죄 수가 증가하네? 이렇게 해석이 된다. \\(\\to\\) 즉, 인구의 수가 같은 주들끼리 놓고 봐야한다.\n\\(Y_0\\)와 \\(Y_2\\)의 순수한 선형관계를 보고싶다면 \\(Y_1\\)을 통제해야 한다.\n\\(Cor(Y_0,Y_2|Y_1)\\)\n\n\n\n\n\nFootnotes\n\n\n\\(Y_0\\)이 증가할때 \\(Y_2\\)도 평균적으로 증가해보임.↩︎\n\\(Y_1\\)을 통제한다고 생각하면 됩니다.↩︎\n\\(Y_1\\)을 given, \\(Y_1\\)의 효과를 제거↩︎"
  },
  {
    "objectID": "posts/4_TS2023/ts8week_2.html",
    "href": "posts/4_TS2023/ts8week_2.html",
    "title": "[TS] 8wk-2. 7장 연습문제",
    "section": "",
    "text": "\\[\n(1-B)Z_t=5+(1-0.5B)\\epsilon_t\n\\] 정리하면 \\[\nZ_t=5+Z_{t-1}+\\epsilon_t-0.5\\epsilon_{t-1}\n\\]\n\n## 7.5 model 2 \nset.seed(777)\ne<-rnorm(10000)\nz<-e*0\nz[1]<-5\nfor(t in 2:10000) z[t]<-5+z[t-1]+e[t]-0.5*e[t-1]\n\n\n## (a)\noptions(repr.plot.width=10, repr.plot.height=3,repr.plot.res=300)\nplot(z)\n\n\n\n\n\n## (b)\nacf(z)\npacf(z)\n\n\n\n\n\n\n\n\n## (c) \nw<-c(5,diff(z))\nplot(w)\nacf(w)\npacf(w)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n(1-0.3B)(1-B)Z_t=100+(1-0.5B)\\epsilon_t\n\\] 정리하면 \\[\nZ_t=100+1.3Z_{t-1}-0.3Z_{t-2}+\\epsilon_t-0.5\\epsilon_{t-1}\n\\]\n\\[\n(1-0.3B)W_t=100+(1-0.5B)\\epsilon_t\n\\] \\[\nW_t-0.3W_{t-1}=100+\\epsilon_t-0.5\\epsilon_{t-1}\n\\] \\[\n\\mu-0.3\\mu=100\n\\] \\[\n\\mu=100/0.7\n\\]\n\n100/0.7\n\n142.857142857143\n\n\n\n## 7.5 model 3 \nset.seed(777)\ne<-rnorm(10000)\nz<-e*0\nz[1]<-0\nz[2]<-100/0.7\nfor(t in 3:10000) z[t]<-100+1.3*z[t-1]-0.3*z[t-2]+e[t]-0.5*e[t-1]\n\n\n## (a)\nplot(z)\n\n\n\n\n\n## (b)\nacf(z)\npacf(z)\n\n\n\n\n\n\n\n\n## (c)\nw<-c(100/0.7,diff(z))\nplot(w)\nacf(w)[1:5]\npacf(w)[1:5]\n\n\n\n\n\nAutocorrelations of series ‘w’, by lag\n\n     1      2      3      4      5 \n-0.184 -0.039 -0.021 -0.012  0.018 \n\n\n\n\n\n\nPartial autocorrelations of series ‘w’, by lag\n\n     1      2      3      4      5 \n-0.184 -0.075 -0.044 -0.029  0.007 \n\n\n\n\n\nACF그림을 보면 MA(1)처럼 보인다. 즉 아래모형인듯하다. \\[\nW_t=100/0.7+\\epsilon_t+\\theta\\epsilon_{t-1}\n\\] SACF결과로부터 \\(\\hat{\\rho}_1=-0.184\\)이다. MA(1)의 이론적인 ACF의 값은 \\[\n\\rho_1=\\frac{\\theta}{1+\\theta^2}\n\\] 이므로, \\[\n-0.184=\\frac{\\theta}{1+\\theta^2}\n\\] 를 풀면 \\(\\theta\\)를 추정할 수 있다. \\[\n0.184\\theta^2+\\theta+0.184=0\n\\]\n\n\nprint((-1+sqrt(1-4*0.184^2))/(2*0.184))\nprint((-1-sqrt(1-4*0.184^2))/(2*0.184))\n\n[1] -0.1906908\n[1] -5.244092\n\n\n\n우리는 가역인 모델에 관심이 있으므로 \\[\\theta=-0.191\\] 이라고 볼 수 있다.\n즉 아래의 모형을 적합할 수 있다. \\[\n\\mbox{적합된모형}: W_t=\\epsilon_t-0.191\\epsilon_{t-1}\n\\]\n하지만 실제모델은 아래와 같다. \\[\n\\mbox{실제모형}: W_t=0.3W_{t-1}+\\epsilon_t-0.5\\epsilon_{t-1}\n\\]\n\n(모델1) \\[\nW_t=\\epsilon_t-0.191\\epsilon_{t-1}\n\\]\n(모델2) \\[\nW_t=0.3W_{t-1}+\\epsilon_t-0.5\\epsilon_{t-1}\n\\]\n\n사실 위의 두 모형은 거의 구별할 수 없다.\n\n먼저 (모델1)의 이론적인 ACF는 아래와 같다.\n\n\n\n\\(\\rho_1\\)\n\\(\\rho_2\\)\n\\(\\rho_3\\)\n\\(\\rho_4\\)\n\\(\\rho_5\\)\n\\(\\dots\\)\n\n\n\n\n−0.184\n0\n0\n0\n0\n\n\n\n\n이론적인 PACF는 아래와 같다.\n\n\n\n\n\n\n\n\n\n\n\n$_{11} $\n\\(\\phi_{22}\\)\n\\(\\phi_{33}\\)\n\\(\\phi_{44}\\)\n\\(\\phi_{55}\\)\n\\(\\dots\\)\n\n\n\n\n−0.184\n-0.0350423953\n-0.0066819524\n-0.0012741846\n-0.0002429753\n\n\n\n\n\n## \nfind_phi<-function(rho){\n  phi_11<-rho[1]\n  denominator2<-c(1,rho[1],\n                  rho[1],1)\n  denominator3<-cbind(1,rho[1],rho[2],\n                      rho[1],1,rho[1],\n                      rho[2],rho[1],1)\n  denominator4<-cbind(1,rho[1],rho[2],rho[3],\n                      rho[1],1,rho[1],rho[2],\n                      rho[2],rho[1],1,rho[1],\n                      rho[3],rho[2],rho[1],1)\n  denominator5<-cbind(1,rho[1],rho[2],rho[3],rho[4],\n                      rho[1],1,rho[1],rho[2],rho[3],\n                      rho[2],rho[1],1,rho[1],rho[2],\n                      rho[3],rho[2],rho[1],1,rho[1],\n                      rho[4],rho[3],rho[2],rho[1],1)\n  dim(denominator2)<-c(2,2)\n  dim(denominator3)<-c(3,3)\n  dim(denominator4)<-c(4,4)\n  dim(denominator5)<-c(5,5)\n  \n  numerator2<-cbind(denominator2[,-2],rho[1:2])\n  numerator3<-cbind(denominator3[,-3],rho[1:3])\n  numerator4<-cbind(denominator4[,-4],rho[1:4])\n  numerator5<-cbind(denominator5[,-5],rho[1:5])\n\n  phi_22<-det(numerator2)/det(denominator2)\n  phi_33<-det(numerator3)/det(denominator3)\n  phi_44<-det(numerator4)/det(denominator4)\n  phi_55<-det(numerator5)/det(denominator5)\n  c(phi_11,phi_22,phi_33,phi_44,phi_55)\n}\nprint(find_phi(c(-0.184,0,0,0,0)))\n\n[1] -0.1840000000 -0.0350423953 -0.0066819524 -0.0012741846 -0.0002429753\n\n\n\n교재 p.229에 제시된 MA(1)과정의 PACF공식을 참고하여 계산해도 된다. 예를들면 Lag=2일 경우는 아래와 같다.\n\n(-(0.1906908)^2*(1-0.1906908^2))/(1-0.1906908^6)\n\n-0.0350423996953854\n\n\n\n\n\n\n\n\n이제 (모델2)의 ACF를 따져보자.\n\n\n\\[\nW_t=\\frac{1-0.5B}{1-0.3B}\\epsilon_t=(1+0.3B+0.3^2B^2+0.3^3B^3+\\dots)\\epsilon_t-0.5B(1+0.3B+0.3^2B^2+0.3^3B^3+\\dots)\\epsilon_t.\n\\]\n\n\n이다. lag=0임을 가정하면,\n\n\n| | \\(\\epsilon_t\\)의 계수 | \\(\\epsilon_{t-1}\\)의 계수 | \\(\\epsilon_{t-2}\\)의 계수 | \\(\\epsilon_{t-3}\\)의 계수 | \\(\\epsilon_{t-4}\\)의 계수 | \\(\\dots\\) | |—|———————|———————|———————|———|———|———| |\\(W_t\\) | 1 | 0.3-0.5 | 0.3(0.3-0.5) | 0.3^2(0.3-0.5) | 0.3^3(0.3-0.5) |\\(W_t\\) | 1 | 0.3-0.5 | 0.3(0.3-0.5) | 0.3^2(0.3-0.5) | 0.3^3(0.3-0.5)\n\n\n이므로, \\(\\gamma_0=1+\\frac{(0.3-0.5)^2}{1-0.3^2}=1.043956\\)가 된다.\n\n\n\n\ngamma0<-1+(0.3-0.5)^2/(1-0.3^2)\nprint(gamma0)\n\n[1] 1.043956\n\n\n\n\n\n\n\n\nlag=1이라고 하면,\n\n\n| | \\(\\epsilon_t\\)의 계수 | \\(\\epsilon_{t-1}\\)의 계수 | \\(\\epsilon_{t-2}\\)의 계수 | \\(\\epsilon_{t-3}\\)의 계수 | \\(\\epsilon_{t-4}\\)의 계수 | \\(\\dots\\) | |—|———————|———————|———————|———|———|———| |\\(Z_t\\) | 1 | 0.3-0.5 | 0.3(0.3-0.5) | 0.3^2(0.3-0.5) | 0.3^3(0.3-0.5) |\\(Z_{t-1}\\) | | 1 | 0.3-0.5 | 0.3(0.3-0.5) | 0.3^2(0.3-0.5) |\n\n\n이므로, \\(\\gamma_1=(0.3-0.5)+\\frac{0.3(0.3-0.5)^2}{1-0.3^2}=-0.1868132\\)가 된다. 따라서 \\[\n\\rho_1=\\frac{ -0.1868132}{1.043956}=-0.1789474\n\\] 가 된다. 이후의 ARMA과정은 \\[\n\\rho_2=\\rho_1\\phi=\\rho_1\\times 0.3\n\\] \\[\n\\rho_3=\\rho_1\\times 0.3^2\n\\] 등을 따르므로, (모델2)의 이론적인 ACF와 PACF는 아래와 같다.\n\n\n| \\(\\rho_1\\)| \\(\\rho_2\\) | \\(\\rho_3\\) | \\(\\rho_4\\) | \\(\\rho_5\\) | \\(\\dots\\) | |———|———-|———-|———-|———-|———| | -0.1789474 | -0.05368422 | -0.01610527 | -0.00483158 | -0.00483158 | |\n\n\n이론적인 PACF는 아래와 같다.\n\n\n| $_{11} $| \\(\\phi_{22}\\) | \\(\\phi_{33}\\) | \\(\\phi_{44}\\) | \\(\\phi_{55}\\) | \\(\\dots\\) | |———|———-|———-|———-|———-|———| | -0.17894740 | -0.08854169 | -0.04415586 | -0.02206360 | -0.01456021 | |\n\n\n\n\nrho1<- -0.1789474\nrho<-c(rho1,rho1*0.3,rho1*0.3^2,rho1*0.3^3,rho1*0.3^3)\nprint(rho)\nprint(find_phi(rho))\n\n[1] -0.17894740 -0.05368422 -0.01610527 -0.00483158 -0.00483158\n[1] -0.17894740 -0.08854169 -0.04415586 -0.02206360 -0.01456021\n\n\n\n두 모델의 이론적인 ACF와 PACF를 비교하여보자.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\rho_1\\)\n\\(\\rho_2\\)\n\\(\\rho_3\\)\n\\(\\rho_4\\)\n\\(\\rho_5\\)\n\\(\\dots\\)\n\n\n\n\n모델1\n−0.184\n0\n0\n0\n0\n\n\n\n모델2\n-0.1789474\n-0.05368422\n-0.01610527\n-0.00483158\n-0.00483158\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$_{11} $\n\\(\\phi_{22}\\)\n\\(\\phi_{33}\\)\n\\(\\phi_{44}\\)\n\\(\\phi_{55}\\)\n\\(\\dots\\)\n\n\n\n\n모델1\n−0.184\n-0.0350423953\n-0.0066819524\n-0.0012741846\n-0.0002429753\n\n\n\n모델2\n-0.17894740\n-0.08854169\n-0.04415586\n-0.02206360\n-0.01456021\n\n\n\n\n\n정말 두 모델을 구분할 수 있을까? 그리고 구분하는 것이 의미가 있을까?\n\n그렇다면 아래의 모델들은 구분할 수 있을까? \\[\n\\begin{cases}\nZ_t=\\epsilon_t \\\\\nZ_t=0.1 Z_{t-1}+\\epsilon_t\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\nZ_t=\\epsilon_t \\\\\nZ_t=0.01 Z_{t-1}+\\epsilon_t\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\nZ_t=\\epsilon_t \\\\\nZ_t=0.00000000000000000001 Z_{t-1}+\\epsilon_t\n\\end{cases}\n\\]\n.."
  },
  {
    "objectID": "posts/4_TS2023/ts8week_1.html",
    "href": "posts/4_TS2023/ts8week_1.html",
    "title": "[TS] 7wk. ARIMA",
    "section": "",
    "text": "7장. ARIMA\n의문: 정말 비정상시계열은 분석할수 없을까요?\n비정상 시계열의 대표적인 특성: 1. 시계열의 수준이 시간에 따라 다르다. (수준=평균) 2. 시계열이 추세를 가진다. (시계열에 증가하거나, 감소하는 추세가 보인다.) 3. 시계열이 계절성을 보인다. 4. 시계열의 분산이 시간에 따라 변한다.\n\n2,3 은 사실 1에 포함되는 개념.\n아래와 같은 자료를 생각해보자.\n\ne<-rnorm(1000)\nt<-1:1000\ntrend<- (1:1000 / 1000)*30 \n## 1:1000 = 1,2,3,...,1000인 벡터가 만들어짐. \n## 1:1000 / 1000 = 1/1000, 2/1000, ... 1인 벡터가 만들어짐. \n## ((1:1000)/1000)*30 = 30/1000, 60/3000, ... 30인 벡터가 만들어짐. \nz<-trend+e\nplot(z)\nlines(trend,col=2,lwd=3)\n\n\n\n\n\n\n\n위의 자료는 (굳이 따지면) 비정상시계열로 볼 수 있다.\n\n\n1. 시계열로 볼 수 있는 이유? white noise만 있는 경우도 시계열로 해석하였음.\n\n\n2. 비정상시계열인 이유? 평균이 \\(t\\)에 의존함. 즉 평균이 \\(t\\)의 함수임. 즉 평균이 \\(t\\)에 depend함.\n\n\n\n위의 시계열은 비정상시계열이지만, 위의 자료를 분석할 수 없는 것은 아니다.\n위의 자료는 단순한 회귀분석으로도 분석가능하다. 즉 위의 자료를 모델로 표현하면 아래와 같다.\n(모델1)\n\\[\nz_t=\\frac{30}{1000}t +\\epsilon_t, \\quad \\epsilon_t \\sim N(0,1)\n\\]\n\n위의 모델은 아래와 같이 분석가능하다.\n\n\nlm(z~t)\n\n\nCall:\nlm(formula = z ~ t)\n\nCoefficients:\n(Intercept)            t  \n   -0.02170      0.03001  \n\n\n\n따라서 모든 비정상시계열이 분석불가능한것은 아니다!!\n\n분석가능한 비정상시계열이 있다는 것은 알겠음.\n하지만 (모델1)과 같은 시계열은 관심없음. (오차항이 서로 독립이므로, 회귀분석 수준의 분석으로 처리가능함.)\n시계열을 배운 의미가 있으려면? 오차항이 서로 독립이 아닌 비정상시계열을 분석해야함.\n예를들면 아래와 같은 자료를 분석할 수 있어야 한다.\n(모델2) 연습문제 7.6의 모형1\n\\[\n(Z_t-Z_{t-1})=0.8(Z_{t-1}-Z_{t-2})+\\epsilon_t, \\quad \\epsilon_t \\sim N(0,1).\n\\]\n\n위의 시계열은 분명히 비정상이다. 왜냐하면 위의 자료는\n\\[\n(1-B)Z_t=0.8(B-B^2)Z_t+\\epsilon_t\n\\]\n와 같이 표현할 수 있고,\n이는 다시\n\\[\n(1-B)Z_t=0.8B(1-B)Z_t+\\epsilon_t\n\\]\n와 같이 표현가능하고, 이는 다시\n\\[\n(1-0.8B)(1-B)Z_t=\\epsilon_t\n\\]\n와 같이 표현가능하다. 따라서 특성방정식을 풀면 \\(B=1\\)을 근으로 가지므로, 이 시계열은 비정상이다.\n\n하지만 \\(Z_t-Z_{t-1}\\) 자체를 새로운 시계열 \\(W_t\\)로 생각해보자. 즉\n\\[\nW_t=Z_t-Z_{t-1}\n\\]\n라고하자. 그러면\n\\[\nW_t=0.8W_{t-1}+\\epsilon_t\n\\]\n와 같이 볼 수 있다.\n\n위의 모델은 정상시계열이 된다. 그래서 분석할 수 있다.\n\n\\(Z_t\\)는 분석할수 없지만, \\(W_t\\)는 분석할 수 있다.\n그런데 \\(W_t\\)는 \\(Z_t\\)를 차분(연속인 경우 미분)하여 얻은 자료이다.\n차분을 했다는 의미는, \\[\nZ_t=\\dots,1,2,3,5,\\dots\n\\] 이라면 \\[\nW_t=\\dots,?,1,1,2,\\dots\n\\] 이라는 의미이다.\n즉 \\(W_t\\)는 \\(Z_t\\)의 변화량, 즉 \\(\\Delta Z_t\\)로 생각할 수 있다.\n\n지금까지의 상황을 요약하면 아래와 같다. 1. 우리가 관심있는 것은 \\(Z_t\\)이다. 2. 그런데 \\(Z_t\\)는 비정상시계열이다. 3. 그래서 \\(Z_t\\)를 분석할 수 없다. 4. 그런데 \\(W_t=\\Delta Z_t= Z_t - Z_{t-1}\\)는 정상시계열이 되어 분석할 수 있다.\n\n그렇다면 의문은 “\\(Z_t\\)대신에 \\(W_t\\)를 분석해도 의미가 있을까?” 이다.\n의미가 있다.\n\n아래와 같은 자료를 관찰했다고 가정하자. \\[\nz_{t-1}=1, z_t=2.5\n\\]\n차분을 하면 \\(w_t=z_t-z_{t-1}=2.5-1=1.5\\)를 계산할 수 있다.\n아래의 모델을 활용하면,\n\\[\nW_{t+1}=0.8 W_{t}+\\epsilon_{t+1}\n\\]\n\\(W_{t+1}\\)을 아래와 같이 추측할 수 있다.\n\\[\n\\hat{W}_{t+1}=0.8\\times 1.5\n\\]\n이때 자료로부터 0.8이라는 숫자는 적절하게 추측하였다고 가정하자.\n그런데 \\[\nZ_{t+1}=Z_t+W_{t+1}\n\\]\n이므로, \\(Z_t\\)자리에 관측한 \\(z_t=2.5\\)를 대입하고, \\(W_{t+1}\\)대신에 추측한 \\(0.8\\times 1.5\\)값을 대입하면,\n\\[\n\\hat{Z}_{t+1}=2.5+0.8\\times 1.5\n\\]\n와 같이 추측할 수 있다.\n\n위의 논의를 일반화 시키면, 1번 차분하여 ARMA(p,q)를 따르는 모델은 모두 분석가능하며 분석의 의미도 있다고 생각할 수 있다.\n이러한 모델을 ARIMA(p,1,q)라고 한다. 차분된 시계열을 \\(W_t\\)라고 한다면, ARIMA(p,1,q)는 아래와 같은 모양이 된다.\n\\[\n{\\boldsymbol \\phi}(B)W_t={\\boldsymbol \\theta}(B)\\epsilon_t\n\\]\n그런데 \\(W_t=Z_t-Z_{t-1}=(1-B)Z_t\\)이므로, 위의 모델은 아래와 같이 쓸 수 있다. \\[\n{\\boldsymbol \\phi}(B)(1-B)Z_t={\\boldsymbol \\theta}(B)\\epsilon_t\n\\]\n\n위의 논의를 다시 일반화 하면 \\(d\\)번 차분하여 ARMA(p,q)를 따르는 모델은 모두 분석가능하고 분석의 의미가 있다. 이러한 모델을 ARIMA(p,d,q)라고 하자. ARIMA(p,d,q)의 일반적인 형태는\n\\[\n{\\boldsymbol \\phi}(B)(1-B)^dZ_t={\\boldsymbol \\theta}(B)\\epsilon_t\n\\]\n와 같이 된다.\n\n예제를 풀어보자. 아래의 모형\n\\[\n(Z_t-Z_{t-1})=0.8(Z_{t-1}-Z_{t-2})+\\epsilon_t, \\quad \\epsilon_t \\sim N(0,1).\n\\]\n을 정리하면\n\\[\nZ_t=1.8Z_{t-1}-0.8Z_{t-2}+\\epsilon_t\n\\]\n와 같이 된다. 시뮬레이션 해보면,\n\nset.seed(777)\ne<-rnorm(10000)\nz<-e*0\nz[1]<-0\nz[2]<-0\nfor(t in 3:10000) z[t]<-1.8*z[t-1]-0.8*z[t-2]+e[t] \nplot(z)\n\n\n\n\nSACF를 확인할 필요도 없이 비정상시계열처럼 보인다.\n그래도 SACF를 그려보면,\n\nacf(z)\n\n\n\n\n\n\\(Z_t\\)는 전형적인 비정상 시계열이 된다.\n하지만 차분해서 ARMA를 따르는 경우도 있으므로, 분석을 포기하지 않고 차분을 시도해본다.\n차분은 아래와 같이 하면된다.\n\n\nz[1:5]\nz[2]-z[1]\nz[3]-z[2]\nz[4]-z[3]\nz[5]-z[4]\n\n\n000.5108363216906030.5206933255579112.16726498743783\n\n\n0\n\n\n0.510836321690603\n\n\n0.00985700386730759\n\n\n1.64657166187992\n\n\n\n하지만 \\(\\tt{diff}\\)함수를 사용해도 된다.\n\n\ndiff(z[1:5])\n\n\n00.5108363216906030.009857003867307591.64657166187992\n\n\n\n원래 \\(z[1:5]\\)에는 5개의 자료가 있는데, 차분으로 인하여 1개의 자료가 없어지고 4개의 자료만 남게됨을 주목하라.\n이처럼 1차차분을 하면 1개의 자료가 손상됨을 유의하자.\n동일한 논리로 \\(d\\)차차분을 하면 \\(d\\)개의 자료가 줄어든다.\n\n차분한 자료를 \\(W_t\\)라고 두자.\n\n\nw<-c(0,diff(z))\n\n\n이때 \\(W_1=0\\)으로 가정하여 1개의 손상된 자료를 끼워넣었다.\n\\(W_t\\)의 그림을 그려보자.\n\n\nplot(w)\n\n\n\n\n\n정상인것처럼 보인다.\nSACF, SPACF를 그려보자.\n\n\nacf(w)$acf[1:5]\npacf(w)$acf[1:5]\n\n\n10.8060891894910010.6535243491642610.5274416090725250.428669062083039\n\n\n\n\n\n\n0.8060891894910010.0106920376131423-0.006692229096698640.008371735256214640.0131231419074575\n\n\n\n\n\n\n명백하게 AR(1)모형임을 알 수 있다.\n계수는 \\(\\hat{\\phi}=0.806089189491001\\)으로 추측할 수 있다.\n\n한번 차분하였더니 계수가 0.806089189491001 인 AR(1) 모형을 따르므로, 원래 시계열 \\(Z_t\\) ARIMA(1,1,0) 이라고 볼 수 있다. 모형의 형태는 아래와 같은 형태로 추정된다.\n\\[\n(Z_t-Z_{t-1})=0.806089189491001 (Z_{t-1}-Z_{t-2})+\\epsilon_t.\n\\]"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-16-4wk.html",
    "href": "posts/4_TS2023/2023-05-16-4wk.html",
    "title": "[TS] 4wk. ACF",
    "section": "",
    "text": "Summary\n\n확률정의 \\(\\to\\) 확률변수 정의 \\(\\to\\) 확률과정.\n\n\npoint: 확률과정의 1개의 relization. \\(\\Rightarrow\\) 정상확률과정\n\n\n정상성(Stationary): iid의 약화버전\n\n\n평균이 \\(t\\)에 depend하지 X\n분산이 \\(t\\)에 depend하지 X\n\\(lag=1,2,3,\\dots\\)에 대해서 \\(\\text{Cov}\\)가 \\(t\\)에 depend하지 X\n\n\n모델: \\(AR(1), AR(2), AR(p), ...\\)\n\n\n모델을 세우는 이유? 현상을 설명 + 예측 + anomally detection + \\(\\cdots\\)\nex. 모델1: 삼성전자 주가 = 과거값 + 랜덤오차(=white noise) \\(\\to\\) 비정상1\nex. 모델2: 삼성전자 주가 = 0.9*과거값 + white noise \\(\\to\\) 정상\nex. 모델3: 삼성전자 주가 = 0.45*과거값 + white noise + 기세 \\(\\to\\) ? AR(p)\n\n모델을 세운다 \\(\\Rightarrow\\) 정상인지 check! (이 과정이 매우 고통스럽다..) \\(\\Rightarrow\\) (1) 특성방정식을 풀어서 단위근의 절대값이 ~~ (2) 모델별로 암기2\n- 질문\n모델 1,2,3… \\(\\to\\) AR계열의 모델.\n세운 모델에서 정상성을 체크하는 것은 다음과 같다.\n\n\nAR모델 중 적당한 후보를 고른다.\n\n\n정상성 check!\n\n\n통과하면 사용 \\(\\to\\) goodness of fit.3\n\n\n(i),(ii)를 종합하면, 정상성을 만족하는 AR모델 중 적당한 모델을 고르겠다는 것이죠.\n그럼 삼성전자 주가가 정상성을 만족하는 AR모델 중 하나라는 증거가 어딨냐?\n사실 증거가 없었음. 삼성전자 주가는 과거값 플러스 랜덤오차 아닐까? 라고 나이브하게 생각했던 것이였다.\n그렇다면 뭐라고 답변해야 할까?\n- 답변 : ACF를 그려보니까 AR모델이라고 판단됩니다.\n논리전개\n\nAR(p) 모델의 이론적인 ACF는 1.exponential decay function4 혹은 2.damped sine wave5\n그런데 삼성전자 주식의 \\(\\widehat{ACF}\\)6를 그려보니, exponential decay 혹은 damped sine이 나왔어요.\n따라서 삼성전자 주식은 \\(AR(p)\\) 모델 중 하나를 따른다고 볼 수 있습니다.\n\n- 재질문: \\(AR(p)\\) 모델 \\(\\to\\) \\(ACF\\)는 exponential-decay or. damped-sine 이건 맞는데, \\(ACF\\)가 exponential-decay or. damped-sine \\(\\to\\) \\(AR(p)\\)가 맞다는 보장은 없지 않느냐?\n\n즉, 답변의 논리가 성립하려면 “ACF가 모델을 유일하게 결정” 한다는 전제가 필요.7\n당연히 성립 안합니다.8\n- 반론: “ACF가 모델을 유일하게 결정못함” But. 모델의 범위를 “정상시계열”에 한정하면 “ACF가 모델을 유일하게 결정함.” <- 매우매우 중요합니다.\n- 결론: ACF를 파악하는 일이 매우 중요함.\n시계열의 처음과 끝은 ACF..!\n모델을 선택할 수 있어요! 우리가 배운 AR모델에 한하여 생각해보면, AR모델에 대한 이론적인 ACF를 계산을 했잖아요. AR모델은 이런 모양이다~ 그런데 정상시계열에 한정해서 역도 성립한다고 했죠? AR모델이면 ACF가 이런모양이다 이건 당연히 성립하는데, 정상시계열에 한정하여 ACF를 그렸더니 이런 모양이 나왔어 그럼 AR모델이네? 이런 논리가 맞다는 말입니다.\n그래서 시계열 받자마자 ACF를 파악해야 합니다. ACF를 파악하려면 우리가 배운 ACF는 이론적인 ACF이기 때문에 ACF의 Sample 버전을 배웁니다. 이것을 SACF라고 표현해요.\n\n\n# \\(SACF, \\widehat{ACF}\\)\n\n교재 5.3, p193\n\n\\(\\widehat{acf} = \\hat{\\rho}(h)=\\frac{\\hat{\\gamma}(h)}{\\hat{\\gamma}(0)}, \\quad \\hat{\\gamma}(h) = \\frac{\\sum_{i=1}^{n-h}(Z_t-\\bar{Z})(Z_{t+h}-\\bar{Z})}{n}, h=0,1,2,\\dots\\)\n\n\n연습문제 5.2\n다음의 시계열이 주어졌다. SACF \\(\\hat{\\rho}_k, k=1,2,3\\)과 \\(\\hat{\\phi}_{kk},k=1,2,3\\)을 직접 계산하라.\n\\(Z_t = \\{\\dots, 7,6,5,8,9,4,5,5,4,6,7,8,5,6,5,\\dots\\}\\)\n\\(\\bar{Z} = \\frac{90}{15}=6\\)\n- \\(h=0: lag=0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n\\(Z_{t}-\\bar{Z}\\)\n1\n0\n-1\n2\n3\n-2\n-1\n-1\n-2\n0\n1\n2\n-1\n0\n-1\n\n\n\\(Z_{t+h}-\\bar{Z}\\)\n1\n0\n-1\n2\n3\n-2\n-1\n-1\n-2\n0\n1\n2\n-1\n0\n-1\n\n\nx\n1\n0\n1\n4\n9\n4\n1\n1\n4\n0\n1\n4\n1\n0\n1\n\n\n\n\n\\(\\widehat{cov}(Z_t-\\bar{Z}, Z_t-\\bar{Z})= \\frac{32}{15}\\)\n\n- \\(h=1 : lag=1\\)\n\n- \\(h=2 : lag=2\\)\n\n\n위의 내용을 실습을 통해서 확인해보자.\n\n\n\nR 실습\n다음의 시계열이 주어졌다. SACF \\(\\hat{\\rho}_k, k=1,2,3\\)과 \\(\\hat{\\phi}_{kk},k=1,2,3\\)을 직접 계산하라.\n\nzt <- c(7,6,5,8,9,4,5,5,4,6,7,8,5,6,5)\nprint(mean(zt))\n\n[1] 6\n\n\n- 방법1: 직접 구현\n\n## lag0\nyt<- c(zt-mean(zt))\ngamma0 <- sum(yt*yt)/15\ncat('gamma0: ', sum(yt*yt),'/',15,'\\n')\ncat('rho0: ', gamma0/gamma0)\n\ngamma0:  32 / 15 \nrho0:  1\n\n\n\n## lag1\nyt1<- c(yt,0) # 맨 마지막에 0 추가.\nyt_lag1<-c(0,zt-mean(zt)) # 한 칸씩 밀린 형태.\ngamma1<-sum(yt1*yt_lag1)/15\nrho1 <- gamma1/gamma0\ncat('rho1: ', sum(yt1*yt_lag1),'/',sum(yt*yt))\ncat(' =', rho1)\n\nrho1:  3 / 32 = 0.09375\n\n\n\n3/32\n\n0.09375\n\n\n\n## lag2\nyt2<-c(yt,0,0) # 맨 마지막에 0 2개 추가.\nyt_lag2<-c(0,0,zt-mean(zt))\ngamma2<-sum(yt2*yt_lag2)/15\nrho2<-gamma2/gamma0\ncat('rho2: ',sum(yt2*yt_lag2),'/',sum(yt*yt))\ncat(' =', rho2)\n\nrho2:  -9 / 32 = -0.28125\n\n\n\n-9/32\n\n-0.28125\n\n\n\n## lag3\nyt3<-c(yt,0,0,0)\nyt_lag3<-c(0,0,0,yt)\ngamma3<-sum(yt3*yt_lag3)/15\ncat('rho3: ', sum(yt3*yt_lag3),'/',sum(yt*yt))\n\nrho3:  -4 / 32\n\n\n\n-4/32\n\n-0.125\n\n\n- 방법2: 함수이용 (이렇게 하면 됩니다!)\n\nacf(zt)\n\n\n\n\n\nnames(acf(zt))\n\n\n'acf''type''n.used''lag''series''snames'\n\n\n\n\n\n\nacf(zt)$acf\n\n\n10.09375-0.28125-0.125-0.1875-0.250.093750.3125-0.03125-0.0625-0.031250\n\n\n\n\n\n\nrho0, rho1, rho2,…을 의미\n\n다음시간은 PACF를 공부해볼 것\n\n\n\n\n\nFootnotes\n\n\n랜덤워크과정↩︎\n예를들어, AR(1): \\(Z_t = \\phi Z_{t-1} + \\epsilon_t.\\) 이면 \\(|\\phi|<1\\) 이면 정상인 것처럼..↩︎\n잘 맞으면 쓰고 안맞으면 1로 되돌아가서 반복.↩︎\n지수적으로 감소↩︎\n증폭이 점점 감소하는 sine wave↩︎\nACF추정치를 SACF라고 한다. Sample ACF의 약자.↩︎\n모델 하나에 ACF 함수가 딱 매칭이 된다는말 (1:1 corresponding)↩︎\n교재 p.193 각주 참고↩︎"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-26-7wk-2.html",
    "href": "posts/4_TS2023/2023-05-26-7wk-2.html",
    "title": "[TS] 7wk-2. 6장 연습문제 (++)",
    "section": "",
    "text": "처음 \\((q+1)\\)개의 eq를 연립하여 \\(\\gamma_0,\\dots, \\gamma_q\\)를 구한다.\n이후의 eq은 항상 아래의 형태를 따름.\n\n\\(\\gamma_{q+1} = \\phi_1\\gamma_q + \\phi_2\\gamma_{q-1} + \\dots +\\phi_p\\gamma_{q-p+1}\\)\n\\(\\gamma_{q+2} = \\phi_1\\gamma_{q+1} + \\phi_2\\gamma_{q} + \\dots + \\phi_p\\gamma_{q-p+2}\\)\n\\(\\vdots\\)\n\\(AR(p)\\)모형과 동일. 즉, \\(\\gamma_{q-p+1}\\) 이후의 ACF 모양이 \\(AR(p)\\) 모형의 ACF 모양과 동일.\n\\(\\therefore ARMA(p,q)\\) 모델의 ACF.\n\ntail off after lag \\(q-p.\\)\ntails off"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-26-7wk-2.html#section",
    "href": "posts/4_TS2023/2023-05-26-7wk-2.html#section",
    "title": "[TS] 7wk-2. 6장 연습문제 (++)",
    "section": "6.3",
    "text": "6.3\n정상성 조건을 만족하면, AR모형을 MA모형으로 나타내라.\n- 모델1: \\(Z_t = 158 + 0.8Z_{t-1} + \\epsilon_t\\)\n\n정상성 만족\n\n\nMA모형으로\n\n\\((1-0.8B)(Z_t-\\mu)=\\epsilon_t.\\)\n\\(0.2\\mu = 158.\\to \\mu=158\\times 5\\)\n\\(Z_t = \\mu + \\epsilon_t + 0.8\\epsilon_{t-1}+\\dots\\\\ \\quad =\\mu + \\frac{1}{1-0.8B}\\epsilon_t\\)\n- 모델2: \\((1-1.3B+0.5B^2)(Z_t-3.5)=\\epsilon_t\\)\n\n\n\n\n다른풀이\n\n\n\n\n\n\n- 모형3: \\(0.5Z_{t-1}+0.6Z_{t-2}+\\epsilon_t\\)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-26-7wk-2.html#section-1",
    "href": "posts/4_TS2023/2023-05-26-7wk-2.html#section-1",
    "title": "[TS] 7wk-2. 6장 연습문제 (++)",
    "section": "6.4",
    "text": "6.4"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-26-7wk-2.html#section-2",
    "href": "posts/4_TS2023/2023-05-26-7wk-2.html#section-2",
    "title": "[TS] 7wk-2. 6장 연습문제 (++)",
    "section": "6.5",
    "text": "6.5"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-26-7wk-2.html#section-3",
    "href": "posts/4_TS2023/2023-05-26-7wk-2.html#section-3",
    "title": "[TS] 7wk-2. 6장 연습문제 (++)",
    "section": "6.6",
    "text": "6.6"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html",
    "href": "posts/4_TS2023/2023-05-10-1wk.html",
    "title": "[TS] 1wk. 확률",
    "section": "",
    "text": "확률 \\(\\to\\) 확률변수 \\(\\to\\) 확률과정 \\(\\to\\) 시계열"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#ex1.-동전던지기",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#ex1.-동전던지기",
    "title": "[TS] 1wk. 확률",
    "section": "Ex1. 동전던지기",
    "text": "Ex1. 동전던지기\n\n\\(\\Omega = \\{H,T\\}\\): sample space\n\\(P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}\\): prob\n\\(\\Omega\\)의 모든(=임의의) 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)을 모순없이 정의할 수 있어야함.\n\n- 질문: \\(\\Omega\\)의 임의의 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있을까?\n\n당연한거 아냐?\n이게 왜 안돼?\n\n- 질문에 대한 대답\n즉, \\(\\Omega\\)의 부분집합: \\(\\emptyset, \\Omega, \\{H\\}, \\{T\\}\\)에 대해 \\(P(\\emptyset)=0, P(\\Omega)=1, P(\\{H\\})=1/2, P(\\{T\\})=1/2\\) 이런식으로 정의할 수 있어야 된다는 뜻이다.\n- 모순없이 의 의미?\n\n우리가 상식적으로 확률에 적용가능한 어떠한 연산들이 있음. (확률의 공리 + 기본성질)\n이러한 연산을 적용해도 상식적인 수준에서 납득이 가야함.\n\n\n확률의 성질\n\\(P(\\emptyset)=0, P(\\Omega)=1, P(\\{H\\})=1/2, P(\\{T\\})=1/2\\)\n\n\\(\\emptyset \\subset \\{H\\} \\Rightarrow P(\\emptyset)<P(\\{H\\})\\)\n\\(\\begin{align*} \\{H\\} \\cap \\{T\\} = \\emptyset &\\Rightarrow P(\\{H\\} \\cup \\{T\\}) = P(\\Omega)=1 \\\\ &=P(\\{H\\}) +P(\\{T\\})=1\\end{align*}\\)\n\\(\\begin{align*}\\Omega - \\{H\\} = \\{T\\} &\\Rightarrow P(\\Omega-\\{H\\}) = P(\\{T\\})=1/2 \\\\ &=P(\\Omega)-P(\\{H\\})=1/2\\end{align*}\\)\n\n\n모순없이 잘 정의되었다. 왜 확률을 정의하는 것이 어렵다는 걸까? \\(\\to\\) 앞의 예제에서는 \\(\\Omega\\)의 원소가 유한인 경우이지만 무한이라면 확률을 정의하기 쉽지 않다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#ex2.-바늘이-하나만-있는-시계",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#ex2.-바늘이-하나만-있는-시계",
    "title": "[TS] 1wk. 확률",
    "section": "Ex2. 바늘이 하나만 있는 시계",
    "text": "Ex2. 바늘이 하나만 있는 시계\n\n시계바늘을 돌려서 나오는 각도를 재는 일 \\(\\Leftrightarrow\\) \\([0,2\\pi)\\) 사이의 숫자중에 하나를 뽑는 일\n\nSample space: \\(\\Omega = [0,2\\pi]\\)\nProb: \\(\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\)\n- 질문: 바늘을 랜덤으로 돌렸을 때 12시-6시 사이에 바늘이 있을 확률? \\(\\frac{1}{2}\\)\n\\(\\Omega\\)의 부분집합을 \\(\\Omega^*\\)라 하자.\n\n\\(\\Omega^* = [0,\\pi)\\)\n\\(P(\\Omega^*)= \\frac{1}{2}\\)\n\n\\(\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\)\n단, 여기에서 \\(m\\)은 구간의 길이를 재는 함수.\n연습 : \\(m\\)의 사용 - \\(m(\\Omega)=m\\big([0,2\\pi)\\big)=2\\pi\\) - \\(m(\\Omega^*) = m\\big([0,\\pi)\\big)= \\pi\\)\n- 위와 같은 방식으로 확률을 정의하면 잘 정의될까? 이게 쉽지 않음. 왜냐하면 확률을 잘 정의하기 위해서는\n\n\\(\\Omega\\)의 모든 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있어야하는데, 이게 쉬운일이 아님.\n\n\n- 도전적 질문\n\n\\(\\emptyset\\subset \\Omega, \\quad P(\\Omega)=0\\)\n\\([0,\\pi) \\subset \\Omega, \\quad \\frac{m([0,\\pi)}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\)\n\n질문1 \\(\\{0\\} \\subset \\Omega, \\quad P(\\{0\\})=\\frac{m(\\{0\\})}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\) - 점 하나의 길이는 \\(0\\)??\n왜 \\(0\\)이지? 점은 원래 길이가 없는데 굳이 재야한다면 \\(0\\)이라고 대답한다. 찝찝하지만 여기까지는 별 문제가 없다.\n질문2 \\(\\emptyset \\subset \\{0\\} \\Rightarrow P(\\emptyset) \\leq P(\\{0\\})\\)\n우측 부등호에 등호를 넣어줌으로써 디펜스\n질문3 \\(\\{0,1\\} \\subset \\Omega \\Rightarrow P(\\{0,1\\})=P(\\{0\\}) + P(\\{1\\})=0+0=0\\)\n\n\\(\\{0,1\\} = \\{0\\} \\cup \\{1\\}\\)\n\\(\\{0\\} \\cap \\{1\\} = \\emptyset\\)\n\n질문4 \\([0,2\\pi)=\\) 무수히 많은 점들의 집합\n\n무수히 많은 것도 끕이 있다. (countable many, uncountable many)\n유리수 정도로 무수히 많은 것 \\(\\to\\) countable many\n무리수 정도로 무수히 많은 것 \\(\\to\\) uncountable many\n\n무수히 많은 점들의 집합이라고 하면 둘 중 뭔지 모르겠지만, 다 더해서 길이가 있다는 것은 uncountable many 겠지?\n\n점 하나의 길이 \\(= 0\\)\n\\(0\\)을 무한번 더해도 \\(0\\)\n\\([0,2\\pi)\\)의 길이 \\(= 0+0+0+\\dots = 0?\\)  \\(\\Rightarrow 2\\pi\\) \n\n논리전개는 틀린게 없어보이는데 말이 안됨. \\([0,2\\pi)\\) 의 길이는 \\(2\\pi\\) 아냐?\n\n디펜스 : 무한번 더해도 \\(0\\) 여기를 걸고 넘어지자. 점을 하나 합쳐도 점, 두개 합쳐도 점, 3개 합쳐도 점인데 무한번 합치면? 점이 선이 될 수 있잖아, 그런데 선은 길이가 될 수 있다고 했잖아. 그러니까 \\(2\\pi\\)가 되는거야!\n\n\n유한번 더하면 \\(0\\)이 맞는데 무한번 더하면 달라지는거야\n\n질문5 \\(A = [0,2\\pi) \\cap \\mathbb{Q}\\)\n\n결론: \\(0\\)도 아니고, \\(2\\pi\\)도 아니야..\n\n\\(A\\)의 원소는 무한개, \\(m(A) = 2\\pi\\)\n\\(A' = [0,2\\pi) \\cap (\\mathbb{R} - \\mathbb{Q})\\), \\(\\quad(\\mathbb{R} - \\mathbb{Q})\\) : 무리수 집합\n\\(m(A') = ?\\)\n\\(P(A\\cup A') = P(A) + P(A') = \\frac{m(A)}{m(\\Omega)}+\\frac{m(A')}{m(\\Omega)}\\)\n이렇게 되면 \\(m(A')=0\\) 이라는 소리인데 이건 말이안돼.. 무리수가 더 많고 무한개 더했는데??\n그럼 결론은 \\(A\\)의 길이를 \\(2\\pi\\) 라고 대답못해.. 근데 또 \\(0\\)이라고 할 수도 없는데? 에매하게 대답할 수밖에.\n디펜스\n\n\\(A\\)의 원소는 무한개\n\\(m(A) = a\\) \\(\\rightarrow\\)그냥 \\(0\\) 이야, \\(\\quad 0<a<2\\pi\\) (구체적으로 \\(a\\)가 뭔지는 나도 몰라.)\n\\(m(A') = 2\\pi -a\\)\n\n유리수만 뽑으면 길이가 \\(a\\)야. 그럼 무리수만 뽑으면 \\(2\\pi-a\\) 겠지? 이렇게 디펜스를 하고 넘어가자..\n질문6 디펜스 불가능한 질문\n\n\\(A=[0,\\pi) \\cap \\mathbb{Q}\\)\n\\(A' = A \\oplus \\frac{\\pi}{2}\\) (\\(A\\)를 \\(\\frac{\\pi}{2}\\)만큼 평행이동한 집합을 \\(A'\\)라고 하자.)\n\n\n\n\\(A\\)의 모든원소: 유리수 \\(\\to\\) 유리수 다 더하면 길이가 빵!\n\\(A'\\)의 모든 원소: 무리수 \\(\\to\\) \\([0,2\\pi)\\) 구간 안에 있는 값들을 다 포함해야지 길이가 생긴다. 고로 무리수여도 이건 길이가 빵! \n\n유리수 만큼의 길이를 평행이동 한거니까 그냥 유리수 숫자만큼의 무리수가 생긴 것 뿐\n\\(\\Rightarrow A\\cap A' = \\emptyset\\) (\\(A\\)와 \\(A'\\)은 서로소)\n그럼 \\(P(A\\cup A') = P(A) + P(A') = \\frac{m(A)}{m(\\Omega)}+\\frac{m(A')}{m(\\Omega)}\\)이 성립한다.\n\\(= \\frac{m(A)}{2\\pi}+\\frac{m(A')}{2\\pi}= \\frac{a/2}{2\\pi}+\\frac{a/2}{2\\pi}=\\frac{a}{2\\pi}\\)\n결국 종합하면, \\(m(A) + m(A') = a\\)라는 소린데\n그림을 참고해서 직접 계산해보면 각각의 길이에 겹치는 부분의 길이를 뺀 \\(\\frac{a}{2}+\\frac{a}{2}-\\frac{a}{4}=\\frac{3}{4}a\\)일 것 같은데, \\(a\\)라고 주장하고 있는것이다.\n우리가 알고있는 길이 상식과는 다르다. 모순발생!\n이건 디펜스가 불가능한 질문이다. 즉, 지금까지 했던 말이 다 거짓!! 확률을 이렇게 \\(\\frac{m(\\Omega^*)}{m(\\Omega)}\\)정의하는 것부터가 말이 안됨. 이렇게 정의할 수 없다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#약속-받아들이기",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#약속-받아들이기",
    "title": "[TS] 1wk. 확률",
    "section": "약속: 받아들이기^^",
    "text": "약속: 받아들이기^^\n(i) 한 점에 대한 길이는 \\(0\\)\n(ii) \\([0,2\\pi)\\) 사이의 모든 유리수를 합친 집합의 길이\\(=0\\) - 아까 무한히 점을 더하면 선이된다? 다 없는소리.. (유한한 점을 더하면 길이가 0이된다.)\n(iii) \\([0,2\\pi)\\) 사이의 모든 무리수를 합친 집합의 길이\\(=2\\pi\\)\n\n위의 내용은 Measure Theory의 내용입니다. 그냥 받아들입시다~\n\n이제 모든 질문들에 대해서 깔끔하게 디펜스가 된다. \n이제 이 정의가 다시 살아나게 된다. \\(\\{0\\} \\subset \\Omega, \\quad P(\\{0\\})=\\frac{m(\\{0\\})}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\)\n\n주장 (X) : 틀린주장\n위의 3가지 원리. 즉 (i)-(iii)를 사용하면(=받아들이면) \\([0,2\\pi)\\)의 어떤 부분집합 \\(\\Omega^*\\)에 대해서도 \\(\\Omega^*\\)의 길이를 모순없이 정의할 수 있다.\n길이를 잴 수 없는 집합이 존재함 : 비탈리 집합"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-24-7wk.html",
    "href": "posts/4_TS2023/2023-05-24-7wk.html",
    "title": "[TS] 7wk. 5~6장 연습문제 (Ongoing)",
    "section": "",
    "text": "\\(Z_t = \\epsilon_t + \\epsilon_{t-1} -\\epsilon_{t-2}, \\quad \\{\\epsilon_t\\}\\)는 WN(0,1)이다.\n\n유한차수 MA모델은 정상임.\n\n\n\n\n\\(Z_t \\overset{d}{=}\\epsilon_t\\epsilon_{t-1}+\\epsilon_{t}\\)\n\n\\(\\eta_t \\overset{d}{=} \\epsilon_t\\epsilon_{t-1} + \\epsilon_t\\)\n\\(\\eta_t, \\eta_{t-1},\\dots, \\eta_{t-h} \\Rightarrow\\) 독립이고 분포가 같다.\n따라서 \\(Z_t\\)는 정상\n\n\n\n\n\\(Z_t = \\epsilon_t-350\\epsilon_{t-1}, \\quad \\{\\epsilon_t\\}\\)는 \\(WN(0,2)\\)\n\n유한차수 MA \\(\\Rightarrow\\) 정상.\n\n\n\n\n\\(Z_t = 0.8Z_{t-1} + \\epsilon_t -0.5\\epsilon_{t-1}\\)\n\nMA부분 무시하고 AR부분 정상성 체크 \\(\\to\\) 0.8 < 1 이므로 정상\nMA부분은 유한차수이므로 정상\n\\(\\Rightarrow\\) 정상"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-20-6wk.html",
    "href": "posts/4_TS2023/2023-05-20-6wk.html",
    "title": "[TS] 6wk. 연습문제5장(3,4번) 실습",
    "section": "",
    "text": "연습문제 5.3, 5.4 실습"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-20-6wk.html#연습문제-5.3",
    "href": "posts/4_TS2023/2023-05-20-6wk.html#연습문제-5.3",
    "title": "[TS] 6wk. 연습문제5장(3,4번) 실습",
    "section": "연습문제 5.3",
    "text": "연습문제 5.3\n아래와 같이 자료를 입력한다.\n\nzt<-c(144.652,195.596,236.569,269.265,296.791,316.682,332.593,344.834,356.644,\n      363.775,370.994,377.784,382.254,386.211,388.574,391.118,394.627,395.785,\n      395.693,396.811,397.249,397.433,398.767,398.971,399.108,400.958,398.660,\n      399.348,398.293,397.886)\n\n\n(a)\n시계열 그림을 그려라.\n\nplot(zt)\n\n\n\n\n\n\n(b)\n(a)의 시계열로부터 \\(\\rho_1\\)은 양수, \\(0\\), 혹은 음수 중 어느 값이라 기대되는가?\n\n\\(\\rho_1>0\\) 일 것으로 기대함.\n\n\nyt<-c(zt-mean(zt),0) # 표준화\nyt_lag1<-c(0,zt-mean(zt))\nplot(yt,yt_lag1)\n\n\n\n\n\n\n(c)\n\\(Z_t\\)에 대하여 \\(Z_{t-1}\\)의 산점도를 그려보고, 다시 \\(\\rho_1\\)은 어느 정도의 값이 되리라 기대되는가?\n\nyt<-c(zt-mean(zt),0)\nyt_lag1<-c(0,zt-mean(zt))\nplot(yt,yt_lag1)\nlm(yt~yt_lag1)$coefficients[2]\n\nyt_lag1: 0.786722460931916\n\n\n\n\n\n\nacf의 계수값은 regression을 한 coefficient의 계수값이라고 생각해도 된다.\n\n\n\n(d)\nSACF \\(\\hat{\\rho}_k,k=0,1,\\dots,10\\) 를 구하여 표본상관도표를 그려라.\n\nacf_result<-acf(zt)\nacfvalues<-acf_result$acf\nacfvalues\nplot(acf_result)\n\n\n10.7867224609319160.6131090566970590.4713483960761320.3554331828267370.2623305872119750.1848873120158860.1193170448208660.06197038720874510.0152480323267708-0.0278522483752027-0.0654859242598054-0.0965225838496274-0.124280187334351-0.148215235099583\n\n\n\n\n\n\n\n(e)\n\\(Z_t\\)에 대하여 \\(Z_{t-2}\\)의 산점도를 그려보고, 이 그림이 (d)에서 계산된 \\(\\hat{\\rho}_2\\)에 상응하는지를 논하라.\n\nyt<-c(zt-mean(zt),0,0)\nyt_lag1<-c(0,zt-mean(zt),0)\nyt_lag2<-c(0,0,zt-mean(zt))\nplot(yt,yt_lag2)\nlm(yt~yt_lag2)$coefficients[2]\n\nyt_lag2: 0.613109056697059\n\n\n\n\n\nsacf를 구하는 방법 1\n\ngamma_0 <- sum(yt*yt)\ngamma_1 <- sum(yt*yt_lag1)\nrho1 <- gamma_1/gamma_0\ngamma_2 <- sum(yt*yt_lag2)\nrho2 <- gamma_2/gamma_0\ncat(rho1, rho2)\n\n0.7867225 0.6131091\n\n\nsacf를 구하는 방법 2\n\nacf(zt)$acf\n\n\n10.7867224609319160.6131090566970590.4713483960761320.3554331828267370.2623305872119750.1848873120158860.1193170448208660.06197038720874510.0152480323267708-0.0278522483752027-0.0654859242598054-0.0965225838496274-0.124280187334351-0.148215235099583\n\n\n\n\n\nsacf를 구하는 방법 3\n\n# (1) rho1을 구하는 법: yt ~ yt_lag1\nlm(yt~yt_lag1)$coef[2]\n\n# (2) rho2을 구하는 법: yt ~ yt_lag2\nlm(yt~yt_lag2)$coef[2]\n\nyt_lag1: 0.786722460931917\n\n\nyt_lag2: 0.613109056697059\n\n\n\npar(mfrow=c(2,1))\nplot(yt_lag1, yt)\nplot(yt_lag2, yt)\n\n\n\n\n\n위에 있는 그래프의 기울기가 아래에 있는 그래프의 기울기보다 조금 더 가파르게 나타난다. (아주 미세한 차이지만..)\n즉, yt와 lag1의 correlation이 yt와 lag2의 correlation 보다 강하다고 추측을 할 수 있다.\n\n\n\n(f) SPACF를 구하라.\nSPACF \\(\\hat{\\phi}_{kk},k=1,2,\\dots,10\\)을 구하여 표본상관도표를 그려라.\n\npacf_result<-pacf(zt)\npacfvalues<-pacf_result$acf\npacfvalues\nplot(pacf_result)\n\n\n0.915142832372850.09709916362351230.02780312951723640.0023436840732835-0.0600699044140887-0.1117452874219410.08063707048421640.01030459612319460.1324089785441610.0315743336953914-0.088386730109637-0.0584577460737368-0.04492505219212510.04549418578588550.0338085090119136-0.006926640757195950.001553929244265640.0311171061759323-0.171366229465896-0.0224072170637755\n\n\n\n\n\n\n파란 점선보다 작으면 \\(0\\)으로 봐도 무방하다.\nPACF는 Lag=1일 때를 제외하고 나머지는 절삭된다. \\(\\to\\) Lag1은 의미있다. \\(\\to\\) AR(1) 모델로 추정.\n\n\nacf(zt) # exponentially 하게 감소\n\n\n\n\n\nplot(zt) # 이것만 보면 non-stationary 같음.\n\n\n\n\n그림만 보면 non-stationary한 것 같지만 20번째 이후로는 일정한 값만 갖는다.\n\nplot(zt[15:30]) # 무한대로 가면 stationary 하겠다!\n\n\n\n\n결국 시계열에서 \\(-\\infty \\sim \\infty\\) 시점에서 stationary 한지 따져보는 방법과, 0시점에서 시작해서 \\(\\infty\\) 까지 갈 때 stationary 한지 따져보는 방법이 있는데 지금은 0시점에 시작해서 무한대까지 가는 시계열이라고 해석을 할 수 있고, 무한대로 갔을 때 stationary하게 400 근처에 있을 것.\n(번외) stationary한지 테스트하는 방법이 있다. adf test 했을 때 non-stationary라고 나오지만 여러 이론적 근거를 봤을 때 무한대로 갔을 때 무한대 부분만 따로 잘라서 보면 stationary하겠구나 라는 것을 추측해볼 수 있다.\n\n\n(g) : \\(\\hat{\\phi}_{22}\\)의 의미:\n\n교재의 설명: \\(\\hat{\\phi}_{22}\\)는 \\(Z_t\\)와 \\(Z_{t+2}\\)로부터 \\(Z_{t+1}\\)의 효과를 제거한후 2시차만큼 떨어진 \\(Z_t\\)와 \\(Z_{t+2}\\)의 순수한 상관계수. (p.199)\n좀더 엄밀한 정의\n\n\n\npartial correlation (conditional correlation)1\n\n\ncoefficients in the multiple regression model2\n\n\n(orthogonalization) partial regression coefficients – back fitting이라고도 함.3\n\n\n이전 시간에 다중회귀를 통해서 회귀계수를 구하는 것과 back-fitting을 통해서 회귀계수를 구하는 것과 결과가 동일함을 증명했었다.\n\n(방법1): 가장 쉬운 방법\nlag=2에선 SPACF, 즉 \\(\\hat{\\phi}_{22}\\)는 아래와 같이 구할수 있다.\n\npacf(zt)$acf[2]\n\n0.0970991636235123\n\n\n\n\n\n\n\n(방법2) multiple linear regression\n\nlm1<-lm(yt~yt_lag1+yt_lag2) # multiple linear regression\nlm1$coefficients[3]\n\nyt_lag2: 0.0970991636235151\n\n\n\nnames(lm1)\n\n\n'coefficients''residuals''effects''rank''fitted.values''assign''qr''df.residual''xlevels''call''terms''model'\n\n\n\nlm1$coefficients\n\n(Intercept)0.775214809725691yt_lag10.826283228753391yt_lag20.0970991636235151\n\n\n(참고) : - lm1$coefficients[2] : \\(\\phi_{21}\\).4 - lm(yt~yt_lag1)$coef[2] : \\(\\phi_{11}\\) 첫번재 pacf\n\nlm1$coefficients[2] # phi_{21}\n\nyt_lag1: 0.826283228753391\n\n\n\nlm(yt~yt_lag1)$coef[2] # \\phi_{11} : 첫번째 pacf\n\nyt_lag1: 0.91514283237285\n\n\n\n\n(방법3) Back-fitting\n\nstep1: residual을 구한다.\nstep2: residual끼리 regression\nstep3: 적합한 모델의 coef\n\n\n## step1\nres1 <- lm(yt~yt_lag1)$res\nres2 <- lm(yt_lag2~yt_lag1)$res\nlm(res1~res2)$coef[2] # pacf(zt)$acf[2]\n\nres2: 0.097099163623515\n\n\n\npacf(zt)$acf[2]\n\n0.0970991636235123\n\n\n\n\n\n\n## residual\nlm01<-lm(yt~yt_lag1) \nlm21<-lm(yt_lag2~yt_lag1)\nres1<-lm01$residuals\nres2<-lm21$residuals\nlm(res1~res2)$coefficients[2] # pacf(zt)$acf[2]\n\nres2: 0.097099163623515\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nlm1$coefficient[3] : \\(\\phi_{21}\\)\nlm(yt~yt_lag1)$coef[2] : \\(\\phi_{11}\\)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-20-6wk.html#연습문제-5.5",
    "href": "posts/4_TS2023/2023-05-20-6wk.html#연습문제-5.5",
    "title": "[TS] 6wk. 연습문제5장(3,4번) 실습",
    "section": "연습문제 5.5",
    "text": "연습문제 5.5\n확률과정 \\(Z_t=1+0.9Z_{t-1}+\\epsilon_t\\), \\(t=1,2,\\dots,100\\)으로부터 시계열 자료를 생성한 후 다음을 수행하라. 단, \\(Z_0=10\\)의 값을 주고 \\(\\{\\epsilon_t\\}\\)는 \\(\\text{WN}\\) \\(N(0,1)\\)이다.\nmodel: \\(Z_t=1+0.9Z_{t-1}+\\epsilon_t\\), \\(t=1,2,\\dots,100\\).\n\nset.seed(1306) # 평행세계의 인덱스 (1306번째 평행세계)\nzt<-c() # 차원이 미지수인 벡터 \nzt[1]<-1+0.9*10+rnorm(1)\n# zt[2]<-1+0.9*[1]+rnorm(1)\n# zt[3]<-1+0.9*z[2]+rnorm(1)\nfor(i in 2:100) zt[i]<-1+0.9*zt[i-1]+rnorm(1)\nzt\n\n\n10.777675156123310.660962285612511.129924124298710.72965261829329.382788371100859.2910901989592710.41226898833499.280670890580849.27899016050819.05015700672179.777134247967919.3827437027398.805520704157118.574071762172179.6636658123469110.00861320816310.05764137744179.088979358533399.8276465336302210.221844414899212.170444768457612.868114101802113.236760396548812.939105598428714.064828596912614.689415446656911.874573906167310.117135550635810.736236255557211.427873690594810.870492894735511.926313181054113.31363122509212.119022964977213.091749563285411.537622686662713.564256841632212.867269494275312.301225842344712.746934590026913.450773623818314.667384985405313.411672728483115.307673601167614.31080669561413.122242922602813.087510434643511.151738641912.500317116730712.13404312046612.216239664191113.294608735464813.236689850995213.206156716153813.78324231113312.746677793918712.107155554152811.286981791349910.709525433817310.36601924534988.197414292426479.075632673116098.349392905574369.305533140426197.439774508267778.190042742106178.546629064163698.6961349150551610.773878959064610.591571559416310.394556162971810.90274714975139.7702631175148910.122316507885610.4691927396949.587717000802729.321003528797548.71353442951276.863494371741878.102940909020597.681025224157677.309214676676114.915844466537725.597363062778256.577784336802857.037913967975987.518736237494756.669018224231434.465009391376395.514308334623417.445959648935566.222425141186764.740819833587065.294629081477515.991278762102885.196732211338576.505053865127626.64389757653257.958163700266119.1357435140494\n\n\n\n(a)\n\nplot(zt)\n\n\n\n\n\n\n(b)\n\nacf(zt)$acf\n\n\n10.915142832372850.8532663379270770.7983750544090320.7465985472025080.6884378995118340.6189412007053020.5726526260077430.5286664207628990.5073207823027460.4852741924763170.4497322740097530.4147161651964330.3788675323308670.3569530878065190.3327447909578890.3041226830109790.2785422896851010.2625319695615710.2264291330534140.194780443141645\n\n\n\n\n\n\n\n(c)\n\npacf(zt)$acf # 정상인 AR(1)\n\n\n0.915142832372850.09709916362351230.02780312951723640.0023436840732835-0.0600699044140887-0.1117452874219410.08063707048421640.01030459612319460.1324089785441610.0315743336953914-0.088386730109637-0.0584577460737368-0.04492505219212510.04549418578588550.0338085090119136-0.006926640757195950.001553929244265640.0311171061759323-0.171366229465896-0.0224072170637755\n\n\n\n\n\n\n\n(d) - (e)\n\npar(mfrow=c(2,1))\nyt<-c(zt,mean(zt),mean(zt)) # yt<-c(zt-mean(zt),0,0)\nyt_lag1<-c(mean(zt),zt,mean(zt))\nyt_lag2<-c(mean(zt),mean(zt),zt)\nplot(yt,yt_lag1)\nplot(yt,yt_lag2)\n\n\n\n\n\n양의 상관관계를 보인다.\nlag2는 lag1보다는 약한 상관관계를 보인다.\n\n\nlm(yt~yt_lag1)$coefficients # 이론적인 true값은 0.9\n\n(Intercept)0.858582447256087yt_lag10.91514283237285\n\n\n\nlm(yt~yt_lag2)$coefficients # 이론적인 true값은 0.9\n\n(Intercept)1.48464708639543yt_lag20.853266337927077\n\n\n\n1307번째 평행세계, 2000번째 평행세계,… 계속 반복을 하다보면 값들의 평균이 결국 \\(0.9\\) 로 수렴한다.\nacf값이 큰수의 법칙에 따라 true acf값으로 수렴하게 될 것이다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-18-4wk-2.html",
    "href": "posts/4_TS2023/2023-05-18-4wk-2.html",
    "title": "[TS] 4wk-2. PACF",
    "section": "",
    "text": "PACF\n\n\nMotivation\n우선 PACF가 등장하게 된 모티브는 ACF가 아쉬운 점이 있었던 것.\n- ACF:\n\n정상인 AR(p)임을 주장하는 근거.\nwhite-noise.1임을 주장하는 근거.\n\nACF의 아쉬운 점은 ACF만 가지고는 AR(1)인지 AR(2)인지 판단할 수 있는 근거가 없다. 그래서 PACF라는 개념을 만들었습니다.\n결론은 PACF를 활용하면 AR모형일 때 AR(1)인지 AR(2)인지 AR(3), … 인지 판단할 수 있어요.\n- 예시\n\n\n실습\n3번 문제 pacf\n\nzt <- c(7,6,5,8,9,4,5,5,4,6,7,8,5,6,5)\n\n\npacf(zt)$acf\n\n\n0.09375-0.292610837438424-0.0700455193966981-0.275261299435028-0.319266184753246-0.05111939051204050.0906650359255257-0.179143783577863-0.0487796620350025-0.1303428788036220.0623391055134182\n\n\n\n\n\n\nA<-cbind(c(1,3/32,-9/32),c(3/32,1,3/32),c(-9/32,3/32,1))\nA\n\n\n\nA matrix: 3 × 3 of type dbl\n\n     1.000000.09375-0.28125\n     0.093751.00000 0.09375\n    -0.281250.09375 1.00000\n\n\n\n\n\nA3<-cbind(c(1,3/32,-9/32),c(3/32,1,3/32),c(3/32,-9/32,-0.125))\nA3\n\n\n\nA matrix: 3 × 3 of type dbl\n\n     1.000000.09375 0.09375\n     0.093751.00000-0.28125\n    -0.281250.09375-0.12500\n\n\n\n\n\ndet(A3)/det(A)\n\n-0.0700455193966981\n\n\n\npacf(zt)$acf[3]\n\n-0.0700455193966981\n\n\n\n\n\n\n함수를 이용해서 구한 값과 일치함을 확인!\n\n\n\n\n\n\nFootnotes\n\n\nlag=1일때만 존재하고 나머지는 다 빵.↩︎"
  },
  {
    "objectID": "posts/4_TS2023/2023-06-14-ts-begas_guebin.html",
    "href": "posts/4_TS2023/2023-06-14-ts-begas_guebin.html",
    "title": "0616 TS 공부 (교수님)",
    "section": "",
    "text": "library(forecast)\nlibrary(tseries)\nlibrary(ggplot2)\nlibrary(reshape)\nlibrary(zoo)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nAttaching package: ‘zoo’\n\n\nThe following objects are masked from ‘package:base’:\n\n    as.Date, as.Date.numeric\n\n\n\n\n\nData Load\n\n#============================================================\n# Data Load\n# - 1949년 ~ 1960년 까지의 월별 비행기 탑승 고객 수\n#============================================================ \norigin <- AirPassengers\norigin\n\n\n\nA Time Series: 12 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1949112118132129121135148148136119104118\n    1950115126141135125149170170158133114140\n    1951145150178163172178199199184162146166\n    1952171180193181183218230242209191172194\n    1953196196236235229243264272237211180201\n    1954204188235227234264302293259229203229\n    1955242233267269270315364347312274237278\n    1956284277317313318374413405355306271306\n    1957315301356348355422465467404347305336\n    1958340318362348363435491505404359310337\n    1959360342406396420472548559463407362405\n    1960417391419461472535622606508461390432\n\n\n\n\n\nclass(origin) # ts 객체\n\n'ts'\n\n\n\nstart(origin)\nend(origin)\nfrequency(origin)\n\n\n19491\n\n\n\n196012\n\n\n12\n\n\n\n\nEDA\n\n# 시도표\nplot(origin)\n# 데이터에 이분산이 존재함을 확인일 수 있음\n# 분산 안정화를 위한 데이터 변환 필요\n\n\n\n\n\nBoxcox먼저 (등분산) , seasonal, 차분, 계절차분 순서 중요!\n\n시즈널, 트렌드, 분산이상한데 분산맞춰주는게 우산.\n\n#분산 안정화를 위한 BoxCox 변환\nlambda <- BoxCox.lambda(origin)\ntran_org <- BoxCox(origin, BoxCox.lambda(origin))\nplot(tran_org)\n# BoxCox 변환 이후 이분산의 효과가 줄어 든것을 확인\n\n\n\n\n\nBoxCox.lambda(origin)\n\n-0.294715585559316\n\n\n\n## 질문?\n# 정규성 및 Corr\n# Hist Plot\nhist(tran_org,prob=TRUE,12)\nlines(density(tran_org))\n\n\n\n\nQQ Plot, 정규성 검정 \\(\\to\\) 왜하는지?\n\n# Q-Q PLOT\nqqnorm(tran_org)\nqqline(tran_org)\n\n\n\n\n\n# 상관관계 확인\nlag.plot(tran_org,12,do.lines=FALSE)\n#전반적으로 데이터는 정규분포를 따르고 시차가 12일때 상관관계가 높음\n\n\n\n\n- 원래는 아래와 같이 해야한다.\n\n\n\n\n## lag =1 \n\n\nn=length(y)\nlag = 1 \ncorrs <- c()\nfor(lag in 1:15){\ncorrs[lag] <- cor(y[1:(144-lag)],y[(1+lag):144])\n}\n\n\nplot(corrs,type='o')\n\n\n\n\n\n산점도가 직선일 경우에만 coef 가 의미가 있으므로 이는 문제가 생김\n\n- ACF를 보는 경우\n\nacf(tran_org)\n\n\n\n\n\n해석: 만약에 lag=12에 해당하는 coef 가 0이라면 일정하게 감소해야하는데, lag=12에서 반등 -> \\(y_t\\)와 \\(y_{t-12}\\)와 상관관계 존재 -> \\(y_{t},y_{t-12},y_{t-24}\\) 와도 관계가 있음 -> 주기가 존재 (12)\n단점: 보기 불편\n\n- \\(y_t\\)와 \\(y_{t-1}\\)의 상관성이 강한편이라. 이러한 상관관계가 lag에 따라서 물려지므로 (\\(y_t\\)와 \\(y_{t-1}\\)이 0.9의 상관관계를 가진다면 \\(y_{t}\\)와 \\(y_{t-2}\\)의 직접적 상관관계가 없어도 0.81이 계산됨) 차분을 한뒤에 ACF를 관찰할 수 있음\n\nacf(diff(tran_org,1))\n\n\n\n\n\n해석: 차분한뒤에는 lag=12에서 상관관계가 뚜렷 -> 주기가 12임을 추측 -> SARIMA에서 이런식으로 주기잡아냄\n\n\nacf(tran_diff_org, lag.max = 24) # sarima에서 가져온 코드\n\n\n\n\n– 이러한 방식의 해석을 SARIMA에서 함\n\n만약에 lag=12에 해당하는 coef 가 0이라면 일정하게 감소해야하는데, lag=12에서 반등 -> \\(y_t\\)와 \\(y_{t-12}\\)와 상관관계 존재 -> \\(y_{t},y_{t-12},y_{t-24}\\) 와도 관계가 있음 -> 주기가 존재 (12)\n\n\n\n시계열 분해 및 회귀분석 이용 예측\n\\(y_t = season_t + trend_t + noise\\)\n와 같다고 가정하자.\n우리가 ARMA통해서 맞출수있는건 noise 뿐임\nseason + trend가 있으면 non-stationary timse serise이므로 ARMA로 분석X\n\ntrend를 제거하기위해서는 차분이 사용\nseason을 제거하기 위해서는 계절차분을 사용\n그런데 분해방법을 이용하면, 차분과 계절차분을 쓰지 않고도 season , trend를 제거할 수 있음.\n\n결국 만약에 \\(y_t\\)를 입력으로 넣으면 출력이 \\(season_t, trend_t, noise\\)로 알아서 data-adative 하게 나오게 만드는 장치가 있다면,차분과 계절차분을 사용하지 않아도 무방\n\n비정상시계열의 ACF, PACF 를 판단하면서 lag을 얼마로 차분할지 계절차분할지 순서는어떻게할지 등을 고민할 필요 X\n\n그 장치가 stl\n\nstl_tran_org <- stl(tran_org, s.window = 12) # --주기를 12로 잡은 근거는 위에있음\n\n결과로 stl_tran_org 이게 있음\n\ny1= as.data.frame(stl_tran_org$time.series)$seasonal # 계절성분\ny2= as.data.frame(stl_tran_org$time.series)$trend # 트렌드\ny3= as.data.frame(stl_tran_org$time.series)$remainder # s노이즈\n\n\nplot(y1+y2+y3)\nlines(y)\n\n\n\n\n\n# plot(stl_tran_org)\n# # 1차 Trend와 Seasonality 존재\n# # 잔차는 White Noise로 판단\n\n만약에 \\(y3\\)가 ARMA같으면 그냥 분석해도 무방\n\nplot(y3,type='l')\n\n\n\n\n\nacf(y3)\n\n\n\n\n\n이걸 MA(4)로 피팅해도 무방\n\n방법1: \\(Y_t =T_t + S_t+ {\\tt 오차항은 정규로가정}\\)\n방법2: \\(Y_t= T_t+{\\tt 계절성을 모델링하는 더미변수}+{\\tt 오차항은 정규가정}\\)\n방법3: \\(Y_t= S_t+{\\tt 시간에 비례하는 선형트렌드가정} + {\\tt 오차항은 정규가정}\\)\n\ny1_ = 2*1:100/100\ny2_ = 3*1:100/100+3\ny_ = c(y1_,y2_)\n\n\nplot(y-y2,type='l') # 이것을 회귀분석 \n# y = Y_t-T_t \n# x = 1월에 해당하는 더미변수 + ...+ 12월에 해당하는 더미변수 \n# 오차항 = 정규\n\n\n\n\n- 이중에서 trend를 이용 + season은 버림 // season은 따로 모델링\n\n# 계절형 Dummy 변수 생성\nM <- factor(cycle(tran_org))\nstl_tran_org_df <- as.data.frame(stl_tran_org$time.series)\n\n\n# 회귀 모형 생성\n# 모형식 : tran_org=trend∗β1+M1∗d1+...+M11∗d11+ϵ\nmodel_stl <- lm(formula = tran_org~0+stl_tran_org_df$trend+M, na.action = NULL)\nsummary(model_stl)\n\n\nCall:\nlm(formula = tran_org ~ 0 + stl_tran_org_df$trend + M, na.action = NULL)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0208982 -0.0030056  0.0003675  0.0032375  0.0186285 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \nstl_tran_org_df$trend  1.003132   0.006557 152.982  < 2e-16 ***\nM1                    -0.025890   0.017899  -1.446  0.15043    \nM2                    -0.029141   0.017911  -1.627  0.10614    \nM3                    -0.002850   0.017923  -0.159  0.87389    \nM4                    -0.009503   0.017936  -0.530  0.59713    \nM5                    -0.010617   0.017948  -0.592  0.55519    \nM6                     0.012901   0.017961   0.718  0.47386    \nM7                     0.032071   0.017974   1.784  0.07669 .  \nM8                     0.030402   0.017986   1.690  0.09335 .  \nM9                     0.004045   0.017998   0.225  0.82255    \nM10                   -0.023032   0.018011  -1.279  0.20322    \nM11                   -0.052048   0.018023  -2.888  0.00454 ** \nM12                   -0.028326   0.018036  -1.571  0.11870    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.006548 on 131 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.92e+06 on 13 and 131 DF,  p-value: < 2.2e-16\n\n\ntran_org 에서 이미 \\(\\hat{\\beta}_0+ \\hat{\\beta}_1x_i\\) 의 성분은 추정되었다고 가정하였으므로\nmodel_stl <- lm(formula = tran_org~stl_tran_org_df$trend+M, na.action = NULL)\n이 아니라\nmodel_stl <- lm(formula = tran_org~0+stl_tran_org_df$trend+M, na.action = NULL)\n을 사용하는 것임\n\n# 잔차 검정\npar(mfrow=c(3,1))\n# time Plot\nplot(resid(model_stl))\n# Hist Plot\nhist(resid(model_stl),prob=TRUE,12)\nlines(density(resid(model_stl)))\n# Q-Q PLOT\nqqnorm(resid(model_stl))\nqqline(resid(model_stl))\n# Q-Q Plot과 Histogram을 확인하면 양쪽 끝이 두텁지만 White Noise라고 판단하기 어려움이 없음\n\n\n\n\n\n트렌드 분산 같이 잡고싶을 때\n\n\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\n\n# 원 데이터 및 fitted 데이터의 비교\n# BoxCox 역변환 필요 함\nlines(InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)), col='red')\nmean((origin - InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)))^2, na.rm = TRUE)\n\n81.1346391326119\n\n\n\n\n\n- 방법1\n\n# 회귀 모형 생성\n# 모형식 : tran_org=trend∗β1+M1∗d1+...+M11∗d11+ϵ\nmodel_stl <- lm(formula = tran_org~ 0+stl_tran_org_df$trend+stl_tran_org_df$seasonal, na.action = NULL)\nsummary(model_stl)\n\n\nCall:\nlm(formula = tran_org ~ 0 + stl_tran_org_df$trend + stl_tran_org_df$seasonal, \n    na.action = NULL)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0176596 -0.0024179  0.0002433  0.0028433  0.0138835 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \nstl_tran_org_df$trend    0.9999916  0.0001588 6298.75   <2e-16 ***\nstl_tran_org_df$seasonal 1.0086463  0.0178343   56.56   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.005194 on 142 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.984e+07 on 2 and 142 DF,  p-value: < 2.2e-16\n\n\n\n# 잔차 검정\npar(mfrow=c(3,1))\n# time Plot\nplot(resid(model_stl))\n# Hist Plot\nhist(resid(model_stl),prob=TRUE,12)\nlines(density(resid(model_stl)))\n# Q-Q PLOT\nqqnorm(resid(model_stl))\nqqline(resid(model_stl))\n# Q-Q Plot과 Histogram을 확인하면 양쪽 끝이 두텁지만 White Noise라고 판단하기 어려움이 없음\n\n\n\n\n\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\n\n# 원 데이터 및 fitted 데이터의 비교\n# BoxCox 역변환 필요 함\nlines(InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)), col='red')\n#mean((origin - InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)))^2, na.rm = TRUE)\n\n\n\n\n- 방법3\n\n# 회귀 모형 생성\n# 모형식 : tran_org=trend∗β1+M1∗d1+...+M11∗d11+ϵ\nmodel_stl <- lm(formula = tran_org~ time(tran_org)+stl_tran_org_df$trend+stl_tran_org_df$seasonal, na.action = NULL)\nsummary(model_stl)\n\n\nCall:\nlm(formula = tran_org ~ time(tran_org) + stl_tran_org_df$trend + \n    stl_tran_org_df$seasonal, na.action = NULL)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0177582 -0.0021157 -0.0002719  0.0030251  0.0138833 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               2.1642334  1.5824743   1.368    0.174    \ntime(tran_org)           -0.0011787  0.0008586  -1.373    0.172    \nstl_tran_org_df$trend     1.0513689  0.0356252  29.512   <2e-16 ***\nstl_tran_org_df$seasonal  1.0087073  0.0178209  56.602   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.00519 on 140 degrees of freedom\nMultiple R-squared:  0.9966,    Adjusted R-squared:  0.9965 \nF-statistic: 1.352e+04 on 3 and 140 DF,  p-value: < 2.2e-16\n\n\n\n# 잔차 검정\npar(mfrow=c(3,1))\n# time Plot\nplot(resid(model_stl))\n# Hist Plot\nhist(resid(model_stl),prob=TRUE,12)\nlines(density(resid(model_stl)))\n# Q-Q PLOT\nqqnorm(resid(model_stl))\nqqline(resid(model_stl))\n# Q-Q Plot과 Histogram을 확인하면 양쪽 끝이 두텁지만 White Noise라고 판단하기 어려움이 없음\n\n\n\n\n\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\n\n# 원 데이터 및 fitted 데이터의 비교\n# BoxCox 역변환 필요 함\nlines(InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)), col='red')\n#mean((origin - InvBoxCox(model_stl$fitted.values, lambda = BoxCox.lambda(origin)))^2, na.rm = TRUE)\n\n\n\n\n\n\n지수평활을 이용한 예측\n\n단순 지수 평활: 추세나 계절적 변동이 없는 시계열 예측에 사용\n이중 지수 평활: 추세만 존재하는 시계열 예측에 사용\nHoltWinters: 추세와 계절 요인이 있는 시계열 예측에 사용\n\n이중 지수 평활을 확장한 개념으로 특정 기간 내의 계절성을 함께 고려 가능\n- 더하는 모형\n\\(Y_t = T_t + S_t + {\\tt 오차}\\)\n\nt = (1:120/120)*10\ns = rep(c(1,2,3,4,5,6,7,6,5,4,3,2),10)\ne = rnorm(120)*0.9\n\n\nplot(t+s+e,type='l')\n\n\n\n\n- 곱하는 모형\n\\(Y_t = T_t * S_t + {\\tt 오차}\\)\n\nplot(t*s+e,type='l')\n\n\n\n\n얘는 t랑 s를 엄청 잘찾으면 분산안정화가 필요없음\n\n#============================================================\n# 지수평활을 이용한 예측\n#============================================================\n\nplot(stl(origin, s.window=12))\n# Trend 및 Seasonality 존재\n# Holt-Winter 지수평활 모형이 적합\n\n\n\n\n\n#HoltWinters 모형 생성\nmodel_es <- HoltWinters(origin, seasonal = \"multiplicative\")\n\n# 원 데이터 및 fitted 데이터의 비교\n# plot\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\nlines(model_es$fitted[,1], col='red')\n# mse 125.5\nmean((origin-model_es$fitted[,1])^2)\n\n125.536195962121\n\n\n\n\n\n- 또다른방법\n\n#HoltWinters 모형 생성\nmodel_es <- HoltWinters(tran_org, seasonal = \"additive\")\n\n# 원 데이터 및 fitted 데이터의 비교\n# plot\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\nlines(InvBoxCox(model_es$fitted[,1], lambda = BoxCox.lambda(origin)), col='red')\n# mse 125.5\n#mean((tran_org-model_es$fitted[,1])^2)\n\n\n\n\n\n\nARIMA를 이용한 예측\n\nSeasonality 제거/ 차분인데 시즈널리티가 뚜렷하면 시즈널 제거…\n\n\n# 데이터 탐색 및 모형식별\n# 시도표\nplot(origin)\n# 데이터의 이분산과 1차 추세가 존재함\n# 분산 안정화를 위한 Box Cox 변환과 1차 차분 필요\n\n\n\n\n\n# 분산 안정화 및 차분\ntran_org <- BoxCox(origin, BoxCox.lambda(origin))\nplot(tran_org)\ntran_diff_org <- diff(tran_org)\nplot(tran_diff_org)\n\n\n\n\n\n\n\n\n계절성을 먼저 제거하고 차분을 해야하는 케이스가 존재.\n일반적으로는 차분을 먼저한다.\n\n\n# ACF, PACF를 통한 탐색\nlayout(1:2)\nacf(tran_diff_org, lag.max = 24)\npacf(tran_diff_org, lag.max=24)\n\n\n\n\n\n# 계절 차분 및 ACF, PACF를 통한 탐색\ntran_sdiff_org <- diff(tran_diff_org, lag = 12)\n\n\nacf(tran_sdiff_org, lag.max = 48)\n# acf는 lag=1,3,12에서 0이 아닌값 가짐  비계절 시차 4부터 절단 -> MA(3), 계절 -> 시차 2부터 절단 SMA(1)\n\n\n\n\n\npacf(tran_sdiff_org, lag.max = 24)\n# 시차 2와 8에서 0보다 큰 값을 가지지만 정확한 모형을 찾기 위해 auto.arima를 통해 aic가 최소가 되는 order 값 구함\n\n\n\n\n\nauto.arima(tran_sdiff_org, max.p = 3, max.q=3, max.Q=1)\nauto.arima(tran_org, max.p = 3, max.q=3, max.Q=1)\n# 모형 구축\n\nSeries: tran_sdiff_org \nARIMA(0,0,1)(0,0,1)[12] with zero mean \n\nCoefficients:\n          ma1     sma1\n      -0.4355  -0.5847\ns.e.   0.0908   0.0725\n\nsigma^2 = 5.789e-05:  log likelihood = 451.59\nAIC=-897.18   AICc=-896.99   BIC=-888.55\n\n\nSeries: tran_org \nARIMA(0,1,1)(0,1,1)[12] \n\nCoefficients:\n          ma1     sma1\n      -0.4355  -0.5847\ns.e.   0.0908   0.0725\n\nsigma^2 = 5.855e-05:  log likelihood = 451.6\nAIC=-897.19   AICc=-897.01   BIC=-888.57\n\n\n\nmodel_arima <- arima(tran_sdiff_org, order=c(0,0,1), seasonal = list(order = c(0,0,1), period = 12))\nmodel_arima <- arima(tran_org, order=c(0,1,1), seasonal = list(order = c(0,1,1), period = 12))\n\n\n# 모형 검진\n# 잔차 검정\ntsdiag(model_arima)\n# 독립성 검정\n\n\n\n\n\nBox.test(model_arima$residuals, type=\"Ljung-Box\")\n# 잔차의 독립성, 등분산성, 정규성 만족\n\n\n    Box-Ljung test\n\ndata:  model_arima$residuals\nX-squared = 0.15595, df = 1, p-value = 0.6929\n\n\nplot(spline(time(origin), origin),type=‘l’,xlab=‘Time’,ylab=‘Pop’)\n\n# spline ? underline function을 부드럽게 만드는 함수...\n\n\n# 원 데이터 및 fitted 데이터의 비교\nplot(spline(time(origin), origin),type='l',xlab='Time',ylab='Pop')\nlines(InvBoxCox(fitted(model_arima), BoxCox.lambda(origin)), col='red')\nmean((origin - InvBoxCox(fitted(model_arima), BoxCox.lambda(origin)))^2)\n\n107.241415231708\n\n\n\n\n\n\n# 12개월 예측\narima_fit <- predict(model_arima, n.ahead=12) #BoxCox 변환 데이터 사용\nlambda <- BoxCox.lambda(origin)\n\n\nts.plot(origin, xlim=c(1950,1965), ylim = c(0, 1000))\nlines(InvBoxCox(arima_fit$pred, lambda),col=\"red\")\nlines(InvBoxCox(arima_fit$pred+1.96*arima_fit$se, lambda),col=\"blue\",lty=1)\nlines(InvBoxCox(arima_fit$pred-1.96*arima_fit$se, lambda),col=\"blue\",lty=1)"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-numpy4.html",
    "href": "posts/1_IP2022/2023-02-23-numpy4.html",
    "title": "Numpy 4단계(concat, stack)",
    "section": "",
    "text": "Numpy array를 결합하는 기능들에 대해 알아보자. (np.concatenate, np.concat)\n\n\n\n- 기본예제\n\nimport numpy as np\n\n\na = np.array([1,2])\nb = -a\n\n\nnp.concatenate([a,b])\n\narray([ 1,  2, -1, -2])\n\n\n- 응용\n\na = np.array([1,2])\nb = -a\nc = np.array([3,4,5])\n\n\nnp.concatenate([a,b,c])\n\narray([ 1,  2, -1, -2,  3,  4,  5])\n\n\n\n여기까진 딱히 concatenate의 메리트가 없어보임\n리스트였다면 a+b+c하면 되는 기능이니까?\n\n- 2d array에 적용해보자.\n\na = np.arange(4).reshape(2,2)\nb = -a\n\n\na\n\narray([[0, 1],\n       [2, 3]])\n\n\n\nb\n\narray([[ 0, -1],\n       [-2, -3]])\n\n\n\nnp.concatenate([a,b])\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n위아래로 붙었네! 그럼 옆으로 붙이려면 어떻게 하지?\n\n- 옆으로 붙이려면?\n\nnp.concatenate([a,b], axis=1)\n\narray([[ 0,  1,  0, -1],\n       [ 2,  3, -2, -3]])\n\n\n- 위의 코드에서 axis=1 이 뭐지? axis=0,2 등을 치면 결과가 어떻게 될까?\n\nnp.concatenate([a,b],axis=0)\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n이건 그냥 np.concatenate([a,b])와 같다.\nnp.concatenate([a,b])는 np.concatenate([a,b],axis=0)의 생략버전이군?\n\n\nnp.concatenate([a,b],axis=2)\n\nAxisError: axis 2 is out of bounds for array of dimension 2\n\n\n\n이런건 없다.\n\n- axis의 의미가 뭔지 궁금함. 좀 더 예제를 살펴보자.\n\na = np.array(range(2*3*4)).reshape(2,3,4) # 3d array\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\nb = -a\nb\n\narray([[[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=0)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=1)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b], axis=2)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\n이번에는 axis=2까지 된다?\n\n\nnp.concatenate([a,b], axis=3)\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\naxis=3까지는 안된다?\n\n- 뭔가 나름의 방식으로 합쳐지는데 원리가 뭘까?\n(분석1) np.concatenate([a,b], axis=0)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=0).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n첫번째 차원이 바뀌었다. \\(\\Rightarrow\\) 첫번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=0 (파이썬은 0부터 시작하니까!)\n\n(분석2) np.concatenate([a,b], axis=1)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n두번째 차원이 바뀌었다. \\(\\Rightarrow\\) 두번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=1\n\n(분석3) np.concatenate([a,b], axis=2)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n세번째 차원이 바뀌었다. \\(\\Rightarrow\\) 세번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=2\n\n(분석4) np.concatenate([a,b], axis=3)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=3).shape\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\n네번째 차원이 없다. \\(\\Rightarrow\\) 세번째 축이 없다. \\(\\Rightarrow\\) axis=3으로 하면 에러가 난다.\n\n(보너스)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-1)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n마지막 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막 축이 바뀌었다. \\(\\Rightarrow\\) axis=-1\n\n(보너스2)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-2)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n마지막에서 2번째 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막에서 2번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=-2\n\n(보너스3)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-3)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-3).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n마지막에서 3번째 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막에서 3번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=-3\n\n(보너스4)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-4)\n\nAxisError: axis -4 is out of bounds for array of dimension 3\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-4).shape\n\nAxisError: axis -4 is out of bounds for array of dimension 3\n\n\n\n마지막에서 4번째 차원은 없다. \\(\\Rightarrow\\) 마지막에서 4번째 축은 없다. \\(\\Rightarrow\\) axis=-4는 에러가 난다.\n\n- 0차원은 축이 없으므로 concatenate를 쓸 수 없다.\n\na = np.array(1)\nb = np.array(-1)\n\n\na.shape, b.shape\n\n((), ())\n\n\n\nnp.concatenate([a,b])\n\nValueError: zero-dimensional arrays cannot be concatenated\n\n\n이게 만약에 이렇게 바뀌면 1차원이니까 쓸 수 있다.\n\na = np.array([1])\nb = np.array([-1])\na.shape, b.shape\n\n((1,), (1,))\n\n\n\nnp.concatenate([a,b])\n\narray([ 1, -1])\n\n\n- 꼭 a,b가 같은 차원일 필요는 없다.\n\na = np.array(range(4)).reshape(2,2)\nb = np.array(range(2)).reshape(2,1)\n\n\nnp.concatenate([a,b], axis=1)\n\narray([[0, 1, 0],\n       [2, 3, 1]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=1).shape\n\n((2, 2), (2, 1), (2, 3))\n\n\n\n\n\n- 혹시 아래가 가능할까?\n\n\\((3,)\\) 결합 : \\((3,) \\Rightarrow (3,2)\\)\n\n\na = np.array([1,2,3])\nb = -a\n\n\na,b\n\n(array([1, 2, 3]), array([-1, -2, -3]))\n\n\n\na.shape, b.shape\n\n((3,), (3,))\n\n\n\nnp.concatenate([a,b], axis=1)\n\nAxisError: axis 1 is out of bounds for array of dimension 1\n\n\n\n불가능\n\n- 아래와 같이 하면 해결 가능\n\na = np.array([1,2,3]).reshape(3,1)\nb = -a\n\n\na.shape, b.shape\n\n((3, 1), (3, 1))\n\n\n\na,b\n\n(array([[1],\n        [2],\n        [3]]),\n array([[-1],\n        [-2],\n        [-3]]))\n\n\n\nnp.concatenate([a,b], axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n\n분석: \\((3) (3) \\Rightarrow (3,1),(3,1)\\Rightarrow (3,1) \\space \\tt{concat} \\space (3,1)\\)\n\n- 위의 과정을 줄여서 아래와 같이 할 수 있다.\n\na = np.array([1,2,3])\nb = -a\n\n\nnp.stack([a,b], axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n- 아래도 가능\n\nnp.stack([a,b],axis=0)\n\narray([[ 1,  2,  3],\n       [-1, -2, -3]])\n\n\n- 분석해보고 외우자\n(분석1)\n\na = np.array([1,2,3])\nb = -a\n\n\na.shape, b.shape, np.stack([a,b],axis=0).shape\n\n((3,), (3,), (2, 3))\n\n\n\n\\((3)(3) \\Rightarrow \\text{첫 위치에 축을 추가 (axis=0)} \\Rightarrow (1,3)(1,3) \\Rightarrow (2,3)\\)\n\n(분석2)\n\na = np.array([1,2,3])\nb = -a\n\n\na.shape, b.shape, np.stack([a,b],axis=1).shape\n\n((3,), (3,), (3, 2))\n\n\n\\((3)(3)\\Rightarrow \\text{두번째 위치에 축을 추가 (axis=1)} \\Rightarrow (3,1)(3,1) \\Rightarrow (3,2)\\)\n- 고차원예제\n\na = np.arange(3*4*5).reshape(3,4,5)\nb = -a\n\n\na.shape, b.shape\n\n((3, 4, 5), (3, 4, 5))\n\n\n\nnp.stack([a,b], axis=0).shape # (3,4,5) => (1,3,4,5) // 첫 위치에 축이 추가되고 스택\n\n(2, 3, 4, 5)\n\n\n\nnp.stack([a,b], axis=1).shape # (3,4,5) => (3,1,4,5) // 두번째 위치에 축이 추가되고 스택\n\n(3, 2, 4, 5)\n\n\n\nnp.stack([a,b], axis=2).shape # (3,4,5) => (3,4,1,5) // 세번째 위치에 축이 추가되고 스택\n\n(3, 4, 2, 5)\n\n\n\nnp.stack([a,b], axis=3).shape # (3,4,5) => (3,4,5,1) // 네번째 위치에 축이 추가되고 스택\n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b], axis=-1).shape # axis=-1 <=> axis=3\n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b], axis=-2).shape # axis=-2 <=> axis=2\n\n(3, 4, 2, 5)\n\n\nnp.concatenate 는 축의 총 개수를 유지하면서 결합, np.stack은 축의 개수를 하나 증가시키면서 결합"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class3.html",
    "href": "posts/1_IP2022/2023-02-15-class3.html",
    "title": "class 3단계",
    "section": "",
    "text": "이 단계에서는 클래스오브젝트에 소속된 변수와 인스턴스오브젝트에 소속된 변수를 설명한다.\n\n\n\n- 파이썬은 모든 것이 오브젝트로 이루어져 있다. \\(\\leftarrow\\) 우선 그냥 외우기!\n- 오브젝트는 메모리 주소에 저장되는 모든 것을 의미한다.\n\na = 1\nid(a) # 메모리주소를 보는 명령어\n\n7618240\n\n\n\na = 'asdf'\nid(a)\n\n140366991918512\n\n\n\na = [1,2,3]\nid(a)\n\n140366923845376\n\n\n- 클래스와 인스턴스도 오브젝트다.\n\nclass A:\n    x = 0\n    def f(self):\n        print(self.x)\n\n\nid(A)\n\n39987760\n\n\n\nA는 오브젝트\n\n\nb = A()\n\n\nid(b)\n\n140366932540960\n\n\n\nb는 오브젝트\n\n- 앞으로는 A를 클래스 오브젝트, a,b를 인스턴스 오브젝트라고 부르자.\n\n\n- 시점0\n\n# 클래스 선언 시점\nclass A:\n    x = 0\n    y = 0\n    def f(self):\n        self.x = self.x + 1\n        A.y = A.y + 1\n        print('현재 인스턴스에서 f가 {}번 실행'.format(self.x))\n        print('A클래스에서 만들어진 모든 인스턴스들에서 f가 {}번 실행'.format(self.y))\n\n\nid(A) # A라는게 메모리 어딘가에 저장되어 있음.\n\n53014736\n\n\n\nA.x, A.y\n\n(0, 0)\n\n\n- 시점1\n\n# a라는 인스턴스\na = A()\n\n\n# b라는 인스턴스\nb = A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 0], [0, 0], [0, 0])\n\n\n- 시점2\n\na.f() # a에서 f라는 메소드 사용\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 1번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 1], [1, 1], [0, 1])\n\n\n\n여기서 현재 인스턴스라 함은 a를 의미한다.\n\n[1,1] 에서 첫번째 1은 현재 인스턴스(a)에서 f가 1번 실행되었다는 것을 의미하고\n[1,1] 에서 두번째 1은 A클래스에서 만들어진 모든 인스턴스들에서 f가 1번 실행되었음을 의미한다.\n\n\n- 시점3\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 2번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 2], [1, 2], [1, 2])\n\n\n\n여기서 현재 인스턴스라 함은 b를 의미한다.\n\n[1,2] 에서 첫번째 1은 현재 인스턴스(b)에서 f가 1번 실행되었다는 것을 의미하고\n[1,2] 에서 두번째 2는 A클래스에서 만들어진 모든 인스턴스들에서 f가 2번 실행되었음을 의미한다 (왜냐면, 위에서 이미 한번 실행을 했기 때문)\n\n\n- 시점4\n\nb.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 3번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 3], [1, 3], [2, 3])\n\n\n- 시점5\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 4번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 4], [2, 4], [2, 4])\n\n\n- 시점6\n\n# c라는 인스턴스를 만들어보자.\nc = A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 4], [2, 4], [2, 4], [0, 4])\n\n\n- 시점7\n\nc.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 5번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 5], [2, 5], [2, 5], [1, 5])\n\n\n- 신기한 점: 각 인스턴스에서 인스턴스이름.f()를 실행한 횟수를 서로 공유하는 듯 하다. (마치 A가 관리하는 것 처럼 느껴진다.)"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class6.html",
    "href": "posts/1_IP2022/2023-02-23-class6.html",
    "title": "class 6단계",
    "section": "",
    "text": "상속, 사용자정의 자료형\n\n\n\n- 아래와 같은 클래스를 만들자.\n\n이름, 직급, 연봉에 대한 정보가 있다.\n연봉을 올려주는 메소드가 존재함.\n\n\nclass Employee:\n    def __init__(self, name,position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self, pct):\n        self.pay = self.pay * (1+pct)\n\n- 확인\n\niu = Employee('iu', position = 'staff', pay = 5000)\nhynn = Employee('hynn', position = 'staff', pay = 4000)\nhd = Employee('hodong', position = 'mgr', pay = 8000)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5000 \n        \n\n\n\niu.giveraise(0.1)\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn.giveraise(0.2)\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4800.0 \n        \n\n\n- 회사의 모든 직원의 연봉을 \\(10\\%\\)씩 올려보자.\n\niu = Employee('iu', position = 'staff', pay = 5000)\nhynn = Employee('hynn', position = 'staff', pay = 4000)\nhd = Employee('hodong', position = 'mgr', pay = 8000)\n\n\nfor i in [iu, hynn, hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 8800.0 \n        \n\n\n- 매니저직은 일반직원들의 상승분에서 \\(5\\%\\)의 보너스가 추가되어 상승한다고 가정하고 모든 직원의 연봉을 \\(10\\%\\)씩 올리는 코드를 구현해보자.\n\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Employee('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu, hynn, hd]:\n    if i.position == 'mgr':\n        i.giveraise(0.1 + 0.05)\n    else:\n        i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.0 \n        \n\n\n\n\n\n\nclass Manager:\n    def __init__(self, name, position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Manager('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n\n\n\n\nclass Manager(Employee):\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Manager('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1) \n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n- 요약: 이미 만들어진 클래스에서 대부분의 기능은 그대로 쓰지만 일부기능만 변경 혹은 추가하고 싶다면 클래스를 상속하면 된다!\n\n\n\n\nref: http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791165213190\n\n- list와 비슷한데 멤버들의 빈도가 계산되는 메소드를 포함하는 새로운 나만의 list를 만들고 싶다.\n\nlst = ['a','b','a','c','b','a','d']\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n- 아래와 같은 딕셔너리를 만들고 싶다.\n\nfreq = {'a':3, 'b':2, 'c':1, 'd':1} \nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n\nlst.frequency()를 입력하면 위의 기능이 수행되도록 변형된 list를 쓰고 싶다.\n\n- 구현\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = {'a':0, 'b':0, 'c':0, 'd':0}\nfreq\n\n{'a': 0, 'b': 0, 'c': 0, 'd': 0}\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\nKeyError: 'a'\n\n\n에러이유? freq['a']를 호출할 수 없다. \\(\\to\\) freq.get('a',0) 이용\n\nfreq['a']\n\nKeyError: 'a'\n\n\n\nfreq.get?\n\n\nSignature: freq.get(key, default=None, /)\nDocstring: Return the value for key if key is in the dictionary, else default.\nType:      builtin_function_or_method\n\n\n\n\nkey에 대응하는 값이 있으면 그 값을 리턴하고 없으면 default를 리턴\n\n\nfreq.get('a') # freq['a']에 해당하는 자료가 없어도 에러가 나지 않음\n\n\nfreq.get('a',0) # freq['a']에 해당하는 자료가 없어도 에러가 나지 않음 + freq['a']에 해당하는 자료가 없으면 0을 리턴\n\n0\n\n\n\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq.get(item,0) + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n- 이것을 내가 정의하는 새로은 list의 메소드로 넣고 싶다.\n\nclass L(list):\n    def frequency(self):\n        freq = dict()\n        for item in self:\n            freq[item] = freq.get(item,0) + 1\n        return freq\n\n\nlst = L([1,1,1,2,2,3])\n\n\nlst # 원래 list에 있는 repr 기능을 상속받아서 이루어지는 결과\n\n[1, 1, 1, 2, 2, 3]\n\n\n\n_lst = L([4,5,6])\nlst + _lst  # L자료형끼리의 덧셈\n\n[1, 1, 1, 2, 2, 3, 4, 5, 6]\n\n\n\nlst + [4,5,6] # lst + [4,5,6] # L자료형과 list자료형의 덧셈도 가능\n\n[1, 1, 1, 2, 2, 3, 4, 5, 6]\n\n\n\nL자료형의 덧셈은 list의 덧셈과 완전히 같음\n\n\nlst.append(10) # append 함수도 그대로 쓸 수 있음.\n\n\nlst\n\n[1, 1, 1, 2, 2, 3, 10]\n\n\n- 기존 리스트에서 추가로 frequency() 메소드가 존재함.\n\nlst.frequency()\n\n{1: 3, 2: 2, 3: 1, 10: 1}\n\n\n\n\n\n\n\n- 사용자정의 자료형이 어떤 경우에는 유용할 수 있다.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\nyear = ['2016','2017','2017','2017',2017,2018,2018,2019,2019] \nvalue = np.random.randn(9)\n\n\ndf = pd.DataFrame({'year':year, 'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      -0.140139\n    \n    \n      1\n      2017\n      1.412758\n    \n    \n      2\n      2017\n      -0.065478\n    \n    \n      3\n      2017\n      0.107847\n    \n    \n      4\n      2017\n      0.824112\n    \n    \n      5\n      2018\n      0.061573\n    \n    \n      6\n      2018\n      -0.463060\n    \n    \n      7\n      2019\n      -0.808921\n    \n    \n      8\n      2019\n      0.389417\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value)\n\nTypeError: 'value' must be an instance of str or bytes, not a int\n\n\n\n\n\n에러의 이유: df.year에 str,int가 동시에 있음.\n\nnp.array(df.year)\n\narray(['2016', '2017', '2017', '2017', 2017, 2018, 2018, 2019, 2019],\n      dtype=object)\n\n\n자료형을 바꿔주면 해결할 수 있다.\n\nnp.array(df.year, dtype=np.float64)\n#np.array(df.year).astype(np.float64)\n#df.year.astype(np.float64)\n\narray([2016., 2017., 2017., 2017., 2017., 2018., 2018., 2019., 2019.])\n\n\n\nplt.plot(df.year.astype(np.float64),df.value,'.')\n\n\n\n\n\n\n\n\nyear = ['2016','2017','2017','2017년','2017년',2018,2018,2019,2019] \nvalue = np.random.randn(9)\n\n\ndf= pd.DataFrame({'year':year,'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      0.127739\n    \n    \n      1\n      2017\n      1.437921\n    \n    \n      2\n      2017\n      -1.137349\n    \n    \n      3\n      2017년\n      -0.178713\n    \n    \n      4\n      2017년\n      -0.276401\n    \n    \n      5\n      2018\n      2.467760\n    \n    \n      6\n      2018\n      -1.068202\n    \n    \n      7\n      2019\n      -0.313908\n    \n    \n      8\n      2019\n      1.049837\n    \n  \n\n\n\n\n\nnp.array(df.year,dtype=np.float64) # 타입을 일괄적으로 바꾸기 어렵다. \n\nValueError: could not convert string to float: '2017년'\n\n\n\nL(df.year).frequency()\n\n{'2016': 1, '2017': 2, '2017년': 2, 2018: 2, 2019: 2}\n\n\n\n’2016’와 같은 형태, ’2017년’와 같은 형태, 숫자형이 혼합 \\(\\to\\) 맞춤형 변환이 필요함\n\n\n'2017년'.replace('년','')\n\n'2017'\n\n\n\ndef f(a): ## 사실 데이터의 구조를 모르면 이런 함수를 짤 수 없음 --> 자료의 구조를 확인해준다는 의미에서 freq가 있다면 편리하다. \n    if type(a) is str:\n        if '년' in a:\n            return int(a.replace('년',''))\n        else:\n            return int(a)\n    else:\n        return a\n\n\n[f(a) for a in df.year]\n\n[2016, 2017, 2017, 2017, 2017, 2018, 2018, 2019, 2019]\n\n\n\ndf.year = [f(a) for a in df.year]\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      0.127739\n    \n    \n      1\n      2017\n      1.437921\n    \n    \n      2\n      2017\n      -1.137349\n    \n    \n      3\n      2017\n      -0.178713\n    \n    \n      4\n      2017\n      -0.276401\n    \n    \n      5\n      2018\n      2.467760\n    \n    \n      6\n      2018\n      -1.068202\n    \n    \n      7\n      2019\n      -0.313908\n    \n    \n      8\n      2019\n      1.049837\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value,'.')"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas1.html",
    "href": "posts/1_IP2022/2023-03-14-pandas1.html",
    "title": "Pandas 1단계",
    "section": "",
    "text": "데이터프레임 선언, 행\\(\\cdot\\)열 이름부여, 자료형, pd.Series"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas1.html#pandas-공부-1단계",
    "href": "posts/1_IP2022/2023-03-14-pandas1.html#pandas-공부-1단계",
    "title": "Pandas 1단계",
    "section": "pandas 공부 1단계",
    "text": "pandas 공부 1단계\n\nimport numpy as np\nimport pandas as pd\n\n\n데이터프레임 선언\n- 방법1: dictionary에서 만든다.\n\npd.DataFrame({'att':[30,40,50], 'mid':[50,60,70]}) # 리스트\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':(30,40,50),'mid':(50,60,70)}) # 튜플\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':np.array([30,40,50]),'mid':np.array([50,60,70])}) # numpy array\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: 2차원 ndarray에서 만든다.\n\nnp.arange(2*3).reshape(2,3)\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\npd.DataFrame(np.arange(2*3).reshape(2,3))\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n열의 이름 부여\n- 방법1: 딕셔너리를 통하여 만들면 딕셔너리의 key가 자동으로 열의 이름이 된다.\n\npd.DataFrame({'att':np.array([30,40,50]), 'mid':np.array([50,60,70])})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: pd.DataFrame()의 옵션에 columns를 이용\n\npd.DataFrame(np.arange(2*3).reshape(2,3),columns=['X1','X2','X3'])\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n- 방법3: df.columns에 원하는 열이름 덮어씀 (1)\n\ndf=pd.DataFrame(np.arange(2*3).reshape(2,3))\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns = ['X1','X2','X3'] # columns 메소드 이용.\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns, type(df.columns)\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n- 방법4: df.columns에 원하는 열이름 덮어씀 (2)\n\ndf=pd.DataFrame(np.arange(2*3).reshape(2,3))\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns = pd.Index(['X1','X2','X3'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n방법4 가 방법3 의 방식보다 컴퓨터가 이해하기 좋다. (=불필요한 에러를 방지할 수 있다.)\n\n## 방법3\ndf.columns, type(df.columns)  ## 내부적으로 list 타입을 pandas.core.indexes~~형태로 바꿔주긴 함.\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n\n['X1','X2','X3'], type(['X1','X2','X3'])\n\n(['X1', 'X2', 'X3'], list)\n\n\n\n처음부터 타입을 맞춰놓게 하는 게 좋다. (컴퓨터가 이해하기 명시적인 표현)\n\n\n## 방법4\npd.Index(['X1','X2','X3']), type(pd.Index(['X1','X2','X3']))\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n\n\n행의 이름 부여\n- 방법1: 중첩 dict이면 nested dic의 key가 알아서 행의 이름으로 된다.\n\n바깥쪽 딕셔너리의 키는 컬럼이름으로, 안쪽 딕셔너리의 키는 로우이름으로 들어간다.\n\n\npd.DataFrame({'att':{'guebin':30, 'iu':40, 'hynn':50} , 'mid':{'guebin':5, 'iu':45, 'hynn':90}})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법2: pd.DataFrame()의 index옵션 이용\n\npd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]}, index=['guebin','iu','hynn'])\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법3: df.index에 덮어씌움.\n\ndf=pd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.index = pd.Index(['guebin','iu','hynn']) ## 좋은 코드!\n#df.index = ['guebin','iu','hynn'] <- 이것도 실행 되기는 된다.\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법4: df.set_index()를 이용하여 덮어씌운다.\n\ndf=pd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.set_index(pd.Index(['guebin','iu','hynn'])) # set_index 메소드 이용\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n(주의) 아래는 에러가 난다.\n\ndf.set_index(['guebin','iu','hynn'])\n\nKeyError: \"None of ['guebin', 'iu', 'hynn'] are in the columns\"\n\n\n\ndf.set_index([['guebin','iu','hynn']]) # 꺽쇠를 한번 더 넣어주면 에러를 피할수 있다. \n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n\n\n자료형, len, shape, for문의 반복변수\n\ndf = pd.DataFrame({'att':[30,40,50],'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n- type\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n- len\n\nlen(df) # row의 개수\n\n3\n\n\n- shape\n\ndf.shape\n\n(3, 2)\n\n\n- for문의 반복변수\n\nfor k in df:\n    print(k) # 딕셔너리 같죠?\n\natt\nmid\n\n\n\nfor k in {'att':[30,40,50],'mid':[5,45,90]}:\n    print(k)\n\natt\nmid\n\n\n\n\npd.Series\n- 2차원 ndarray가 데이터프레임에 대응한다면 1차원 ndarray는 pd.Series에 대응한다.\n\na=pd.Series(np.random.randn(10))\na\n\n0   -0.015761\n1    0.793164\n2   -0.194785\n3   -1.704138\n4    0.196202\n5   -0.542479\n6    0.134923\n7   -1.151843\n8    0.567016\n9    2.469013\ndtype: float64\n\n\n\ntype(a)\n\npandas.core.series.Series\n\n\n\nlen(a)\n\n10\n\n\n\na.shape\n\n(10,)\n\n\n\nfor value in a:\n    print(value)\n\n-0.01576052104052408\n0.7931636561267669\n-0.19478516128697446\n-1.7041378729481649\n0.19620173234455546\n-0.542479066364815\n0.13492305158609827\n-1.1518431416352932\n0.5670160023697828\n2.4690128371679556\n\n\n\nfor value in np.random.randn(10):\n    print(value)\n\n-0.0864801362204059\n-0.9294913581613311\n-0.4818729848296065\n2.1539740078272693\n0.5075567770278344\n0.6907204209585092\n0.2885924769916613\n-0.5636921329605091\n-0.9741967151982581\n1.8705475972066663"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-비상식적인-append",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-비상식적인-append",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1: 비상식적인 append",
    "text": "예제1: 비상식적인 append\n\n포인트: 이상한 일의 관찰\n\n- 원소의 추가: + 이용\n\na=[1,2,3]\nb=a\na=a+[4]\n\n\na\n\n[1, 2, 3, 4]\n\n\n\nb\n\n[1, 2, 3]\n\n\n- 원소의 추가 .append 이용\n\na=[1,2,3]\nb=a\na.append(4) # a=a+[4]\n\n\na\n\n[1, 2, 3, 4]\n\n\n\nb\n\n[1, 2, 3, 4]"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#append의-동작원리-틀린상상",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#append의-동작원리-틀린상상",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "append의 동작원리: 틀린상상",
    "text": "append의 동작원리: 틀린상상\n- 상자로서의 변수: 변수가 데이터를 저장하는 일종의 상자와 같다. <– 아주 흔한 오해 (Fluent Python)\n\n흔히 비유하는 ‘상자로서의 변수’ 개념이 실제로는 객체지향적 언어에서 참조변수를 이해하는 데 방해가 된다.\n\n- “상자로서의 변수” 관점에서 아래의 코드를 해석하자. (일단 아래의 해석들이 틀린해석이라는 사실을 명심할 것)\na=[1,2,3]\nb=a\na.append(4)\na,b라는 변수들은 메모리에 어떻게 저장이 되어있을까?\n상상력을 조금 발휘하면 아래와 같이 여길 수 있다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\na=[1,2,3]\n\n메모리주소1에 존재하는 방을 a라고 하고, 그 방에 [1,2,3]을 넣는다.\n\n\n아래를 실행하였을 경우\n\nb=a\n\n메모리주소2에 존재하는 방을 b라고 하고, 그 방에 a를 넣어야하는데, a는 [1,2,3]이니까 [1,2,3]을 넣는다.\n\n\n아래를 실행하면\n\na.append(4)\n\n방 a로가서 [1,2,3]을 [1,2,3,4]로 바꾼다.\n그리고 방 b에는 아무것도 하지 않는다.\n\n- R에서는 맞는 비유인데, 파이썬은 적절하지 않은 비유이다.\n\n틀린이유\n\nid(a)\n\n139765704687936\n\n\n\nid(b)\n\n139765704687936"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#append의-동작원리-올바른-상상",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#append의-동작원리-올바른-상상",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "append의 동작원리: 올바른 상상",
    "text": "append의 동작원리: 올바른 상상\n\n파이썬에서의 변수는 자바에서의 참조변수와 같으므로 변수는 객체에 붙은 레이블이라고 생각하는 것이 좋다.\n\n- 파이썬에서는 아래가 더 적절한 비유이다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\na=[1,2,3]\n\n메모리주소 139753545242336에서 [1,2,3]을 생성\n방 139753545242336의 방문에 a라는 포스트잇을 붙인다.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙은 방을 찾아가면 된다.\n\n\n아래를 실행하였을 경우\n\nb=a\n\na라는 포스트잇이 지칭하는 객체를 가져옴. 그리고 그 객체에 b라는 포스트잇을 붙인다.\n쉽게말하면 b라는 포스트잇을 방 139753545242336의 방문에 붙인다는 이야기.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙어 있거나 b라는 포스트잇이 붙어있는 방을 찾아가면 된다.\n\n\n아래를 실행하면\n\na.append(4)\n\na라는 포스트잇이 붙어있는 방으로 가서, 그 내용물에 append함수를 적용하여 4를 추가하라. 즉 내용물 [1,2,3]을 [1,2,3,4]로 바꾸라.\n같은방(139753545242336)에 a,b라는 포스트잇이 모두 붙어있음. 따라서 b라는 포스트잇이 붙은 방을 찾아가서 내용물을 열어보면 [1,2,3,4]가 나온다."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-같은-value-다른-id",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-같은-value-다른-id",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1: 같은 value, 다른 id",
    "text": "예제1: 같은 value, 다른 id\n\n포인트: (1) 포스트잇 개념의 확실한 이해 (2) 할당문을 새로운 시각으로 해석하는 연습 (3) “생성->할당”과 “참조/에일리어싱”의 구분\n\n\na=[1,2,3] # 우변: 생성된 오브젝트, 좌변: 이름 \nb=a # 우변: 가져온 오브젝트, 좌변: 별명 --> 참조, 에일리어싱(별칭부여)이라고 한다\na.append(4) # a라는 오브젝트를 직접변경\nc=[1,2,3,4] # 우변: 생성된 오브젝트, 좌변: 이름\n\n여기에서 a,b,c는 모두 같은 value를 가진다.\n\na\n\n[1, 2, 3, 4]\n\n\n\nb\n\n[1, 2, 3, 4]\n\n\n\nc\n\n[1, 2, 3, 4]\n\n\n하지만 그 id까지 같은 것은 아니다.\n\nid(a), id(b), id(c)\n\n(140237129249664, 140237129249664, 140237128836544)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n\n선행지식: “생성->할당” 과 “참조/에일리어싱”의 구분\n\n\n포인트: 재할당의 이해!!\n\n(관찰)\n\na=[1,2,3] # 생성->할당\nb=a # 참조/에일리어싱 \na=a+[4] # 생성->재할당 \nprint('a=',a)\nprint('b=',b)\n\na= [1, 2, 3, 4]\nb= [1, 2, 3]\n\n\n(해설)\n\nid(a),id(b)\n\n(140237129283584, 140237129350912)\n\n\n\n포인트: [1,2,3]+[4] 가 실행되는 순간 새로운 오브젝트가 만들어지고 그 오브젝트를 a라는 이름으로 다시 할당되었음. (재할당)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n\n선행지식: “생성->할당,재할당” 과 “참조/에일리어싱”의 구분\n\n\n포인트: 인터닝을 위한 떡밥예제\n\n\na=1+2021\nid(a)\n\n139753546122608\n\n\n\nb=2023-1\nid(b)\n\n139753545299280\n\n\n\nid(2022)\n\n139753545299472\n\n\n\n당연한결과임."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-이제-다-이해했다고-생각했는데..",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-이제-다-이해했다고-생각했는데..",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2: 이제 다 이해했다고 생각했는데..",
    "text": "예제2: 이제 다 이해했다고 생각했는데..\n\n선행지식: “생성->할당,재할당” 과 “참조/에일리어싱”의 구분\n\n\n포인트: 인터닝의 이해\n\n\na=1+2 \nid(a)\n\n7394720\n\n\n\nb=4-1\nid(b)\n\n7394720\n\n\n\nid(a)와 id(b)가 왜 똑같지..?\n\n(해설) 파이썬의 경우 효율성을 위해서 -5~256까지의 정수를 미리 저장해둠.\n\nid(3)\n\n7394720\n\n\n\n3은 언제나 7394720에 지박령마냥 밖혀있음"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n(관찰) 아래의 예제를 살펴보자. 참조를 제대로 이해했다면 아래의 예제는 자연스럽게 이해가능할 것임.\n\nl1 = [3, [66,55,44]]\nl2 = l1 \nprint('시점1')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1[0]=4 \nprint('시점2')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl2.append(5)\nprint('시점3')\nprint('l1=',l1)\nprint('l2=',l2)\n\n시점1\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점2\nl1= [4, [66, 55, 44]]\nl2= [4, [66, 55, 44]]\n시점3\nl1= [4, [66, 55, 44], 5]\nl2= [4, [66, 55, 44], 5]\n\n\n(해설)\n\nl1 = [3, [66,55,44]]\nl2 = l1 \n\n\nid(l1),id(l2)\n\n(140571068242688, 140571068242688)\n\n\n이해는 되지만 우리가 원한건 이런게 아니야"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-r과-같이-를-쓰고-싶다면",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-r과-같이-를-쓰고-싶다면",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2: R과 같이 = 를 쓰고 싶다면?",
    "text": "예제2: R과 같이 = 를 쓰고 싶다면?\n\n선행지식: “생성->할당,재할당” 과 “참조/에일리어싱”의 구분\n\n\n포인트: 복사의 사용, 얕은복사의 떡밥\n\n(관찰)\n\nl1 = [3, [66,55,44]]\nl2 = l1.copy()\nprint('시점1')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1[0]=4 \nprint('시점2')\nprint('l1=',l1)\nprint('l2=',l2)\n\nl2.append(5)\nprint('시점3')\nprint('l1=',l1)\nprint('l2=',l2)\n\n시점1\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점2\nl1= [4, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n시점3\nl1= [4, [66, 55, 44]]\nl2= [3, [66, 55, 44], 5]\n\n\n(해설)\n\nl1 = [3, [66,55,44]]\nl2 = l1.copy()\n\n\nid(l1),id(l2) ## 드디어 주소가 달라졌다.\n\n(140571068242688, 140571068242240)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3-이제-다-이해했다고-생각했는데..",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3-이제-다-이해했다고-생각했는데..",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제3: 이제 다 이해했다고 생각했는데..",
    "text": "예제3: 이제 다 이해했다고 생각했는데..\n\n선행지식: “생성->할당,재할당” 과 “참조/에일리어싱”의 구분, 복사의 사용\n\n\n포인트: 얕은복사를 이해하지 못할때 생기는 개념충돌\n\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[1].append(33)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n(의문)\n\nid(l1),id(l2)\n\n(140571077644352, 140571068253376)\n\n\n\nl1이랑 l2의 주소도 다르게 나오는데 왜 또 참조한것마냥 l1과 l2가 같이 바뀌고 있지?\n\n나는 진정한 복사(=깊은복사)를 하고싶다"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-2",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-2",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n\n선행지식: 이전까지 모든것\n\n\n포인트: 0차원 자료형의 메모리 구조 이해, 1차원 자료형의 메모리 구조를 위한 떡밥\n\n(관찰+해설)\n\na=2222\nb=2222\n\n\nid(a),id(b)\n\n(139753545300880, 139753545301808)\n\n\n메모리 상황\n\n2222라는 오브젝트가 어떤공간(139753545300880)에 생성되고 그 공간에 a라는 라벨이 붙음\n2222라는 오브젝트가 어떤공간(139753545301808)에 생성되고 그 공간에 b라는 라벨이 붙음\n\n즉 -5~256 이외의 2개의 메모리 공간을 추가적으로 사용"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n\n선행지식: 이전까지 모든것, 0차원 자료형의 메모리저장상태 이해\n\n\n포인트: (1) 1차원 자료형의 메모리 구조 이해 (2) 가변형객체라는 표현의 의미\n\n(관찰)\n\na=[1,2,2222]\nb=[1,2,2222]\na.append(4)\nprint('a=',a)\nprint('b=',b)\n\na= [1, 2, 2222, 4]\nb= [1, 2, 2222]\n\n\n(해설)\n\na=[1,2,2222]\nb=[1,2,2222]\n\n\nid(a), [id(a[0]),id(a[1]),id(a[2])] # a=[1,2,2222]\n\n(140527746917824, [7585472, 7585504, 140528016796752])\n\n\n\nid(b), [id(b[0]),id(b[1]),id(b[2])] # b=[1,2,2222] \n\n(140527746917568, [7585472, 7585504, 140528016796144])\n\n\n\na.append(4)\n\n\na\n\n[1, 2, 2222, 4]\n\n\n\nb\n\n[1, 2, 2222]\n\n\n\nid(a)\n\n140527746917824\n\n\n메모리상황\n\n-5~256까지의 숫자는 미리 메모리에 저장되어 있다. 이중에서 1은 7394656, 2는 7394688에 저장되어있음.\n2222가 공간 139753178093776에서 만들어진다.\n어떠한 리스트오브젝트가 공간 139753182327904에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 a라는 포스트잇을 붙인다.\n2222가 공간 139753178095568에서 만들어진다.\n어떠한 리스트오브젝트가 공간 139753173818656에서 만들어지고 원소로 [1,2,2222]를 가진다. 이 공간에 b라는 포스트잇을 붙인다.\na라는 포스트잇이 붙은 공간으로 이동하여 원소에 4를 추가시킨다.\n\n즉 -5~256이외에 4개의 메모리 공간을 추가사용 (a,b,a의 2222,b의 2222)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제3",
    "text": "예제3\n\n선행지식: 이전까지 모든 것\n\n\n포인트: l2=l1 와 l2=l1.copy() 의 차이점\n\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[0] = 7777\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [7777, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n\n\n(해설)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753183437040, [7394720, 139753183707216])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753182311120, [7394720, 139753183707216])\n\n\n메모리상황\n\n-5~256까지의 숫자가 메모리에 저장되어 있다.\n저장된 숫자중 66,55,44를 묶어서 리스트로 구성하고 이 리스트를 공간 139753183707216에 저장.\n숫자 3과 공간 139753183707216에 저장된 리스트 [66,55,44]를 하나로 묶어서 새로운 리스트를 구성하고 이를 공간 139753183437040에 저장. 공간 139753183437040에 l1이라는 포스트잇 생성.\n공간 139753182311120에 l1의 원소들을 모아서 새로운 리스트를 구성함. 공간 139753182311120에 l2라는 포스트잇 생성. 그런데 따져보니까 내부구성은 똑같아?\n\n\nl1[0] = 7777\nl1,l2\n\n([7777, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753183437040, [139753178092080, 139753183707216])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753182311120, [7394720, 139753183707216])\n\n\n\nl1[0]은 원래 공간 7394720와 binding 되어 있었음.\n\n그런데 7777이라는 새로운 오브젝트가 공간 139753178092080에 생성되고 l1[0]이 공간 139753178092080와 다시 binding 됨."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제4",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제4",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제4",
    "text": "예제4\n\n선행지식: 이전까지 모든것, .copy()의 동작원리\n\n\n포인트: .copy()의 동작원리 재학습\n\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1.append(7777)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44], 7777]\nl2= [3, [66, 55, 44]]\n\n\n(해설)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1.append(7777)\n\n\nl1,l2\n\n([3, [66, 55, 44], 7777], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1]), id(l1[2])]\n\n(139753183257056, [7394720, 139753184484240, 139753180268560])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753183216656, [7394720, 139753184484240])"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제5-우리를-힘들게-했던-그-예제.",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제5-우리를-힘들게-했던-그-예제.",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제5: 우리를 힘들게 했던 그 예제.",
    "text": "예제5: 우리를 힘들게 했던 그 예제.\n\n선행지식: 이전까지 모든것, .copy()의 동작원리\n\n\n포인트: (1) .copy()의 한계, (2) 얕은복사라는 명칭의 유래\n\n(관찰)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\nl1[1].append(7777)\nprint('l1=',l1)\nprint('l2=',l2)\n\nl1= [3, [66, 55, 44, 7777]]\nl2= [3, [66, 55, 44, 7777]]\n\n\n(해설-시점1)\n\nl1 = [3,[66,55,44]]\nl2 = l1.copy()\n\n\nl1,l2\n\n([3, [66, 55, 44]], [3, [66, 55, 44]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753181411920, [7394720, 139753181409920])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753181409440, [7394720, 139753181409920])\n\n\n(해설-시점2)\n\nl1[1].append(7777)\n\n\nl1,l2\n\n([3, [66, 55, 44, 7777]], [3, [66, 55, 44, 7777]])\n\n\n\nid(l1), [id(l1[0]), id(l1[1])]\n\n(139753181411920, [7394720, 139753181409920])\n\n\n\nid(l2), [id(l2[0]), id(l2[1])]\n\n(139753181409440, [7394720, 139753181409920])\n\n\n해설: 사실 시점1에서 메모리 주소상황을 잘 이해했다면 신기한 일이 아니다. .copy()는 l1과 l2의 주소만 다르게 만들 뿐 내용물인 l1[0],l1[1]는 동일하니까."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제6-신임교수최규빈이영미",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제6-신임교수최규빈이영미",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제6: 신임교수=[‘최규빈’,‘이영미’]",
    "text": "예제6: 신임교수=[‘최규빈’,‘이영미’]\n\n선행지식: 이전까지의 모든것\n\n\n포인트: 이전까지의 모든것 점검\n\n- 최규빈, 이영미는 신임교수임\n\n신임교수 = ['최규빈','이영미']\n\n\nid(신임교수), id('최규빈'), id('이영미')\n\n(139753182527808, 139753171447312, 139753171447408)\n\n\n- 신임교수를 누군가는 막내들이라고 부르기도 함.\n\n막내들 = 신임교수 \n\n\nid(막내들), id(신임교수)\n\n(139753182527808, 139753182527808)\n\n\n“막내들”이라는 단어와 “신임교수”라는 단어는 사실 같은 말임\n- 새로운 교수 “박혜원”이 뽑혔음.\n\n신임교수.append(\"박혜원\")\n\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 전북대 통계학과에서 R특강팀을 구성하여 방학중 R교육을 실시하고자함. 특강팀은 우선 신임교수들로 구성.\n\nR특강팀 = 신임교수.copy()\nR특강팀 \n\n['최규빈', '이영미', '박혜원']\n\n\n- R특강팀에 최혜미교수님 추가. (그렇지만 최혜미교수님이 막내는 아니야.. // 참조와 shallow copy의 차이점)\n\nR특강팀.append(\"최혜미\") \n\n\nR특강팀, 신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원', '최혜미'], ['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- R특강팀에서 양성준 교수를 추가하여 파이썬 특강팀을 구성 (R특강팀의 구분을 위해서 중첩리스트 구조로 만들자)\n\n파이썬특강팀 = [R특강팀, \"양성준\"]\n파이썬특강팀\n\n[['최규빈', '이영미', '박혜원', '최혜미'], '양성준']\n\n\n- 이영미교수는 다른 일이 많아서 R특강 팀에서 제외됨. (그럼 자연히 파이썬에서도 제외됨!!)\n\nR특강팀.remove(\"이영미\")\n\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])\n\n\n하지만 이영미교수는 여전히 신임교수이면서 막내들임\n\n신임교수, 막내들\n\n(['최규빈', '이영미', '박혜원'], ['최규빈', '이영미', '박혜원'])\n\n\n- 새로운 교수로 “손흥민”이 임용됨.\n\n막내들.append(\"손흥민\")\n\n\n막내들, 신임교수\n\n(['최규빈', '이영미', '박혜원', '손흥민'], ['최규빈', '이영미', '박혜원', '손흥민'])\n\n\n- 그렇다고 해서 손흥민 교수가 바로 R이나 파이썬 특강팀에 자동소속되는건 아님\n\nR특강팀, 파이썬특강팀\n\n(['최규빈', '박혜원', '최혜미'], [['최규빈', '박혜원', '최혜미'], '양성준'])"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-motivation-example",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-motivation-example",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1: Motivation example",
    "text": "예제1: Motivation example\n- 아래의 상황을 다시 생각해보자.\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = 파이썬특강팀.copy()\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '최혜미']])\n\n\n이슈: 이영미교수가 파이썬특강에서 제외되면서 ADSP특강팀에서도 제외되었음. 그런데 사실 이영미교수가 파이썬특강팀에서만 제외되길 원한 것이지 ADSP특강팀에서 제외되길 원한게 아닐수도 있음.\n해결: Deep copy의 사용\n\nimport copy\n\n\n파이썬특강팀 = [\"양성준\",[\"최규빈\",\"이영미\",\"최혜미\"]]\nADSP특강팀 = copy.deepcopy(파이썬특강팀)\n파이썬특강팀[-1].remove(\"이영미\")\n\n\n파이썬특강팀, ADSP특강팀\n\n(['양성준', ['최규빈', '최혜미']], ['양성준', ['최규빈', '이영미', '최혜미']])"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-2",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-2",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n\n선행지식: 이전까지 모든것, 얕은복사\n\n\n포인트: (1) 깊은복사 (2) 복사의 레벨을 이해 (3) 얕은복사 = 1단계 깊은복사\n\n- deepcopy\n\nl1 = [3,[66,[55,44]]] \nl2 = copy.deepcopy(l1)\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140137133270656\nl2: 140137132727232\n\n\n\n레벨1: l1,l2 의 메모리 주소가 다름을 확인\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140137133270656 [7585536, 140137133267712]\nl2: 140137132727232 [7585536, 140137133267456]\n\n\n\n레벨2: l1안에 있는 [66,[55,44]]와 l2안에 있는 [66,[55,44]]의 메모리 주소가 다름도 확인.\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140137133270656 [7585536, [7587552, 140137133704320]]\nl2: 140137132727232 [7585536, [7587552, 140137137410624]]\n\n\n\n레벨3: l1안의 [66,[55,44]] 안의 [55,44]와 l2안의 [66,[55,44]] 안의 [55,44]의 메모리 주소까지도 다름을 확인.\n\n- 비교를 위한 shallow copy\n\nl1 = [3,[66,[55,44]]] \nl2 = l1.copy()\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140137133470528\nl2: 140137137411136\n\n\n\n레벨1: l1,l2 의 메모리 주소가 다름을 확인\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140137133470528 [7585536, 140137133703424]\nl2: 140137137411136 [7585536, 140137133703424]\n\n\n\n레벨2: l1안에 있는 [66,[55,44]]와 l2안에 있는 [66,[55,44]]의 메모리 주소는 같음!!\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140137133470528 [7585536, [7587552, 140137137410880]]\nl2: 140137137411136 [7585536, [7587552, 140137137410880]]\n\n\n\n레벨3: l1안의 [66,[55,44]] 안의 [55,44]와 l2안의 [66,[55,44]] 안의 [55,44]의 메모리 주소도 같음!!\n\n- 비교를 위한 참조\n\nl1 = [3,[66,[55,44]]] \nl2 = l1\n\n\nl2[1][1].append(33)\n\n\nl1,l2\n\n([3, [66, [55, 44, 33]]], [3, [66, [55, 44, 33]]])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140137133223232\nl2: 140137133223232\n\n\n\n레벨1: l1,l2 여기서부터 메모리 주소가 같다.\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140137133223232 [7585536, 140137133698560]\nl2: 140137133223232 [7585536, 140137133698560]\n\n\n\nprint('level 3')\nprint('l1:', id(l1), [id(l1[0]),[id(l1[1][0]),id(l1[1][1])]])\nprint('l2:', id(l2), [id(l2[0]),[id(l2[1][0]),id(l2[1][1])]])\n\nlevel 3\nl1: 140137133223232 [7585536, [7587552, 140137133438144]]\nl2: 140137133223232 [7585536, [7587552, 140137133438144]]\n\n\n\nNote: 문헌에 따라서 shallow copy를 level1 deep copy라고 부르기도 한다."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-3",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-3",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1",
    "text": "예제1\n\n선행지식: 이전까지 모든것\n\n\n포인트: 얕은복사의 한계점 이해\n\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]]\nl2= l1.copy() \nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n\n포인트: shallow copy (=level 1 deep copy) 이므로 l1안의 [66,55,44]와 l2안의 [66,55,44]는 같은 메모리 주소를 가짐"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-3",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제2-3",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제2",
    "text": "예제2\n\n선행지식: 이전까지 모든것\n\n\n포인트: 재할당의 활용하여 얕은복사의 한계점 극복\n\n- 아래의 코드결과를 예측하라. 결과가 나오는 이유를 설명하라.\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44]]\n\n\n\n포인트: l1[-1]+[33]가 실행되는 순간 새로운 오브젝트가 생성되고 이 새로운 오브젝트가 l1의 마지막 원소에 새롭게 할당된다."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3-1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제3-1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제3",
    "text": "예제3\n\n선행지식: 이전까지 모든것\n\n\n포인트: 재할당의 활용하여 얕은복사의 한계점 극복, 예제4를 위한 떡밥\n\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44]]\nl2= [3, [66, 55, 44]]\n\n\n\n포인트: 이 상황에서 l1안의 [66,55,44]와 l2안의 [66,55,44]는 서로 다른 메모리 주소를 가진다."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제4-1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제4-1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제4",
    "text": "예제4\n\n선행지식: 이전까지 모든것\n\n\n포인트: 재할당으로 인해 메모리주소가 틀어짐을 이용한 트릭예제, 예제5의 떡밥예제\n\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33]\nl1[-1].remove(33) \nl1[-1].append(33)\n\n(잘못된 상상) 아래의 코드와 결과가 같을거야!!\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \n# l1[-1] = l1[-1]+[33] \n# l1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n(하지만 현실은)\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44]]"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제5",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제5",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제5",
    "text": "예제5\n\n선행지식: 이전까지 모든것\n\n\n포인트: +=는 재할당이 아니다.\n\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1] = l1[-1]+[33] \nl1[-1].remove(33)\nl1[-1].append(33)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n+= 연산자의 올바른 이해\n\n??? 예제4랑 예제5는 같은코드가 아니었음!!! a += [1] 는 새로운 오브젝트를 만드는게 아니고, 기존의 오브젝트를 변형하는 스타일의 코드였음! (마치 append 메소드처럼)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-motivation-example-1",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#예제1-motivation-example-1",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "예제1: Motivation example",
    "text": "예제1: Motivation example\n\n선행지식: 이전까지 모든것\n\n\n포인트: +=는 재할당이 아니다.\n\n- 우리는 이제 아래의 내용은 마스터함\n\nl1= [3,[66,55,44]] \nl2= l1.copy() \nl1[-1] += [33] # l1[-1].append(33)이랑 같은거..\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, [66, 55, 44, 33]]\nl2= [3, [66, 55, 44, 33]]\n\n\n- 아래의 결과를 한번 예측해볼까?\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\nl2[1] += (33,)\n\n\nprint('l1=', l1)\nprint('l2=', l2)\n\nl1= [3, (66, 55, 44)]\nl2= [3, (66, 55, 44, 33)]"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#해설",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#해설",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "해설",
    "text": "해설\n(시점1)\n\nl1=[3,(66,55,44)]\nl2=l1.copy()\n\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140006812656640\nl2: 140006812645888\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140006812656640 [7585536, 140006812590400]\nl2: 140006812645888 [7585536, 140006812590400]\n\n\n(시점2)\n\nl2[1] += (33,)\n\n\nl1,l2\n\n([3, (66, 55, 44)], [3, (66, 55, 44, 33)])\n\n\n\nprint('level 1')\nprint('l1:', id(l1))\nprint('l2:', id(l2))\n\nlevel 1\nl1: 140006812656640\nl2: 140006812645888\n\n\n\nprint('level 2')\nprint('l1:', id(l1), [id(l1[0]),id(l1[1])])\nprint('l2:', id(l2), [id(l2[0]),id(l2[1])])\n\nlevel 2\nl1: 140006812656640 [7585536, 140006812590400]\nl2: 140006812645888 [7585536, 140006813422272]\n\n\n주소 140006812590400:(66,55,44)에 있는 값을 바꾸고 싶지만 불변형이라 못바꿈 \\(\\to\\) 그냥 새로 만들자. 그래서 그걸 140006813422272에 저장하자."
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#차원의-실체",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#차원의-실체",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "2차원의 실체",
    "text": "2차원의 실체\n- 2차원 array a,b를 선언하자.\n\na = np.array([[11,22,33,44]]).reshape(2,2)\nb = np.array([[11,22,33,44,55,66]]).reshape(2,3)\nc = np.array([11,22,33,44]).reshape(4,1)\nd = np.array([11,22,33,44]) # 1d\n\n- a,b,c,d 속성비교\n\na.shape, b.shape, c.shape, d.shape ## 차원 \n\n((2, 2), (2, 3), (4, 1), (4,))\n\n\n\na.strides, b.strides, c.strides, d.strides ## 차원이랑 관련이 있어보임.. + 8의 배수 \n\n((16, 8), (24, 8), (8, 8), (8,))\n\n\n- ((16, 8), (24, 8), (8, 8), (8,)) 와 같은 저 숫자들이 도데체 무엇을 의미하는거야?!\n\n사전지식: 컴퓨터는 하나의 숫자를 저장하는데 메모리를 8칸 쓴다.\n가정: 만약에 컴퓨터가 1차원으로만 숫자를 저장한다면??\nstrides의 의미: (다음 행으로 가기위해서 JUMP해야하는 메모리 공간수, 다음 열로 가기위해서 JUMP해야하는 메모리 공간수)\n\n- 통찰: strides의 존재로 인해서 유추할 수 있는 것은 a,b,c,d 는 모두 1차원으로 저장되어있다는 사실이다. (중첩된 리스트꼴이 아니라)\n- 그렇다면.. shallow copy = deep copy?!\n\nA1=[[1,2],[3,4]]\nA2=A1.copy()\nB1=np.array([[1,2],[3,4]])\nB2=B1.copy()\n\n\nB1\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nA2[0][0]=11\nB2[0][0]=11\n\n\nA1,A2\n\n([[11, 2], [3, 4]], [[11, 2], [3, 4]])\n\n\n\nB1,B2\n\n(array([[1, 2],\n        [3, 4]]),\n array([[11,  2],\n        [ 3,  4]]))\n\n\n- 해방: 넘파이를 쓰면 copy.deepcopy()를 쓰지 않아도 된다.\n- 용어정리: (필요할까..?)\n\nnumpy 한정 .copy() 는 copy모듈의 deep copy와 동등한 효과를 준다. 하지만 실제로는 shallow copy 이다. 공식문서에는 “Note that np.copy is a shallow copy and will not copy object elements within arrays.” 라고 명시되어 있음.\n일부 블로그에서 deep copy라고 주장하기도 함. 블로그1, 블로그2, 블로그3 // 블로그2의 경우 참조와 shallow copy도 구분못함..\n이따가 view라는 개념도 나올텐데 .copy()를 deep copy라고 주장하는 블로거들 대부분 .view()를 shallow copy 혹은 참조라고 주장한다. 하지만 copy와 view를 설명하는 공식문서에서는 view가 shallow copy라는 말을 찾아볼 수 없음.\n\n- 정리 (넘파이한정)\n\nnparray.copy(): 실제로는 shallow copy, 그런데 느낌은 deep copy\nnparray.view(): 실제로는 shallow copy 보다 더 얕은 단계의 카피, 그런데 느낌은 shallow copy"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#참조",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#참조",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "참조",
    "text": "참조\n- a를 선언, b는 a의 참조\n\na=np.array([[1,2],[3,4]])\nb=a ## 참조 \n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n- a의 shape을 바꾸어보자 \\(\\to\\) b도 같이 바뀐다\n\na.shape = (4,)\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3, 4])\n\n\n\nid(a),id(b)\n\n(139680327738544, 139680327738544)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#view",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#view",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "view",
    "text": "view\n- a를 선언, b는 a의 view\n\na=np.array([[1,2],[3,4]]) \nb=a.view() ## 어떤 블로그등에서는 shallow copy라고 부르기도 한다. 그렇게 공부하지 마세여..\n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\na.shape\n\n(2, 2)\n\n\n\nb.shape\n\n(2, 2)\n\n\n\na.shape= (4,1)\n\n\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nid(a), id(b)\n\n(139679960161232, 139679932937872)\n\n\n- 그런데..\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n- 출생의 비밀\n\nb\n\narray([[100,   2],\n       [  3,   4]])\n\n\n\nb.base\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\n? 이거 바뀐 a아니야?\n\n\nid(b.base), id(a)\n\n(139679960161232, 139679960161232)\n\n\n- View\n\nb가 a의 뷰라는 의미는, b가 a를 소스로하여 만들어진 오브젝트란 의미이다.\n따라서 이때 b.base는 a가 된다.\nb는 자체적으로 데이터를 가지고 있지 않으며 a와 공유한다.\n\nnote1 원본 ndarray의 일 경우는 .base가 None으로 나온다.\n\na.base\n\nnote2 b.base의 shpae과 b의 shape은 아무 관련없다.\n\nb.shape\n\n(2, 2)\n\n\n\nb.base.shape # a.shape과 같음\n\n(4, 1)\n\n\n- numpy에서 view를 사용하는 예시 (transpose)\n\nX = np.random.normal(size=[100,2])\nid((X.T).base), id(X)\n\n(139679932937584, 139679932937584)\n\n\n\nX.T 는 X의 view 이다.\n\n\nX.T @ X ## 실제로 X.T를 메모리공간에 새로 만들어 숫자를 저장하지않고 X.T @ X를 계산할 수 있음 (R과차이점) \n\narray([[124.15127928,  -0.45772606],\n       [ -0.45772606,  79.17005817]])"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#copy",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#copy",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "copy",
    "text": "copy\n- a를 선언, b는 a의 copy\n\na=np.array([[1,2],[3,4]])\nb=a.copy() # 껍데기를 새로 생성 (strides, shape) + 데이터도 a와 독립적으로 새로 생성하여 따로 메모리에 저장함. \n\n\nid(a),id(b)\n\n(139680327737776, 139679932938832)\n\n\n- a의 shape을 바꿔도 b에는 적용되지 않음\n\na.shape = (4,1)\na\n\narray([[1],\n       [2],\n       [3],\n       [4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- 그리고 a[0]의 값을 바꿔도 b에는 적용되지 않음.\n\na[0]=100\n\n\na\n\narray([[100],\n       [  2],\n       [  3],\n       [  4]])\n\n\n\nb\n\narray([[1, 2],\n       [3, 4]])\n\n\n- b의 출생을 조사해보니..\n\na.base,b.base\n\n(None, None)\n\n\n출생의 비밀은 없었다. 둘다 원본.\n- .view() 는 껍데기만 새로생성 // .copy() 는 껍데기와 데이터를 모두 새로 생성\n\nAppendix: .copy의 한계(?)\n(관찰)\n\na=np.array([1,[1,2]],dtype='O')\nb=a.copy()\nprint('시점1')\nprint('a=',a)\nprint('b=',b)\n\na[0]=222\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\na[1][0]=333\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\n시점1\na= [1 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([333, 2])]\nb= [1 list([333, 2])]\n\n\n\n왜 또 시점2에서는 a와 b가 같이 움직여?\n\n해결책: 더 깊은 복사\n\nimport copy\n\n\na=np.array([1,[1,2]],dtype='O')\nb=copy.deepcopy(a)\nprint('시점1')\nprint('a=',a)\nprint('b=',b)\n\na[0]=222\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\na[1][0]=333\nprint('시점2')\nprint('a=',a)\nprint('b=',b)\n\n시점1\na= [1 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([1, 2])]\nb= [1 list([1, 2])]\n시점2\na= [222 list([333, 2])]\nb= [1 list([1, 2])]\n\n\n- 중간요약\n\n사실 b=a.copy()는 에서 .copy()는 사실 온전한 deep-copy가 아니다.\n그래서 a의 데이터가 중첩구조를 가지는 경우는 온전한 deep-copy가 수행되지 않는다.\n그런데 일반적으로 넘파이를 이용할때 자주 사용하는 데이터 구조인 행렬, 텐서등은 데이터가 중첩구조를 가지지 않는다. (1차원 array로만 저장되어 있음)\n따라서 행렬, 텐서에 한정하면 .copy()는 온전한 deep-copy라고 이해해도 무방하다. <– 이것만 기억해!"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#요약",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#요약",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "요약",
    "text": "요약\n아래를 구분할 수 있으면 잘 이해한 것!!\narr = np.array(...) # arr -- [arr.shape, arr.strides, arr.base, ... ] \narr2 = arr \narr2 = arr.view()\narr2 = arr.copy()\narr2 = copy.deepcopy(arr)"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#별명-뷰-카피",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#별명-뷰-카피",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "별명, 뷰, 카피",
    "text": "별명, 뷰, 카피\n- test 함수 작성\n\ndef test(a,b): \n    if id(a) == id(b): \n        print(\"별명\")\n    elif id(a) == id(b.base) or id(a.base)==id(b): \n        print(\"뷰\")\n    elif (id(a.base)!=id(None) and id(b.base)!=id(None)) and id(a.base) == id(b.base):\n        print(\"공통의 base를 가짐\")\n    else: \n        print(\"카피, 혹은 아무 관련없는 오브젝트\") \n\n- 잘 동작하나?\n(테스트1)\n\na=np.array([1,2,3,4])\nb=a\n\n\ntest(a,b)\n\n별명\n\n\n(테스트2)\n\na=np.array([1,2,3,4])\nb=a.view()\n\n\ntest(a,b)\n\n뷰\n\n\n(테스트3)\n\na=np.array([1,2,3,4])\nb=a.view()\nc=a.view()\n\n\ntest(b,c)\n\n공통의 base를 가짐\n\n\n\ntest(a,b)\n\n뷰\n\n\n\ntest(a,c)\n\n뷰\n\n\n(테스트4)\n\na=np.array([1,2,3,4])\nb=a.copy()\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트"
  },
  {
    "objectID": "posts/1_IP2022/2023-06-21-13wk-1.html#결론",
    "href": "posts/1_IP2022/2023-06-21-13wk-1.html#결론",
    "title": "13wk-1: 깊은복사와 얕은복사",
    "section": "결론",
    "text": "결론\n- 참조, 뷰, 카피의 개념을 잘 알고 있고 때에 따라 메모리를 아끼면서 이들을 적절하게 사용하고 싶을것 같음. 하지만 이건 불가능한 소망임.\n- 우리가 사용했던 어떠한 것들이 뷰가 나올지 카피가 나올지 잘 모른다. (그래서 원리를 이해해도 대응할 방법이 사실없음)\n\n예시1\n\na=np.array([1,2,3,4])\nb=a[:3]\n\n\na\n\narray([1, 2, 3, 4])\n\n\n\nb\n\narray([1, 2, 3])\n\n\n\ntest(a,b)\n\n뷰\n\n\n\nc=a[[0,1,2]]\nc\n\narray([1, 2, 3])\n\n\n\ntest(a,c)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\n\n예시2\n\na=np.array([[1,2],[3,4]])\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nb=a.flatten() # 플래튼은 펼치는건데..\nc=a.ravel() # 라벨도 펼치라는 뜻인데..\nd=a.reshape(-1) # 이것도 뜻은 펼치는건데..\n# 걍 다 똑같은거아냐?\n\n\ntest(a,b)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n\ntest(a,c)\n\n뷰\n\n\n\ntest(a,d)\n\n뷰\n\n\n\ntest(c,d)\n\n공통의 base를 가짐\n\n\n\ntest(b,c)\n\n카피, 혹은 아무 관련없는 오브젝트\n\n\n- 심지어 copy인줄 알았던것이 사실 view라서 원치않는 side effect이 생길수 있음. \\(\\to\\) 그냥 방어적 프로그래밍이 최선인듯"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class9.html",
    "href": "posts/1_IP2022/2023-02-23-class9.html",
    "title": "class 9단계",
    "section": "",
    "text": "global/local 변수, 인스턴스/클래스 변수, 인스턴스/클래스 메서드\n\n\n\n커널을 재시작하고 아래를 관찰하자.\n\n\n- 관찰1: 함수내의 변수 출력\n\ndef f():\n    x = 10\n    print(x)\n\n\nf()\n\n10\n\n\n- 관찰2: 함수내의 변수가 없을 경우 출력이 되지 않음\n\ndef g():\n    print(x)\n\n\ng()\n\nNameError: name 'x' is not defined\n\n\n- 관찰3: 동일한 이름의 변수가 global에 있다면 함수내에 (local) 그 이름의 변수가 선언되지 않아도 global 변수를 빌려서 사용함.\n\nx = 20\ndef g():\n    print(x)\n\n\ng()\n\n20\n\n\n- 관찰4: f()가 실행되면서 x=10이 함수내에(=local에) 실행되지만 이 결과가 외부의 x=20에(=global에) 영향을 미치지는 못함.\n\nf()\n\n10\n\n\n\nx\n\n20\n\n\n\n\n\n(코드1)\n\nx = 38\ndef nextyear():\n    y = x+1\n    print(x,y)\nnextyear()\n\n38 39\n\n\n(코드2)\n\nx = 38\ndef nextyear():\n    y = x+1\n    print(x,y)\n    x = 0\nnextyear()\n\nUnboundLocalError: local variable 'x' referenced before assignment\n\n\n- 해석: - 잘못된해석: 코드1은 실행되었고, 코드2에서 에러가 났다. 코드1과 2의 차이점은 x=0 이라는 코드가 코드2에 추가로 포함되어있다는 것이다. 따라서 x=0이 잘못된 코드이고 이걸 실행하는 과정에서 에러가 발생했다.\n\n올바른해석: 코드1에서는 x가 global variable이고 코드2에서는 x가 local variable이어서 생기는 문제\n\n- 코드2의 올바른 수정\n\nx = 38\ndef nextyear():\n    x = 0\n    y = x+1\n    print(x,y)\nnextyear()\n\n0 1\n\n\n\n\n\n\n- 예비학습이 주는 교훈\n(원칙1) global에서 정의된 이름은 local에서 정의된 이름이 없을 경우 그를 대신할 수 있다. (local은 경우에 따라서 global에 있는 변수를 빌려 쓸 수 있다.)\n(원칙2) local과 global에서 같은 이름 ’x’가 각각 정의되어 있는 경우? global의 변수와 local의 변수는 각각 따로 행동하여 서로 영향을 주지 않는다. (독립적이다)\n\n만약에 local에 global의 변수를 같이 쓰고 있었다고 할지라도, 추후 새롭게 local에 이름이 새롭게 정의된다면 그 순간 local과 global의 변수를 각자 따로 행동하며 서로 영향을 주지 않는다.\\(\\to\\) 아래예제 확인\n\n\nx = 10\ndef f():\n    print(x)\n\n\nf() # x를 빌려쓰는 신세\n\n10\n\n\n\ndef f():\n    x = 20 # 이제 새롭게 x를 정의했으니까\n    print(x)\n\n\nf() # 다른길을 간다.\n\n20\n\n\n- 이전에 공부하였던 인스턴스변수와 클래스변수 역시 비슷한 행동을 보인다.\n\nclass Moo:\n    x = 0 # 클래스 변수\n\n\nmoo=Moo()\n\n(관찰1)\n\nMoo.x, moo.x\n\n(0, 0)\n\n\n\nmoo.x는 사실 정의한적이 없지만 Moo.x를 빌려쓰고 있다. (원칙1)\n\n(관찰2)\n\nMoo.x = 100\n\n\nMoo.x, moo.x\n\n(100, 100)\n\n\n\nMoo.x를 변화시키면 moo.x도 변화한다. (빌려쓰고 있는 것이니까, 원칙1의 재확인)\n\n(관찰3)\n\nmoo.x = 200\n\n\nMoo.x, moo.x\n\n(100, 200)\n\n\n\nmoo.x=200을 하는 순간 새롭게 인스턴스변수를 선언한 셈이된다. 따라서 원칙2가 적용되어 이제부터 Moo.x와 moo.x는 서로 독립적으로 행동한다.\n\n(관찰4)\n\nMoo.x = -99\n\n\nMoo.x, moo.x\n\n(-99, 200)\n\n\n\nmoo.x = 99\n\n\nMoo.x, moo.x\n\n(-99, 99)\n\n\n\nMoo.x를 바꾼다고 해서 moo.x가 영향받지 않고 moo.x를 바꿔도 Moo.x가 영향받지 않음. (완전히 독립, 원칙2의 재확인)\n\n\n\n\n\n클래스변수와 인스턴스 변수의 구분\n\n\n인스턴스 변수가 정의되지 않으면 클래스변수를 빌려쓸 수 있음(클래스변수가 상위개념)\n\n\n인스턴스변수와 클래스변수가 같은 이름으로 저장되어 있으면 각각 독립적으로 행동\n\n\n\n\n\n\n- self 비밀: 사실 클래스에서 정의된 함수의 첫번째 인자의 이름이 꼭 self일 필요는 없다. (무엇으로 전달하든 클래스 안에서 정의된 메소드의 첫번째 인자는 기본적으로 태명역할을 한다.)\n\nclass Moo:\n    def __init__(self):\n        self.name = 'jordy'\n    def f(self):\n        print(self.name)\n\n\nmoo = Moo()\n\n\nmoo.name\n\n'jordy'\n\n\n\nmoo.f()\n\njordy\n\n\n\n꼭 위와 같이 할 필요는 없다.\n\n\nclass Moo:\n    def __init__(abab):\n        abab.name = 'jordy'\n    def f(cdcd):\n        print(cdcd.name)\n\n\nmoo = Moo()\n\n\nmoo.name\n\n'jordy'\n\n\n\nmoo.f()\n\njordy\n\n\n- 인스턴스 메서드: 위의 __init__와 f와 같이 첫번째 인자를 인스턴스의 태명으로 받는 함수를 인스턴스 메서드 (간단히 메서드) 라고 한다.\n\n인스턴스 메소드는 self.f()와 같이 사용한다. 의미는 f(self) 이다.\n\n\nmoo.name = 'chunsik'\n\n\nmoo.name\n\n'chunsik'\n\n\n\nmoo.__init__()\n\n\nmoo.name # 인스턴스 메서드의 사용예시: self.__init__()의 꼴로 사용\n\n'jordy'\n\n\n\n오 신기하다.\n\n- 아래와 같이 사용할 수 없다.\n\nMoo.__init__() # 인스턴스가 들어와야하는데 클래스가 들어와버려서 이렇게 쓸순 없다.\n\nTypeError: __init__() missing 1 required positional argument: 'abab'\n\n\n\n인스턴스 메소드이기때문에 에러가 난다. 즉, 첫번째 입력 (.__init__()앞에)에 인스턴스가 들어가야 하는데 클래스가 들어와버렸다.\n\n\n\n\n- 클래스 메서드: 함수의 첫 인자로 클래스오브젝트를 받는 메서드를 클래스메서드라고 한다.\n- 목표: Moo.f() 와 같은 형태로 사용할 수 있는 함수를 만들어 보자. \\(\\to\\) 클래스메서드를 만들어보자.\n\nclass Moo:\n    def f(self): # 클래스 안에서 함수를 선언하면 디폴트로 인스턴스 메서드가 만들어진다.\n        print('인스턴스 메서드') \n\n\nmoo = Moo()\n\n\nmoo.f()\n\n인스턴스 메서드\n\n\n\nMoo.f() # 인스턴스 메서드니까 안되는게 당연\n\nTypeError: f() missing 1 required positional argument: 'self'\n\n\n\nclass Moo:\n    @classmethod\n    def f(cls): # 함수의 첫 인자로 클래스오브젝트를 받는다. cls는 클래스 Moo의 별명? 이라고 생각하면 된다.\n        print('클래스 메서드')\n\n\nmoo = Moo()\n\n\nMoo.f()\n\n클래스 메서드\n\n\n\nmoo.f() # 인스턴스 메서드를 따로 정의한적은 없지만 같은 이름의 클래스 메서드가 있으므로 빌려와서 씀!\n\n클래스 메서드\n\n\n- 예제\n\nclass Moo:\n    @classmethod\n    def set_class_x(cls, value): # 클래스 메서드\n        cls.x = value # 클래스변수선언, Moo.x = value와 같은 코드!\n    def set_instance_x(self, value): # 인스턴스 메서드\n        self.x = value # 인스턴스 변수선언\n\n\nmoo = Moo()\n\n\nMoo.set_class_x(10) # 클래스메서드로 클래스변수에 10을 설정\n\n\nMoo.x\n\n10\n\n\n\nMoo.set_instance_x(10) # 클래스에서 인스턴스 메서드 사용 -> 사용불가\n\nTypeError: set_instance_x() missing 1 required positional argument: 'value'\n\n\n\nMoo.x, moo.x # 인스턴스변수는 따로 설정하지 않았지만 클래스 변수값을 빌려쓰고 있음\n\n(10, 10)\n\n\n\nmoo.set_class_x(20) # 인스턴스에서는 원래 set_class_x 라는 메서드는 없지만 클래스에서 빌려씀\n\n\nMoo.x, moo.x # 현재 moo.x(인스턴스)는 클래스 변수를 빌려쓰고 있는 상황이므로 같이 바뀜\n\n(20, 20)\n\n\n\nmoo.set_instance_x(-20) \n# 인스턴스에서 인스턴스 메서드를 사용하여 인스턴스 변수값을 -20으로 설정 \n# -> 이때부터 인스턴스 변수와 클래스 변수는 서로 독립적인 노선을 간다.\n\n\nMoo.set_class_x(30) # 독립적인 노선을 가기로 헀으므로 클래스변수만 30으로 바뀜.\nMoo.x, moo.x\n\n(30, -20)\n\n\n\nmoo.set_class_x(-40) # 여전히 인스턴스에서 set_class_x라는 함수는 없으므로 클래스메소드를 빌려쓰고 있음.\n\n\n\n\n- 스태틱 메서드: 첫 인자로 인스턴스와 클래스 모두 받지 않음. (클래스안에 정의되어 있지만 그냥 함수와 같음)\n\nclass Cals:\n    @staticmethod\n    def add(a,b):\n        return a+b\n    @staticmethod\n    def sub(a,b):\n        return a-b\n\n\nfs = Cals()\n\n\nfs.add(1,2)\n\n3\n\n\n\nfs.sub(1,2)\n\n-1\n\n\n\nfs는 그냥 함수들을 묶어놓은 느낌? 정리하기 편하게?"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class8.html",
    "href": "posts/1_IP2022/2023-02-23-class8.html",
    "title": "class 8단계",
    "section": "",
    "text": "for문 복습, iterable object\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\n\n\n- 아래와 같은 예제들을 관찰하여 for문을 복습하자.\n(예제1)\n\nfor i in [1,2,3,4]:\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제2)\n\nfor i in (1,2,3,4):\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제3)\n\nfor i in '1234':\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제4)\n\na=5\nfor i in a:\n    print(i)\n\nTypeError: 'int' object is not iterable\n\n\n\n5라고 출력되어야 하지 않나?\n\n- 의문1:\nfor i in ???:\n    print(i)\n에서 ???자리에 올 수 있는 것이 무엇일까?\n(예제5)\n상황1\n\nlst = [[1,2,3,4],[3,4,5,6]]\nlst\n\n[[1, 2, 3, 4], [3, 4, 5, 6]]\n\n\n\nfor l in lst:\n    print(l)\n\n[1, 2, 3, 4]\n[3, 4, 5, 6]\n\n\n상황2\n\ndf = pd.DataFrame(lst)\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\n0\n1\n2\n3\n\n\n칼럼이름들이 나오는 것 같음 \\(\\to\\) 확인해보자.\n\ndf.columns = pd.Index(['X'+str(i) for i in range(1,5)])\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n      X4\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n- 의문2: for의 출력결과는 어떻게 예측할 수 있을까?\n\n\n\n- 의문1의 해결: 아래의 ??? 자리에 올 수 있는 것은 dir() 하여 __iter__ 가 있는 object이다.\nfor i in ???:\n    print(i)\n- 확인\n\na = [1,2,3] # list\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na = 1,2,3 # tuple\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na = '123' # string\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na=3\nset(dir(a)) & {'__iter__'}\n\nset()\n\n\niterable 하지 않다라는 것은dir()을 쳤을 때 __iter__ 라는 메소드가 없다는 것을 의미\n\n예상대로 예제1~예제4에서는 int클래스의 instance만 __iter__가 없다.\nfor문 뒤 ??? 자리에 올 수 있는 것은 iterable object만 올 수 있다.\n\n- __iter__의 역할: iterable object를 iterator로 만들 수 있다.\n\nlst = [1,2,3]\nlst\n\n[1, 2, 3]\n\n\n\nlst[1] # 충실한 리스트\n\n2\n\n\n\nltor = iter(lst) # 아래와 같은 표현 (a.__str__() = str(a)가 같은 것처럼)\n#ltor = lst.__iter__() # list iterator\nltor\n\n<list_iterator at 0x7f2dfc4c51f0>\n\n\n\nltor[1] # 더이상 리스트가 아니다.\n\nTypeError: 'list_iterator' object is not subscriptable\n\n\n\nltor?\n\n\nType:        list_iterator\nString form: <list_iterator object at 0x7f2dfc4c51f0>\nDocstring:   <no docstring>\n\n\n\n- iterator가 되면 무엇이 좋은가? \\(\\to\\) 숨겨진 기능 __next__가 열린다.\n\nlst\n\n[1, 2, 3]\n\n\n\nset(dir(lst)) & {'__next__'}, set(dir(ltor)) & {'__next__'}\n\n(set(), {'__next__'})\n\n\n\nlst에는 __next__ 가 없지만 ltor에는 있다.\n\n- 그래서 __next__의 기능은? \\(\\to\\) 원소를 차례대로 꺼내준다. + 더 이상 꺼낼 원소가 없으면 Stopiteration Error 발생시킨다.\n\nlst\n\n[1, 2, 3]\n\n\n\nltor.__next__()\n\n1\n\n\n\nltor.__next__()\n\n2\n\n\n\nltor.__next__()\n\n3\n\n\n\nltor.__next__()\n\nStopIteration: \n\n\n- for문의 동작원리\nfor i in lst:\n    print(i)\n\nlst.__iter__() 혹은 iter(lst)를 이용하여 lst를 iterator로 만든다. (iterable object를 iterator object로 만든다.)\niterator에서 .__next__() 함수를 호출하고 결과를 i에 저장한 뒤에 for문 블락안에 있는 내용 (들여쓰기 된 내용)을 실행한다. \\(\\to\\) 반복\nStopIteration 에러가 발생하면 for문을 멈춘다.\n\n- 아래의 ??? 자리에 올 수 있는 것이 iterable object 가 아니라 iterator 자체여도 for문이 돌아갈까? (당연히 돌아가야 할 것 같음)\nfor i in ???:\n    print(i)\n\nfor i in [1,2,3]: # iterable object\n    print(i)\n\n1\n2\n3\n\n\n\n당연히 가능!\n\n- a가 iterator일때 iter(a)의 출력결과가 a와 같도록 조정한다면 for문의 동작원리 (1)-(3)을 수행하지 않아도 좋다. \\(\\to\\) 실제로 이렇게 동작한다.\n- 요약\n\niterable object는 숨겨진 기능으로 __iter__를 가진다.\niterator object는 숨겨진 기능으로 __iter__와 __next__를 가진다. (즉 iterator는 그 자체로 iterable object가 된다!)\n\n\nlst = [1,2,3]\nltor = iter(lst)\n\n\nset(dir(lst)) & {'__iter__','__next__'}\n\n{'__iter__'}\n\n\n\nset(dir(ltor)) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n- 의문2의 해결: for의 출력결과는 어떻게 예측할 수 있을까? iterator를 만들어서 .__next__()의 출력값을 확인하면 알 수 있다.\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n\ndftor = iter(df)\ndftor?\n\n\nType:        map\nString form: <map object at 0x7f2dfc4c85b0>\nDocstring:  \nmap(func, *iterables) --> map object\nMake an iterator that computes the function using arguments from\neach of the iterables.  Stops when the shortest iterable is exhausted.\n\n\n\n\ndftor.__next__()\n\n'X1'\n\n\n\ndftor.__next__()\n\n'X2'\n\n\n\ndftor.__next__()\n\n'X3'\n\n\n\ndftor.__next__()\n\n'X4'\n\n\n\ndftor.__next__()\n\nStopIteration: \n\n\n\n\n\n- 파이썬에서 for문을 처음 배울 때: range(5)를 써라!\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\nrange(5)가 도대체 무엇이길래? ## iterator 아니면 iterable object 일건데..\n\n\nrange(5)\n\nrange(0, 5)\n\n\n\nrepr(range(5))\n\n'range(0, 5)'\n\n\n- range(5)의 정체는 그냥 iterable object이다.\n\nset(dir(range(5))) & {'__iter__', '__next__'}\n\n{'__iter__'}\n\n\n__next__ 는 갖고있지 않은데 __iter__만 갖고있으니까 range(5)는 iterable object\n- 그래서 언제든지 iterator로 바꿀 수 있다.\n\nrtor = iter(range(5))\n\n\nrtor?\n\n\nType:        range_iterator\nString form: <range_iterator object at 0x7f2dfc4c56c0>\nDocstring:   <no docstring>\n\n\n\n\nset(dir(rtor)) & {'__iter__','__next__'}\n\n{'__iter__', '__next__'}\n\n\n- for문에서 range(5)가 행동하는 방법?\n\nrtor.__next__()\n\n0\n\n\n\nrtor.__next__()\n\n1\n\n\n\nrtor.__next__()\n\n2\n\n\n\nrtor.__next__()\n\n3\n\n\n\nrtor.__next__()\n\n4\n\n\n\nrtor.__next__()\n\nStopIteration: \n\n\n\n\n\n- 이터레이터의 개념을 알면 for문에 대한 이해도가 대폭 상승한다.\n\nfor i in zip([1,2,3],'abc'):\n    print(i)\n\n(1, 'a')\n(2, 'b')\n(3, 'c')\n\n\n\nzip은 뭐지???\n\n\nzip([1,2,3],'abc')\n\n<zip at 0x7f2dfc4e8340>\n\n\n- 어차피 for i in ????: 의 ???? 자리는 iterable object(iterator)의 자리이다.\n\nset(dir(zip([1,2,3],'abc'))) & {'__iter__','__next__'}\n\n{'__iter__', '__next__'}\n\n\n\n__next__() 함수가 있음 \\(\\to\\) zip([1,2,3],'abc')는 그자체로 iterator 였다!\n\n\nz = zip([1,2,3],'abc')\n\n\nz.__next__()\n\n(1, 'a')\n\n\n\nz.__next__()\n\n(2, 'b')\n\n\n\nz.__next__()\n\n(3, 'c')\n\n\n\nz.__next__()\n\nStopIteration: \n\n\n\n\n\n- 내가 이터레이터를 만들어보자.\n\nclass Klass: # 찌를 내는 순간 for문이 멈추도록 하는 이터레이터를 만들자.\n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        if action == '찌':\n            print('찌가 나와서 for문을 멈춥니다.')\n            raise StopIteration\n        else:\n            return action\n\n\na = Klass() # 클래스로부터 인스턴스 만들기\n\n\na?\n\n\nType:        Klass\nString form: <__main__.Klass object at 0x7f2dfc373af0>\nDocstring:   <no docstring>\n\n\n\n\nset(dir(a)) & {'__iter__', '__next__'} # a는 이터레이터!\n\n{'__iter__', '__next__'}\n\n\n\na.__next__()\n\n'빠'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n찌가 나와서 for문을 멈춥니다.\n\n\nStopIteration: \n\n\n\nfor i in a:\n    print(i)\n\n빠\n묵\n묵\n빠\n찌가 나와서 for문을 멈춥니다.\n\n\n\n\n\n\n파이썬의 비밀1: 자료형은 클래스의 이름이다.\n파이썬의 비밀2: 클래스에는 __str__ 처럼 숨겨진 매서드가 존재한다. 이를 이용하여 파이썬 내부의 기능을 가로챌 수 있다.\n파이썬의 비밀3: 주피터노트북(대화형 콘솔)에서는 “오브젝트이름 + 엔터”를 쳐서 나오는 출력은 __repr__로 가로챌 수 있다. (주피터의 비밀)\n파이썬의 비밀4: 함수와 클래스는 숨겨진 메소드에 __call__을 가진 오브젝트일 뿐이다.\n파이썬의 비밀5: for문의 비밀(iterable object, iterator, StopIteration Error)"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html",
    "href": "posts/1_IP2022/2023-05-27-class활용.html",
    "title": "Class 활용",
    "section": "",
    "text": "클래스(class)는 여러 정보를 하나의 객체에 담을 때 사용할 수 있다.\n캐릭터 객체를 만들 때, 캐릭터에 대한 정보로는 다음과 같은 것들이 있다.\n\n\n이름\n\n\n체력\n\n\n힘\n\n\n민첩도\n\n\n\n\nclass Character:\n    def __init__(self, name, hp, strength, agility):\n        self.name = name\n        self.hp = hp\n        self.strength = strength\n        self.agility = agility\n        \n    def show_character(self):\n        print('=======캐릭터 정보=======')\n        print(f'이름: {self.name}')\n        print(f'체력: {self.hp}')\n        print(f'힘: {self.strength}')\n        print(f'민첩도: {self.agility}')\n        \n    def attack(self):\n        print(f'[{self.name}] 기본 공격 수행 (공격력: {self.strength})')\n\n\ncharacter1 = Character(\"슬라임\", 50, 5, 3)\ncharacter1.show_character()\ncharacter1.attack()\n\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 50\n힘: 5\n민첩도: 3\n[슬라임] 기본 공격 수행 (공격력: 5)\n\n\n\ncharacter2 = Character(\"용사1\", 200, 10, 5)\ncharacter2.show_character()\ncharacter2.attack()\n\n=======캐릭터 정보=======\n이름: 용사1\n체력: 200\n힘: 10\n민첩도: 5\n[용사1] 기본 공격 수행 (공격력: 10)\n\n\n\ncharacter1, 2 각 각 인스턴스가 다르기 때문에 서로 다른 정보를 갖는다.\nCharacter라는 클래스 내에 character1, character2처럼 같은 클래스 내의 인스턴스는 다를 수 있다."
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#몬스터-클래스-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#몬스터-클래스-자식",
    "title": "Class 활용",
    "section": "2. 몬스터 클래스 (자식)",
    "text": "2. 몬스터 클래스 (자식)\n앞서 정의했던 Character 클래스를 이용해서 몬스터 클래스를 정의할 수 있다.\n\n클래스의 상속(inheritance) 은 체계적인 프로그램 개발을 위해 필요하다.1\n예를 들어 캐릭터 객체는 몬스터(monster) 와 주인공(hero) 로 나누어질 수 있다.\n\n이들은 공통적으로 이름(name), 힘(strength) 등의 정보를 가지고 있다.\n\n상속을 사용하여, 공통적으로 사용되는 변수를 매번 선언하지 않는다.\n몬스터는 모두 마력(MP) 정보를 가지고 있다고 가정하자.\n\n\nclass Monster(Character):\n    def __init__(self, name, hp, strength, agility, mp):\n        super().__init__(name, hp, strength, agility)\n        self.mp = mp\n    \n    def recovery(self):\n        print(f'[{self.name}] 자기 치유 (회복된 체력: {self.mp})')\n        self.hp += self.mp\n\n\nmonster1 = Monster('슬라임', 50, 5, 3, 5)\nmonster1.show_character()\nmonster1.attack()\nmonster1.recovery()\nmonster1.show_character()\n\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 50\n힘: 5\n민첩도: 3\n[슬라임] 기본 공격 수행 (공격력: 5)\n[슬라임] 자기 치유 (회복된 체력: 5)\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 55\n힘: 5\n민첩도: 3\n\n\n\nMonster 클래스는 기존의 Character 클래스를 상속받은 것이기 때문에 기존 Character 클래스가 가지고 있던 기능까지 함께 사용할 수 있다."
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#주인공-클래스-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#주인공-클래스-자식",
    "title": "Class 활용",
    "section": "3. 주인공 클래스 (자식)",
    "text": "3. 주인공 클래스 (자식)\n\n주인공은 모두 직업(job) 정보를 가지고 있다고 가정하자.\n\n\nclass Hero(Character):\n    def __init__(self, name, hp, strength, agility, job):\n        super().__init__(name, hp, strength, agility)\n        self.job = job\n    def show_hero(self):\n        print('==========주인공 정보==========')\n        print(f'직업: {self.job}')\n\n\nhero1 = Hero('용사1', 200, 10, 5, '마법사')\nhero1.show_character()\n\n=======캐릭터 정보=======\n이름: 용사1\n체력: 200\n힘: 10\n민첩도: 5\n\n\n\nhero1.show_hero()\n\n==========주인공 정보==========\n직업: 마법사"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#딥러닝-모델-클래스-예시",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#딥러닝-모델-클래스-예시",
    "title": "Class 활용",
    "section": "딥러닝 모델 클래스 예시",
    "text": "딥러닝 모델 클래스 예시\n\n1. 딥러닝 이미지 모델 클래스 (부모)\n\n기초적인 이미지 처리 모델은 일반적으로 인코더 정보를 포함한다.\n인코더(encoder)\n\n특징 추출기(feature extractor)\n입력 모양(input shape)\n\n딥러닝 모델은 입력을 통해 출력을 뱉는 forward() 함수가 존재한다.\n\n\nclass Model:\n    def __init__(self, feature_extractor, input_shape):\n        self.feature_extractor = feature_extractor\n        self.input_shape = input_shape\n        \n    def show(self):\n        print('==========인코더 정보===============')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'입력 차원: {self.input_shape}')\n        \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기] {self.feature_extractor}')\n\n\nmodel = Model('ResNet50 backbone', (224,224,3))\nmodel.show()\n\n==========인코더 정보===============\n특징 추출기: ResNet50 backbone\n입력 차원: (224, 224, 3)\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기] ResNet50 backbone\n\n\n\n인코더는 동일하게 설정하되 디코더는 다르게 설정하는 경우가 많다.\n\n\n\n2. 이미지 분류 모델 (자식)\n\n기초적인 이미지 분류 모델은 다음의 두 가지를 포함하는 경우가 많다.\n\n분류기(classifier)\n출력 모양(output shape)\n\n오버라이딩(overriding) 을 이용해 forward() 함수를 재정의 할 수 있다.\n\n\nclass Classifier(Model):\n    def __init__(self, feature_extractor, input_shape, classifier, output_shape):\n        super().__init__(feature_extractor, input_shape)\n        self.classifier = classifier\n        self.output_shape = output_shape\n    \n    def show_classifier(self):\n        print('=======모델 정보=====')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'분류 모델: {self.classifier}')\n        print(f'입력 차원: {self.input_shape}')\n        print(f'출력 차원: {self.output_shape}')\n        \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기] {self.feature_extractor}')\n        print(f'[분류 모델] {self.classifier}')\n\n\nmodel = Classifier(\"ResNet50 backbone\", (256,256,3), \"FC layer\", (10))\nmodel.show_classifier()\n\n=======모델 정보=====\n특징 추출기: ResNet50 backbone\n분류 모델: FC layer\n입력 차원: (256, 256, 3)\n출력 차원: 10\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기] ResNet50 backbone\n[분류 모델] FC layer"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#이미지-분할segmentation-모델-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#이미지-분할segmentation-모델-자식",
    "title": "Class 활용",
    "section": "3. 이미지 분할(Segmentation) 모델 (자식)",
    "text": "3. 이미지 분할(Segmentation) 모델 (자식)\n\n기초적인 이미지 분할 모델은 다음의 두 가지를 포함하는 경우가 많다.\n\n디코더(decoder)\n출력 모양(output shape)\n\n오버라이딩(overriding)을 이용해 forward() 함수를 재정의할 수 있다.\n\n\nclass SegmentationModel(Model):\n    def __init__(self, feature_extractor, input_shape, decoder, output_shape):\n        super().__init__(feature_extractor, input_shape)\n        self.decoder = decoder\n        self.output_shape = output_shape\n        \n    def show_segmentation_model(self):\n        print('========모델 정보========')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'디코더: {self.decoder}')\n        print(f'입력 차원: {self.input_shape}')\n        print(f'출력 차원: {self.output_shape}')\n    \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기]: {self.feature_extractor}')\n        print(f'[디코더]: {self.decoder}')\n\n\nmodel = SegmentationModel('ResNet50 backbone', (256,256,3), 'U-Net', (256,256,3))\n\n\nmodel.show_segmentation_model()\n\n========모델 정보========\n특징 추출기: ResNet50 backbone\n디코더: U-Net\n입력 차원: (256, 256, 3)\n출력 차원: (256, 256, 3)\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기]: ResNet50 backbone\n[디코더]: U-Net"
  },
  {
    "objectID": "posts/1_IP2022/2022_06_09_2021년_파이썬입문_기말고사_(풀이포함).html",
    "href": "posts/1_IP2022/2022_06_09_2021년_파이썬입문_기말고사_(풀이포함).html",
    "title": "2021 final exam solution",
    "section": "",
    "text": "2021년 1학기 파이썬입문 기말고사 (풀이포함)\nLINK HERE!\n\n# 1. (20점)\nN사에서 게임유저들에게 여름방학 기념이벤트로 진명왕의 집판검이라는 이름의 아이템을 선물했다고 하자. 진명왕의 집판검은 총 5회에 걸쳐서 강화(upgrade)될 수 있데 강화의 성공확률은 10%라고 하자. 강화가 5번성공하면 더 이상 강화가 진행되지 않는다고 하자. (따라서 더 이상 강화시도를 하지 않아도 무방하다) 아래는 이 아이템에 강화를 진행하였을때 각 강화상태를 설명한 예시이다.\n\n\n\n시도횟수\n강화성공여부\n강화상태\n비고\n\n\n\n\n1\n강화실패\n+0 \\(\\to\\) +0\n강화실패로 인하여 강화상태 변화없음\n\n\n2\n강화성공\n+0 \\(\\to\\) +1\n강화성공으로 인한 강화상태 변화\n\n\n3\n강화실패\n+1 \\(\\to\\) +1\n강화실패로 인하여 강화상태 변화없음\n\n\n4\n강화성공\n+1 \\(\\to\\) +2\n강화성공으로 인한 강화상태 변화\n\n\n5\n강화성공\n+2 \\(\\to\\) +3\n강화성공으로 인한 강화상태 변화\n\n\n6\n강화성공\n+3 \\(\\to\\) +4\n강화성공으로 인한 강화상태 변화\n\n\n7\n강화실패\n+4 \\(\\to\\) +4\n강화실패로 인하여 강화상태 변화없음\n\n\n8\n강화성공\n+4 \\(\\to\\) +5\n모든 강화 성공\n\n\n9\n-\n+5 \\(\\to\\) +5\n더 이상 강화시도 하지 않음\n\n\n10\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\n강화는 하루에 한 번씩만 시도할 수 있으며 시도가능한 기간은 7월1일부터 8월31일까지로 한정되어 있다고 하자. 따라서 방학동안 유저들은 총 62번 시도를 할 수 있다. 방학이 끝난이후 100명 유저중 대략 몇명정도 +5 강화상태에 있겠는가? 파이썬을 통한 시뮬레이션을 활용하여 추론하라. (단, +5강화에 성공하지 못한 모든 유저는 반드시 하루에 한번 강화를 시도해야 한다고 가정하자.)\n(풀이1)\n\nimport numpy as np\nnp.random.seed(1)\nsum(np.random.binomial(n=62, p=0.1, size=10000)>=5)/10000\n\n0.7514\n\n\n(풀이2)\n\nclass ExecutionSword():\n    def __init__(self,prob):\n        self.nuser=100000\n        self.prob=prob\n        self.attemptresult=None\n        self.upgradestate=pd.DataFrame({'day0':[0]*self.nuser})\n        self.failstate=pd.DataFrame({'day0':[0]*self.nuser})\n        self.ratio=0\n        self.day=0\n    def addday(self):\n        self.day=self.day+1            \n    def attempt(self):\n        self.attemptresult = np.random.binomial(n=1, p=self.prob, size=self.nuser)\n    def update(self):\n        # 강화상태 업데이트\n        self.upgradestate['day%s' % self.day] = np.minimum(5,self.upgradestate['day%s' % (self.day-1)]+self.attemptresult)\n        # 강화실패누적횟수 업데이트 \n        self.failstate['day%s' % self.day]=self.failstate['day%s' % (self.day-1)]+(self.attemptresult==0)*1\n        # 강화상태==5 or 강화상태==0 일 경우 강화실패누적횟수 초기화 \n        self.failstate['day%s' % self.day][self.upgradestate['day%s' % self.day]== 0]=0\n        self.failstate['day%s' % self.day][self.upgradestate['day%s' % self.day]== 5]=0\n    def reset(self):\n        # 실패횟수 = 2 인것을 찾아 index_ 에 저장 -> index_ 에 해당하는 유저의 강화횟수와 실패횟수를 모두 0으로 초기화 \n        index_= self.failstate['day%s' % self.day]==2\n        self.failstate['day%s' % self.day][index_] = 0\n        self.upgradestate['day%s' % self.day][index_] = 0\n    def arrangeprob(self):\n        self.ratio=sum(self.upgradestate['day%s' % self.day]==5) / self.nuser\n        if self.ratio > 0.5:\n            self.prob = 0.9\n\n\n# 1 \nimport pandas as pd\ns1=ExecutionSword(0.1)\nfor i in range(62):\n    s1.addday()\n    s1.attempt()\n    s1.update()\n\n\nsum(s1.upgradestate.day62==5)/s1.nuser\n\n0.75551\n\n\n\n\n# 2. (70점)\n강화성공확률을 40%로 수정한다. 강화에 누적2회 실패하면 강화상태가 초기화 된다고 하자. (따라서 강화실패 누적횟수를 카운트하는 변수가 필요하다) 단, 강화실패 누적횟수는 누적2회 달성시 0으로 초기화 된다. 또한 강화상태가 +0인 경우는 실패하여도 강화실패 누적횟수가 추가되지 않는다.\n\n\n\n시도횟수\n강화성공여부\n강화상태\n강화실패누적\n비고\n\n\n\n\n1\n강화성공\n+0 \\(\\to\\) +1\n0 \\(\\to\\) 0\n-\n\n\n2\n강화성공\n+1 \\(\\to\\) +2\n0 \\(\\to\\) 0\n-\n\n\n3\n강화실패\n+2 \\(\\to\\) +2\n0 \\(\\to\\) 1\n-\n\n\n4\n강화성공\n+2 \\(\\to\\) +3\n1 \\(\\to\\) 1\n-\n\n\n5\n강화실패\n+3 \\(\\to\\) +0\n1 \\(\\to\\) 0\n강화실패로 누적2회로 인한 초기화\n\n\n6\n강화실패\n+0 \\(\\to\\) +0\n0 \\(\\to\\) 0\n강화실패 누적횟수 증가하지 않음\n\n\n7\n강화성공\n+0 \\(\\to\\) +1\n0 \\(\\to\\) 0\n-\n\n\n8\n강화성공\n+1 \\(\\to\\) +2\n0 \\(\\to\\) 0\n-\n\n\n9\n강화성공\n+2 \\(\\to\\) +3\n0 \\(\\to\\) 0\n-\n\n\n10\n강화성공\n+3 \\(\\to\\) +4\n0 \\(\\to\\) 0\n-\n\n\n11\n강화성공\n+4 \\(\\to\\) +5\n0 \\(\\to\\) 0\n모든 강화 성공\n\n\n12\n-\n+5 \\(\\to\\) +5\n0 \\(\\to\\) 0\n더 이상 강화시도 하지 않음\n\n\n13\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\n(1) 이 경우 62일의 방학뒤에 100명의 유저중 대략 몇명정도 +5 강화상태에 있겠는가? 시뮬레이션을 활용하여 추론하라. (단, +5강화에 성공하지 못한 모든 유저는 반드시 하루에 한번 강화를 시도해야 한다고 가정하자.)\n(2) 31번째 시도 이후 대략 몇명의 유저가 +5 강화상태에 있겠는가?\n\n# 2-1,2 \ns2=ExecutionSword(0.4)\n\n\nfor i in range(62):\n    s2.addday()\n    s2.attempt()\n    s2.update()\n    s2.reset() ## 초기화가 되는 조건이 있으므로 문제1에서 reset함수만 추가하면 된다. \n\n\n# 2-1\nsum(s2.upgradestate.day31==5)/s2.nuser\n\n0.36392\n\n\n\n# 2-2\nsum(s2.upgradestate.day62==5)/s2.nuser\n\n0.61803\n\n\n(3) 100명의 유저중 50명이상의 유저가 +5 강화상태에 도달하는 순간 모든 유저의 강화성공확률을 90%로 증가시킨다고 하자. 62일의 방학뒤에 100명의 유저 중 몇명 정도가 +5 강화상태에 있겠는가?\n\n# 2-3 \ns3=ExecutionSword(0.4)\n\n\nfor i in range(62):\n    s3.addday()\n    s3.attempt()\n    s3.update()\n    s3.reset() ## 초기화가 되는 조건이 있으므로 reset함수 추가\n    s3.arrangeprob() ## 전체유저의 50%가 강화성공하면 강화확률이 조정되는 조건이 있으므로 arragneprob 추가 \n\n\nsum(s3.upgradestate.day62==5)/s3.nuser\n\n0.9993"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class10.html",
    "href": "posts/1_IP2022/2023-02-23-class10.html",
    "title": "class 10단계",
    "section": "",
    "text": "문자열 join, matplotlib, 참조와 에일리어싱\n\n\n\n- 예제\n\n'abcd'\n\n'abcd'\n\n\n\nlst = list('abcd')\nlst\n\n['a', 'b', 'c', 'd']\n\n\n\n['a','b','c','d']를 붙여서 'abcd'로 하고 싶은데?\n\n\n''.join(lst)\n\n'abcd'\n\n\n\na='' # string object\n\n\na?\n\n\nType:        str\nString form: \nLength:      0\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n\na.join? # iterable이 와야함.\n\n\nSignature: a.join(iterable, /)\nDocstring:\nConcatenate any number of strings.\nThe string whose method is called is inserted in between each given string.\nThe result is returned as a new string.\nExample: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\nType:      builtin_function_or_method\n\n\n\n\na.join(lst) # lst도 일단 리스트니까 iterable object\n\n'abcd'\n\n\n\nset(dir(lst)) & {'__iter__' , '__next__'} # iterable object임을 확인\n\n{'__iter__'}\n\n\n- 해설: ''는 string object이고, .join는 string object에 소속된 메서드이다.\n\na = ''\na.join(lst) # join(a,lst) 와 같은 효과\n\n'abcd'\n\n\n- join의 간단한 사용방법\n\n'-'.join(lst)\n\n'a-b-c-d'\n\n\n\n\n\n- 파이썬의 모든것은 객체이다:matplotlib의 다른 사용 (객체지향적 언어로 그림그리기!)\n- 그림오브젝트 생성\n\nimport matplotlib.pyplot as plt\n\n\nfig = plt.figure() # plt라는 모듈안에서 figure()라는 함수 실행\n\n<Figure size 432x288 with 0 Axes>\n\n\n그림오브젝트가 실행되고 fig라는 이름이 붙음\n\nid(fig)\n\n140529470770096\n\n\n\nfig\n\n<Figure size 432x288 with 0 Axes>\n\n\n- 그림오브젝트의 액시즈를 확인 -> 아무것도 없음\n\nfig.axes\n\n[]\n\n\n- (0,0) 자리에 (가로=1, 세로=1) 크기의 액시즈를 넣어보자.\n\nfig.add_axes([0,0,1,1])\n\n<Axes: >\n\n\n\nfig.axes\n\n[<Axes: >]\n\n\n\n아까는 빈 리스트였는데 뭔가 추가되어 있다.\n\n\nfig\n\n\n\n\n- (0,1.2) 위치에 (가로=1,세로=1) 크기의 엑시즈 추가\n\nfig.add_axes([0,1.2, 1,1])\nfig\n\n\n\n\n- (0.5,0.5) 위치에 (가로=1, 세로=1) 크기의 그림 추가\n\nfig.add_axes([0.5,0.5,1,1])\n\n<Axes: >\n\n\n\nfig\n\n\n\n\n- fig의 세번째 엑시즈에 접근\n\na3 = fig.axes[2] # 이것역시 오브젝트임.\na3\n\n<Axes: >\n\n\n\nid(fig.axes[2]) # 어딘가에 저장이 되어있으니까 오브젝트!\n\n140529466106976\n\n\n- 엑시즈의 메소드 중에 plot이 있음 \\(\\to\\) 이것으로 그림을 그려봄.\n\na3.plot([1,2,3],[4,5,3],'--r')\n\n\nfig\n\n\n\n\n- 다시 세번째 축에 접근하여 다른 그림을 그려보자.\n\nfig.axes[-1].plot([1,2,3],[5,4,3],':o')\nfig\n\n\n\n\n- 이제 첫번째 축에 접근하여 새로운 그림을 그려보자.\n\nfig.axes[0].plot([1,2,3],[4,1,4],'--b')\nfig\n\n\n\n\n- 클래스에 대한 이해가 없다면 위와 같은 그림을 그리기도 힘들고 코드를 해석하기도 힘듬\n\n\n\n\n# !conda install -c conda-forge rise -y\n\n- 아래의 코드를 관찰하자.\n\na = [1,2,3]\nb = a\n\n\na, b\n\n([1, 2, 3], [1, 2, 3])\n\n\n\nid(a), id(b)\n\n(140529440320192, 140529440320192)\n\n\n같은 방문 앞에 a라는 포스트잇과, b라는 포스트잇이 같이 붙어있었음.\n\na = a + [4] ## 추가\na,b\n\n([1, 2, 3, 4], [1, 2, 3])\n\n\n\nid(a), id(b) # id 추적 -> a의 id 달라짐.\n\n(140529450518400, 140529440320192)\n\n\n새로운 공간(다른방)에 a라는 포스트잇을 붙인것 (방이 바뀐것)\n- 이제 다시 아래의 코드를 관찰하자.\n\na = [1,2,3]\nb = a\na.append(4)\n\n현재 a,b의 출력결과는?\n\na, b\n\n([1, 2, 3, 4], [1, 2, 3, 4])\n\n\n- 아래의 코드를 다시 살펴보자.\n\na = [1,2,3]\nb = a\na.append(4)\n\na,b라는 변수들은 메모리에 어떻게 저장이 되어있을까?\n상상력을 조금 발휘하면 아래와 같이 여길 수 있다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\n\na = [1,2,3]\n\n\n메모리주소1에 존재하는 방을 a라고 하고, 그 방에 [1,2,3]을 넣는다.\n\n\n아래를 실행하였을 경우\n\n\nb = a\n\n\n메모리주소 38에 존재하는 방을 b라고 하고, 그 방에 a를 넣어야하는데 a는 [1,2,3]이니까 [1,2,3]을 넣는다.\n\n\n아래를 실행하면\n\n\na.append(4)\n\n\n방 a로 가서 [1,2,3]을 [1,2,3,4]로 바꾼다.\n그리고 방 b에는 아무것도 하지 않는다.\n\n- R에서는 맞는 비유인데, 파이썬은 적절하지 않은 비유이다.\n\nid(a)\n\n140529439072192\n\n\n\nid(b)\n\n140529439072192\n\n\n실제로는 a,b가 저장된 메모리 주소가 동일함\n- 파이썬에서는 아래가 더 적절한 비유이다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\n\na = [1,2,3]\n\n\n메모리주소 140529439072192에서 [1,2,3]을 생성한다.\n방 140529439072192의 방문에 a라는 포스트잇을 붙인다.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙은 방을 찾아가면 된다.\n\n\n아래를 실행하였을 경우\n\n\nb=a\n\n\na 라는 포스트잇이 있는데, a라는 포스트잇이랑 b라는 포스트잇과 같은 효과를 주도록 한다.\n쉽게말하면, b라는 포스트잇을 방 140529439072192의 방문에 붙인다는 이야기.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방 중에서 a라는 포스트잇이 붙어있거나, b라는 포스트잇이 붙어있는 방을 찾아가면 된다.\n\n\n아래를 실행하면\n\n\na.append(4)\n\n\na라는 포스트잇이 붙어있는 방으로 가서, 그 내용물 append함수를 써서 4를 추가하라. 즉 내용물 [1,2,3]을 [1,2,3,4]로 바꾸라.\n같은방에 a,b라는 포스트잇이 모두 붙어있음. 따라서 b라는 포스트잇이 붙은 방을 찾아가서 내용물을 열어보면 [1,2,3,4]가 나온다.\n\n- 결론: 파이썬의 모든것은 오브젝트이다. 그리고 모든 오브젝트는 메모리주소 위에 올라간다. 하지만 그 메모리 주소에 붙어있는 포스트잇이 하나라는 보장은 없다."
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class1.html",
    "href": "posts/1_IP2022/2023-02-15-class1.html",
    "title": "class 1단계",
    "section": "",
    "text": "클래스 선언 및 사용 예시\n\n\n\n1. 이미지 자료 불러오기 (PIL 이용)\n2. 클래스 성능 정리\n3. 연습문제\n\n\n\n- 예제1\n\n# 이미지 출력을 위한 패키지 불러오기\nimport requests\nfrom PIL import Image\n\n\nurl= 'https://stat.jbnu.ac.kr/sites/stat/images/intro_about_02.jpg'\n\n\nImage.open(Image.io.BytesIO(requests.get(url).content))\n\n\n\n\n- 예제2\n\nurl1 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true' \n\n\nImage.open(Image.io.BytesIO(requests.get(url1).content))\n\n\n\n\n\nImage.open(Image.io.BytesIO(requests.get(url2).content))\n\n\n\n\n\n\n\nclass STOOOP:\n    title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n                \n\n\n규칙1 : 메소드(=class 안에서 정의된 함수)의 첫번째 인자는 무조건 self\n규칙2 : 메소드에서 class 안에 정의된 변수들 (title, url, end)을 사용하려면 self.변수이름 과 같은 형식으로 쓴다.\n\n즉, self.title, self.url, self.end 와 같은 방식으로 써야한다.\n\n(참고) : 규칙2에서 가끔 self 자리에 STOOOP.title, STOOOP.url, STOOOP.end 와 같이 클래스의 이름을 쓰기도 한다.\n\n\n\n\n\n\n\nschool = STOOOP()\n\n\nschool.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\nkospi = STOOOP()\n\n\nkospi.title = 'KOSPI 하락'\n\n\nkospi.stop()\n\nKOSPI 하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n\n\nschool = STOOOP()\nkospi = STOOOP()\n\n\n함수의 사용법과 비슷하다.\n클래스 이름을 쓰고, 콘텐츠를 구체화하는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. 이때는 STOOOP(입력1, 입력2) 와 같이 생성\n위의 예시는 따로 입력이 없으므로 비워둔 상태이다. 즉, STOOOP() 와 같은 식으로 생성\n\n\n\n\n\nschool.title # 출력\n\n'학교폭력!'\n\n\n\nkospi.title # 출력\n\n'학교폭력!'\n\n\n\nkospi.title = '코스피하락' # 변경\n\n\nkospi.title\n\n'코스피하락'\n\n\n\n\n\n\nschool.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~~\n\n\n\nkospi.stop()\n\n코스피하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 True이다.\n- 클래스에는 show()라는 메소드가 있다. show() 기능은 a의 값을 print하는 기능을 한다.\n\nclass Klass1:\n    a = True # 초기값\n    def show(self):\n        print(self.a)\n\n\nex1 = Klass1()\n\n\nex1.a # 초기값\n\nTrue\n\n\n\nex1.show()\n\nTrue\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 1이다.\n- 클래스에는 up()이라는 메소드가 있다. up()의 기능은 a의 값을 1증가시키는 기능을 한다.\n\nclass Klass2:\n    a = 1 # 초깃값\n    def up(self):\n        self.a = self.a + 1\n\n\nex2 = Klass2()\nex2.a\n\n1\n\n\n\nex2.up()\nex2.a\n\n2\n\n\n\nex2.up()\nex2.a\n\n3\n\n\n\nex2.up()\nex2.a\n\n4\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 \\(0\\) 이다.\n- 클래스에는 up(), down(), show() 라는 메소드가 있다. 각각은 a의 값을 1증가, a값을 1감소, a의 값을 print하는 기능을 한다.\n\nclass Klass3:\n    a = 0\n    def up(self):\n        self.a  = self.a + 1\n    def down(self):\n        self.a = self.a - 1\n    def show(self):\n        print(self.a)\n\n\nex3 = Klass3()\n\n\nex3.show()\n\n0\n\n\n\nex3.up()\nex3.show()\n\n1\n\n\n\nex3.up()\nex3.up()\nex3.show()\n\n3\n\n\n\nex3.down()\nex3.show()\n\n2\n\n\n\n\n\n- 클래스 내에는 변수 url이 있음. url의 초기값은 다음과 같다. https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true\n- 클래스에는 show() 라는 메소드(클래스 안에 정의된 함수)를 가지는데, 메소드는 아래와 같은 기능을 한다. - 기능1: url의 그림을 출력 - 기능2: ‘당신은 이 그림을 \\(n\\) 번 보았습니다.’ 출력. (여기에서 \\(n\\)은 그림을 본 횟수)\n\nclass Klass4:\n    n = 1 # 초기값\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 그림을 {}번 보았습니다.'.format(self.n))\n        self.n = self.n + 1\n\n\nex4 = Klass4()\nex4.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다.\n\n\n\nex4.show()\n\n\n\n\n당신은 이 그림을 2번 보았습니다.\n\n\n\n# url 변환 (학교 폭력 이미지 말고, SNL 이미지로 출력되게 바꿔보자.)\nex4_1 = Klass4()\nex4_1.url = url2 # SNL image link\n\n\nex4_1.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다.\n\n\n\n\n\n\n- 클래스를 선언하라. [‘가위’, ‘바위’, ‘보’] 중 하나를 골라서 내는 메소드를 정의하라.\n\n# hint\nimport numpy as np\nnp.random.choice(['가위', '바위', '보'])\n\n'가위'\n\n\n\nclass Klass5:\n    def game(self):\n        print(np.random.choice(['가위','바위','보']))\n\n\nex5 = Klass5()\n\n\nex5.game()\n\n보"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-13-pandas0.html",
    "href": "posts/1_IP2022/2023-03-13-pandas0.html",
    "title": "Pandas 0단계",
    "section": "",
    "text": "판다스를 왜 써야할까?, pandas 개발동기\n\n\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\n\n\n- 예제1: 기본인덱싱\n\na = 'asdf'\na[2]\n\n'd'\n\n\n\na[-1]\n\n'f'\n\n\n- 예제2: 슬라이싱\n\na='asdf'\na[1:3]\n\n'sd'\n\n\n- 예제3: 스트라이딩\n\na='asdf'\na[::2] # 1번째, 3번째 원소 출력\n\n'ad'\n\n\n- 예제4: 불가능한 것\n\na = 'asdf'\na[[1,2]] # 정수인덱스를 리스트화 시켜서 인덱싱하는 것을 불가능\n\nTypeError: string indices must be integers\n\n\n\n\n\n- 예제1: 인덱스의 리스트 (혹은 ndarray)를 전달\n\na = np.arange(5)\na,a[[1,2,-1]]\n\n(array([0, 1, 2, 3, 4]), array([1, 2, 4]))\n\n\n\na = np.arange(55,61)\na, a[[1,2,-1]]\n\n(array([55, 56, 57, 58, 59, 60]), array([56, 57, 60]))\n\n\n- 예제2: bool로 이루어진 리스트 (혹은 ndarray)를 전달\n\na[[True, True, False, False, False, False]]\n\narray([55, 56])\n\n\n\na[np.array([True, True, False, False, False, False])] # 꼭 리스트로 전달할 필요는 없음.\n\narray([55, 56])\n\n\n\na[a<58]\n\narray([55, 56, 57])\n\n\n\n\n\n- 예제1\n\na = np.arange(4*3).reshape(4,3)\na\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11]])\n\n\n\na[0:2,1]\n\narray([1, 4])\n\n\n- 예제2: 차원을 유지하면서 인덱싱을 하고 싶으면?\n\na = np.arange(4*3).reshape(4,3)\na[0:2, [1]]\n\narray([[1],\n       [4]])\n\n\n\n\n\n- 예제1: (key, value)o\n\nd = {'att':65, 'rep':45, 'mid':30, 'fin':100}\nd\n\n{'att': 65, 'rep': 45, 'mid': 30, 'fin': 100}\n\n\n\nd['att'] # key를 넣으면 value가 리턴\n\n65\n\n\n- 예제2: numpy와 비교\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,200)\nrep = np.random.choice(np.arange(5,21)*5,200)\nmid = np.random.choice(np.arange(0,21)*5,200)\nfin = np.random.choice(np.arange(0,21)*5,200)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),200,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(200)}\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\ndel(att);del(rep);del(mid);del(fin);del(key)\n\n\n#test_dic\n\n학번 202212460에 해당하는 학생의 출석점수를 알고 싶다면?\n- (풀이1)\n\ntest_dic['202212460']['att'] ## 가독성이 좋음.\n\n55\n\n\n- (풀이2)\n\ntest_ndarray[test_ndarray[:,0] == 202212460, 1] ## 가독성이 떨어짐.\n\narray([55])\n\n\n정보를 뽑을 때 Numpy indexing을 이용하는 것보다 딕셔너리를 이용하고 hash 타입으로 접근하는것이 편리할 때가 많이 있다.\n(풀이2)가 (풀이1)에 비하여 불편한 점\n\ntest_ndarray의 첫칼럼은 student id 이고 두번째 칼럼은 att라는 사실을 암기하고 있어야 한다.\nstudent id가 아니고 만약에 학생이름을 써서 데이터를 정리한다면 모든 자료형은 문자형이 되어야 한다.\n작성한 코드의 가독성이 없다. (위치로 접근하기 때문)\n\n- 요약: hash 스타일로 정보를 추출하는 것이 유용할 때가 있다. 그리고 보통 hash 스타일로 정보를 뽑는 것이 유리하다. (사실 Numpy는 정보추출을 위해 개발된 자료형이 아니라 행렬 및 벡터의 수학연산을 지원하기 위해 개발된 자료형이다.)\n- 소망: 정보를 추출할때는 hash 스타일도 유용하다는 것은 이해함 \\(\\to\\) 하지만 나는 넘파이스타일로 정보를 뽑고 싶은걸? 그리고 딕셔너리 형태가 아니고 엑셀처럼(행렬처럼) 데이터를 보고 싶은걸? \\(\\to\\) pandas의 개발\n\n\n\n\n\n\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(20)}\n\n\ntest_dic\n\n{'202212380': {'att': 65, 'rep': 55, 'mid': 50, 'fin': 40},\n '202212370': {'att': 95, 'rep': 100, 'mid': 50, 'fin': 80},\n '202212363': {'att': 65, 'rep': 90, 'mid': 60, 'fin': 30},\n '202212488': {'att': 55, 'rep': 80, 'mid': 75, 'fin': 80},\n '202212312': {'att': 80, 'rep': 30, 'mid': 30, 'fin': 100},\n '202212377': {'att': 75, 'rep': 40, 'mid': 100, 'fin': 15},\n '202212463': {'att': 65, 'rep': 45, 'mid': 45, 'fin': 90},\n '202212471': {'att': 60, 'rep': 60, 'mid': 25, 'fin': 0},\n '202212400': {'att': 95, 'rep': 65, 'mid': 20, 'fin': 10},\n '202212469': {'att': 90, 'rep': 80, 'mid': 80, 'fin': 20},\n '202212318': {'att': 55, 'rep': 75, 'mid': 35, 'fin': 25},\n '202212432': {'att': 95, 'rep': 95, 'mid': 45, 'fin': 0},\n '202212443': {'att': 95, 'rep': 55, 'mid': 15, 'fin': 35},\n '202212367': {'att': 50, 'rep': 80, 'mid': 40, 'fin': 30},\n '202212458': {'att': 50, 'rep': 55, 'mid': 15, 'fin': 85},\n '202212396': {'att': 95, 'rep': 30, 'mid': 30, 'fin': 95},\n '202212482': {'att': 50, 'rep': 50, 'mid': 45, 'fin': 10},\n '202212452': {'att': 65, 'rep': 55, 'mid': 15, 'fin': 45},\n '202212387': {'att': 70, 'rep': 70, 'mid': 40, 'fin': 35},\n '202212354': {'att': 90, 'rep': 90, 'mid': 80, 'fin': 90}}\n\n\n\n테이블형태로 보고싶다.\n\n(방법1) – 행렬이기는 하지만 방법 2,3,4,5에 비하여 우리가 원하는 만큼 가독성을 주는 형태는 아님.\n\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n(방법2)\n\npd.DataFrame(test_dic).T\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법3)\n\ntest_dic2 = {'att':{key[i]:att[i] for i in range(20)},\n             'rep':{key[i]:rep[i] for i in range(20)},\n             'mid':{key[i]:mid[i] for i in range(20)},\n             'fin':{key[i]:fin[i] for i in range(20)}}\n\n\npd.DataFrame(test_dic2)\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법4)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin}, index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법5)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      55\n      50\n      40\n    \n    \n      1\n      95\n      100\n      50\n      80\n    \n    \n      2\n      65\n      90\n      60\n      30\n    \n    \n      3\n      55\n      80\n      75\n      80\n    \n    \n      4\n      80\n      30\n      30\n      100\n    \n    \n      5\n      75\n      40\n      100\n      15\n    \n    \n      6\n      65\n      45\n      45\n      90\n    \n    \n      7\n      60\n      60\n      25\n      0\n    \n    \n      8\n      95\n      65\n      20\n      10\n    \n    \n      9\n      90\n      80\n      80\n      20\n    \n    \n      10\n      55\n      75\n      35\n      25\n    \n    \n      11\n      95\n      95\n      45\n      0\n    \n    \n      12\n      95\n      55\n      15\n      35\n    \n    \n      13\n      50\n      80\n      40\n      30\n    \n    \n      14\n      50\n      55\n      15\n      85\n    \n    \n      15\n      95\n      30\n      30\n      95\n    \n    \n      16\n      50\n      50\n      45\n      10\n    \n    \n      17\n      65\n      55\n      15\n      45\n    \n    \n      18\n      70\n      70\n      40\n      35\n    \n    \n      19\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf = df.set_index([key])\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n\n\n- 예제1: 출석점수를 출력\n\ntest_dic2['att']\n\n{'202212380': 65,\n '202212370': 95,\n '202212363': 65,\n '202212488': 55,\n '202212312': 80,\n '202212377': 75,\n '202212463': 65,\n '202212471': 60,\n '202212400': 95,\n '202212469': 90,\n '202212318': 55,\n '202212432': 95,\n '202212443': 95,\n '202212367': 50,\n '202212458': 50,\n '202212396': 95,\n '202212482': 50,\n '202212452': 65,\n '202212387': 70,\n '202212354': 90}\n\n\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 예제2: 학번 202212380의 출석점수 출력\n\ntest_dic2['att']['202212380']\n\n65\n\n\n\ndf['att']['202212380']\n\n65\n\n\n\n\n\n- 예제1: 첫번째 학생의 기말고사 성적을 출력하고 싶다.\n\ntest_ndarray[0,-1]\n\n40\n\n\n\ndf.iloc[0,-1]\n\n40\n\n\n\n벼락치기: df에서 iloc이라는 특수기능을 이용하면 넘파이 인덱싱처럼 원소출력이 가능하다.\n\n- 예제2: 홀수번째 학생의 점수를 뽑고 싶다.\n\ntest_ndarray[::2]\n\narray([[202212380,        65,        55,        50,        40],\n       [202212363,        65,        90,        60,        30],\n       [202212312,        80,        30,        30,       100],\n       [202212463,        65,        45,        45,        90],\n       [202212400,        95,        65,        20,        10],\n       [202212318,        55,        75,        35,        25],\n       [202212443,        95,        55,        15,        35],\n       [202212458,        50,        55,        15,        85],\n       [202212482,        50,        50,        45,        10],\n       [202212387,        70,        70,        40,        35]])\n\n\n\ndf.iloc[::2]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 예제3: 맨 끝에서 3명의 점수를 출력하고 싶다.\n\ntest_ndarray[-3:]\n\narray([[202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ndf.iloc[-3:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제4: 맨 끝에서 3명의 점수 중 마지막 2개의 칼럼만 출력하고 싶다.\n\ntest_ndarray[-3:,-2:]\n\narray([[15, 45],\n       [40, 35],\n       [80, 90]])\n\n\n\ndf.iloc[-3:,-2:]\n\n\n\n\n\n  \n    \n      \n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      15\n      45\n    \n    \n      202212387\n      40\n      35\n    \n    \n      202212354\n      80\n      90\n    \n  \n\n\n\n\n\n\n\n- 예제1: 중간고사 점수가 20점 이상이면서 동시에 출석점수가 60점미만인 학생들의 기말고사 점수를 출력\n\ndf.query('mid >= 20 and att < 60')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n  \n\n\n\n\n\ndf.query('mid >= 20 and att < 60')['fin']\n\n202212488    80\n202212318    25\n202212367    30\n202212482    10\nName: fin, dtype: int64\n\n\n(방법2) 넘파이 스타일이라면?\n\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ntest_ndarray[:,3] >= 20 ## 중간고사가 20점이상\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True,  True, False,\n        True,  True])\n\n\n\ntest_ndarray[:,1] < 60 ## 출석이 60미만 \n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True,  True, False,  True, False,\n       False, False])\n\n\n\n(test_ndarray[:,3] >= 20) & (test_ndarray[:,1] < 60)\n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True, False, False,  True, False,\n       False, False])\n\n\n\nnote: test_ndarray[:,3] >= 20 & test_ndarray[:,1] >= 60와 같이 하면 에러가 난다. 조심하자! 괄호!!!\n\n\ntest_ndarray[(test_ndarray[:,3] >= 20) & (test_ndarray[:,1] < 60),-1]\n\narray([80, 25, 30, 10])\n\n\n\n구현난이도 어려움, 가독성 꽝..\n\n- 예제2: 중간고사점수<기말고사점수인 학생들의 출석점수 평균을 구하자.\n\ndf.query('mid < fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf.query('mid < fin')['att'].mean()\n\n76.66666666666667\n\n\n\n\n\n\n\n- 방법1: dictionary에서 만든다.\n\npd.DataFrame({'att':[30,40,50], 'mid':[50,60,70]}"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class2.html",
    "href": "posts/1_IP2022/2023-02-15-class2.html",
    "title": "class 2단계",
    "section": "",
    "text": "__init__\nself의 의미\n파이썬의 비밀1\n파이썬의 비밀2\n\n\n\n\n\n\n# 이미지 출력을 위한 패키지 불러오기\nfrom PIL import Image\nimport requests\n\n\n\n- STOOOP을 다시 복습\n\nurl1 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true' \n\n\nclass STOOOP:\n    title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~'\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\ns1 = STOOOP() # STOOOP 이라는 클래스에서 s1이라는 인스턴스를 만드는 과정\n\n\ns1.title, s1.url, s1.end\n\n('학교폭력!',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~')\n\n\n\ns1.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~\n\n\n- 왜 s1의 default title이 항상 ‘학교폭력’ 이어야 하는가? \\(\\to\\) __init__ 의 개발\n- 성능4: __init__() 함수를 이용하여 ‘클래스 \\(\\to\\) 인스턴스’ 의 시점에서 수행하는 일련의 동작들을 묶어서 수행할 수 있음.\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n- 잘못된 사용\n\ns1 = STOOOP() # 이 시점에서 __init__ 이 수행된다.\n\nTypeError: __init__() missing 1 required positional argument: 'title'\n\n\n- 올바른 사용\n\ns1 = STOOOP('수강신청매크로') # 이 시점에서 __init__ 이 수행된다!\n\n\ns1.title, s1.url, s1.end\n\n('수강신청매크로',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~~')\n\n\n\ns1.stop()\n\n수강신청매크로\n\n\n\n\n\n멈춰~~~~\n\n\n- 잘못된 사용에서 에러가 발생한 이유는?\nTypeError: __init__() missing 1 required positional argument: 'title'\n\ns1 = STOOOP() 이 실행되는 순간 __init__() 이 내부적으로 실행된다.\n그런데 __init__() 의 첫번째 입력인 self는 입력안해도 무방했음. 그런데 두번째 입력은 title은 입력을 해야했음.\n그런데 title을 입력하지 않아서 발생하는 에러.\n\n- __init__(self, arg1, arg2,...) 함수에 대하여\n\n엄청나게 특별해 보이지만 사실 몇가지 특별한 점을 제외하고는 어떠한 마법도 없는 함수이다.\n특별한 점1: 첫번째 입력으로 반드시 self를 넣어야함. (이건 사실 클래스 내의 메소드 거의 다 그러함)\n특별한 점2: 클래스에서 인스턴스를 만드는 시점에 자동으로 실행된다.\n특별한 점3: __init(self, arg1, arg2,...)의 입력중 self 이외의 입력들은 ‘클래스 \\(\\to\\) 인스턴스’ 시점에서 ’인스턴스이름 = 클래스이름(arg1, arg2,…)’와 같이 사용한다. (이 예제의 경우 STOOOP(title) 와 같이 사용해야함)\n\n- title이 디폴트로 들어가는 상황도 불편했지만, title을 명시적으로 넣지 않으면 에러가 발생하는 것도 불편하다?\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title=None):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\ns2 = STOOOP()\ns3 = STOOOP('KOSPI 하락')\n\n\ns2.stop() # title 없는 경우\n\nNone\n\n\n\n\n\n멈춰~~~~\n\n\n\n제목이 없으면 없는대로 잘 출력이 된다.\n\n\ns3.stop() # title = 'KOSPI 하락'\n\nKOSPI 하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n- 이전 예제를 복습\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n        self.n = self.n+1 \n\n\nk4 = Klass4()\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 2번 보았습니다\n\n\n- 위의 예제는 아래와 같이 구현할 수도 있다.\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 이미지를 {}번 보았습니다.'.format(self.n))\n        # slef.n = self.n + 1\n\n\nk4 = Klass4()\n\n\nk4.n\n\n1\n\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 1번 보았습니다.\n\n\n\nk4.n = k4.n + 1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 2번 보았습니다.\n\n\n\nk4.n = k4.n + 1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 3번 보았습니다.\n\n\n\n결국에는 k4.n = k4.n + 1의 기능을 구현하여 넣은 것이 self.n = self.n + 1 이다.\n따라서 self는 k4에 대응한다. 즉, self는 인스턴스 이름에 대응한다.\n\n우리가 하고 싶은 것은 클래스를 선언하는 시점에서 인스턴스가 생성된 이후 시점에 대한 어떠한 동작들을 정의하고 싶다.\n그런데 클래스가 설계하는 시점에서 인스턴스의 이름이 정해지지 않았으므로 이러한 동작들을 정의하기에 불편하다.\n그래서 클래스를 설계하는 시점에 그 클래스로부터 만들어지는 인스턴스는 그냥 self라는 가칭으로 부른다.\n\n굳이 비유를 하자면 self는 인스턴스의 태명 같은 것이다.\n\n\n요약: self의 의미는 (후에 만들어질 ) 인스턴스의 이름이다. (즉, self는 인스턴스의 태명같은 것!)\n\n\n\n탐구: 인스턴스의 자료형이 무엇인지 탐구해보자.\n- 아래의 두 클래스를 선언해보자.\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title=None):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 이미지를 {}번 보았습니다.'.format(self.n))\n        # self.n = self.n + 1\n\n- 인스턴스를 생성해보자.\n\nk4 = Klass4()\ns1 = STOOOP()\n\n\n\n\nk4?\n\n\nType:        Klass4\nString form: <__main__.Klass4 object at 0x7fb4956082b0>\nDocstring:   <no docstring>\n\n\n\n\ns1?\n\n\nType:        STOOOP\nString form: <__main__.STOOOP object at 0x7fb495608310>\nDocstring:   <no docstring>\n\n\n\n- ??? 타입은 자료형 즉, int, float, list 이런 것 아니었나?\n\na = [1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n- 그런데 지금 k4, s1의 타입은 Klass4, STOOOP이다.\n\n가설1 : 사실 파이썬 내부에 Klass4, STOOOP이라는 자료형이 있었다. 그런데 내가 만든 k4, s1이 우연히 그 자료형을 따르는 것! (이건 너무 억지스럽다.)\n가설2: type이 list인 것은 사실 list라는 클래스에서 생긴 인스턴스이다. \\(\\to\\) 리스트 자료형을 찍어낼 수 있는 어떤 클래스가 파이썬에 내부적으로 존재할 것이다. (이게 맞는 것 같다.)\n\n꺠달음1\n- 가설2가 맞다? 그렇다면 아래는 모두 어딘가에서 찍혀진 인스턴스이다.\n\na = [1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\na = 1,2,3\na\n\n(1, 2, 3)\n\n\n\na = 1\na?\n\n\nType:        int\nString form: 1\nDocstring:  \nint([x]) -> integer\nint(x, base=10) -> integer\nConvert a number or string to an integer, or return 0 if no arguments\nare given.  If x is a number, return x.__int__().  For floating point\nnumbers, this truncates towards zero.\nIf x is not a number or if base is given, then x must be a string,\nbytes, or bytearray instance representing an integer literal in the\ngiven base.  The literal can be preceded by '+' or '-' and be surrounded\nby whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\nBase 0 means to interpret the base from the string as an integer literal.\n>>> int('0b100', base=0)\n4\n\n\n\n\na = '1'\na?\n\n\nType:        str\nString form: 1\nLength:      1\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n- 그리고 위의 a=[1,2,3] 과 같은 것들은 모두 ‘클래스\\(\\to\\) 인스턴스’ 에 해당하는 과정이었다.\n깨달음2\n- 생각해보니까 아래와 같이 list를 선언하는 방식도 있었음\n\na = list()\na\n\n[]\n\n\n\n이거 지금 생각해보니까 list라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법이다?!\n\n- 아래도 가능함\n\na = list((1,2,3))\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n이것도 지금 보니까 list라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법이다. 여기에서 (1,2,3)은 __init__() 의 입력이다.\n\n깨달음3\n- 그러고보니까 각 자료형마다 특수한 기능들이 있었음.\n- a. + tab을 하면 append, clear 등등이 나온다.\n- 이러한 기능은 지금까지 우리가 ‘list자료형 특수기능들’ 이라고 부르면서 사용했었다. 그런데 a가 list 클래스에서 생성된 인스턴스라는 관점에서 보면 이러한 기능들은 list 클래스에서 정의된 메소드라고 볼 수 있다.\n깨달음4 - a.f() 는 f(a) 로 해석 가능하다고 하였다. 이 해석에 따르면 메소드의 첫번째 입력은 메소드가 소속된 인스턴스라고 해석할 수 있다.\n- 동일한 논리로 아래의 코드는 stop() 의 입력에서 s1을 넣는다는 의미이다.\n\ns1.stop()\n\nNone\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n아래의 조건에 맞는 클래스를 생성하라.\n\n['가위', '바위'] 와 같은 리스트를 입력으로 받아 인스턴스를 생성한다.\n위의 리스트에서 하나의 값을 뽑는 메소드 f를 가지고 있다.\n\n# 사용예시\na = Klass(['가위', '바위'])\na.f() # 가위가 1/2 바위가 1/2의 확률로 출력\nb = Klass(['가위', '바위', '보'])\nb.f() # 가위, 바위, 보가 1/3의 확률로 출력"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html",
    "href": "posts/1_IP2022/2023-02-23-class7.html",
    "title": "class 7단계",
    "section": "",
    "text": "함수형 프로그래밍, callable object, 파이썬의 비밀"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제1-숫자입력-함수출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제1-숫자입력-함수출력",
    "title": "class 7단계",
    "section": "(예제1) 숫자입력, 함수출력",
    "text": "(예제1) 숫자입력, 함수출력\n\ndef f(a):\n    def _f(x):\n        return (x-a)**2\n    return _f\n\n\ng = f(10) # g(x) = (x-10)**2\n\n\ng(2) # (2-10)**2 = 64\n\n64\n\n\n\n해석: \\(f(a)\\)는 \\(a\\)를 입력으로 받고 \\(g(x)=(x-a)^2\\)를 함수를 리턴해주는 함수"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제1의-다른-표현-익명함수-lambda",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제1의-다른-표현-익명함수-lambda",
    "title": "class 7단계",
    "section": "(예제1)의 다른 표현: 익명함수 lambda",
    "text": "(예제1)의 다른 표현: 익명함수 lambda\n\n표현1\n\ndef f(a):\n    _f = lambda x: (x-a)**2 ### lambda x: (x-a)**2 가 실행되는 순간 함수오브젝트가 만들어지고 그것이 _f 로 저장됨 \n    return _f\n\n\ng = f(10) # g(x) = (x-10)**2\n\n\ng(3)\n\n49\n\n\n\n\n표현2\n\ndef f(a):\n    return lambda x: (x-a)**2\n\n\ng = f(10)\n\n\ng(3)\n\n49\n\n\n\nlambda x: (x-a)**2는 \\(\\text{lambda}(x) = (x-a)^2\\)의 느낌으로 기억하면 외우기 쉽다.\nlambda x: (x-a)**2는 “아직 이름이 없는 함수 오브젝트를 (가칭 lambda라고 하자) 만들고 기능은 x를 입력으로 하고 (x-2)**2를 출력하도록 하자” 라는 뜻으로 해석하면 된다."
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제2-함수입력-숫자출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제2-함수입력-숫자출력",
    "title": "class 7단계",
    "section": "(예제2) 함수입력, 숫자출력",
    "text": "(예제2) 함수입력, 숫자출력\n\ndef f(x):\n    return x**2\n\n\ndef d(f,x): # 함수를 입력을 받는 함수를 정의\n    h=0.000000000001\n    return (f(x+h)-f(x))/h \n\n\\[f'(x)\\approx \\frac{f(x+h)-f(x)}{h}\\]\n\n\\(h\\)의 값이 점점 0에 가까울수록 등호에 가까워짐.\n\n\nd(f,4) # f'(4) = 2*4 = 8\n\n8.000711204658728"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제3-함수입력-함수출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제3-함수입력-함수출력",
    "title": "class 7단계",
    "section": "(예제3) 함수입력, 함수출력",
    "text": "(예제3) 함수입력, 함수출력\n\ndef f(x): \n    return x**2 \n\n\ndef derivate(f): \n    def df(x): \n        h=0.000000000001\n        return (f(x+h)-f(x))/h \n    return df\n\n\nff = derivate(f)\n\n\nff(7) # f의 도함수\n\n14.004797321831575\n\n\n원래함수 시각화\n\nx = np.linspace(-1,1,100)\nplt.plot(x,f(x))\n\n\n\n\n도함수 시각화\n\nx = np.linspace(-1,1,100)\nplt.plot(x, ff(x))"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제3의-다른-표현",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제3의-다른-표현",
    "title": "class 7단계",
    "section": "(예제3)의 다른 표현",
    "text": "(예제3)의 다른 표현\n\ndef f(x): \n    return x**2\n\n\ndef derivate(f): \n    h=0.000000000001\n    return lambda x: (f(x+h)-f(x))/h \n\n\nff = derivate(f)\n\n\nff(10)\n\n20.00888343900442"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제4-함수들의-리스트",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제4-함수들의-리스트",
    "title": "class 7단계",
    "section": "(예제4) 함수들의 리스트",
    "text": "(예제4) 함수들의 리스트\n[오브젝트, 오브젝트, 오브젝트]\n\nflst = [lambda x: x, lambda x: x**2, lambda x: x**3]  # [함수오브젝트,함수오브젝트,함수오브젝트]\nflst # 이것의 타입은 function\n\n[<function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>]\n\n\n\nfor f in flst:\n    print(f(2))\n\n2\n4\n8\n\n\n\n첫번째 함수에 적용될 때는 2출력, 2번째 함수에 적용될 때는 4출력, 3번째 함수에 적용될 때는 8출력\n\n\nfor f in flst:\n    plt.plot(x,f(x),'--')\n\n\n\n\n위의 코드는 아래와 같음.\n\nplt.plot(x, (lambda x: x)(x),'--')\nplt.plot(x, (lambda x: x**2)(x),'--')\nplt.plot(x, (lambda x: x**3)(x),'--')"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas2.html",
    "href": "posts/1_IP2022/2023-03-14-pandas2.html",
    "title": "Pandas 2단계",
    "section": "",
    "text": "하나 혹은 여러개의 col\\(\\cdot\\)row 선택하는 법\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\n- 데이터\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\n\n\ndf=pd.DataFrame({'att':att,'rep':rep,'mid':mid,'fin':fin},index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n\n- 방법1\n\ndf.att\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법2: dict 스타일\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n\ntype(df['att'])\n\npandas.core.series.Series\n\n\n- 방법3: dict 스타일\n\ndf[['att']]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ntype(df[['att']])\n\npandas.core.frame.DataFrame\n\n\n\ndf.att나 df['att']는 series를 리턴하고 df[['att']]는 dataframe을 리턴한다.\n\n- 방법4: ndarray스타일\n\ndf.iloc[:,0] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n\ntype(df.iloc[:,0] )\n\npandas.core.series.Series\n\n\n- 방법5: ndarray 스타일\n\ndf.iloc[:,[0]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ntype(df.iloc[:,[0]])\n\npandas.core.frame.DataFrame\n\n\n\ndf.iloc[:,0]은 series를 리턴하고 df.iloc[:,[0]]은 dataframe을 리턴한다.\n\n- 방법6: ndarray 스타일과 dict스타일의 혼합\n\ndf.loc[:,'att'] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법7: ndarray 스타일과 dict스타일의 혼합\n\ndf.loc[:,['att']] \n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ndf.loc[:,'att']은 series를 리턴하고 df.loc[:,['att']] 은 dataframe을 리턴한다.\n\n- 방법7: ndarray 스타일 + bool 인덱싱\n\ndf.iloc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n- 방법8: ndarray와 dict의 혼합형 + bool 인덱싱\n\ndf.loc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\n\n\n- 방법1: dict 스타일\n\ndf[['att','fin']]\n\n\n\n\n\n  \n    \n      \n      att\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      40\n    \n    \n      202212370\n      95\n      80\n    \n    \n      202212363\n      65\n      30\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      100\n    \n    \n      202212377\n      75\n      15\n    \n    \n      202212463\n      65\n      90\n    \n    \n      202212471\n      60\n      0\n    \n    \n      202212400\n      95\n      10\n    \n    \n      202212469\n      90\n      20\n    \n    \n      202212318\n      55\n      25\n    \n    \n      202212432\n      95\n      0\n    \n    \n      202212443\n      95\n      35\n    \n    \n      202212367\n      50\n      30\n    \n    \n      202212458\n      50\n      85\n    \n    \n      202212396\n      95\n      95\n    \n    \n      202212482\n      50\n      10\n    \n    \n      202212452\n      65\n      45\n    \n    \n      202212387\n      70\n      35\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n- 방법2: ndarray 스타일 (정수리스트로 인덱싱, 슬라이싱, 스트라이딩)\n\ndf.iloc[:,[0,1]] # 정수의 리스트를 전달하여 컬럼추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,range(2)] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,:2]  # 슬라이싱 , 0,1,2에서 마지막 2는 제외되고 0,1에 해당하는 것만 추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,::2]  # 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n- 방법3: ndarray와 dict의 혼합형\n\ndf.loc[:,['att','mid']] \n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,'att':'mid']  # 마지막의 mid도 포함된다. \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n    \n    \n      202212370\n      95\n      100\n      50\n    \n    \n      202212363\n      65\n      90\n      60\n    \n    \n      202212488\n      55\n      80\n      75\n    \n    \n      202212312\n      80\n      30\n      30\n    \n    \n      202212377\n      75\n      40\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n    \n    \n      202212471\n      60\n      60\n      25\n    \n    \n      202212400\n      95\n      65\n      20\n    \n    \n      202212469\n      90\n      80\n      80\n    \n    \n      202212318\n      55\n      75\n      35\n    \n    \n      202212432\n      95\n      95\n      45\n    \n    \n      202212443\n      95\n      55\n      15\n    \n    \n      202212367\n      50\n      80\n      40\n    \n    \n      202212458\n      50\n      55\n      15\n    \n    \n      202212396\n      95\n      30\n      30\n    \n    \n      202212482\n      50\n      50\n      45\n    \n    \n      202212452\n      65\n      55\n      15\n    \n    \n      202212387\n      70\n      70\n      40\n    \n    \n      202212354\n      90\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,'rep':] \n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212370\n      100\n      50\n      80\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212312\n      30\n      30\n      100\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212400\n      65\n      20\n      10\n    \n    \n      202212469\n      80\n      80\n      20\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      45\n      0\n    \n    \n      202212443\n      55\n      15\n      35\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212396\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 방법4: bool을 이용한 인덱싱\n\ndf.iloc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\n\n\n- 방법1\n\ndf.iloc[0]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.iloc[0])\n\npandas.core.series.Series\n\n\n- 방법2\n\ndf.iloc[[0]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.iloc[[0]])\n\npandas.core.frame.DataFrame\n\n\n- 방법3\n\ndf.iloc[0,:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.iloc[0,:])\n\npandas.core.series.Series\n\n\n- 방법4\n\ndf.iloc[[0],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.iloc[[0],:])\n\npandas.core.frame.DataFrame\n\n\n- 방법5\n\ndf.loc['202212380']\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.loc['202212380'])\n\npandas.core.series.Series\n\n\n- 방법6\n\ndf.loc[['202212380']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.loc[['202212380']])\n\npandas.core.frame.DataFrame\n\n\n- 방법7\n\ndf.loc['202212380',:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.loc['202212380',:])\n\npandas.core.series.Series\n\n\n- 방법8\n\ndf.loc[['202212380'],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.loc[['202212380'],:])\n\npandas.core.frame.DataFrame\n\n\n- 방법9\n\nlen(df)\n\n20\n\n\n\n_lst = [True]+[False]*19\n\n\ndf.iloc[_lst] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.iloc[_lst,:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst,:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\n\n\n- 방법1\n\ndf.iloc[[0,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.iloc[[0,2],:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 방법2\n\ndf.loc[['202212380','202212363']] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.loc[['202212380','202212363'],:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 그 밖의 방법들\n\ndf.iloc[::3] # 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.iloc[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.loc[:'202212312']\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.loc[list(df.att<80),'rep':]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.loc[df.att<80,'rep':]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.iloc[list(df.att<80),1:]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 아래는 에러가 난다 주의!\n\ndf.iloc[df.att<80, 1:]\n\nValueError: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class4.html",
    "href": "posts/1_IP2022/2023-02-15-class4.html",
    "title": "class 4단계",
    "section": "",
    "text": "프린트 가로채기 __str__, __repr__ (파이썬의 비밀2,3)\n\n\n\n\n\nmotivating example\n__str__, 파이썬의 비밀2\n__repr__, 파이썬의 비밀3\n주피터 노트북의 비밀 (_repr_html_), __repr__와 __str__의 우선적용 순위\n\n\n\n\n\n\nimport numpy as np\n\n\n\n\n\n\n\n\n\n# class1 hw's review\nclass RPC:\n    def throw(self):\n        print(np.random.choice(['가위','바위','보']))\n\n\na = RPC()\n\n\na.throw()\n\n가위\n\n\n\n\n\n[가위, 바위, 보] 말고 [가위, 보] 혹은 [바위, 보] 처럼 정해진 케이스가 아닌 입력으로 받고 싶을 수도 있다.\n\nclass RPC:\n    def throw(self, candidate):\n        print(np.random.choice(candidate))\n\n\na = RPC()\n\n\n# throw(a, ['가위','바위','보'])\na.throw(['가위','바위','보'])\n\n보\n\n\n\na.throw(['가위', '보']) # 보, 가위만.\n\n가위\n\n\n\n\n\n\nclass RPC:\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def throw(self):\n        print(np.random.choice(self.candidate))\n\n\na = RPC() # __init__ 는 암묵적으로 실행\n\n\na.throw()\n\n보\n\n\n\n\n\n위의 코드 3줄과 동일한 코드이며, 풀어써보면 다음과 같다.\n\nclass RPC2:\n    pass\n\n\nb = RPC2() # 아무것도 없음..\n\n\ndef initt(b, candidate = ['가위','바위','보']):\n    b.candidate = candidate\n\n\ninitt(b)\n\n\n# 던져서 화면에 보여주는 과정까지 추가\ndef throw(b):\n    print(np.random.choice(b.candidate))\n\n\nthrow(b)\n\n보\n\n\n\n\n\n풀어쓴 코드를 조합해보면?\n\nclass RPC2:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n    def throw(self):\n        print(np.random.choice(self.candidate))\n\n\nb = RPC2()\n\n\nb.candidate\n\n['가위', '바위', '보']\n\n\n\nb.throw()\n\n가위\n\n\n\n\n\n생각해보니까 throw는 choose + show의 결합인 것 같다.\n\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def choose(self):\n        self.actions = np.random.choice(self.candidate)\n    def show(self):\n        print(self.actions)\n\n\na = RPC()  ## 시점2\n\n\na.actions ## 시점3 (지금은 정의되지 않음, choose를 해야함)\n\nAttributeError: 'RPC' object has no attribute 'actions'\n\n\n\na.choose() # 뭔가 선택했겠지?    ## 시점4\n\n\na.actions # 바위를 선택했구만     ## 시점5 \n\n'바위'\n\n\n\na.show()   ## 시점6\n\n바위\n\n\n\n\n\n위와 같은 코드입니다.\n\nclass _RPC:  ## 시점1 \n    pass  # <-- 이렇게하면 아무 기능이 없는 비어있는 클래스가 정의된다.\n\n\n_a  = _RPC()  ## 시점2\n\ndef _init(_a, candidate = ['가위','바위','보']):\n    _a.candidate = candidate\n    \n_init(_a)\n\n\n_a.actions ## 시점3\n\nAttributeError: '_RPC' object has no attribute 'actions'\n\n\n\n# choose 선언      ## 시점4\ndef _choose(_a):\n    _a.actions = np.random.choice(_a.candidate)\n_choose(_a)\n\n\n_a.actions  ## 시점5\n\n'바위'\n\n\n\n# show 선언    ## 시점6\ndef _show(_a):\n    print(_a.actions)\n_show(_a)\n\n바위\n\n\n\n\n\n\n또 다른 인스턴스 b를 만들자. b는 가위만 낼 수 있다.\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def choose(self):\n        self.actions = np.random.choice(self.candidate)\n    def show(self):\n        print(self.actions)\n        \n\nb = RPC()\n\n\nb.candidate\n\n['가위', '바위', '보']\n\n\n\n아무것도 없으면 b의 candidate이 가위, 가위, 보로 들어감\n\n\nb = RPC(['가위']) # 가위만 포함된 리스트 전달\n\n\nb.candidate\n\n['가위']\n\n\n\nb.choose()\nb.show()\n\n가위\n\n\n- a, b의 선택들을 모아서 기록하고 싶다.\n\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n        self.actions = list() ## 추가\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate)) ## 추가\n    def show(self):\n        print(self.actions)\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nnp.random.seed(123)\nfor i in range(5):\n    a.choose()\n    a.show()\n\n['보']\n['보', '바위']\n['보', '바위', '보']\n['보', '바위', '보', '보']\n['보', '바위', '보', '보', '가위']\n\n\n\nshow() 지난 히스토리까지 다 나오니까 보기 좀 불편하댜\n\n\nnp.random.seed(123)\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n        self.actions = list() ## 추가\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate)) ## 추가\n    def show(self):\n        print(self.actions[-1]) ### 추추가\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n바위\n보\n보\n가위\n\n\n\na.actions\n\n['보', '바위', '보', '보', '가위']\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\nb.actions\n\n['가위', '가위', '가위', '가위', '가위']\n\n\n\na.candidate, a.actions # (낼 수 있는 패, 내가 낸 패)\n\n(['가위', '바위', '보'], ['보', '바위', '보', '보', '가위'])\n\n\n\nb.candidate, b.actions # (낼 수 있는 패, 내가 낸 패)\n\n(['가위'], ['가위', '가위', '가위', '가위', '가위'])\n\n\n- info라는 함수를 만들어서 a의 오브젝트가 가지고 있는 정보를 모두 보도록 하자.\n(예비학습) 문자열 \\n 이 포함된다면?\n\n'클래스\\n어렵네..'\n\n'클래스\\n어렵네..'\n\n\n\nprint('클래스\\n어렵네..')\n\n클래스\n어렵네..\n\n\n예비학습 끝\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])      \n    def info(self):\n        print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n바위\n가위\n보\n가위\n바위\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\na.info()\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위', '가위', '보', '가위', '바위']\n\n\n\nb.info()\n\n낼 수 있는 패: ['가위']\n기록: ['가위', '가위', '가위', '가위', '가위']\n\n\n- 만들고보니까 info와 print의 기능이 거의 비슷함 \\(\\to\\) print(a)를 하면 a.info()와 동일한 효과를 내도록 만들 수 있을까?\n- 말도 안되는 소리같다. 왜? - 안될것 같은 이유1: print는 파이썬 내장기능, 내장기능을 우리가 맘대로 커스터마이징해서 쓰기는 어려울 것 같다. - 안될 것 같은 이유2: 이유1이 해결된다 해도 문제다. 그럼 지금까지 우리가 사용했던 수 많은 print()의 결과는 어떻게 되는가?\n결론은 가능하다\n- 그런데 a의 자료형(RPC 자료형)에 해당하는 오브젝트에 한정하여 print를 수정하는 방법이 가능하다면? (그럼 다른 오브젝트들은 수정된 print에 영향을 받지 않음)\n\n\n\n\n- 관찰1: 현재 print(a)의 결과는 아래와 같다.\n\nprint(a)\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n\na는 RPC클래스에서 만든 오브젝트이며 a가 저장된 메모리 주소는 0x7faaa7500850라는 의미\n\n- 관찰2: a에는 __str__ 이 있다.\n\ndir(a)\n\n['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n 'actions',\n 'candidate',\n 'choose',\n 'info',\n 'show']\n\n\n\nset(dir(a)) & {'__str__'}\n\n{'__str__'}\n\n\n이것을 함수처럼 사용하니까 아래와 같다.\n\na.__str__\n\n<method-wrapper '__str__' of RPC object at 0x7faaa7500850>\n\n\n\na.__str__() # 클래스 안에 있는 메소드, 문자열 리턴\n\n'<__main__.RPC object at 0x7faaa7500850>'\n\n\n\nprint(a.__str__()) # 이거 print(a)를 실행한 결과와 같다?\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n\nprint(a)\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n- 생각: 만약에 내가 a.__str__() 라는 함수를 재정의 하여 리턴값을 ’너는 해킹당했다’로 바꾸게 되면 print(a)해서 나오는 결과는 어떻게 될까? (약간 해커같죠)\n(예비학습) 함수 덮어씌우기\n\ndef f():\n    print('asdf')\n\n\nf()\n\nasdf\n\n\n\ndef f():\n    print('guebin hahaha')\n\n\nf()\n\nguebin hahaha\n\n\n이런식으로 함수가 이미 정의되어 있더라도, 내가 나중에 덮어씌우면 그 함수의 기능을 다시 정의한다.\n(해킹시작)\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return '너는 해킹당했다'\n    def info(self):\n        print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\nprint(a)\n\n너는 해킹당했다\n\n\n- __str__ 의 리턴값을 info에서 타이핑했던 문자열로 재정의한다면?\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    # def info(self):\n    #     print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n    def __str__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.choose()\na.show()\n\n바위\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위']\n\n\n\na.choose()\na.show()\n\n가위\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위', '가위']\n\n\n\n\n- print(a) 와 print(a.__str__()) 는 같은 문법이다.\n- 참고로 a.__str__() 와 str(a) 도 같은 방법이다.\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['바위', '가위']\"\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['바위', '가위']\"\n\n\n- 지금까지 우리가 썼던 기능을 확인!\n(예제1)\n\na = [1,2,3]\n\n\nprint(a)\n\n[1, 2, 3]\n\n\n\na.__str__()\n\n'[1, 2, 3]'\n\n\n\nstr(a)\n\n'[1, 2, 3]'\n\n\n(예제2)\n\na = {1,2,3}\nprint(a)\n\n{1, 2, 3}\n\n\n\nstr(a)\n\n'{1, 2, 3}'\n\n\n\na.__str__()\n\n'{1, 2, 3}'\n\n\n(예제3)\n\na = np.array(1)\na.shape\n\n()\n\n\n\ntype(a.shape)\n\ntuple\n\n\n\nprint(a.shape)\n\n()\n\n\n\na.shape.__str__()\n\n'()'\n\n\n\nstr(a.shape)\n\n'()'\n\n\n(예제4)\n\na = range(10)\nprint(a)\n\nrange(0, 10)\n\n\n\na.__str__()\n\n'range(0, 10)'\n\n\n(예제5)\n\na = np.arange(100).reshape(10,10)\nprint(a)\n\n[[ 0  1  2  3  4  5  6  7  8  9]\n [10 11 12 13 14 15 16 17 18 19]\n [20 21 22 23 24 25 26 27 28 29]\n [30 31 32 33 34 35 36 37 38 39]\n [40 41 42 43 44 45 46 47 48 49]\n [50 51 52 53 54 55 56 57 58 59]\n [60 61 62 63 64 65 66 67 68 69]\n [70 71 72 73 74 75 76 77 78 79]\n [80 81 82 83 84 85 86 87 88 89]\n [90 91 92 93 94 95 96 97 98 99]]\n\n\n\na.__str__()\n\n'[[ 0  1  2  3  4  5  6  7  8  9]\\n [10 11 12 13 14 15 16 17 18 19]\\n [20 21 22 23 24 25 26 27 28 29]\\n [30 31 32 33 34 35 36 37 38 39]\\n [40 41 42 43 44 45 46 47 48 49]\\n [50 51 52 53 54 55 56 57 58 59]\\n [60 61 62 63 64 65 66 67 68 69]\\n [70 71 72 73 74 75 76 77 78 79]\\n [80 81 82 83 84 85 86 87 88 89]\\n [90 91 92 93 94 95 96 97 98 99]]'\n\n\n\n\n\n\n- 생각해보니까 print를 써서 우리가 원하는 정보를 확인하는건 아니였음\n\na = [1,2,3]\n\n\na\n\n[1, 2, 3]\n\n\n\nprint(a) # print(a.__str__()) + enter ==> a + enter\n\n[1, 2, 3]\n\n\n-`` a + 엔터를 하면 print(a) + 엔터를 하는 것과 같은 효과인가?\n(반례)\n\na = np.array([1,2,3,4]).reshape(2,2)\n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nprint(a)\n\n[[1 2]\n [3 4]]\n\n\n- a + 엔터 는 print(a) + 엔터 가 다른 경우도 있다. \\(\\to\\) 추측: 서로 다른 숨겨진 기능이 있다! \\(\\to\\) 결론: 그 기능은 __repr__ 에 저장되어 있음.\n\n__repr__ 추가 전\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\na\n\n<__main__.RPC at 0x7faaa6d821c0>\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\n__repr__ 추가 후\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\na # print(a.__repr__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- 그럼 우리가 지금까지 했던 것?\n\na = np.array([1,2,3])\n\n\na\n\narray([1, 2, 3])\n\n\n\nprint(a)\n\n[1 2 3]\n\n\n\na.__repr__()\n\n'array([1, 2, 3])'\n\n\n\na.__str__()\n\n'[1 2 3]'\n\n\n\n\n- 대화형콘솔에서 오브젝트이름 + 엔터를 쳐서 나오는 출력은 __repr__의 결과와 연관이 있다.\n\na = np.array(range(10000)).reshape(100,100)\na\n\narray([[   0,    1,    2, ...,   97,   98,   99],\n       [ 100,  101,  102, ...,  197,  198,  199],\n       [ 200,  201,  202, ...,  297,  298,  299],\n       ...,\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])\n\n\n\na.__repr__()\n\n'array([[   0,    1,    2, ...,   97,   98,   99],\\n       [ 100,  101,  102, ...,  197,  198,  199],\\n       [ 200,  201,  202, ...,  297,  298,  299],\\n       ...,\\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])'\n\n\n- 참고로 a.__repr__()은 repr(a)와 같다.\n\nrepr(a)\n\n'array([[   0,    1,    2, ...,   97,   98,   99],\\n       [ 100,  101,  102, ...,  197,  198,  199],\\n       [ 200,  201,  202, ...,  297,  298,  299],\\n       ...,\\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])'\n\n\n\n\n\n- 요즘에는 IDE 발전에 따라서 오브젝트 + 엔터 칠 때 나오는 출력의 형태도 다양해지고 있음.\n\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,2,3],\n                   'b':[2,3,4]})\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n예쁘게 나온다.\n\n- 위의 결과는 print(df.__repr__())의 결과와 조금 다르게 나온다?\n\nprint(df.__repr__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n- print(df.__repr__())는 예전 검은화면에서 코딩할 때 나오는 출력임\nPython 3.10.2 | packaged by conda-forge | (main, Feb  1 2022, 19:28:35) [GCC 9.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n> >> import pandas as pd \n>>> df = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})>>> df\n   a  b\n0  1  2\n1  2  3\n2  3  4\n>>>\n- 주피터에서는 ‘오브젝트이름 + 엔터’ 치면 HTML(df.__repr_html())이 실행되고 repr_html_()이 정의되어 있지 않으면 print(df.__rept__())이 실행된다.\n\ndf._repr_html_()\n\n'<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>a</th>\\n      <th>b</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>1</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>2</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>3</td>\\n      <td>4</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>'\n\n\n\nhtml 코드!\n\n\nfrom IPython.core.display import HTML\n\n\nHTML(df._repr_html_())\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n- 물론 df._repr_html_()함수가 내부적으로 있어도 html이 지원되지 않는 환경이라면 print(df.__repr__())이 내부적으로 수행된다.\n\n\n\n\n(예제1)\n- 아래의 예제를 관찰하자.\n\nclass RPS:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPS()\na\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__repr__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nrepr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n- 여기까지는 상식수준의 결과임. 이제 아래를 관찰하라.\n\nprint(a) # print(a.__repr__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\n__str__()은 건드린적이 없는데?\n\n\na.__repr__??\n\n\nSignature: a.__repr__()\nDocstring: Return repr(self).\nSource:   \n    def __repr__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\nFile:      ~/Dropbox/Quarto-Blog/posts/Python/<ipython-input-296-bcd76efb6380>\nType:      method\n\n\n\n\na.__str__??\n\n\nSignature:      a.__str__()\nCall signature: a.__str__(*args, **kwargs)\nType:           method-wrapper\nString form:    <method-wrapper '__str__' of RPS object at 0x7faaa47aae20>\nDocstring:      Return str(self).\n\n\n\n\n__str__()은 건드린 적이 없는데 \\(\\to\\) 건드린적은 없는데 기능이 바뀌어있음.\n\n(예제2)\n- 아래의 예제를 관찰하자.\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\na.__repr__()\n\n'<__main__.RPC object at 0x7f8f38ca22e0>'\n\n\n\na.__str__??\n\n\nSignature: a.__str__()\nDocstring: Return str(self).\nSource:   \n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\nFile:      ~/Dropbox/Quarto-Blog/posts/Python/<ipython-input-3-2e46ee18321f>\nType:      method\n\n\n\n\na.__repr__??\n\n\nSignature:      a.__repr__()\nCall signature: a.__repr__(*args, **kwargs)\nType:           method-wrapper\nString form:    <method-wrapper '__repr__' of RPC object at 0x7f8f38ca22e0>\nDocstring:      Return repr(self).\n\n\n\n2번째 예제에서는 건드린 애만 바뀌었는데 첫번째 예제에서는 건드리지 않은 애들까지 기능이 바뀌었다.\n(예제3)\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return '너는 해킹당했다. 하하하'\n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\na\n\n너는 해킹당했다. 하하하\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- __str__ 와 __repr__을 건드리지 않고 출력결과를 바꾸고 싶다면?\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\nstr(a)\n\n'<__main__.RPC object at 0x7f8f38bb7730>'\n\n\n\nrepr(a)\n\n'<__main__.RPC object at 0x7f8f38bb7730>'\n\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: []\n        \n\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n바위\n가위\n바위\n보\n\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['보', '바위', '가위', '바위', '보']\n        \n\n\n\n\n\n아래의 클래스를 수정하여\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions)\n클래스에서 생성된 인스턴스의 출력결과가 아래와 같도록 하라.\n학번: 202143052 \n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['가위', '가위', '보', '보', '바위']\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        학번: {} <br/>\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(202143052,self.candidate,self.actions)\n\n\na = RPS()\n\n\na\n\n\n        학번: 202143052 \n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: []\n        \n\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n가위\n바위\n바위\n가위\n\n\n\na\n\n\n        학번: 202143052 \n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: ['보', '가위', '바위', '바위', '가위']"
  },
  {
    "objectID": "posts/1_IP2022/2022-06-13-final.html",
    "href": "posts/1_IP2022/2022-06-13-final.html",
    "title": "2022 final exam",
    "section": "",
    "text": "ref: 기말고사 풀이 링크\n\n\n\n아래코드를 이용하여 numpy, matplotlib, pandas를 import하라.\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nfrom IPython.display import HTML\n\n\n\n\n(1) 도함수를 구하는 함수 derivate를 선언하라. 이 함수를 이용하여 \\(f(x)=x^2\\)의 그래프와 \\(f'(x)=2x\\)의 그래프를 \\(x \\in (-1,1)\\)의 범위에서 그려라.\n\ndef f(x):\n    return x**2\n\n\ndef derivate(f): \n    def df(x): \n        h=0.00000000000001\n        return (f(x+h)-f(x))/h \n    return df\n\n\nx = np.linspace(-1,1,100)\nplt.plot(x, f(x))  ## f(x)=x**2\nplt.plot(x, derivate(f)(x)) ## f'(x)=2*x\n\n\n\n\n(2) 적당한 클래스 정의하여 인스턴스 a를 만들고 print(a)의 출력결과가 본인의 학번이 나오도록 하라.\n## 코드예시\nclass Klass:\n    ???\n    ???\na=Klass()\nprint(a)\n## 출력결과\n2022-43052\n\nclass Klass:\n    def __str__(self):\n        return('12345678')\n\n\na = Klass()\n\n\nprint(a)\n\n12345678\n\n\n(3) for문이 실행될때마다 [묵,찌,빠] 중에 하나를 내며 빠를 누적 3회 낼경우 for문이 멈추는 이터레이터를 생성하라.\n(나의풀이)\n\nclass Klass: # 빠를 누적 3회 낼 경우 for문이 멈추는 이터레이터를 만들자.\n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n        self.n = 0\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        if action == '빠':\n            self.n += 1\n            print(action,self.n)\n            if self.n == 3:\n                print('빠가 누적3회 나와서 for문을 멈춥니다.')\n                raise StopIteration\n            else:\n                return action\n        else:\n            return action\n\n\na = Klass()\n\n\nfor i in a:\n    print(i)\n\n찌\n찌\n묵\n찌\n찌\n묵\n빠 1\n빠\n찌\n빠 2\n빠\n빠 3\n빠가 누적3회 나와서 for문을 멈춥니다.\n\n\n(모범답안)\n\nclass Klass: \n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n        self.dic = {'묵':0,'찌':0,'빠':0}\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        self.dic[action] += 1\n        if self.dic['빠'] == 3:\n            print('빠가 3번 누적되어 for문을 멈춥니다.')\n            raise StopIteration\n        else:\n            return action\n\n\na = Klass()\nfor i in a:\n    print(i)\n\n묵\n빠\n찌\n찌\n빠\n빠가 3번 누적되어 for문을 멈춥니다.\n\n\n(4)-(6)\nclass GS25: \n    n=0 \n    total_number_of_guests = 0 \n    def __init__(self):\n        self.number_of_guests = 0 \n(4) 위의 클래스를 수정하여 아래와 같이 GS25에서 새로운 인스턴스가 생성될때마다\nGS25의 점포수가 ?개로 늘었습니다.\n라는 메시지가 출력되도록 하라.\n(5) 함수 come를 인스턴스 메소드로 정의하라. 이 메소드가 실행될때마다 각 점포의 손님 인스턴스 변수 number_of_guests와 클래스변수 total_number_of_guests를 1씩 증가시키고 아래의 메시지를 출력하라.\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 n명입니다. \n현재 GS25 점포를 방문한 손님수는 m명입니다. \n(6) 새로운 클래스메서드 show를 만들고 아래와 같은 메시지를 출력하도록 하라.\nGS25의 점포수: ??\nGS25를 방문한 총 손님수: ??\n(사용예시) (4)-(6)을 모두 적용한 경우 사용예시는 아래와 같다.\n\nclass GS25:\n    n = 0\n    total_numer_of_guests = 0\n    def __init__(self):\n        self.number_of_guests = 0\n        GS25.n += 1\n        print('GS25의 점포수가 {}개로 늘었습니다.'.format(GS25.n))\n    def come(self):\n        GS25.total_number_of_guests += 1\n        self.number_of_guests += 1\n        print('새로운 손님이 오셨습니다.')\n        print('GS25를 방문한 총 손님 수는 {}명입니다.'.format(GS25.total_number_of_guests))\n        print('현재 GS25 점포를 방문한 손님수는 {}명입니다.'.format(self.number_of_guests))\n    @classmethod\n    def show(cls):\n        print('GS25의 점포수:{}'.format(cls.n))\n        print('GS를 방문한 총 손님 수: {}'.format(cls.total_number_of_guests))\n\n\na = GS25()\n\nGS25의 점포수가 5개로 늘었습니다.\n\n\n\na=GS25() ## (4)의 사용예시\n\nGS25의 점포수가 1개로 늘었습니다.\n\n\n\nb=GS25() ## (4)의 사용예시\n\nGS25의 점포수가 2개로 늘었습니다.\n\n\n\na.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 1명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다. \n\n\n\na.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 2명입니다.\n현재 GS25 점포를 방문한 손님수는 2명입니다. \n\n\n\nb.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 3명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다. \n\n\n\nGS25.show() ## (6)의 사용예시\n\nGS25의 점포수: 2\nGS25를 방문한 총 손님수: 3\n\n\n(풀이시작)\n\nclass GS25: \n    n=0 \n    total_number_of_guests = 0 \n    def __init__(self):\n        self.number_of_guests = 0\n        GS25.n += 1\n        print('GS25의 점포수가 {}개로 늘었습니다.'.format(GS25.n))\n    def come(self):\n        self.number_of_guests += 1\n        GS25.total_number_of_guests += 1\n        print('새로운 손님이 오셨습니다!')\n        print('GS25를 방문한 총 손님수는 {}명입니다.'.format(GS25.total_number_of_guests))\n        print('현재 GS25 점포를 방문한 손님수는 {}명입니다.'.format(self.number_of_guests))\n    @classmethod\n    def show(cls):\n        print('GS25의 점포수: {}'.format(cls.n))\n        print('GS25를 방문한 총 손님수: {}'.format(cls.total_number_of_guests))\n\n\na = GS25()\n\nGS25의 점포수가 1개로 늘었습니다.\n\n\n\nb = GS25()\n\nGS25의 점포수가 2개로 늘었습니다.\n\n\n\na.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 1명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다.\n\n\n\na.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 2명입니다.\n현재 GS25 점포를 방문한 손님수는 2명입니다.\n\n\n\nb.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 3명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다.\n\n\n\nGS25.show()\n\nGS25의 점포수: 2\nGS25를 방문한 총 손님수: 3\n\n\n(7) __eq__는 연산 == 를 재정의하는 메소드이다. 클래스 RPS_BASE를 상속하여 새로운 클래스 RPS5를 만들라. 연산 ==를 재정의하여 RPS5의 두 인스턴스의 action이 같은 경우 true를 리턴하는 기능을 구현하라.\n\nclass RPS_BASE:\n    def __init__(self):\n        self.action = np.random.choice(['가위','바위','보'])\n\nhint: Appendix를 참고할 것\nhint: RPS5의 선언부분은 아래와 같은 형태를 가지고 있다.\nclass RPS5(???):\n    def __eq__(self,other):\n        return ??????\nhint: RPS5클래스의 사용예시는 아래와 같다.\n\na=RPS5()\na.action\n\n'바위'\n\n\n\nb=RPS5()\nb.action\n\n'보'\n\n\n\na==b\n\nFalse\n\n\n(풀이시작)\n(8) __gt__는 연산 > 를 재정의하는 메소드이다. 클래스 RPS_BASE를 상속하여 새로운 클래스 RPS6를 만들라. 연산 >를 재정의하여 RPS6의 두 인스턴스 a,b의 action이 각각 (‘가위’,‘보’), (‘바위’,‘가위’), (‘보’,‘바위’) 인 경우 true를 리턴하는 기능을 구현하라.\nhint: Appendix를 참고할 것\nhint: RPS6클래스의 사용예시는 아래와 같다.\n\na=RPS6()\na.action\n\n'바위'\n\n\n\nb=RPS6()\nb.action\n\n'보'\n\n\n\na>b, a<b\n\n(False, True)\n\n\n(9)-(10)\n아래와 같은 데이터프레임을 선언하고 물음에 답하라.\n\nnp.random.seed(43052)\ndf=pd.DataFrame({'type':np.random.choice(['A','B'],100), 'score':np.random.randint(40,95,100)})\ndf\n\n\n\n\n\n  \n    \n      \n      type\n      score\n    \n  \n  \n    \n      0\n      B\n      45\n    \n    \n      1\n      A\n      40\n    \n    \n      2\n      B\n      79\n    \n    \n      3\n      B\n      46\n    \n    \n      4\n      B\n      57\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      B\n      69\n    \n    \n      96\n      A\n      71\n    \n    \n      97\n      A\n      93\n    \n    \n      98\n      A\n      63\n    \n    \n      99\n      A\n      82\n    \n  \n\n100 rows × 2 columns\n\n\n\n(9) type==’A’의 평균score를 구하는 코드를 작성하라.\n(10) type==’A’의 평균score보다 같거나 큰 값을 가지는 행을 출력하라.\n\n\n\n(1) 플레이어A는 (가위,가위) 중 하나를 선택할 수 있고 플레이어B는 (가위,바위) 중 하나를 선택할 수 있다. 각 플레이어는 각 패 중 하나를 랜덤으로 선택하는 액션을 한다고 가정하자. 아래에 해당하는 확률을 시뮬레이션을 이용하여 추정하라.\n\n플레이어A가 승리할 확률:\n플레이어B가 승리할 확률:\n플레이어A와 플레이어B가 비길 확률:\n\nhint: 50% 확률로 b가 승리하고 50% 확률로 비긴다.\n(2) 문제 (1)과 같이 아래의 상황을 가정하자.\n\n\n\n\n플레이어A\n플레이어B\n\n\n\n\n각 플레이어가 낼 수 있는 패 (candidate)\n(가위,가위)\n(가위,바위)\n\n\n각 패를 선택할 확률 (prob)\n(0.5,0.5)\n(0.5,0.5)\n\n\n\n각 플레이어는 아래와 같은 규칙으로 가위바위보 결과에 따른 보상점수를 적립한다고 하자. - 승리: 보상점수 2점 적립 - 무승부: 보상점수 1점 적립 - 패배: 보상점수 0점 적립\n100번째 대결까지 시뮬레이션을 시행하고 플레이어B가 가위를 낼 경우 얻은 보상점수의 총합과 바위를 낼 경우 얻은 보상점수의 총합을 각각 구하라. 플레이어B는 가위를 내는것이 유리한가? 바위를 내는것이 유리한가?\nhint: 플레이어B는 바위를 내는 것이 유리하다.\nhint: 플레이어B가 100번중에 49번 가위를 내고 51번 바위를 낸다면 플레이어B가 적립할 보상점수는 각각 아래와 같다. - 가위를 내었을 경우: 49 * 1 = 49점 - 바위를 내었을 경우: 51 * 2 = 102점 - 총 보상점수 = 49점 + 102점 = 151점\n(3) (2)에서 얻은 데이터를 학습하여 플레이어B가 “가위” 혹은 “바위” 를 선택할 확률을 매시점 조금씩 조정한다고 가정하자. 구체적으로는 현재시점까지 얻은 보상점수의 비율로 확률을 결정한다. 예를들어 플레이어B가 100회의 대결동안 누적한 보상점수의 총합이 아래와 같다고 하자.\n\n가위를 내었을 경우 보상점수 총합 = 50점\n바위를 내었을 경우 보상점수 총합 = 100점\n\n그렇다면 플레이어B는 각각 (50/150,100/150) 의 확률로 (가위,바위) 중 하나를 선택한다. 101번째 대결에 플레이어B가 가위를 내서 비겼다면 이후에는 (51/151,100/151) 의 확률로 (가위,바위) 중 하나를 선택한다. 102번째 대결에 플레이어B가 바위를 내서 이겼다면 이후에는 각각 (51/153,102/153) 의 확률로 (가위,바위) 중 하나를 선택한다. 이러한 상황을 요약하여 표로 정리하면 아래와 같다.\n\n\n\n\n\n\n\n\n\n시점\n플레이어B가 가위를 냈을 경우 얻은 점수 총합\n플레이어B가 바위를 냈을 경우 얻은 점수 총합\nt+1시점에서 플레이어B가 (가위,바위)를 낼 확률\n\n\n\n\nt=100\n50\n100\n(50/150, 100/150)\n\n\nt=101\n51\n100\n(51/151, 100/151)\n\n\nt=102\n51\n102\n(51/153, 102/153)\n\n\n\n이러한 방식으로 500회까지 게임을 진행하며 확률을 수정하였을 경우 501번째 대결에서 플레이어B가 (가위,바위)를 낼 확률은 각각 얼마인가?\nhint: 시간이 지날수록 플레이어B는 (가위,바위)중 바위를 내는 쪽이 유리하다는 것을 알게 될 것이다.\n\n앞으로 아래와 같은 용어를 사용한다. - (정의) 어떠한 플레이어가 양손 중 하나를 선택하는 확률을 데이터를 바탕으로 매 순간 업데이트 한다면 그 플레이어는 “학습모드 상태이다”고 표현한다. - (정의) 반대로 어떠한 플레이어가 양손 중 하나를 항상 동일한 확률로 낸다면 그 플레이어는 “학습모드 상태가 아니다”라고 표현한다.\n\n(4) 새로운 두명의 플레이어C와 플레이어D를 만들어라. 두 플레이어는 모두 동일하게 (가위,바위) 중 하나를 선택할 수 있다. 두 명의 플레이어는 100번째 대결까지는 두 가지 패중 하나를 랜덤하게 선택하고 101번째 대결부터 500번째 대결까지는 문제(3)의 플레이어B와 같은 방식으로 확률을 업데이트 하여 두 가지 패를 서로 다른 확률로 낸다고 하자. 즉 100번째 대결까지는 두 플레이어가 모두 학습모드 상태가 아니고 101번째부터 500번째 대결까지는 두 플레이어가 모두 학습모드 상태이다. 500번째 대결까지의 학습이 끝났을 경우 플레이어 C와 플레이어D가 각 패를 낼 확률은 각각 얼마인가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어C가 (가위,바위)를 낼 확률\n플레이어D가 (가위,바위)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n대결 데이터를 학습하여 수정한 확률\n대결 데이터를 학습하여 수정한 확률\n양쪽 플레이어 모두 학습모드임\n\n\n\nhint: 시간이 지날수록 두 플레이어 모두 바위를 내는 쪽이 유리하다는 것을 알게 될 것이다.\n(5) 새로운 플레이어 E와 F를 생각하자. 플레이어E와 플레이어F는 각각 (가위,바위) 그리고 (가위,보) 중 하나를 선택할 수 있다고 가정하자. 시뮬레이션 대결결과를 이용하여 아래의 확률을 근사적으로 추정하라.\n\n플레이어E가 승리할 확률:\n플레이어F가 승리할 확률:\n플레이어E와 플레이어F가 비길 확률:\n\nhint: 플레이어E가 가위를 낸다면 최소한 지지는 않기 때문에 플레이어E가 좀 더 유리한 패를 가지고 있다. 따라서 플레이어E의 결과가 더 좋을 것이다.\n(6) (5)와 동일한 두 명의 플레이어E, F를 생각하자. 두 플레이어는 100회까지는 랜덤으로 자신의 패를 선택한다. 그리고 101회부터 500회까지는 플레이어F만 데이터로 부터 학습을 하여 수정된 확률을 사용한다. 500번의 대결이 끝나고 플레이어F가 (가위,보)를 선택하는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\n\nhint: 플레이어F는 보를 내는 것이 낫다고 생각할 것이다. (가위를 내면 지거나 비기지만 보를 내면 지거나 이긴다.)\n(7) (6)번의 플레이어E와 플레이어F가 500회~1000회까지 추가로 게임을 한다. 이번에는 플레이어E만 데이터로부터 학습한다. 1000회까지 대결을 끝낸 이후 플레이어E가 (가위,바위)를 내는 확률은 어떻게 업데이트 되었는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\nt=500시점에 업데이트된 확률\n플레이어E는 학습모드 / 플레이어F는 학습모드아님\n\n\n\nhint: 플레이어F는 보를 내도록 학습되어 있다. 따라서 플레이어E가 바위를 내면 지고 가위를 내면 이길것이다. 따라서 플레이어E는 가위가 유리하다고 생각할 것이다.\n(8) (7)번의 플레이어E와 플레이어F가 1000회~30000회까지 추가로 게임을 한다. 이번에는 플레이어F만 데이터로부터 학습한다. 30000회까지 대결을 끝낸 이후 플레이어F가 (가위,보)를 내는 확률은 어떻게 업데이트 되었는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\nt=500시점에 업데이트된 확률\n플레이어E는 학습모드 / 플레이어F는 학습모드아님\n\n\nt <= 30000\nt=1000시점에 업데이트된 확률\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\n\nhint: 플레이어F는 원래 보가 유리하다고 생각하여 보를 자주 내도록 학습되었다. 하지만 플레이어E가 그러한 플레이어F의 성향을 파악하고 가위를 주로 내도록 학습하였다. 플레이어F는 그러한 플레이어E의 성향을 다시 파악하여 이번에는 가위을 자주 내는 것이 유리하다고 생각할 것이다.\n(9) 플레이어E와 플레이어F의 대결기록을 초기화 한다. 이번에는 플레이어F가 항상 (3/4)의 확률로 가위를 (1/4)의 확률로 보를 낸다고 가정한다. 플레이어E는 100번의 대결까지는 랜덤으로 (가위,바위)중 하나를 내고 101번째 대결부터 1000번째 대결까지는 대결 데이터를 학습하여 수정한 확률을 사용한다고 하자. 1000번째 대결이후에 플레이어E가 (가위,바위)를 내는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(3/4, 1/4)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\n(3/4, 1/4)\n플레이어E는 학습모드 / 플레이어F는 학습모드 아님\n\n\n\n(10) 플레이어E와 플레이어F의 대결기록을 초기화 한다. 이번에는 플레이어F가 항상 (2/3)의 확률로 가위를 (1/3)의 확률로 보를 낸다고 가정한다. 플레이어E는 100번의 대결까지는 랜덤으로 (가위,바위)중 하나를 내고 101번째 대결부터 1000번째 대결까지는 대결 데이터를 학습하여 수정한 확률을 사용한다고 하자. 1000번째 대결이후에 플레이어E가 (가위,바위)를 내는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(2/3, 1/3)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\n(2/3, 1/3)\n플레이어E는 학습모드 / 플레이어F는 학습모드 아님\n\n\n\n\n\n\n- 아래의 클래스를 참고하여 문제1,2을 풀어라. (5월25일 강의노트에 소개된 클래스를 약간 정리한 것) - 참고하지 않아도 감점은 없음\n\nclass RPS:\n    def __init__(self,candidate):\n        self.candidate = candidate\n        self.actions = list() \n        self.rewards = list()\n        self.prob = [0.5,0.5]\n\n    def __eq__(self,other): # 연산 == 를 재정의 \n        return self.actions[-1] == other.actions[-1] \n        #note: 둘의 액션이 같으면 무승부 \n    \n    def __gt__(self,other): # 연산 > 를 재정의 \n        pair = self.actions[-1], other.actions[-1]\n        return pair == ('가위','보') or pair == ('바위','가위') or pair == ('보','바위') \n        #note: 가위>보, 바위>가위, 보>가위 \n    \n    def __mul__(self,other):\n        # step1: 각자의 패를 선택 \n        self.choose()\n        other.choose()\n        \n        # step2: 승패 판단 + upate reward\n        if self == other: # 무승부일경우 \n            self.rewards.append(1)\n            other.rewards.append(1)\n        elif self > other: # self의 승리 \n            self.rewards.append(2)\n            other.rewards.append(0)\n        else: # other의 승리 \n            self.rewards.append(0)\n            other.rewards.append(2)\n        \n        # step3: update data\n        self.update_data()\n        other.update_data()\n    \n    def update_data(self):\n        self.data = pd.DataFrame({'actions':self.actions, 'rewards':self.rewards})\n    \n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        데이터: <br/>\n        {}\n        \"\"\"        \n        return html_str.format(self.candidate,self.data._repr_html_())\n    \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate,p=self.prob))\n\n- 사용예시\n\na=RPS(['가위','가위'])\nb=RPS(['가위','보'])\n\n\nfor i in range(5):\n    a*b\n\n\na\n\n\n\n        낼 수 있는 패: ['가위', '가위']  \n        데이터: \n        \n\n\n  \n    \n      \n      actions\n      rewards\n    \n  \n  \n    \n      0\n      가위\n      2\n    \n    \n      1\n      가위\n      2\n    \n    \n      2\n      가위\n      1\n    \n    \n      3\n      가위\n      2\n    \n    \n      4\n      가위\n      2\n    \n  \n\n\n        \n\n\n\nb\n\n\n\n        낼 수 있는 패: ['가위', '보']  \n        데이터: \n        \n\n\n  \n    \n      \n      actions\n      rewards\n    \n  \n  \n    \n      0\n      보\n      0\n    \n    \n      1\n      보\n      0\n    \n    \n      2\n      가위\n      1\n    \n    \n      3\n      보\n      0\n    \n    \n      4\n      보\n      0"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class5.html",
    "href": "posts/1_IP2022/2023-02-23-class5.html",
    "title": "class 5단계",
    "section": "",
    "text": "특정 자료형에 한정하여 print 이외에 파이썬 내부기능을 재정의해보자.\n\n- 지난시간까지 배운 것: RPC자료형에 한정해서 print() 등의 기능을 조작할 수 있었다. (재정의 할 수 있었다.)\n- 이번시간에 배울 것: 특정 자료형에 한정하여 print 이외에 파이썬 내부기능을 조작하여 보자. (재정의하여 보자.)\n\nimport numpy as np\n\n\n\n- 아래의 연산구조를 관찰하자.\n\na = 1\nb = 2\n\n\na?? # a는 int class에서 만들어진 인스턴스다.\n\n\nType:        int\nString form: 1\nDocstring:  \nint([x]) -> integer\nint(x, base=10) -> integer\nConvert a number or string to an integer, or return 0 if no arguments\nare given.  If x is a number, return x.__int__().  For floating point\nnumbers, this truncates towards zero.\nIf x is not a number or if base is given, then x must be a string,\nbytes, or bytearray instance representing an integer literal in the\ngiven base.  The literal can be preceded by '+' or '-' and be surrounded\nby whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\nBase 0 means to interpret the base from the string as an integer literal.\n>>> int('0b100', base=0)\n4\n\n\n\n\na + b\n\n3\n\n\n\na라는 인스턴스와 b라는 인스턴스를 +라는 기호가 연결하고 있다.\n\n- 이번에는 아래의 연산구조를 관찰하자.\n\na = [1,2]\nb = [3,4]\na+b\n\n[1, 2, 3, 4]\n\n\n\na라는 인스턴스와 b라는 인스턴스를 +라는 기호가 연결하고 있다.\n\n- 동작이 다른 이유?\n\n클래스를 배우기 이전: int자료형의 +는 “정수의 덧셈”을 의미하고 list자료형의 +는 “자료의 추가”를 의미한다.\n클래스를 배운 이후: 아마 클래스는 + 라는 연산을 정의하는 숨겨진 메소드가 있을 것이다. (print가 그랬듯이) 그런데 int 클래스에서는 그 메소드를 “정수의 덧셈”이 되도록 정의하였고, list클래스에서는 그 메소드를 “자료의 추가”를 의마하도록 정의하였을 것이다.\n\n- 아래의 결과를 관찰\n\na = 1\nb = 2\n\n\nset(dir(a)) & {'__add__'}\n\n{'__add__'}\n\n\n\na.__add__(b)\n\n3\n\n\n\nb.__add__(a)\n\n3\n\n\n\na = [1,2]\nb = [3,4]\n\n\na.__add__(b)\n\n[1, 2, 3, 4]\n\n\n\nb.__add__(a)\n\n[3, 4, 1, 2]\n\n\n- a+b는 사실 내부적으로 a.__add(b)의 축약구문이다. 따라서 만약 a.__add__(b)의 기능을 바꾸면 (재정의 하면) a+b의 기능도 바뀔 것이다.\n\n\n- 학생예제\n\nclass Student: # student class를 만들어보자. (student 자료형인것.)\n    def __init__(self, age = 20.0, semester = 0):\n        self.age = age\n        self.semester = semester\n        print('입학을 축하합니다. 당신의 나이는 {}이고 현재 학기는 {}학기입니다.'.format(self.age, self.semester))\n    def __add__(self, val):\n        # val == 0: 휴학\n        # val == 1: 등록\n        if val == 0:\n            self.age = self.age + 0.5\n        elif val == 1:\n            self.age = self.age + 0.5\n            self.semester = self.semester + 1\n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {} <br/>\n        학기: {} <br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기입니다.\n\n\n\niu\n\n\n        나이: 20.0 \n        학기: 0 \n        \n\n\n\niu + 1 ## 1학년 1학기 등록\niu\n\n\n        나이: 20.5 \n        학기: 1 \n        \n\n\n\niu + 0 ## 휴학함\niu\n\n\n        나이: 21.0 \n        학기: 1 \n        \n\n\n\niu.__add__(1)\n\n\niu\n\n\n        나이: 21.5 \n        학기: 2 \n        \n\n\n- 연산을 연속으로 하고 싶다.\n\niu + 1 + 0 + 0 + 0 + 0\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러의 이유?\n(되는코드)\n\n(1+1)+1 # 1+1+1은 이렇게 볼 수 있다.\n\n3\n\n\n\n_a = (1+1)\ntype(_a)\n\nint\n\n\n\n_a+1 # 이 연산은 int 인스턴스 + int인스턴스\n\n3\n\n\n(안되는코드)\n\niu + 1 + 1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n\n_a = iu + 1\ntype(_a)\n\nNoneType\n\n\n\n_a + 1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러를 해결하는 방법: iu + 1의 결과로 Student클래스가 리턴되면 된다.\n\nclass Student: # student class를 만들어보자. (student 자료형인것.)\n    def __init__(self, age = 20.0, semester = 0):\n        self.age = age\n        self.semester = semester\n        print('입학을 축하합니다. 당신의 나이는 {}이고 현재 학기는 {}학기입니다.'.format(self.age, self.semester))\n    def __add__(self, val):\n        # val == 0: 휴학\n        # val == 1: 등록\n        if val == 0:\n            self.age = self.age + 0.5\n        elif val == 1:\n            self.age = self.age + 0.5\n            self.semester = self.semester + 1\n        return self\n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {} <br/>\n        학기: {} <br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기입니다.\n\n\n\niu+1  # __add__의 return에 Student 클래스의 인스턴스가 리턴되면서 자동으로 _repr_html_() 실행\n\n\n        나이: 20.5 \n        학기: 1 \n        \n\n\n\niu + 1 + 0 + 0 + 0 + 0\n\n\n        나이: 23.0 \n        학기: 2 \n        \n\n\n\n\n\n\na = 1\nb = 0\na*b\n\n0\n\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n        self.results = list()\n    def __mul__(self, other):\n        self.choose()\n        other.choose()\n        if self.actions[-1] == '가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '가위' and other.actions[-1]=='보':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='가위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='바위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '바위' and other.actions[-1]=='보':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '보' and other.actions[-1]=='보':\n            self.results.append(0)\n            other.results.append(0)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions, self.results)\n\n\na = RPC()\nb = RPC()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\na*b\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: ['보'] \n        승패: [-1]\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: ['가위'] \n        승패: [1]\n        \n\n\n\nfor i in range(50000):\n    a*b\n\n\n#a\n\n\n#b\n\n\nsum(a.results), sum(b.results)\n\n(175, -175)\n\n\n\nsum(a.results)/50000\n\n0.0035\n\n\n\nsum(b.results)/50000\n\n-0.0035\n\n\n\n\n\n\nRPC클래스에서 Player a와 Player b를 만들어라. - Player a는 [‘가위’,‘보’] 중에 하나를 낼 수 있다. - 그리고 Player b는 [‘가위’,‘바위’] 중에 하나를 낼 수 있다. - 두 Player는 가지고 있는 패를 (같은 확률로) 랜덤으로 낸다. (즉, Player a가 가위만 내거나 보만 내는 경우는 없다.)\n\n누가 더 유리한가? 이유를 스스로 생각해보라.\n\n\n비슷하지 않을까?\n\n\n50000번을 시뮬레이션을 해보고 결과를 분석해보라.\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n        self.results = list()\n    def __mul__(self, other):\n        self.choose()\n        other.choose()\n        if self.actions[-1] == '가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '가위' and other.actions[-1]=='보':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='가위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='바위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '바위' and other.actions[-1]=='보':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '보' and other.actions[-1]=='보':\n            self.results.append(0)\n            other.results.append(0)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions, self.results)\n\n\nplayer_a = RPC(['가위', '보'])\nplayer_b = RPC(['가위', '바위'])\n\n\nplayer_a\n\n\n        낼 수 있는 패: ['가위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\nplayer_b\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        액션: [] \n        승패: []\n        \n\n\n\nplayer_a*player_b\n\n\nplayer_a\n\n\n        낼 수 있는 패: ['가위', '보'] \n        액션: ['보'] \n        승패: [1]\n        \n\n\n\nplayer_b\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        액션: ['바위'] \n        승패: [-1]\n        \n\n\n\nfor i in range(50000):\n    player_a*player_b\n\n\nsum(player_a.results), sum(player_b.results)\n\n(-12279, 12279)\n\n\n\nsum(player_a.results)/50000, sum(player_b.results)/50000\n\n(-0.24558, 0.24558)"
  },
  {
    "objectID": "4_ts2023.html",
    "href": "4_ts2023.html",
    "title": "TS2023",
    "section": "",
    "text": "This page is organized based on the contents of the Time Series Analysis lectures and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 16, 2023\n\n\n0616 시계열 실습 (수정본)\n\n\nJiyunLim\n\n\n\n\nJun 16, 2023\n\n\n0616 TS 공부\n\n\nJiyunLim\n\n\n\n\nJun 16, 2023\n\n\n0616 TS 공부 (origin)\n\n\nJiyunLim\n\n\n\n\nJun 16, 2023\n\n\n0616 TS 공부 (교수님)\n\n\nJiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[TS] 8wk-2. 7장 연습문제\n\n\njiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[TS] 12wk. 추세 (++)\n\n\njiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[TS] 7wk. ARIMA\n\n\njiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[TS] 7wk-2. 6장 연습문제 (++)\n\n\njiyunLim\n\n\n\n\nMay 24, 2023\n\n\n[TS] 7wk. 5~6장 연습문제 (Ongoing)\n\n\njiyunLim\n\n\n\n\nMay 22, 2023\n\n\n[TS] 6wk. wold의 관찰 / MA / ARMA\n\n\njiyunLim\n\n\n\n\nMay 20, 2023\n\n\n[TS] 6wk. 연습문제5장(3,4번) 실습\n\n\nJiyunLim\n\n\n\n\nMay 19, 2023\n\n\n[TS] 5wk. PACF\n\n\nJiyunLim\n\n\n\n\nMay 18, 2023\n\n\n[TS] 4wk-2. PACF\n\n\nJiyunLim\n\n\n\n\nMay 16, 2023\n\n\n[TS] 4wk. ACF\n\n\nJiyunLim\n\n\n\n\nMay 14, 2023\n\n\n[TS] 3wk. 여러가지 확률과정 (random walk, AR)\n\n\nJiyunLim\n\n\n\n\nMay 13, 2023\n\n\n[TS] 2wk-2. 연습문제 5.1\n\n\nJiyunLim\n\n\n\n\nMay 12, 2023\n\n\n[TS] 2wk. 확률과정과 정상성\n\n\nJiyunLim\n\n\n\n\nMay 10, 2023\n\n\n[TS] 1wk. 확률\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "5_study.html",
    "href": "5_study.html",
    "title": "STUDY",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 24, 2023\n\n\n2.1 선형모델\n\n\nJiyunLim\n\n\n\n\nJun 23, 2023\n\n\n[Essays] 퓨리에변환4jy\n\n\n신록예찬\n\n\n\n\nJun 22, 2023\n\n\n푸리에변환\n\n\nJiyunLim\n\n\n\n\nJun 18, 2023\n\n\nChap2. 신경망의 수학적 구성요소\n\n\nJiyunLim\n\n\n\n\nJun 14, 2023\n\n\n[Essays] 추정 for JY\n\n\n신록예찬\n\n\n\n\nFeb 25, 2023\n\n\nJT test\n\n\njiyun Lim\n\n\n\n\nFeb 19, 2023\n\n\nts1\n\n\njiyun Lim\n\n\n\n\nFeb 19, 2023\n\n\nsimultaneous equation\n\n\njiyun Lim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "1_ip2022.html",
    "href": "1_ip2022.html",
    "title": "IP2022",
    "section": "",
    "text": "This page is organized based on the contents of the Introduction to Python (2022-1) and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 21, 2023\n\n\n13wk-1: 깊은복사와 얕은복사\n\n\n최규빈\n\n\n\n\nMay 27, 2023\n\n\nClass 활용\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 1단계\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 0단계\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 2단계\n\n\njiyun Lim\n\n\n\n\nFeb 27, 2023\n\n\n2022 final exam\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nNumpy 4단계(concat, stack)\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 6단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 9단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 8단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 10단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 7단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 5단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 3단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 1단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 2단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 4단계\n\n\njiyun Lim\n\n\n\n\nJun 9, 2022\n\n\n2021 final exam solution\n\n\nGuebinChoi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2023 study blog",
    "section": "",
    "text": "(12주차) 5월23일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1 선형모델\n\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[Essays] 퓨리에변환4jy\n\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n푸리에변환\n\n\n\n\n\n\n\n\n\n\n\nJun 22, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13wk-1: 깊은복사와 얕은복사\n\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2023\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChap2. 신경망의 수학적 구성요소\n\n\n\n\n\n\n\n딥러닝 스터디\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n0616 시계열 실습 (수정본)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0616 TS 공부\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0616 TS 공부 (origin)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0616 TS 공부 (교수님)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[Essays] 추정 for JY\n\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\n[STBDA] 11wk. MaxPool2D, Conv2D\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 10wk. 로지스틱 모형\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClass 활용\n\n\n\n\n\n\n\nPython\n\n\nClass\n\n\nStudy\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n[STBDA] 9wk-2. 경사하강법 / 확률적경사하강법\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 9wk. Likelihood function\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 8wk-2. 7장 연습문제\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\njiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 12wk. 추세 (++)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 7wk. ARIMA\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\njiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 7wk-2. 6장 연습문제 (++)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 7wk. 5~6장 연습문제 (Ongoing)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 중간고사\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 6wk. wold의 관찰 / MA / ARMA\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 7wk. Piece-wise LR / Logistic Regression\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 6wk. 연습문제5장(3,4번) 실습\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 5wk. PACF\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 6wk. 회귀모형 적합 with keras\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[TS] 4wk-2. PACF\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 5wk. optimizer를 이용한 최적화\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 4wk. ACF\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 4wk. 미분 / 경사하강법\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 3wk. 여러가지 확률과정 (random walk, AR)\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 2wk-2. 연습문제 5.1\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 3wk. 텐서플로우 intro2 (tf.GradientTape())\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 2wk. 확률과정과 정상성\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 1wk. 확률\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 1wk. 강의소개 및 단순선형회귀\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n아이스크림을 많이 먹으면 걸리는 병\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2023\n\n\njiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n10wk-2 심슨의 역설\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 1단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 0단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 2단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 final exam\n\n\n\n\n\n\n\npython\n\n\nclass\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJT test\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumpy 4단계(concat, stack)\n\n\n\n\n\n\n\nPython\n\n\nNumpy\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 6단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 9단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 8단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 10단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 7단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 5단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nts1\n\n\n\n\n\n\n\nR\n\n\nts\n\n\nbasic\n\n\n\n\ntimeseries study1\n\n\n\n\n\n\nFeb 19, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimultaneous equation\n\n\n\n\n\n\n\nR\n\n\nlinear algebra\n\n\nbasic\n\n\n\n\nimplementation with R\n\n\n\n\n\n\nFeb 19, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 3단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 1단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 2단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 4단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n05wk-2\n\n\n\n\n\n\n\n훌륭한 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05wk-1\n\n\n\n\n\n\n\nseaborn\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021 final exam solution\n\n\n\n\n\n\n\npython\n\n\nclass\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2022\n\n\nGuebinChoi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)\n\n\n\n\n\n\n\npandas\n\n\n통계와 시각화\n\n\n아이스크림을 많이 먹으면 걸리는 병\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2022\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  }
]