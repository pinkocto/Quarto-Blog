[
  {
    "objectID": "3_stbda2022.html",
    "href": "3_stbda2022.html",
    "title": "STBDA2022",
    "section": "",
    "text": "This page is organized based on the contents of the Big Data Analysis Special Lecture (2022-1) and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n(9주차) 5월2일 (1)\n\n\n\n\n\n\n\n\n(4주차) 3월28일\n\n\n\n\n\n\n\n\n(7주차) 4월18일\n\n\n\n\n\n\n\n\n(6주차) 4월11일\n\n\n\n\n\n\n\n\n(5주차) 4월4일\n\n\n\n\n\n\nMay 12, 2023\n\n\n[STBDA] 3wk. 텐서플로우 intro2\n\n\nJiyunLim\n\n\n\n\nMay 10, 2023\n\n\n[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)\n\n\nJiyunLim\n\n\n\n\nMay 8, 2023\n\n\n[STBDA] 1wk. 강의소개 및 단순선형회귀\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "2_dv2022.html",
    "href": "2_dv2022.html",
    "title": "DV2022",
    "section": "",
    "text": "This page is organized based on the contents of the Data Visualization (2022-2) and lecture notes of Professor Guebin Choi of Jeonbuk National University."
  },
  {
    "objectID": "2_dv2022.html#contents",
    "href": "2_dv2022.html#contents",
    "title": "DV2022",
    "section": "Contents",
    "text": "Contents\n1. 시각화 차트 소개\n\nboxplot, histogram, lineplot, scatterplot\n\n2. 파이썬 데이터 시각화 패키지 사용법\n\nmatplotlib, seaborn, plotnine/ggplot2\n\n3. 데이터 시각화와 통계적 해석\n\n히스토그램 이퀄라이제이션\n표본상관계수, 앤스콤의 플랏, 무상관, 무상관과 독립\n\n4. Data Wrangling\n\nlambda, map\npandas: indexing\n\n5. 인포그래픽과 데이터시각화\n\n나이젤홈즈와 애드워드터프티, 찰스미나드의 도표"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog ~~~"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "",
    "text": "아이스크림을 많이 먹으면 걸리는 병(2)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#자료생성-좀-더-그럴듯한-자료-만들기",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "자료생성: 좀 더 그럴듯한 자료 (만들기)",
    "text": "자료생성: 좀 더 그럴듯한 자료 (만들기)\n- 지난 시간의 toy example은 데이터가 너무 작아서 억지스러움 \\(\\to\\) 기상자료개방포털, 회원가입해야 자료받을 수 있음.\n\n_df=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv')\n_df\n\n\n\n\n\n  \n    \n      \n      지점번호\n      지점명\n      일시\n      평균기온(℃)\n      최고기온(℃)\n      최고기온시각\n      최저기온(℃)\n    \n  \n  \n    \n      0\n      146\n      전주\n      2020-01-01\n      -0.5\n      4.3\n      15:09\n      -6.4\n    \n    \n      1\n      146\n      전주\n      2020-01-02\n      1.4\n      6.5\n      14:12\n      -3.0\n    \n    \n      2\n      146\n      전주\n      2020-01-03\n      2.6\n      7.6\n      13:32\n      -0.5\n    \n    \n      3\n      146\n      전주\n      2020-01-04\n      2.0\n      7.7\n      13:51\n      -2.6\n    \n    \n      4\n      146\n      전주\n      2020-01-05\n      2.5\n      8.6\n      14:05\n      -3.2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      146\n      전주\n      2021-10-13\n      19.9\n      25.5\n      14:29\n      15.6\n    \n    \n      652\n      146\n      전주\n      2021-10-14\n      20.4\n      25.5\n      13:36\n      17.0\n    \n    \n      653\n      146\n      전주\n      2021-10-15\n      18.3\n      22.0\n      13:47\n      15.7\n    \n    \n      654\n      146\n      전주\n      2021-10-16\n      12.8\n      17.4\n      0:01\n      6.5\n    \n    \n      655\n      146\n      전주\n      2021-10-17\n      6.7\n      12.4\n      15:18\n      2.2\n    \n  \n\n656 rows × 7 columns\n\n\n\n- 평균기온만 선택\n\npd.Series(_df.columns)\n\n0       지점번호\n1        지점명\n2         일시\n3    평균기온(℃)\n4    최고기온(℃)\n5     최고기온시각\n6    최저기온(℃)\ndtype: object\n\n\n\ntemp = np.array(_df.iloc[:,3])\ntemp[:5]\n\narray([-0.5,  1.4,  2.6,  2. ,  2.5])\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps = np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2*temp + eps\n\n\nplt.plot(temp,icecream,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"icecream\",size=15)\n\nText(0, 0.5, 'icecream')\n\n\n\n\n\n\n\n# 숨은진짜상황1: 온도 \\(\\to\\) 아이스크림 판매량\n- 아래와 같은 관계가 있다고 하자.\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(2) \neps=np.random.normal(size=len(temp),scale=1)\ndisease= 30 + 0.5 * temp + eps\n\n\nplt.plot(temp,disease,'o',alpha=0.3)\nplt.xlabel(\"temp\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\n\n# 우리가 관측한 상황 (온도는 은닉되어있음)\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.xlabel(\"icecream\",size=15)\nplt.ylabel(\"disease\",size=15)\n\nText(0, 0.5, 'disease')\n\n\n\n\n\n\nnp.corrcoef(icecream,disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\n\n0.86정도.."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#직관-여름만-뽑아서-plot-해보자.",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "직관: 여름만 뽑아서 plot 해보자.",
    "text": "직관: 여름만 뽑아서 plot 해보자.\n- temp>25 (여름으로 간주) 인 관측치만 플랏\n\nplt.plot(icecream[temp>25],disease[temp>25], 'o', color='C1') ## 평균기온이 25도가 넘어가면 여름이라 생각 \n\n\n\n\n- 전체적인 산점도\n\nfig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2,figsize=(8,6)) \nax1.plot(temp,icecream,'o',alpha=0.2); ax1.set_xlabel('temp'); ax1.set_ylabel('icecream'); ax1.set_title(\"hidden1\")\nax2.plot(temp,disease,'o',alpha=0.2); ax2.set_xlabel('temp'); ax2.set_ylabel('disease'); ax2.set_title(\"hidden2\")\nax3.plot(icecream,disease,'o',alpha=0.2); ax3.set_xlabel('icecream'); ax3.set_ylabel('disease'); ax3.set_title(\"observed\")\nax4.plot(icecream,disease,'o',alpha=0.2); ax4.set_xlabel('icecream'); ax4.set_ylabel('disease'); ax4.set_title(\"observed\")\nax4.plot(icecream[temp>25],disease[temp>25],'o',label='temp>25')\nax4.legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#ggplot-온도구간을-세분화-하여-시각화",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "ggplot: 온도구간을 세분화 하여 시각화",
    "text": "ggplot: 온도구간을 세분화 하여 시각화\n- 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자.\n\n사실 지금 변수는 온도, 아이스크림판매량, 소아마비\n온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함\n\n\n# df로 자료정리\n- 일단 데이터 프레임을 정리하자.\n\ndf = pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n    \n  \n\n656 rows × 3 columns\n\n\n\n\n\n# 구간세분화\n- 온도를 카테고리화 하자 \\(\\to\\) 적당한 구긴을 설정하기 위해서 히스토그램을 그려보자.\n\ndf.temp.hist() # ? 이거 14주차쯤 배우는데 미리 스포합니다.. 엄청 편해요 \n\n<AxesSubplot:>\n\n\n\n\n\n\nplt.hist(df.temp) # 원래는 이걸 배웠죠\n\n(array([  3.,   9.,  29.,  60.,  92.,  86.,  65.,  93., 139.,  80.]),\n array([-12.4 ,  -8.16,  -3.92,   0.32,   4.56,   8.8 ,  13.04,  17.28,\n         21.52,  25.76,  30.  ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n- 구간은 5정도로 하면 적당할 것 같다.\n\ndef cut(x): # 이거보다 더 좋은 방법이 있을 것 같긴 한데요..\n    if x<0: \n        y='Temp: <0'\n    elif x<5: \n        y='Temp: 0~5'\n    elif x<10: \n        y='Temp: 5~10'\n    elif x<15: \n        y='Temp: 10~15'\n    elif x<20:\n        y='Temp: 15~20'\n    elif x<25: \n        y='Temp: 20~25'\n    else: \n        y='Temp: >30'\n    return y \n\n\ndf.assign(temp2 = list(map(cut,df.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      29.333242\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      30.643733\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      29.163804\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      32.640271\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      29.456564\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.633906\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.920443\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      39.882650\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.613159\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      34.902513\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\n\n# ggplot\n- 온도를 색으로 구분하면\n\nfig = ggplot(data=df.assign(temp2 = list(map(cut,df.temp))))\np1 = geom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.5)\nfig + p1\n\n\n\n\n<ggplot: (8762005360345)>\n\n\n- 추세선을 추가하면\n\nl1 = geom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n\nfig+p1+l1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762010169613)>\n\n\n\n각 온도별로 추세선은 거의 기울기가 0이다. \\(\\to\\) 온도가 비슷한 구간별로 묶어서 보니까 상관관계가 없다는 거!\n아이스크림 판매량과 소아마비의 corr은 유의미해보이지만, 온도를 통제하였을 경우 아이스크림 판매량과 소아마비의 partial corr은 유의미해보이지 않음.\n\n\n\n# 해석\n- 해피앤딩: 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. \\(\\to\\) 아이스크림을 먹으면 소아마비를 유발한다는 이상한 결론이 나올뻔 했지만 우리는 온도라는 흑막을 잘 찾았고 결과적으로 “온도->아이스크림판매량,소아마비” 이라는 합리적인 진리를 얻을 수 있었다.\n\n온도와 같은 변수를 은닉변수라고 한다.\n\n- 또 다른 흑막? 고려할 흑막이 온도뿐이라는 보장이 어디있지? 사실 흑막2, 흑막3이 있어서 그런 흑막들을 고려하다보니까 아이스크림과 소아마비사이의 상관관계가 다시 보이면 어떡하지?\n\n이러한 이유 때문에 상관계수로 인과성을 유추하는건 사실상 불가능.\n그런데 이론적으로는 “세상의 모든 은닉변수를 통제하였을 경우에도 corr(X,Y)의 값이 1에 가깝다면 그때는 인과성이 있다고 봐도 무방함, (물론 이 경우에도 무엇이 원인인지는 통계적으로 따지는것이 불가)” 이라고 주장할 수 있다. 즉 모든 흑막을 제거한다면 “상관성=인과성”이다.\n\n- 실험계획법, 인과추론: 세상의 모든 흑막을 제거하는건 상식적으로 불가능\n\n피셔의주장(실험계획법): 그런데 실험계획을 잘하면 흑막을 제거한 효과가 있음 (무작위로 사람뽑아서 담배를 피우게 한다든가)\n인과추론: 실험계획이 사실상 불가능한 경우가 있음 \\(\\to\\) 모인 데이터에서 최대한 흑막2,3,4,.. 등이 비슷한 그룹끼리 “매칭”을 시킨다!"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "href": "posts/2_DV2022/2022-10-19-7wk-2.html#그냥-궁금해서-진짜-만약에-아이스크림과-소아마비가-관련있는-경우라면",
    "title": "07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)",
    "section": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?",
    "text": "그냥 궁금해서: 진짜 만약에 아이스크림과 소아마비가 관련있는 경우라면?\n- 온도는 아이스크림 판매에 여전히 영향을 주지만\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1)\neps=np.random.normal(size=len(temp), scale=10) \nicecream = 20 + 2 * temp + eps \n\n- 수영장이 원인이 아니라 진짜 아이스크림을 먹고 소아마비에 걸린상황이라면?\n\\[\\text{소아마비 반응수치} = 30 + 0 \\times \\text{온도} + 0.15 \\times \\text{아이스크림 판매량} + \\epsilon\\]\n\nnp.random.seed(2) \neps = np.random.normal(size=len(temp),scale=2)\ndisease= 30+ 0*temp + 0.15*icecream + eps\n\n\ndf2=pd.DataFrame({'temp':temp,'icecream':icecream,'disease':disease})\ndf2.assign(temp2=list(map(cut,df2.temp)))\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n      temp2\n    \n  \n  \n    \n      0\n      -0.5\n      35.243454\n      34.453002\n      Temp: <0\n    \n    \n      1\n      1.4\n      16.682436\n      32.389832\n      Temp: 0~5\n    \n    \n      2\n      2.6\n      19.918282\n      28.715350\n      Temp: 0~5\n    \n    \n      3\n      2.0\n      13.270314\n      35.271089\n      Temp: 0~5\n    \n    \n      4\n      2.5\n      33.654076\n      31.461240\n      Temp: 0~5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      651\n      19.9\n      68.839992\n      39.693811\n      Temp: 15~20\n    \n    \n      652\n      20.4\n      76.554679\n      38.924088\n      Temp: 20~25\n    \n    \n      653\n      18.3\n      68.666079\n      41.765212\n      Temp: 15~20\n    \n    \n      654\n      12.8\n      42.771364\n      36.842022\n      Temp: 10~15\n    \n    \n      655\n      6.7\n      30.736731\n      37.715537\n      Temp: 5~10\n    \n  \n\n656 rows × 4 columns\n\n\n\n\nggplot(data=df2.assign(temp2=list(map(cut,df2.temp))))+\\\ngeom_point(aes(x='icecream',y='disease',colour='temp2'),alpha=0.2)+\\\ngeom_smooth(aes(x='icecream',y='disease',colour='temp2'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8762005194073)>\n\n\n\n이번엔 partial corr도 유의미하게 나옴\n\n- 단순 corr을 봐서는 “온도->아이스크림,소아마비” 인지, “온도->아이스크림->소아마비” 인지 알기 어렵다.\n\ndf.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.975609\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.862990\n    \n    \n      disease\n      0.975609\n      0.862990\n      1.000000\n    \n  \n\n\n\n\n\ndf2.corr()\n\n\n\n\n\n  \n    \n      \n      temp\n      icecream\n      disease\n    \n  \n  \n    \n      temp\n      1.000000\n      0.884366\n      0.725505\n    \n    \n      icecream\n      0.884366\n      1.000000\n      0.830539\n    \n    \n      disease\n      0.725505\n      0.830539\n      1.000000"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html",
    "title": "10wk-2 심슨의 역설",
    "section": "",
    "text": "심슨의 역설을 bar plot으로 시각화하는 방법과 왜 생기게 되는지에 대해 알아보자."
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#버클리대학교의-입학데이터",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#버클리대학교의-입학데이터",
    "title": "10wk-2 심슨의 역설",
    "section": "버클리대학교의 입학데이터",
    "text": "버클리대학교의 입학데이터\n\nhttps://github.com/pinkocto/Quarto-Blog/blob/main/posts/DV/ds.pdf\n\n- 주장: 버클리대학에 gender bias가 존재한다.\n\n1973년 가을학기의 입학통계에 따르면 지원하는 남성이 여성보다 훨씬 많이 합격했고, 그 차이가 너무 커서 우연의 일치라 보기 어렵다.\n\n\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack().reset_index()\\\n.rename({'level_0':'department','level_1':'result','level_2':'gender',0:'count'},axis=1)\ndf\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n    \n    \n      1\n      A\n      fail\n      male\n      314\n    \n    \n      2\n      A\n      pass\n      female\n      89\n    \n    \n      3\n      A\n      pass\n      male\n      511\n    \n    \n      4\n      B\n      fail\n      female\n      7\n    \n    \n      5\n      B\n      fail\n      male\n      208\n    \n    \n      6\n      B\n      pass\n      female\n      18\n    \n    \n      7\n      B\n      pass\n      male\n      352\n    \n    \n      8\n      C\n      fail\n      female\n      391\n    \n    \n      9\n      C\n      fail\n      male\n      204\n    \n    \n      10\n      C\n      pass\n      female\n      202\n    \n    \n      11\n      C\n      pass\n      male\n      121\n    \n    \n      12\n      D\n      fail\n      female\n      244\n    \n    \n      13\n      D\n      fail\n      male\n      279\n    \n    \n      14\n      D\n      pass\n      female\n      131\n    \n    \n      15\n      D\n      pass\n      male\n      138\n    \n    \n      16\n      E\n      fail\n      female\n      299\n    \n    \n      17\n      E\n      fail\n      male\n      137\n    \n    \n      18\n      E\n      pass\n      female\n      94\n    \n    \n      19\n      E\n      pass\n      male\n      54\n    \n    \n      20\n      F\n      fail\n      female\n      103\n    \n    \n      21\n      F\n      fail\n      male\n      149\n    \n    \n      22\n      F\n      pass\n      female\n      238\n    \n    \n      23\n      F\n      pass\n      male\n      224"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화1-전체합격률",
    "title": "10wk-2 심슨의 역설",
    "section": "시각화1: 전체합격률",
    "text": "시각화1: 전체합격률\n- df1\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n    \n    \n      1\n      female\n      pass\n      772\n    \n    \n      2\n      male\n      fail\n      1291\n    \n    \n      3\n      male\n      pass\n      1400\n    \n  \n\n\n\n\n- df2\n\n# df.query('gender ==\"female\"')\n\n\ndf.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      gender\n      count2\n    \n  \n  \n    \n      0\n      female\n      1835\n    \n    \n      1\n      male\n      2691\n    \n  \n\n\n\n\n- merge: 두개의 데이터프레임을 합친다\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n    \n  \n\n\n\n\n- 비율계산\n\ndf.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      gender\n      result\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      female\n      fail\n      1063\n      1835\n      0.579292\n    \n    \n      1\n      female\n      pass\n      772\n      1835\n      0.420708\n    \n    \n      2\n      male\n      fail\n      1291\n      2691\n      0.479747\n    \n    \n      3\n      male\n      pass\n      1400\n      2691\n      0.520253\n    \n  \n\n\n\n\n- 시각화\n\ndata1= df.groupby(['gender','result']).agg({'count':np.sum}).reset_index()\\\n.merge(df.groupby('gender').agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data1.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate')) # 합격률만 시각화.\n\n\n\n\n<ggplot: (8769600261271)>\n\n\n- 결론: 남자의 합격률이 더 높다. \\(\\to\\) 성차별이 있어보인다(?)"
  },
  {
    "objectID": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "href": "posts/2_DV2022/2022-11-09-10wk-2.html#시각화2-학과별-합격률",
    "title": "10wk-2 심슨의 역설",
    "section": "시각화2: 학과별 합격률",
    "text": "시각화2: 학과별 합격률\n- df2\n\ndf.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1)\n\n\n\n\n\n  \n    \n      \n      department\n      gender\n      count2\n    \n  \n  \n    \n      0\n      A\n      female\n      108\n    \n    \n      1\n      A\n      male\n      825\n    \n    \n      2\n      B\n      female\n      25\n    \n    \n      3\n      B\n      male\n      560\n    \n    \n      4\n      C\n      female\n      593\n    \n    \n      5\n      C\n      male\n      325\n    \n    \n      6\n      D\n      female\n      375\n    \n    \n      7\n      D\n      male\n      417\n    \n    \n      8\n      E\n      female\n      393\n    \n    \n      9\n      E\n      male\n      191\n    \n    \n      10\n      F\n      female\n      341\n    \n    \n      11\n      F\n      male\n      373\n    \n  \n\n\n\n\n- merge\n\ndf.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n      count2\n      rate\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n      108\n      0.175926\n    \n    \n      1\n      A\n      pass\n      female\n      89\n      108\n      0.824074\n    \n    \n      2\n      A\n      fail\n      male\n      314\n      825\n      0.380606\n    \n    \n      3\n      A\n      pass\n      male\n      511\n      825\n      0.619394\n    \n    \n      4\n      B\n      fail\n      female\n      7\n      25\n      0.280000\n    \n    \n      5\n      B\n      pass\n      female\n      18\n      25\n      0.720000\n    \n    \n      6\n      B\n      fail\n      male\n      208\n      560\n      0.371429\n    \n    \n      7\n      B\n      pass\n      male\n      352\n      560\n      0.628571\n    \n    \n      8\n      C\n      fail\n      female\n      391\n      593\n      0.659359\n    \n    \n      9\n      C\n      pass\n      female\n      202\n      593\n      0.340641\n    \n    \n      10\n      C\n      fail\n      male\n      204\n      325\n      0.627692\n    \n    \n      11\n      C\n      pass\n      male\n      121\n      325\n      0.372308\n    \n    \n      12\n      D\n      fail\n      female\n      244\n      375\n      0.650667\n    \n    \n      13\n      D\n      pass\n      female\n      131\n      375\n      0.349333\n    \n    \n      14\n      D\n      fail\n      male\n      279\n      417\n      0.669065\n    \n    \n      15\n      D\n      pass\n      male\n      138\n      417\n      0.330935\n    \n    \n      16\n      E\n      fail\n      female\n      299\n      393\n      0.760814\n    \n    \n      17\n      E\n      pass\n      female\n      94\n      393\n      0.239186\n    \n    \n      18\n      E\n      fail\n      male\n      137\n      191\n      0.717277\n    \n    \n      19\n      E\n      pass\n      male\n      54\n      191\n      0.282723\n    \n    \n      20\n      F\n      fail\n      female\n      103\n      341\n      0.302053\n    \n    \n      21\n      F\n      pass\n      female\n      238\n      341\n      0.697947\n    \n    \n      22\n      F\n      fail\n      male\n      149\n      373\n      0.399464\n    \n    \n      23\n      F\n      pass\n      male\n      224\n      373\n      0.600536\n    \n  \n\n\n\n\n- 시각화\n\ndata2=df.merge(df.groupby(['department','gender']).agg({'count':np.sum}).reset_index().rename({'count':'count2'},axis=1))\\\n.eval('rate = count/count2')\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='gender',fill='gender',y='rate'))\\\n+facet_wrap('department')\n\n\n\n\n<ggplot: (8789343111249)>\n\n\n\n학과별로 살펴보니 오히려 A,B,F,D의 경우 여성의 합격률이 높다.\n\n- 교재에서 설명한 이유: 여성이 합격률이 낮은 학과에만 많이 지원하였기 때문\n\nggplot(data2.query('result==\"pass\"'))+geom_col(aes(x='department',y='count2',fill='gender'),position='dodge')\n\n\n\n\n<ggplot: (8789343070225)>\n\n\n\n살펴보니 합격률이 높은 A,B학과의 경우 상대적으로 남성이 많이 지원하였음. 합격률이 낮은 C,D학과는 상대적으로 여성이 많이 지원함. D,F의 지원수는 비슷"
  },
  {
    "objectID": "posts/2_DV2022/dv1.html",
    "href": "posts/2_DV2022/dv1.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "# for test\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4], [1,4,9,16],'ro')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html",
    "title": "05wk-1",
    "section": "",
    "text": "seaborn(2)–scatterplot, mpl미세먼지팁(2)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#plt-복습",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#plt-복습",
    "title": "05wk-1",
    "section": "plt 복습",
    "text": "plt 복습\n\nplt.plot(x1,y1,'o')\nplt.plot(x2,y2,'o')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-array",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-array",
    "title": "05wk-1",
    "section": "sns: array",
    "text": "sns: array\n\nsns.scatterplot(data=None,x=x1,y=y1)\nsns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-wide-df",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-wide-df",
    "title": "05wk-1",
    "section": "sns: wide df",
    "text": "sns: wide df\n\nsns.scatterplot(data=pd.DataFrame({'x':x1,'y':y1}),x='x',y='y')\nsns.scatterplot(data=pd.DataFrame({'x':x2,'y':y2}),x='x',y='y')\n#sns.scatterplot(data=None,x=x2,y=y2)\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\n\n\n\n억지로 그리긴 했는데 이 경우는 wide하게 만든 df는 별로 경쟁력이 없음"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-long-df",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#sns-long-df",
    "title": "05wk-1",
    "section": "sns: long df",
    "text": "sns: long df\n\nx= np.concatenate([x1,x2])\ny= np.concatenate([y1,y2])\ncat = ['x1']*len(x1) + ['x2']*len(x2)\ndf2 = pd.DataFrame({'x':x,'y':y,'cat':cat})\ndf2\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cat\n    \n  \n  \n    \n      0\n      2.023919\n      -0.400176\n      x1\n    \n    \n      1\n      1.229622\n      -1.763752\n      x1\n    \n    \n      2\n      -0.413211\n      2.293004\n      x1\n    \n    \n      3\n      -1.343073\n      0.404232\n      x1\n    \n    \n      4\n      1.062845\n      0.030775\n      x1\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      2.226805\n      3.683857\n      x2\n    \n    \n      1996\n      2.768263\n      2.678292\n      x2\n    \n    \n      1997\n      2.525295\n      2.815478\n      x2\n    \n    \n      1998\n      1.750193\n      2.289812\n      x2\n    \n    \n      1999\n      1.153290\n      2.095922\n      x2\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x',y='y',hue='cat') \n\n<AxesSubplot:xlabel='x', ylabel='y'>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#예제1",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#예제1",
    "title": "05wk-1",
    "section": "예제1",
    "text": "예제1\n\nfig,ax = plt.subplots(1,3,figsize=(12,4))\nax[0].plot([1,2,4,3],'--o')\nsns.scatterplot(x=x1,y=y1,ax=ax[1])\nsns.scatterplot(x=x1,y=y1,ax=ax[2])\nsns.scatterplot(x=x2,y=y2,ax=ax[2])\nax[2].plot([1,2,4,3],'-r',lw=5)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#예제2",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#예제2",
    "title": "05wk-1",
    "section": "예제2",
    "text": "예제2\n\nimport cv2\n\n\n!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg \nimg = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg',0)\n!rm Unequalized_Hawkes_Bay_NZ.jpg \n\n--2022-10-05 16:33:56--  https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\nResolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 110895 (108K) [image/jpeg]\nSaving to: ‘Unequalized_Hawkes_Bay_NZ.jpg’\n\nUnequalized_Hawkes_ 100%[===================>] 108.30K   548KB/s    in 0.2s    \n\n2022-10-05 16:33:57 (548 KB/s) - ‘Unequalized_Hawkes_Bay_NZ.jpg’ saved [110895/110895]\n\n\n\n\nimg2 = cv2.equalizeHist(img)\n\n\nimg.reshape(-1)\n\narray([127, 145, 149, ..., 146, 145, 144], dtype=uint8)\n\n\n\nfig,ax = plt.subplots(2,2,figsize=(10,5))\nax[0,0].imshow(img,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img.reshape(-1),ax=ax[0,1],bins=15,lw=0,kde=True,color='C1')\nax[0,1].set_xlim(0,255)\nax[1,0].imshow(img2,vmin=0,vmax=255,cmap='gray')\nsns.histplot(img2.reshape(-1),ax=ax[1,1],bins=15,lw=0,kde=True,color='C1')\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\n- seaborn: figure-level vs axes-level 의 개념\nref: https://seaborn.pydata.org/tutorial/function_overview.html#figure-level-vs-axes-level-functions"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-간격조정",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-간격조정",
    "title": "05wk-1",
    "section": "축 간격조정",
    "text": "축 간격조정\n\nimport matplotlib as mpl\n\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(3)) # 큰 눈금간격을 3으로\nax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) # 작은 눈금간격을 1로"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-삭제",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-삭제",
    "title": "05wk-1",
    "section": "축 삭제",
    "text": "축 삭제\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.xaxis.set_major_locator(mpl.ticker.NullLocator()) # x축 눈금삭제\nax.yaxis.set_major_locator(mpl.ticker.NullLocator()) # y축 눈금삭제"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#축-범위조정",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#축-범위조정",
    "title": "05wk-1",
    "section": "축 범위조정",
    "text": "축 범위조정\n\nfig, ax = plt.subplots()\nax.plot([(xi/30)**2 for xi in range(30)],'--o')\nax.set_ylim(-1,2) \nax.set_xlim(-5,35)\n#plt.ylim(-1,2)\n#plt.xlim(-5,35)\n\n(-5.0, 35.0)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-03-5wk-1.html#gcf-gca",
    "href": "posts/2_DV2022/2022-10-03-5wk-1.html#gcf-gca",
    "title": "05wk-1",
    "section": "gcf, gca",
    "text": "gcf, gca\n- gcf\n\nplt.plot([1,2,3,2])\nfig = plt.gcf()\n\n\n\n\n\nfig.suptitle('suptitle')\n\nText(0.5, 0.98, 'suptitle')\n\n\n\nfig\n\n\n\n\n- gca\n\nfig\n\n\n\n\n\nax = fig.gca()\n\n\nax.set_title('title') \nfig"
  },
  {
    "objectID": "posts/2_DV2022/9999.html",
    "href": "posts/2_DV2022/9999.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "!wget https://raw.githubusercontent.com/guebin/DV2022/main/posts/2022-10-03-5wk-1.ipynb\n\n--2023-05-21 02:24:58--  https://raw.githubusercontent.com/guebin/DV2022/main/posts/2022-10-03-5wk-1.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 488865 (477K) [text/plain]\nSaving to: ‘2022-10-03-5wk-1.ipynb’\n\n2022-10-03-5wk-1.ip 100%[===================>] 477.41K  --.-KB/s    in 0.02s   \n\n2023-05-21 02:24:58 (25.0 MB/s) - ‘2022-10-03-5wk-1.ipynb’ saved [488865/488865]"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "",
    "text": "판다스– 인덱싱(2), 판다스–새로운열의할당(1), 아이스크림을 많이 먹으면 걸리는 병(1)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#데이터",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#데이터",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "데이터",
    "text": "데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      ...\n      num_user_for_reviews\n      language\n      country\n      content_rating\n      budget\n      title_year\n      actor_2_facebook_likes\n      imdb_score\n      aspect_ratio\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      ...\n      3054.0\n      English\n      USA\n      PG-13\n      237000000.0\n      2009.0\n      936.0\n      7.9\n      1.78\n      33000\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      ...\n      1238.0\n      English\n      USA\n      PG-13\n      300000000.0\n      2007.0\n      5000.0\n      7.1\n      2.35\n      0\n    \n    \n      2\n      Color\n      Sam Mendes\n      602.0\n      148.0\n      0.0\n      161.0\n      Rory Kinnear\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      ...\n      994.0\n      English\n      UK\n      PG-13\n      245000000.0\n      2015.0\n      393.0\n      6.8\n      2.35\n      85000\n    \n    \n      3\n      Color\n      Christopher Nolan\n      813.0\n      164.0\n      22000.0\n      23000.0\n      Christian Bale\n      27000.0\n      448130642.0\n      Action|Thriller\n      ...\n      2701.0\n      English\n      USA\n      PG-13\n      250000000.0\n      2012.0\n      23000.0\n      8.5\n      2.35\n      164000\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      NaN\n      131.0\n      NaN\n      Rob Walker\n      131.0\n      NaN\n      Documentary\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      7.1\n      NaN\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      1.0\n      87.0\n      2.0\n      318.0\n      Daphne Zuniga\n      637.0\n      NaN\n      Comedy|Drama\n      ...\n      6.0\n      English\n      Canada\n      NaN\n      NaN\n      2013.0\n      470.0\n      7.7\n      NaN\n      84\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      43.0\n      NaN\n      319.0\n      Valorie Curry\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      ...\n      359.0\n      English\n      USA\n      TV-14\n      NaN\n      NaN\n      593.0\n      7.5\n      16.00\n      32000\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      13.0\n      76.0\n      0.0\n      0.0\n      Maxwell Moody\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      ...\n      3.0\n      English\n      USA\n      NaN\n      1400.0\n      2013.0\n      0.0\n      6.3\n      NaN\n      16\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      14.0\n      100.0\n      0.0\n      489.0\n      Daniel Henney\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      ...\n      9.0\n      English\n      USA\n      PG-13\n      NaN\n      2012.0\n      719.0\n      6.3\n      2.35\n      660\n    \n    \n      4915\n      Color\n      Jon Gunn\n      43.0\n      90.0\n      16.0\n      16.0\n      Brian Herzlinger\n      86.0\n      85222.0\n      Documentary\n      ...\n      84.0\n      English\n      USA\n      PG\n      1100.0\n      2004.0\n      23.0\n      6.6\n      1.85\n      456\n    \n  \n\n4916 rows × 28 columns\n\n\n\n- 열의 이름을 출력하여 보자.\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\ndf.keys()\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#기본인덱싱-df-인덱싱공부-1단계-내용",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "기본인덱싱 (df 인덱싱공부 1단계 내용)",
    "text": "기본인덱싱 (df 인덱싱공부 1단계 내용)\n- color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. -> loc으로는 못하겠어요..\n\ndf.loc[:,['color':'num_voted_users','aspect_ratio']] # 이건 안됨.\n\nSyntaxError: invalid syntax (<ipython-input-7-0b4cb2e2977c>, line 1)\n\n\n\ndf.loc[:,'color':'num_voted_users'].head(2) # 이건 잘 됨.\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n    \n  \n\n\n\n\n- (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. \\(\\to\\) 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 \\(\\to\\) 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음\n\npd.Series(df.columns) ## 제일 편함.\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\nlist(range(13))+[26]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26]\n\n\n\ndf.iloc[:,list(range(13))+[26]].head(2)\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#actor라는-단어가-포함된-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "actor라는 단어가 포함된 column 선택",
    "text": "actor라는 단어가 포함된 column 선택\n- 다시 열의 이름들을 확인\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n- 방법1\n\n'actor' in 'actor_1_facebook_likes'\n\nTrue\n\n\n\n# list(map(lambda x: 'actor' in x, df.columns))\n\n\ndf.columns[list(map(lambda x: 'actor' in x, df.columns))]\n\nIndex(['actor_3_facebook_likes', 'actor_2_name', 'actor_1_facebook_likes',\n       'actor_1_name', 'actor_3_name', 'actor_2_facebook_likes'],\n      dtype='object')\n\n\n\ndf.iloc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법2\n\ndf.loc[:,list(map(lambda x : 'actor' in x, df.columns) )]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법3\n\ndf.iloc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns\n\n\n\n\n\n- 방법4\n\ndf.loc[:,map(lambda x : 'actor' in x, df.columns)]\n\n\n\n\n\n  \n    \n      \n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      actor_1_name\n      actor_3_name\n      actor_2_facebook_likes\n    \n  \n  \n    \n      0\n      855.0\n      Joel David Moore\n      1000.0\n      CCH Pounder\n      Wes Studi\n      936.0\n    \n    \n      1\n      1000.0\n      Orlando Bloom\n      40000.0\n      Johnny Depp\n      Jack Davenport\n      5000.0\n    \n    \n      2\n      161.0\n      Rory Kinnear\n      11000.0\n      Christoph Waltz\n      Stephanie Sigman\n      393.0\n    \n    \n      3\n      23000.0\n      Christian Bale\n      27000.0\n      Tom Hardy\n      Joseph Gordon-Levitt\n      23000.0\n    \n    \n      4\n      NaN\n      Rob Walker\n      131.0\n      Doug Walker\n      NaN\n      12.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      318.0\n      Daphne Zuniga\n      637.0\n      Eric Mabius\n      Crystal Lowe\n      470.0\n    \n    \n      4912\n      319.0\n      Valorie Curry\n      841.0\n      Natalie Zea\n      Sam Underwood\n      593.0\n    \n    \n      4913\n      0.0\n      Maxwell Moody\n      0.0\n      Eva Boehnke\n      David Chandler\n      0.0\n    \n    \n      4914\n      489.0\n      Daniel Henney\n      946.0\n      Alan Ruck\n      Eliza Coupe\n      719.0\n    \n    \n      4915\n      16.0\n      Brian Herzlinger\n      86.0\n      John August\n      Jon Gunn\n      23.0\n    \n  \n\n4916 rows × 6 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#s로-끝나는-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "s로 끝나는 column 선택",
    "text": "s로 끝나는 column 선택\n\n## 참고 (iterable object -> for문 안에 넣어서 돌릴 수 있다.)\n_map = df.loc[:,map(lambda x: x[-1] == 's', df.columns)]\nset(dir(_map)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\n_gen = iter(_map)\n\n\n_gen.__next__()\n\n'num_critic_for_reviews'\n\n\n\n_gen.__next__()\n\n'director_facebook_likes'\n\n\n- 방법1\n\ndf.iloc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 's' == x[-1],df.columns )]\n\n\n\n\n\n  \n    \n      \n      num_critic_for_reviews\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_1_facebook_likes\n      gross\n      genres\n      num_voted_users\n      cast_total_facebook_likes\n      plot_keywords\n      num_user_for_reviews\n      actor_2_facebook_likes\n      movie_facebook_likes\n    \n  \n  \n    \n      0\n      723.0\n      0.0\n      855.0\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      886204\n      4834\n      avatar|future|marine|native|paraplegic\n      3054.0\n      936.0\n      33000\n    \n    \n      1\n      302.0\n      563.0\n      1000.0\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      471220\n      48350\n      goddess|marriage ceremony|marriage proposal|pi...\n      1238.0\n      5000.0\n      0\n    \n    \n      2\n      602.0\n      0.0\n      161.0\n      11000.0\n      200074175.0\n      Action|Adventure|Thriller\n      275868\n      11700\n      bomb|espionage|sequel|spy|terrorist\n      994.0\n      393.0\n      85000\n    \n    \n      3\n      813.0\n      22000.0\n      23000.0\n      27000.0\n      448130642.0\n      Action|Thriller\n      1144337\n      106759\n      deception|imprisonment|lawlessness|police offi...\n      2701.0\n      23000.0\n      164000\n    \n    \n      4\n      NaN\n      131.0\n      NaN\n      131.0\n      NaN\n      Documentary\n      8\n      143\n      NaN\n      NaN\n      12.0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      1.0\n      2.0\n      318.0\n      637.0\n      NaN\n      Comedy|Drama\n      629\n      2283\n      fraud|postal worker|prison|theft|trial\n      6.0\n      470.0\n      84\n    \n    \n      4912\n      43.0\n      NaN\n      319.0\n      841.0\n      NaN\n      Crime|Drama|Mystery|Thriller\n      73839\n      1753\n      cult|fbi|hideout|prison escape|serial killer\n      359.0\n      593.0\n      32000\n    \n    \n      4913\n      13.0\n      0.0\n      0.0\n      0.0\n      NaN\n      Drama|Horror|Thriller\n      38\n      0\n      NaN\n      3.0\n      0.0\n      16\n    \n    \n      4914\n      14.0\n      0.0\n      489.0\n      946.0\n      10443.0\n      Comedy|Drama|Romance\n      1255\n      2386\n      NaN\n      9.0\n      719.0\n      660\n    \n    \n      4915\n      43.0\n      16.0\n      16.0\n      86.0\n      85222.0\n      Documentary\n      4285\n      163\n      actress name in title|crush|date|four word tit...\n      84.0\n      23.0\n      456\n    \n  \n\n4916 rows × 12 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#c-혹은-d로-시작하는-column-선택",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "c 혹은 d로 시작하는 column 선택",
    "text": "c 혹은 d로 시작하는 column 선택\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n_str = 'color'\n(_str[0] == 'c') or (_str[0] =='d')\n\nTrue\n\n\n\nlist(map(lambda x: (x[0] == 'c') or (x[0] =='d'), df.columns)) # list안해도 이미 iterable object.\n\n[True,\n True,\n False,\n True,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n True,\n False,\n False,\n False,\n False,\n False,\n False]\n\n\n- 방법1\n\ndf.iloc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns\n\n\n\n- 방법2\n\ndf.loc[:,map(lambda x: 'c' == x[0] or 'd' == x[0] ,df.columns )]\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      duration\n      director_facebook_likes\n      cast_total_facebook_likes\n      country\n      content_rating\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      178.0\n      0.0\n      4834\n      USA\n      PG-13\n    \n    \n      1\n      Color\n      Gore Verbinski\n      169.0\n      563.0\n      48350\n      USA\n      PG-13\n    \n    \n      2\n      Color\n      Sam Mendes\n      148.0\n      0.0\n      11700\n      UK\n      PG-13\n    \n    \n      3\n      Color\n      Christopher Nolan\n      164.0\n      22000.0\n      106759\n      USA\n      PG-13\n    \n    \n      4\n      NaN\n      Doug Walker\n      NaN\n      131.0\n      143\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4911\n      Color\n      Scott Smith\n      87.0\n      2.0\n      2283\n      Canada\n      NaN\n    \n    \n      4912\n      Color\n      NaN\n      43.0\n      NaN\n      1753\n      USA\n      TV-14\n    \n    \n      4913\n      Color\n      Benjamin Roberds\n      76.0\n      0.0\n      0\n      USA\n      NaN\n    \n    \n      4914\n      Color\n      Daniel Hsia\n      100.0\n      0.0\n      2386\n      USA\n      PG-13\n    \n    \n      4915\n      Color\n      Jon Gunn\n      90.0\n      16.0\n      163\n      USA\n      PG\n    \n  \n\n4916 rows × 7 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법1-concat",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법1-concat",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법1: concat",
    "text": "방법1: concat\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n_df = pd.DataFrame({'c':[3,4,5]}) \n_df\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      3\n    \n    \n      1\n      4\n    \n    \n      2\n      5\n    \n  \n\n\n\n\n\npd.concat([df,_df],axis=1)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법2-4가지-컨셉에-따른-할당",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법2: 4가지 컨셉에 따른 할당",
    "text": "방법2: 4가지 컨셉에 따른 할당\n\n# 컨셉1: 불가능\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.c = pd.Series([1,2,3]) \ndf\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n# 컨셉2: 가능\n(예시1) – 사실상 이렇게 해야함.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c']=[3,4,5]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) - 굳이 이렇게까지 할필요는 없음.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf[['c','d']]=np.array([[3,4,5],[4,5,6]]).T # 굳이.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf['c'],df['d']=[3,4,5],[4,5,6]\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n# 컨셉3: 불가능\n(예시1)\n\name({'a':[1,2,3],'b':[2,3,4]})\ndfdf = pd.DataFr\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.iloc[:,2] = [3,4,5] \ndf\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n# 컨셉4: 가능\n(예시1)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'] = [3,4,5] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n(예시2) – 굳이 쓸 필요가 없다.\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,['c','d']] = np.array([[3,4,5],[4,5,6]]).T # 이거 솔직히 되는지 몰랐어요.. \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n(예시3)\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'c'],df.loc[:,'d'] = [3,4,5],[4,5,6] \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법3-.assign으로-할당-star-제-최애",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애",
    "text": "방법3: .assign으로 할당 (\\(\\star\\)) – 제 최애\n\n확장성이 있고 다양한 상황에 사용하기 좋음.\n\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]) \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5],d=[4,5,6]) \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6]) # 1->2, 2->3 으로 가는 과정이 메모리 공간안에 모두 저장되어 있다.\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n오오오오 원래 df가 살아있음."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#방법4-.eval을-이용한-할당",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "방법4: .eval을 이용한 할당",
    "text": "방법4: .eval을 이용한 할당\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.eval('c=[3,4,5]').eval('d=[4,5,6]')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n이 방법은 좀 꺼려하는데 아래의 예제를 통해 이유를 알아보자."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#연습해보기",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#연습해보기",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "연습해보기",
    "text": "연습해보기\n\n# 데이터프레임 생성\n\ndf=pd.DataFrame({'x':np.random.randn(1000),'y':np.random.randn(1000)})\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -0.528686\n      -0.822504\n    \n    \n      1\n      -0.570925\n      0.177597\n    \n    \n      2\n      -2.095003\n      0.334422\n    \n    \n      3\n      -0.382900\n      0.573522\n    \n    \n      4\n      -0.971033\n      -1.840163\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      995\n      0.172025\n      -0.770867\n    \n    \n      996\n      -0.086068\n      -0.087574\n    \n    \n      997\n      0.691668\n      0.850134\n    \n    \n      998\n      -0.359600\n      0.913740\n    \n    \n      999\n      0.568702\n      -0.808420\n    \n  \n\n1000 rows × 2 columns\n\n\n\n\n\n# 새로운열 r을 생성하고 \\(r=\\sqrt{x^2 + y^2}\\)를 계산\n- 방법1: 브로드캐스팅\n\ndf.assign(r=np.sqrt(df.x**2 + df.y**2))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법2: lambda + map을 이용한 개별원소 계산\n\ndf.assign(r=list(map(lambda x,y: np.sqrt(x**2+y**2), df.x,df.y)))\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      1.085469\n      -1.427839\n      1.793590\n    \n    \n      1\n      -1.473272\n      -1.527442\n      2.122171\n    \n    \n      2\n      -1.007274\n      -1.312202\n      1.654229\n    \n    \n      3\n      1.220634\n      -0.474995\n      1.309796\n    \n    \n      4\n      -0.101496\n      1.636326\n      1.639470\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      -0.668557\n      -0.435391\n      0.797831\n    \n    \n      996\n      0.455894\n      0.796826\n      0.918026\n    \n    \n      997\n      -1.004412\n      1.843344\n      2.099229\n    \n    \n      998\n      -2.115145\n      -1.971965\n      2.891796\n    \n    \n      999\n      0.861141\n      -0.193742\n      0.882667\n    \n  \n\n1000 rows × 3 columns\n\n\n\n- 방법3: eval\n\ndf.eval('r=sqrt(x**2+y**2)')\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      r\n    \n  \n  \n    \n      0\n      -0.528686\n      -0.822504\n      0.977764\n    \n    \n      1\n      -0.570925\n      0.177597\n      0.597910\n    \n    \n      2\n      -2.095003\n      0.334422\n      2.121527\n    \n    \n      3\n      -0.382900\n      0.573522\n      0.689594\n    \n    \n      4\n      -0.971033\n      -1.840163\n      2.080650\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      0.172025\n      -0.770867\n      0.789828\n    \n    \n      996\n      -0.086068\n      -0.087574\n      0.122788\n    \n    \n      997\n      0.691668\n      0.850134\n      1.095962\n    \n    \n      998\n      -0.359600\n      0.913740\n      0.981954\n    \n    \n      999\n      0.568702\n      -0.808420\n      0.988415\n    \n  \n\n1000 rows × 3 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-17-7wk-1.html#toy-exam",
    "href": "posts/2_DV2022/2022-10-17-7wk-1.html#toy-exam",
    "title": "07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)",
    "section": "Toy exam",
    "text": "Toy exam\n- 교재의 예제상황은 예를들면 아래와 같다.\n(숨은진짜상황1)\n\\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\epsilon\\]\n\nnp.random.seed(1) \ntemp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, \n                25.4, 26.8, 28.9, 35.1, 32.2, 34.6])\neps= np.random.normal(size=12,scale=5)\nicecream= 20 + temp * 2 + eps\n\n\nplt.plot(temp,icecream,'.')\n\n\n\n\n\n온도와 아이스크림 판매량의 산점도\n\n(숨은진짜상황2)\n\\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\epsilon\\] - 좌변은 소아마비임을 나타내는 어떠한 반응수치라고 생각하자.\n\nnp.random.seed(2) \neps = np.random.normal(size=12,scale=5) \ndisease = 30+ temp* 0.5 + eps\n\n\nplt.plot(temp,disease,'.')\n\n\n\n\n\n온도와 소아마비의 산점도\n\n(우리가 데이터로부터 관측한 상황)\n- 아이스크림과 질병의 산점도를 그려보자.\n\nplt.plot(icecream,disease,'.')\n\n\n\n\n\n양의 상관관계에 있다.\n\n- 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. <– 여기서부터 틀렸음\n\\[{\\tt disease}_i =\\beta_0 +\\beta_1 {\\tt icecream}_i +\\epsilon_i,\\quad \\textbf{for} ~~ i=1,2,\\dots, 12\\]\n- 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. <– 틀린주장\n\n틀린 모형\n도데체 우리가 뭘 잘못했는가?\n\n- 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다.\n(ex1)\n\n온도 \\(\\to\\) 익사\n온도 \\(\\to\\) 아이스크림\n아이스크림과 익사자도 양의 상관관계에 있을것이다.\n아이스크림을 먹이면 물에 빠져 죽는다 \\(\\to\\) 틀린주장\n사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다.\n\n(ex2)\n\n인구수 \\(\\to\\) 교회\n인구수 \\(\\to\\) 범죄건수\n지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임\n교회를 지으면 범죄건수도 증가한다? \\(\\to\\) 틀린주장\n사실 인구가 숨겨진 요인임\n\n- ex2, ex1에 대하여 바른 분석을 하려면?\n\nex2: 인구가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄의 건수는 양의 상관관계에 있지 않을것임\nex1: 온도가 비슷한 그룹끼리 묶어보자.\n\n- 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. \\(\\to\\) 상관계수가 줄어들 것이다.\n\nplt.plot(icecream[:6],disease[:6],'.')\n\n\n\n\n\nplt.plot(icecream[6:],disease[6:],'.')\n\n\n\n\n\n진짜로 선형관계가 약해졌다.."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html",
    "title": "05wk-2",
    "section": "",
    "text": "훌륭한 시각화, mpg 데이터 소개, plotnine(p9)을 이용한 고차원 산점도"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#애드워드-터프티",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#애드워드-터프티",
    "title": "05wk-2",
    "section": "애드워드 터프티",
    "text": "애드워드 터프티\n- 데이터 시각화계의 거장\n- 터프티의 이론중 백미: 엄격한 미니멀리즘\n\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다.\n\n- 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량\n- 차트정크 (나이젤홈즈의 그래프)\n\n\n“Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (…) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (…) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.”\n\n\n차트정크 = 대중을 멸시 + 데이터에 대한 모독\n차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다..\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽\n\n- 제 생각: 글쎄…"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#찰스미나드의-도표",
    "title": "05wk-2",
    "section": "찰스미나드의 도표",
    "text": "찰스미나드의 도표\n\n인류역사상 가장 훌륭한 시각화\n\n\n- 터프티의 평\n\n지금까지 그려진 최고의 통계 그래픽일지도 모른다.\n여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 \\(\\to\\) 6차원의 변수\n백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. \\(\\to\\) 미니멀리즘..\n\n- 왜 우수한 그래프일까?\n\n자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존\n이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임\n미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#미나드처럼-그리는게-왜-어려운가",
    "title": "05wk-2",
    "section": "미나드처럼 그리는게 왜 어려운가?",
    "text": "미나드처럼 그리는게 왜 어려운가?\n- 몸무게, 키, 성별, 국적\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')  \ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv') \ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv')\n\n- 미나드의 접근방법\n\n_df = pd.concat([pd.concat([df1,df2],axis=1).assign(g='m'),df3.assign(g='f')])\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')]).reset_index(drop=True)\ndf\n\n\n\n\n\n  \n    \n      \n      w\n      h\n      g\n      g2\n    \n  \n  \n    \n      0\n      72.788217\n      183.486773\n      m\n      korea\n    \n    \n      1\n      66.606430\n      173.599877\n      m\n      korea\n    \n    \n      2\n      69.806324\n      173.237903\n      m\n      korea\n    \n    \n      3\n      67.449439\n      173.223805\n      m\n      korea\n    \n    \n      4\n      70.463183\n      174.931946\n      m\n      korea\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1525\n      78.154632\n      188.324350\n      m\n      foreign\n    \n    \n      1526\n      74.754308\n      183.017979\n      f\n      foreign\n    \n    \n      1527\n      91.196208\n      190.100456\n      m\n      foreign\n    \n    \n      1528\n      87.770394\n      187.987255\n      m\n      foreign\n    \n    \n      1529\n      88.021995\n      193.456798\n      m\n      foreign\n    \n  \n\n1530 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df,x='w',y='h',hue='g',style='g2')\n\n<AxesSubplot:xlabel='w', ylabel='h'>\n\n\n\n\n\n- 어려운점: (1) 센스가 없어서 hue/style을 이용하여 그룹을 구분할 생각을 못함 (2) long df (=tidy data) 형태로 데이터를 정리할 생각을 못함 (3) long df 형태로 데이터를 변형하는 코드를 모름\n\n\n기획력부족 -> 훌륭한 시각화를 많이 볼 것\n\n\n데이터프레임에 대한 이해부족 -> tidydata에 대한 개념\n\n\n프로그래밍 능력 -> 코딩공부열심히 (pandas를 엄청 잘해야함)"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법1-rpy2-코랩-아닌경우-실습금지",
    "title": "05wk-2",
    "section": "방법1: rpy2 (코랩 아닌경우 실습금지)",
    "text": "방법1: rpy2 (코랩 아닌경우 실습금지)\n\nimport rpy2\n%load_ext rpy2.ipython\n\n\n%%R \n### 여기는 R처럼 쓸 수 있다. \na <- c(1,2,3) \na+1\n\n[1] 2 3 4\n\n\n\na\n\nNameError: name 'a' is not defined\n\n\n\n%%R \nlibrary(tidyverse)\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nmpg\n\nNameError: name 'mpg' is not defined\n\n\n\n%R -o mpg # R에 있는 자료가 파이썬으로 넘어옴\n\n\nmpg\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      5\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      234\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법2-저장된-csv파일을-통하여-데이터를-확보",
    "title": "05wk-2",
    "section": "방법2: 저장된 csv파일을 통하여 데이터를 확보",
    "text": "방법2: 저장된 csv파일을 통하여 데이터를 확보\n\nmpg.to_csv(\"mpg.csv\",index=False)\n\n\npd.read_csv(\"mpg.csv\")\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#방법3-github등에-공개된-csv를-읽어오기",
    "title": "05wk-2",
    "section": "방법3: github등에 공개된 csv를 읽어오기",
    "text": "방법3: github등에 공개된 csv를 읽어오기\n\npd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\n\n\n\n\n\n  \n    \n      \n      manufacturer\n      model\n      displ\n      year\n      cyl\n      trans\n      drv\n      cty\n      hwy\n      fl\n      class\n    \n  \n  \n    \n      0\n      audi\n      a4\n      1.8\n      1999\n      4\n      auto(l5)\n      f\n      18\n      29\n      p\n      compact\n    \n    \n      1\n      audi\n      a4\n      1.8\n      1999\n      4\n      manual(m5)\n      f\n      21\n      29\n      p\n      compact\n    \n    \n      2\n      audi\n      a4\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      20\n      31\n      p\n      compact\n    \n    \n      3\n      audi\n      a4\n      2.0\n      2008\n      4\n      auto(av)\n      f\n      21\n      30\n      p\n      compact\n    \n    \n      4\n      audi\n      a4\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      compact\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      auto(s6)\n      f\n      19\n      28\n      p\n      midsize\n    \n    \n      230\n      volkswagen\n      passat\n      2.0\n      2008\n      4\n      manual(m6)\n      f\n      21\n      29\n      p\n      midsize\n    \n    \n      231\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      auto(l5)\n      f\n      16\n      26\n      p\n      midsize\n    \n    \n      232\n      volkswagen\n      passat\n      2.8\n      1999\n      6\n      manual(m5)\n      f\n      18\n      26\n      p\n      midsize\n    \n    \n      233\n      volkswagen\n      passat\n      3.6\n      2008\n      6\n      auto(s6)\n      f\n      17\n      26\n      p\n      midsize\n    \n  \n\n234 rows × 11 columns\n\n\n\n- 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다."
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#data-설명",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#data-설명",
    "title": "05wk-2",
    "section": "data 설명",
    "text": "data 설명\n- displ: 자동차의 엔진크기\n- hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐?\n- 자세한 설명은 R에서 ?mpg를 이용해 스스로 찾아볼 것"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-plotnine을-이용한-산점도",
    "title": "05wk-2",
    "section": "python에서: plotnine을 이용한 산점도",
    "text": "python에서: plotnine을 이용한 산점도\n\nggplot(data=mpg) + geom_point(mapping=aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726736046009)>\n\n\n\n산점도 해석: 엔진크기가 클수록 효율이 낮음.\n\n- 빠르게 그리기: data=와 mapping=은 생략가능함\n\nggplot(mpg) + geom_point(aes(x='displ',y='hwy')) ## plotnine\n\n\n\n\n<ggplot: (8726735544581)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#r에서-ggplot2를-이용한-산점도",
    "title": "05wk-2",
    "section": "R에서: ggplot2를 이용한 산점도",
    "text": "R에서: ggplot2를 이용한 산점도\n- R에서도 거의 똑같은 문법으로 그릴 수 있음 (데이터프레임 혹은 티블에 저장된 column 이름을 사용할때 따옴표만 제거하면 된다!)\n\n%%R -w 800\nggplot(mpg) + geom_point(aes(x=displ,y=hwy)) ## plotnine"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#python에서-객체지향적인-느낌으로-산점도-그리기",
    "title": "05wk-2",
    "section": "python에서: 객체지향적인 느낌으로 산점도 그리기",
    "text": "python에서: 객체지향적인 느낌으로 산점도 그리기\nstep1: 도화지를 준비한다.\n\nfig = ggplot(data=mpg)\nfig\n\n\n\n\n<ggplot: (8726735085529)>\n\n\nstep2 변수와 에스테틱사이의 맵핑을 설정한다.\n\na1= aes(x='displ',y='hwy')\na1\n\n{'x': 'displ', 'y': 'hwy'}\n\n\nstep3 점들의 집합을 만든다. 즉 포인트 지옴을 만든다.\n\npoint1=geom_point(mapping=a1)\n\n\ngeom_point(): 점들을 그려! 어떻게?\na1에서 설정된 표를 보고\n\nstep4 도화지와 지옴을 합친다.\n\nfig+point1\n\n\n\n\n<ggplot: (8726775447877)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경",
    "text": "산점도 + 점크기변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734563561)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도변경",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도변경",
    "title": "05wk-2",
    "section": "산점도 + 투명도변경",
    "text": "산점도 + 투명도변경\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734989121)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-투명도점크기를-동시에-적용",
    "title": "05wk-2",
    "section": "산점도 + 투명도/점크기를 동시에 적용",
    "text": "산점도 + 투명도/점크기를 동시에 적용\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',alpha='class',size='class'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_alpha.py:70: PlotnineWarning: Using alpha for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726734522405)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-형태",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-형태",
    "title": "05wk-2",
    "section": "산점도 + 형태",
    "text": "산점도 + 형태\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',shape='class'))\n\n\n\n\n<ggplot: (8726734265229)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔",
    "title": "05wk-2",
    "section": "산점도 + 색깔",
    "text": "산점도 + 색깔\n\nggplot(data=mpg) + geom_point(mapping = aes(x='displ',y='hwy',color='class'))\n\n\n\n\n<ggplot: (8726734017473)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#객체지향적-느낌으로",
    "title": "05wk-2",
    "section": "객체지향적 느낌으로?",
    "text": "객체지향적 느낌으로?\n\na2 = aes(x='displ', y='hwy', color='class') \n\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\npoint2=geom_point(a2)\n\n\nfig+point2\n\n\n\n\n<ggplot: (8726733712885)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-색깔-적합선",
    "title": "05wk-2",
    "section": "산점도 + 색깔 + 적합선",
    "text": "산점도 + 색깔 + 적합선\n- 일단 색깔이 없는 포인트 지옴부터 연습\n\nfig+point1\n\n\n\n\n<ggplot: (8726733452617)>\n\n\n\nline1 = geom_smooth(a1)\n\n\nfig+point1+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732994973)>\n\n\n- point1(색깔없는 포인트 지옴)을 point2(색깔있는 포인트 지옴)으로 언제든지 바꿔치기 가능!\n\nfig+point2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732661565)>\n\n\n- 명령어로 한번에 그리기\n\nggplot(data=mpg) + \\\ngeom_point(mapping=aes(x='displ',y='hwy',color='class')) + \\\ngeom_smooth(mapping=aes(x='displ',y='hwy'))\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732727485)>\n\n\n- 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함)\n\nggplot(data=mpg,mapping=aes(x='displ',y='hwy')) + \\\ngeom_point(mapping=aes(color='class')) + \\\ngeom_smooth()\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733489953)>\n\n\n- R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다.\n\n%%R -w 800\nggplot(data=mpg,mapping=aes(x=displ,y=hwy)) + geom_point(mapping=aes(color=class)) + geom_smooth()\n\nR[write to console]: `geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔",
    "text": "산점도 + 점크기변경 + 색깔\n- drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다.\n\nggplot(data=mpg, mapping=aes(x='displ',y='hwy')) + geom_point(mapping=aes(size='class',color='drv'),alpha=0.3)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731152845)>\n\n\n\n모든 \\(x\\)에 대하여 붉은색 점들이 대부분 초록색과 보라색 점들에 비하여 아래쪽에 있음 \\(\\to\\) 4륜구동방식이 연비가 좋지 않음"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-객체지향버전",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 (객체지향버전)",
    "text": "산점도 + 점크기변경 + 색깔 (객체지향버전)\n- 맵핑규칙\n\na1,a2\n\n({'x': 'displ', 'y': 'hwy'}, {'x': 'displ', 'y': 'hwy', 'color': 'class'})\n\n\n\na3 = a2.copy() \n\n\na3['color'] = 'drv'\na3['size'] = 'class'\na3\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'}\n\n\n\n아래와 같이 선언해도 괜찮음\n\na3= aes(x='displ',y='hwy',color='drv',size='class')\n\npoint3=geom_point(a3)\n\n\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726731065581)>\n\n\n\n그림의 전체적인 투명도를 조절하면 좋겠음\n\n\npoint3=geom_point(a3,alpha=0.2)\nfig+point3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n<ggplot: (8726730819657)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + 선추가\n\nfig+point3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726730575253)>"
  },
  {
    "objectID": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "href": "posts/2_DV2022/2022-10-06-5wk-2.html#산점도-점크기변경-색깔-drv별로-선추가",
    "title": "05wk-2",
    "section": "산점도 + 점크기변경 + 색깔 + drv별로 선추가",
    "text": "산점도 + 점크기변경 + 색깔 + drv별로 선추가\n- 맵핑규칙\n\na1,a2,a3\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'})\n\n\n\na4 = a2.copy() \na4['color']='drv'\na4\n\n{'x': 'displ', 'y': 'hwy', 'color': 'drv'}\n\n\n\nline2 = geom_smooth(a4)\n\n\nfig + point3 +line2\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726729919385)>\n\n\n- 선의 색깔을 동일하게 하고 선의 타입을 변경하여 drv를 표시하고 싶다면?\n\na1,a2,a3,a4\n\n({'x': 'displ', 'y': 'hwy'},\n {'x': 'displ', 'y': 'hwy', 'color': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv', 'size': 'class'},\n {'x': 'displ', 'y': 'hwy', 'color': 'drv'})\n\n\n\na5=a1.copy()\na5['linetype']='drv' \na5\n\n{'x': 'displ', 'y': 'hwy', 'linetype': 'drv'}\n\n\n\nline3 = geom_smooth(a5,size=0.5,color='gray')\n\n\nfig+point3+line3\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732637457)>\n\n\n- 전체적인 추세선도 추가하고 싶다면?\n\nfig+point3+line3+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726732939513)>\n\n\n- 그려보니까 역시 drv별로 그려지는 추세선은 색깔별로 구분하는게 좋겠음.\n\nline2 = geom_smooth(a4,size=0.5,linetype='dashed')\nfig+point3+line2+line1\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/scales/scale_size.py:50: PlotnineWarning: Using size for a discrete variable is not advised.\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/plotnine/stats/smoothers.py:311: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings.\n\n\n\n\n\n<ggplot: (8726733678229)>\n\n\n- 고차원을 변수를 표현할 수 있는 무기는 다양하다.\n\n산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도\n라인플랏(스무스지옴,라인지옴): 선의형태, 선의색깔, 선의굵기"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_07_(1주차)_3월7일.html",
    "href": "posts/3_STBDA2022/2022_03_07_(1주차)_3월7일.html",
    "title": "[STBDA] 1wk. 강의소개 및 단순선형회귀",
    "section": "",
    "text": "(1주차) 3월7일\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yKGpQh49tnRrA-o2Odea8r\n\n\n\n강의보충자료\n- https://github.com/guebin/STBDA2022/blob/master/_notebooks/2022-03-07-supp1.pdf\n- https://github.com/guebin/STBDA2022/blob/master/_notebooks/2022-03-07-supp2.pdf\n\n\n로드맵\n- 오늘수업할내용: 단순선형회귀\n- 단순선형회귀를 배우는 이유?\n\n우리가 배우고싶은것: 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN) \\(\\to\\) 적대적생성신경망(GAN)\n심층신경망을 바로 이해하기 어려움\n다음의 과정으로 이해해야함: (선형대수학 \\(\\to\\)) 회귀분석 \\(\\to\\) 로지스틱회귀분석 \\(\\to\\) 심층신경망\n\n\n\n선형회귀\n- 상황극 - 나는 동네에 커피점을 하나 차렸음. - 장사를 하다보니까 날이 더울수록 아이스아메리카노의 판매량이 증가한다는 사실을 깨달았다. - 일기예보는 미리 나와있으니까 그 정보를 잘 이용하면 ‘온도 -> 아이스아메리카노 판매량 예측’ 이 가능할것 같다. (내가 앞으로 얼마나 벌지 예측가능)\n- 가짜자료 생성\n\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \n\n온도 \\({\\bf x}\\)가 아래와 같다고 하자.\n\nx=tf.constant([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) # 기온 \nx\n\n<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4],\n      dtype=float32)>\n\n\n아이스아메리카노의 판매량 \\({\\bf y}\\)이 아래와 같다고 하자. (판매량은 정수로 나오겠지만 편의상 소수점도 가능하다고 생각하자)\n\\[{\\bf y} \\approx 10.2 +2.2 {\\bf x}\\]\n\n여기에서 10.2, 2.2 의 숫자는 제가 임의로 정한것임\n식의의미: 온도가 0일때 10.2잔정도 팔림 + 온도가 1도 증가하면 2.2잔정도 더 팔림\n물결의의미: 현실반영. 세상은 꼭 수식대로 정확하게 이루어지지 않음.\n\n\ntf.random.set_seed(43052)\nepsilon=tf.random.normal([10])\ny=10.2 + 2.2*x + epsilon\ny\n\n<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([55.418365, 58.194283, 61.230827, 62.312557, 63.107002, 63.69569 ,\n       67.247055, 71.4365  , 73.1013  , 77.84988 ], dtype=float32)>\n\n\n- 우리는 아래와 같은 자료를 모았다고 생각하자.\n\ntf.transpose(tf.concat([[x],[y]],0))\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[20.1     , 55.418365],\n       [22.2     , 58.194283],\n       [22.7     , 61.230827],\n       [23.3     , 62.312557],\n       [24.4     , 63.107002],\n       [25.1     , 63.69569 ],\n       [26.2     , 67.247055],\n       [27.3     , 71.4365  ],\n       [28.4     , 73.1013  ],\n       [30.4     , 77.84988 ]], dtype=float32)>\n\n\n- 그려보자.\n\nplt.plot(x,y,'.') # 파란점, 관측한 데이터 \nplt.plot(x,10.2 + 2.2*x, '--')  # 주황색점선, 세상의 법칙 \n\n\n\n\n- 우리의 목표: 파란색점 \\(\\to\\) 주황색점선을 추론 // 데이터를 바탕으로 세상의 법칙을 추론\n- 아이디어: 데이터를 보니까 \\(x\\)와 \\(y\\)가 선형의 관계에 있는듯 보인다. 즉 모든 \\(i=1,2,\\dots, 10\\)에 대하여 아래를 만족하는 적당한 a,b (혹은 \\(\\beta_0,\\beta_1\\)) 가 존재할것 같다. - \\(y_{i} \\approx ax_{i}+b\\) - \\(y_{i} \\approx \\beta_1 x_{i}+\\beta_0\\)\n- 어림짐작으로 \\(a,b\\)를 알아내보자.\n데이터를 살펴보자.\n\ntf.transpose(tf.concat([[x],[y]],0))\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[20.1     , 55.418365],\n       [22.2     , 58.194283],\n       [22.7     , 61.230827],\n       [23.3     , 62.312557],\n       [24.4     , 63.107002],\n       [25.1     , 63.69569 ],\n       [26.2     , 67.247055],\n       [27.3     , 71.4365  ],\n       [28.4     , 73.1013  ],\n       [30.4     , 77.84988 ]], dtype=float32)>\n\n\n적당히 왼쪽*2+15 = 오른쪽의 관계가 성립하는것 같다.\n따라서 \\(a=2, b=15\\) 혹은 \\(\\beta_0=15, \\beta_1=2\\) 로 추론할 수 있겠다.\n- 누군가가 \\((\\beta_0,\\beta_1)=(14,2)\\) 이라고 주장할 수 있다. (어차피 지금은 감각으로 추론하는 과정이니까)\n- 새로운 주장으로 인해서 \\((\\beta_0,\\beta_1)=(15,2)\\) 로 볼 수도 있고 \\((\\beta_0,\\beta_1)=(14,2)\\) 로 볼 수도 있다. 이중에서 어떠한 추정치가 좋은지 판단할 수 있을까? - 후보1: \\((\\beta_0,\\beta_1)=(15,2)\\) - 후보2: \\((\\beta_0,\\beta_1)=(14,2)\\)\n- 가능한 \\(y_i \\approx \\beta_0 + \\beta_1 x_i\\) 이 되도록 만드는 \\((\\beta_0,\\beta_1)\\) 이 좋을 것이다. \\(\\to\\) 후보 1,2를 비교해보자.\n(관찰에 의한 비교)\n후보1에 대해서 \\(i=1,2\\)를 넣고 관찰하여 보자.\n\n20.1 * 2 + 15 , 55.418365 # i=1 \n\n(55.2, 55.418365)\n\n\n\n22.2 * 2 + 15 , 58.194283 # i=2\n\n(59.4, 58.194283)\n\n\n후보2에 대하여 \\(i=1,2\\)를 넣고 관찰하여 보자.\n\n20.1 * 2 + 14 , 55.418365 # i=1 \n\n(54.2, 55.418365)\n\n\n\n22.2 * 2 + 14 , 58.194283 # i=2\n\n(58.4, 58.194283)\n\n\n\\(i=1\\)인 경우에는 후보1이 더 잘맞는것 같은데 \\(i=2\\)인 경우는 후보2가 더 잘맞는것 같다.\n(좀 더 체계적인 비교)\n\\(i=1,2,3, \\dots, 10\\) 에서 후보1과 후보2중 어떤것이 더 좋은지 비교하는 체계적인 방법을 생각해보자.\n후보 1,2에 대하여 \\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)를 계산하여 비교해보자.\n\nsum1=0 \nfor i in range(10):\n    sum1=sum1+(y[i]-15-2*x[i])**2 \n\n\nsum2=0 \nfor i in range(10):\n    sum2=sum2+(y[i]-14-2*x[i])**2 \n\n\nsum1,sum2\n\n(<tf.Tensor: shape=(), dtype=float32, numpy=14.734169>,\n <tf.Tensor: shape=(), dtype=float32, numpy=31.521086>)\n\n\n후보1이 더 \\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)의 값이 작다.\n후보1이 종합적으로 후보2에 비하여 좋다. 이 과정을 무한번 반복하면 최적의 추정치를 찾을 수 있다.\n- 그런데 이 알고리즘은 현실적으로 구현이 불가능하다. (무한번 계산하기도 힘들고, 언제 멈출지도 애매함)\n- 수학을 이용해서 좀 더 체계적으로 찾아보자. 결국 아래식을 가장 작게 만드는 \\(\\beta_0,\\beta_1\\)을 찾으면 된다.\n\\(\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2\\)\n그런데 결국 \\(\\beta_0, \\beta_1\\)에 대한 이차식인데 이 식을 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하기 위해서는 아래를 연립하여 풀면된다.\n\\(\\begin{cases} \\frac{\\partial}{\\partial \\beta_0}\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2=0 \\\\ \\frac{\\partial}{\\partial \\beta_1}\\sum_{i=1}^{10} (y_i -\\beta_0 -\\beta_1 x_i)^2=0 \\end{cases}\\)\n- 풀어보자.\n\\(\\begin{cases} \\sum_{i=1}^{10} -2(y_i -\\beta_0 -\\beta_1 x_i)=0 \\\\ \\sum_{i=1}^{10} -2x_i(y_i -\\beta_0 -\\beta_1 x_i)=0 \\end{cases}\\)\n정리하면\n\\[\\hat{\\beta}_0= \\bar{y}-\\hat{\\beta}_1 \\bar{x}\\]\n\\[\\hat{\\beta}_1= \\frac{S_{xy}}{S_{xx}}=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\]\n- 따라서 최적의 추정치 \\((\\hat{\\beta}_0,\\hat{\\beta}_1)\\)를 이용한 추세선을 아래와 같이 계산할 수 있음.\n\nSxx= sum((x-sum(x)/10)**2)\nSxx\n\n<tf.Tensor: shape=(), dtype=float32, numpy=87.84898>\n\n\n\nSxy=  sum((x-sum(x)/10)*(y-sum(y)/10))\nSxy\n\n<tf.Tensor: shape=(), dtype=float32, numpy=194.64737>\n\n\n\nbeta1_estimated = Sxy/Sxx \nbeta1_estimated \n\n<tf.Tensor: shape=(), dtype=float32, numpy=2.2157042>\n\n\n\nbeta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 \nbeta0_estimated\n\n<tf.Tensor: shape=(), dtype=float32, numpy=9.94458>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,beta0_estimated + beta1_estimated * x, '--') # 주황색선: 세상의 법칙을 추정한선 \nplt.plot(x,10.2 + 2.2* x, '--') # 초록색선: ture, 세상의법칙 \n\n\n\n\n\nNote: 샘플수가 커질수록 주황색선은 점점 초록색선으로 가까워진다.\n\n- 꽤 훌륭한 도구임. 그런데 약간의 단점이 존재한다.\n\n공식이 좀 복잡함..\n\\(x\\)가 여러개일 경우 확장이 어려움\n\n- 단점을 극복하기 위해서 우리가 지금까지 했던논의를 매트릭스로 바꾸어서 다시 써보자.\n- 모형의 매트릭스화\n우리의 모형은 아래와 같다.\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad i=1,2,\\dots,10\\)\n풀어서 쓰면\n\\(\\begin{cases} y_1 = \\beta_0 +\\beta_1 x_1 + \\epsilon_1 \\\\ y_2 = \\beta_0 +\\beta_1 x_2 + \\epsilon_2 \\\\ \\dots \\\\ y_{10} = \\beta_0 +\\beta_1 x_{10} + \\epsilon_{10} \\end{cases}\\)\n아래와 같이 쓸 수 있다.\n$\n\\[\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\dots \\\\\ny_{10}\n\\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\dots & \\dots \\\\\n1 & x_{10}\n\\end{bmatrix}\\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\dots \\\\\n\\epsilon_{10}\n\\end{bmatrix}\\]\n$\n\n벡터와 매트릭스 형태로 정리하면\n\\({\\bf y} = {\\bf X} {\\boldsymbol \\beta} + \\boldsymbol{\\epsilon}\\)\n- 손실함수의 매트릭스화: 우리가 최소화 하려던 손실함수는 아래와 같다.\n\\(loss=\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2\\)\n이것을 벡터표현으로 하면 아래와 같다.\n\\(loss=\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2=({\\bf y}-{\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y}-{\\bf X}{\\boldsymbol \\beta})\\)\n풀어보면\n\\(loss=({\\bf y}-{\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y}-{\\bf X}{\\boldsymbol \\beta})={\\bf y}^\\top {\\bf y} - {\\bf y}^\\top {\\bf X}{\\boldsymbol\\beta} - {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf y} + {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf X} {\\boldsymbol\\beta}\\)\n- 미분하는 과정의 매트릭스화\nloss를 최소화하는 \\({\\boldsymbol \\beta}\\)를 구해야하므로 loss를 \\({\\boldsymbol \\beta}\\)로 미분한식을 0이라고 놓고 풀면 된다.\n\\(\\frac{\\partial}{\\partial \\boldsymbol{\\beta}} loss = \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\bf y}^\\top {\\bf y} - \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\bf y}^\\top {\\bf X}{\\boldsymbol\\beta} - \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf y} + \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf X} {\\boldsymbol\\beta}\\)\n$= 0 - {}^- {}^ + 2{}^ $\n따라서 \\(\\frac{\\partial}{\\partial \\boldsymbol{\\beta}}loss=0\\)을 풀면 아래와 같다.\n$= ({}){-1}{}^ $\n- 공식도 매트릭스로 표현하면: $= ({}){-1}{}^ $ <– 외우세요\n- 적용을 해보자.\n(X를 만드는 방법1)\n\nX=tf.transpose(tf.concat([[[1.0]*10],[x]],0)) # \nX \n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[ 1. , 20.1],\n       [ 1. , 22.2],\n       [ 1. , 22.7],\n       [ 1. , 23.3],\n       [ 1. , 24.4],\n       [ 1. , 25.1],\n       [ 1. , 26.2],\n       [ 1. , 27.3],\n       [ 1. , 28.4],\n       [ 1. , 30.4]], dtype=float32)>\n\n\n(X를 만드는 방법2)\n\nfrom tensorflow.python.ops.numpy_ops import np_config\nnp_config.enable_numpy_behavior()\n\n\nX=tf.concat([[[1.0]*10],[x]],0).T\nX\n\n<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\narray([[ 1. , 20.1],\n       [ 1. , 22.2],\n       [ 1. , 22.7],\n       [ 1. , 23.3],\n       [ 1. , 24.4],\n       [ 1. , 25.1],\n       [ 1. , 26.2],\n       [ 1. , 27.3],\n       [ 1. , 28.4],\n       [ 1. , 30.4]], dtype=float32)>\n\n\n\ntf.linalg.inv(X.T @ X) @ X.T @ y\n\n<tf.Tensor: shape=(2,), dtype=float32, numpy=array([9.945175 , 2.2156773], dtype=float32)>\n\n\n- 잘 구해진다.\n- 그런데..\n\nbeta0_estimated,beta1_estimated\n\n(<tf.Tensor: shape=(), dtype=float32, numpy=9.94458>,\n <tf.Tensor: shape=(), dtype=float32, numpy=2.2157042>)\n\n\n값이 좀 다르다..?\n- 같은 값입니다! 신경쓰지 마세요! 텐서플로우가 좀 대충계산합니다.\n\nimport tensorflow.experimental.numpy as tnp \n\n\nx=tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]) \ny=10.2 + 2.2*x + epsilon \n\n\nbeta1_estimated = sum((x-sum(x)/10)*(y-sum(y)/10)) / sum((x-sum(x)/10)**2)\nbeta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 \n\n\nbeta0_estimated, beta1_estimated\n\n(<tf.Tensor: shape=(), dtype=float64, numpy=9.944573243234018>,\n <tf.Tensor: shape=(), dtype=float64, numpy=2.215704607783491>)\n\n\n\nX=tnp.concatenate([[tnp.array([1.0]*10)],[x]],0).T\ntf.linalg.inv(X.T @ X) @ X.T @ y\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([9.94457324, 2.21570461])>\n\n\n\n\n앞으로 할것\n- 선형대수학의 미분이론..\n- 실습 (tensorflow에서 매트릭스를 자유롭게 다루비)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_21_(3주차)_3월21일.html",
    "href": "posts/3_STBDA2022/2022_03_21_(3주차)_3월21일.html",
    "title": "[STBDA] 3wk. 텐서플로우 intro2",
    "section": "",
    "text": "(3주차) 3월21일\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yCZH5zqsORTEkCZ082SCYc\n\n\n\nimports\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\n\n\n\n지난강의 보충\n- max, min, sum, mean\n\na= tf.constant([1.0,2.0,3.0,4.0])\na\n\n<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>\n\n\n\ntf.reduce_mean(a)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=2.5>\n\n\n\nconcat, stack\n- 예제: (2,3,4,5) stack (2,3,4,5) -> (?,?,?,?,?)\n\na = tf.reshape(tf.constant(range(2*3*4*5)),(2,3,4,5))\nb = -a \n\n\nTip: 총 5가지 case가 있다. case1 (1,2,3,4,5) stack (1,2,3,4,5) –> (2,2,3,4,5) # axis=0  case2 (2,1,3,4,5) stack (2,1,3,4,5) –> (2,2,3,4,5) # axis=1  case3 (2,3,1,4,5) stack (2,3,1,4,5) –> (2,3,2,4,5) # axis=2  case4 (2,3,4,1,5) stack (2,3,4,1,5) –> (2,3,4,2,5) # axis=3  case5 (2,3,4,5,1) stack (2,3,4,5,1) –> (2,3,4,5,2) # axis=4\n\ncase1 (1,2,3,4,5) stack (1,2,3,4,5) –> (2,2,3,4,5) # axis=0\n\ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]]],\n\n\n\n       [[[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase2 (2,1,3,4,5) stack (2,1,3,4,5) –> (2,2,3,4,5) # axis=1\n\ntf.stack([a,b],axis=1)\n\n<tf.Tensor: shape=(2, 2, 3, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]]],\n\n\n        [[[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]]],\n\n\n        [[[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase3 (2,3,1,4,5) stack (2,3,1,4,5) –> (2,3,2,4,5) # axis=2\n\ntf.stack([a,b],axis=2)\n\n<tf.Tensor: shape=(2, 3, 2, 4, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   5,    6,    7,    8,    9],\n          [  10,   11,   12,   13,   14],\n          [  15,   16,   17,   18,   19]],\n\n         [[   0,   -1,   -2,   -3,   -4],\n          [  -5,   -6,   -7,   -8,   -9],\n          [ -10,  -11,  -12,  -13,  -14],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [  25,   26,   27,   28,   29],\n          [  30,   31,   32,   33,   34],\n          [  35,   36,   37,   38,   39]],\n\n         [[ -20,  -21,  -22,  -23,  -24],\n          [ -25,  -26,  -27,  -28,  -29],\n          [ -30,  -31,  -32,  -33,  -34],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [  45,   46,   47,   48,   49],\n          [  50,   51,   52,   53,   54],\n          [  55,   56,   57,   58,   59]],\n\n         [[ -40,  -41,  -42,  -43,  -44],\n          [ -45,  -46,  -47,  -48,  -49],\n          [ -50,  -51,  -52,  -53,  -54],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [  65,   66,   67,   68,   69],\n          [  70,   71,   72,   73,   74],\n          [  75,   76,   77,   78,   79]],\n\n         [[ -60,  -61,  -62,  -63,  -64],\n          [ -65,  -66,  -67,  -68,  -69],\n          [ -70,  -71,  -72,  -73,  -74],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [  85,   86,   87,   88,   89],\n          [  90,   91,   92,   93,   94],\n          [  95,   96,   97,   98,   99]],\n\n         [[ -80,  -81,  -82,  -83,  -84],\n          [ -85,  -86,  -87,  -88,  -89],\n          [ -90,  -91,  -92,  -93,  -94],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [ 105,  106,  107,  108,  109],\n          [ 110,  111,  112,  113,  114],\n          [ 115,  116,  117,  118,  119]],\n\n         [[-100, -101, -102, -103, -104],\n          [-105, -106, -107, -108, -109],\n          [-110, -111, -112, -113, -114],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase4 (2,3,4,1,5) stack (2,3,4,1,5) –> (2,3,4,2,5) # axis=3\n\ntf.stack([a,b],axis=-2).shape\n\nTensorShape([2, 3, 4, 2, 5])\n\n\n\ntf.stack([a,b],axis=-2)\n\n<tf.Tensor: shape=(2, 3, 4, 2, 5), dtype=int32, numpy=\narray([[[[[   0,    1,    2,    3,    4],\n          [   0,   -1,   -2,   -3,   -4]],\n\n         [[   5,    6,    7,    8,    9],\n          [  -5,   -6,   -7,   -8,   -9]],\n\n         [[  10,   11,   12,   13,   14],\n          [ -10,  -11,  -12,  -13,  -14]],\n\n         [[  15,   16,   17,   18,   19],\n          [ -15,  -16,  -17,  -18,  -19]]],\n\n\n        [[[  20,   21,   22,   23,   24],\n          [ -20,  -21,  -22,  -23,  -24]],\n\n         [[  25,   26,   27,   28,   29],\n          [ -25,  -26,  -27,  -28,  -29]],\n\n         [[  30,   31,   32,   33,   34],\n          [ -30,  -31,  -32,  -33,  -34]],\n\n         [[  35,   36,   37,   38,   39],\n          [ -35,  -36,  -37,  -38,  -39]]],\n\n\n        [[[  40,   41,   42,   43,   44],\n          [ -40,  -41,  -42,  -43,  -44]],\n\n         [[  45,   46,   47,   48,   49],\n          [ -45,  -46,  -47,  -48,  -49]],\n\n         [[  50,   51,   52,   53,   54],\n          [ -50,  -51,  -52,  -53,  -54]],\n\n         [[  55,   56,   57,   58,   59],\n          [ -55,  -56,  -57,  -58,  -59]]]],\n\n\n\n       [[[[  60,   61,   62,   63,   64],\n          [ -60,  -61,  -62,  -63,  -64]],\n\n         [[  65,   66,   67,   68,   69],\n          [ -65,  -66,  -67,  -68,  -69]],\n\n         [[  70,   71,   72,   73,   74],\n          [ -70,  -71,  -72,  -73,  -74]],\n\n         [[  75,   76,   77,   78,   79],\n          [ -75,  -76,  -77,  -78,  -79]]],\n\n\n        [[[  80,   81,   82,   83,   84],\n          [ -80,  -81,  -82,  -83,  -84]],\n\n         [[  85,   86,   87,   88,   89],\n          [ -85,  -86,  -87,  -88,  -89]],\n\n         [[  90,   91,   92,   93,   94],\n          [ -90,  -91,  -92,  -93,  -94]],\n\n         [[  95,   96,   97,   98,   99],\n          [ -95,  -96,  -97,  -98,  -99]]],\n\n\n        [[[ 100,  101,  102,  103,  104],\n          [-100, -101, -102, -103, -104]],\n\n         [[ 105,  106,  107,  108,  109],\n          [-105, -106, -107, -108, -109]],\n\n         [[ 110,  111,  112,  113,  114],\n          [-110, -111, -112, -113, -114]],\n\n         [[ 115,  116,  117,  118,  119],\n          [-115, -116, -117, -118, -119]]]]], dtype=int32)>\n\n\ncase5 (2,3,4,5,1) stack (2,3,4,5,1) –> (2,3,4,5,2) # axis=4\n\ntf.stack([a,b],axis=-1).shape\n\nTensorShape([2, 3, 4, 5, 2])\n\n\n\ntf.stack([a,b],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 5, 2), dtype=int32, numpy=\narray([[[[[   0,    0],\n          [   1,   -1],\n          [   2,   -2],\n          [   3,   -3],\n          [   4,   -4]],\n\n         [[   5,   -5],\n          [   6,   -6],\n          [   7,   -7],\n          [   8,   -8],\n          [   9,   -9]],\n\n         [[  10,  -10],\n          [  11,  -11],\n          [  12,  -12],\n          [  13,  -13],\n          [  14,  -14]],\n\n         [[  15,  -15],\n          [  16,  -16],\n          [  17,  -17],\n          [  18,  -18],\n          [  19,  -19]]],\n\n\n        [[[  20,  -20],\n          [  21,  -21],\n          [  22,  -22],\n          [  23,  -23],\n          [  24,  -24]],\n\n         [[  25,  -25],\n          [  26,  -26],\n          [  27,  -27],\n          [  28,  -28],\n          [  29,  -29]],\n\n         [[  30,  -30],\n          [  31,  -31],\n          [  32,  -32],\n          [  33,  -33],\n          [  34,  -34]],\n\n         [[  35,  -35],\n          [  36,  -36],\n          [  37,  -37],\n          [  38,  -38],\n          [  39,  -39]]],\n\n\n        [[[  40,  -40],\n          [  41,  -41],\n          [  42,  -42],\n          [  43,  -43],\n          [  44,  -44]],\n\n         [[  45,  -45],\n          [  46,  -46],\n          [  47,  -47],\n          [  48,  -48],\n          [  49,  -49]],\n\n         [[  50,  -50],\n          [  51,  -51],\n          [  52,  -52],\n          [  53,  -53],\n          [  54,  -54]],\n\n         [[  55,  -55],\n          [  56,  -56],\n          [  57,  -57],\n          [  58,  -58],\n          [  59,  -59]]]],\n\n\n\n       [[[[  60,  -60],\n          [  61,  -61],\n          [  62,  -62],\n          [  63,  -63],\n          [  64,  -64]],\n\n         [[  65,  -65],\n          [  66,  -66],\n          [  67,  -67],\n          [  68,  -68],\n          [  69,  -69]],\n\n         [[  70,  -70],\n          [  71,  -71],\n          [  72,  -72],\n          [  73,  -73],\n          [  74,  -74]],\n\n         [[  75,  -75],\n          [  76,  -76],\n          [  77,  -77],\n          [  78,  -78],\n          [  79,  -79]]],\n\n\n        [[[  80,  -80],\n          [  81,  -81],\n          [  82,  -82],\n          [  83,  -83],\n          [  84,  -84]],\n\n         [[  85,  -85],\n          [  86,  -86],\n          [  87,  -87],\n          [  88,  -88],\n          [  89,  -89]],\n\n         [[  90,  -90],\n          [  91,  -91],\n          [  92,  -92],\n          [  93,  -93],\n          [  94,  -94]],\n\n         [[  95,  -95],\n          [  96,  -96],\n          [  97,  -97],\n          [  98,  -98],\n          [  99,  -99]]],\n\n\n        [[[ 100, -100],\n          [ 101, -101],\n          [ 102, -102],\n          [ 103, -103],\n          [ 104, -104]],\n\n         [[ 105, -105],\n          [ 106, -106],\n          [ 107, -107],\n          [ 108, -108],\n          [ 109, -109]],\n\n         [[ 110, -110],\n          [ 111, -111],\n          [ 112, -112],\n          [ 113, -113],\n          [ 114, -114]],\n\n         [[ 115, -115],\n          [ 116, -116],\n          [ 117, -117],\n          [ 118, -118],\n          [ 119, -119]]]]], dtype=int32)>\n\n\n- 예제: (2,3,4), (2,3,4), (2,3,4)\n\na= tf.reshape(tf.constant(range(2*3*4)),(2,3,4))\nb= -a \nc= 2*a\n\n(예시1) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (6,3,4)\n\ntf.concat([a,b,c],axis=0)\n\n<tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)>\n\n\n(예시2) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,9,4)\n\ntf.concat([a,b,c],axis=1)\n\n<tf.Tensor: shape=(2, 9, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11],\n        [  0,   2,   4,   6],\n        [  8,  10,  12,  14],\n        [ 16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23],\n        [ 24,  26,  28,  30],\n        [ 32,  34,  36,  38],\n        [ 40,  42,  44,  46]]], dtype=int32)>\n\n\n(예시3) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,12)\n\ntf.concat([a,b,c],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 12), dtype=int32, numpy=\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3,   0,   2,   4,   6],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7,   8,  10,  12,  14],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11,  16,  18,  20,  22]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15,  24,  26,  28,  30],\n        [ 16,  17,  18,  19, -16, -17, -18, -19,  32,  34,  36,  38],\n        [ 20,  21,  22,  23, -20, -21, -22, -23,  40,  42,  44,  46]]],\n      dtype=int32)>\n\n\n(예시4) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (3,2,3,4)\n\n축이 늘어난 경우\n\n\ntf.stack([a,b,c],axis=0)\n\n<tf.Tensor: shape=(3, 2, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]]],\n\n\n       [[[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]]],\n\n\n       [[[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시5) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=1).shape\n\nTensorShape([2, 3, 3, 4])\n\n\n\ntf.stack([a,b,c],axis=1)\n\n<tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[  0,  -1,  -2,  -3],\n         [ -4,  -5,  -6,  -7],\n         [ -8,  -9, -10, -11]],\n\n        [[  0,   2,   4,   6],\n         [  8,  10,  12,  14],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [ 16,  17,  18,  19],\n         [ 20,  21,  22,  23]],\n\n        [[-12, -13, -14, -15],\n         [-16, -17, -18, -19],\n         [-20, -21, -22, -23]],\n\n        [[ 24,  26,  28,  30],\n         [ 32,  34,  36,  38],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시6) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,3,4)\n\ntf.stack([a,b,c],axis=2)\n\n<tf.Tensor: shape=(2, 3, 3, 4), dtype=int32, numpy=\narray([[[[  0,   1,   2,   3],\n         [  0,  -1,  -2,  -3],\n         [  0,   2,   4,   6]],\n\n        [[  4,   5,   6,   7],\n         [ -4,  -5,  -6,  -7],\n         [  8,  10,  12,  14]],\n\n        [[  8,   9,  10,  11],\n         [ -8,  -9, -10, -11],\n         [ 16,  18,  20,  22]]],\n\n\n       [[[ 12,  13,  14,  15],\n         [-12, -13, -14, -15],\n         [ 24,  26,  28,  30]],\n\n        [[ 16,  17,  18,  19],\n         [-16, -17, -18, -19],\n         [ 32,  34,  36,  38]],\n\n        [[ 20,  21,  22,  23],\n         [-20, -21, -22, -23],\n         [ 40,  42,  44,  46]]]], dtype=int32)>\n\n\n(예시7) (2,3,4), (2,3,4), (2,3,4) \\(\\to\\) (2,3,4,3)\n\ntf.stack([a,b,c],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 3), dtype=int32, numpy=\narray([[[[  0,   0,   0],\n         [  1,  -1,   2],\n         [  2,  -2,   4],\n         [  3,  -3,   6]],\n\n        [[  4,  -4,   8],\n         [  5,  -5,  10],\n         [  6,  -6,  12],\n         [  7,  -7,  14]],\n\n        [[  8,  -8,  16],\n         [  9,  -9,  18],\n         [ 10, -10,  20],\n         [ 11, -11,  22]]],\n\n\n       [[[ 12, -12,  24],\n         [ 13, -13,  26],\n         [ 14, -14,  28],\n         [ 15, -15,  30]],\n\n        [[ 16, -16,  32],\n         [ 17, -17,  34],\n         [ 18, -18,  36],\n         [ 19, -19,  38]],\n\n        [[ 20, -20,  40],\n         [ 21, -21,  42],\n         [ 22, -22,  44],\n         [ 23, -23,  46]]]], dtype=int32)>\n\n\n- 예제: (2,3,4) (4,3,4) \\(\\to\\) (6,3,4)\n\na=tf.reshape(tf.constant(range(2*3*4)),(2,3,4))\nb=tf.reshape(-tf.constant(range(4*3*4)),(4,3,4))\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(6, 3, 4), dtype=int32, numpy=\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]],\n\n       [[-24, -25, -26, -27],\n        [-28, -29, -30, -31],\n        [-32, -33, -34, -35]],\n\n       [[-36, -37, -38, -39],\n        [-40, -41, -42, -43],\n        [-44, -45, -46, -47]]], dtype=int32)>\n\n\n\ntf.concat([a,b],axis=1) # dimension이 달라 오류!\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat\n\n\n\ntf.concat([a,b],axis=2)\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [2,3,4] vs. shape[1] = [4,3,4] [Op:ConcatV2] name: concat\n\n\n- (2,2) @ (2,) 의 연산?\nnumpy\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88])\n\narray([ 77, -88])\n\n\n\n차원이 안맞는데 계산이 된다?\n\n\nnp.array([77,-88]) @ np.array([[1,0],[0,1]])\n\narray([ 77, -88])\n\n\n\nnp.array([[1,0],[0,1]]) @ np.array([77,-88]).reshape(2,1) # dimension 명시\n\narray([[ 77],\n       [-88]])\n\n\n\nnp.array([77,-88]).reshape(2,1) @ np.array([[1,0],[0,1]]) # 잘못된 걸 명시해주니까 계산 안됨!\n\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)\n\n\n\nnp.array([77,-88]).reshape(1,2) @ np.array([[1,0],[0,1]]) \n\narray([[ 77, -88]])\n\n\n–> 요약: numpy에서 길이가 2인 벡터는 매트릭스를 곱할 때 알아서 계산이 되서 결과가 나옴.\ntensorflow\n\nI = tf.constant([[1.0,0.0],[0.0,1.0]]) \nx = tf.constant([77.0,-88.0]) \n\n\nI @ x \n\nInvalidArgumentError: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] has different ndims: [2,2] vs. [2] [Op:MatMul]\n\n\n\nx @ I\n\nInvalidArgumentError: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] has different ndims: [2] vs. [2,2] [Op:MatMul]\n\n\n\nI @ tf.reshape(x,(2,1))\n\n<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\narray([[ 77.],\n       [-88.]], dtype=float32)>\n\n\n\ntf.reshape(x,(1,2)) @ I \n\n<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 77., -88.]], dtype=float32)>\n\n\n\n\n\n\ntf.Variable\n되게 쓸모없어 보이는데 쉽고, 중요합니다.\n\n선언\n- tf.Variable()로 선언\n\ntf.Variable([1,2,3,4])\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntf.Variable([1.0,2.0,3.0,4.0])\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>\n\n\n- tf.constant() 선언후 변환\n\na_ = tf.Variable(tf.constant([1,2,3,4]))\ntype(a_)\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\ntype이 ResourceVariable\n\n\ntf.Variable(tf.constant([1,2,3,4])) # type이렇게 바로 변환 가능\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n- np 등으로 선언후 변환\n\ntf.Variable(np.array([1,2,3,4]))\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int64, numpy=array([1, 2, 3, 4])>\n\n\n\n\n타입\n\ntype(tf.Variable([1,2,3,4]))\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\n\n인덱싱\n\na=tf.Variable([1,2,3,4])\na\n\n<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntype(a)\n\ntensorflow.python.ops.resource_variable_ops.ResourceVariable\n\n\n\na[:2] # 처음 2개의 원소.\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\ntype(a[:2])\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n연산하는 순간 type이 EagerTensor로 바뀜\n\n\n\n연산가능\n\na=tf.Variable([1,2,3,4])\nb=tf.Variable([-1,-2,-3,-4])\n\n\na+b\n\n<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>\n\n\ntf.Variable로 열심히 만들어도 연산하는 순간 tf.constant로 바뀜.. (자료형이 깨짐)\n\n\ntf.Variable도 쓰기 불편함\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14]) ## 에러\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]\n\n\n\n\ntnp의 은총도 일부만 가능\n\nimport tensorflow.experimental.numpy as tnp \ntnp.experimental_enable_numpy_behavior() \n\n- 알아서 형 변환\n\ntf.Variable([1,2])+tf.Variable([3.14,3.14])\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([4.1400001, 5.1400001])>\n\n\n- .reshape 메소드\n\ntf.Variable([1,2,3,4]).reshape(2,2)\n\nAttributeError: 'ResourceVariable' object has no attribute 'reshape'\n\n\n\ntf.constant는 되는데 tf.Variable은 또 안됨…\n\n\n\n대부분의 동작은 tf.constant랑 큰 차이를 모르겠음\n- tf.concat\n\na= tf.Variable([[1,2],[3,4]]) \nb= tf.Variable([[-1,-2],[-3,-4]]) \ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1,  2],\n       [ 3,  4],\n       [-1, -2],\n       [-3, -4]], dtype=int32)>\n\n\n- tf.stack\n\na= tf.Variable([[1,2],[3,4]]) \nb= tf.Variable([[-1,-2],[-3,-4]]) \ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\narray([[[ 1,  2],\n        [ 3,  4]],\n\n       [[-1, -2],\n        [-3, -4]]], dtype=int32)>\n\n\n\n이건 비슷한데?\n\n\n\n변수값변경가능(?)\n\na = 1\nid(a)\n\n7585472\n\n\n\na = 456\nid(a)\n\n140177070372624\n\n\n\n새로만드는 것은 되는데 수정은 안됨. (즉, 재할당밖에 안됨. 수정은 안돼)\n근데 가변형으로 만들어 주는것이 좋은데.. (불변형을 사용하려면 메모리가 커야해..)\n그래서 편집 가능한 변수로 선언하는 것이 의미가 있다.\n보통 딥러닝 학습할 때 Data는 RAM에 올리고 파라미터는 GPU에 올린다. (GPU에 올리면 미분계산(선형연산)이 빨라짐)\n\n\na= tf.Variable([1,2,3,4])\nid(a)\n\n140177068844272\n\n\n\na.assign_add([-1,-2,-3,-4]) # 편집기능.\nid(a)\n\n140177068844272\n\n\n\n주소값이 똑같으니까 편집!\n\n\n\n요약\n- tf.Variable()로 만들어야 하는 뚜렷한 차이는 모르겠음.\n- 애써 tf.Variable()로 만들어도 간단한연산을 하면 그 결과는 tf.constant()로 만든 오브젝트와 동일해짐.\n\n\n\n미분\n\n모티브\n- 예제: 컴퓨터를 이용하여 \\(x=2\\)에서 \\(y=3x^2\\)의 접선의 기울기를 구해보자.\n(손풀이)\n\\[\\frac{dy}{dx}=6x\\]\n이므로 \\(x=2\\)를 대입하면 12이다.\n(컴퓨터를 이용한 풀이)\n단계1\n\nx1=2 \ny1= 3*x1**2 \n\n\nx2=2+0.000000001\ny2= 3*x2**2\n\n\n(y2-y1)/(x2-x1)\n\n12.0\n\n\n단계2\n\ndef f(x):\n    return(3*x**2)\n\n\nf(3)\n\n27\n\n\n\ndef d(f,x):\n    return (f(x+0.000000001)-f(x))/0.000000001\n\n\nd(f,2)\n\n12.000000992884452\n\n\n단계3\n\nd(lambda x: 3*x**2 ,2)\n\n12.000000992884452\n\n\n\nd(lambda x: x**2 ,0)\n\n1e-09\n\n\n단계4\n\\[f(x,y)= x^2 +3y\\]\n\ndef f(x,y):\n    return(x**2 +3*y)\n\n\nd(f,(2,3))\n\nTypeError: can only concatenate tuple (not \"float\") to tuple\n\n\n\n\ntf.GradientTape() 사용방법\n- 예제1: \\(x=2\\)에서 \\(y=3x^2\\)의 도함수값을 구하라.\n\nx=tf.Variable(2.0) # 미분 기울기를 구하고 싶은 지점을 tf.Variable로 선언\na=tf.constant(3.0) # 숫자로 선언하고 싶은 것.\n\n\ntf.GradientTape()     # Tape: 뭔가 기록할 수 있는 것.\n\n<tensorflow.python.eager.backprop.GradientTape at 0x7f7d84347bb0>\n\n\n\n실행결과 오브젝트로 나왔는데 ,그것이 0x7f7d4c6cfdf0 이 메모리 주소 안에 있다.\n\n\ndir(mytape) # 여기서 __enter__와 __exit__에 주목!\n\n['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__enter__',\n '__eq__',\n '__exit__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_ensure_recording',\n '_persistent',\n '_pop_tape',\n '_push_tape',\n '_recording',\n '_tape',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_watch_accessed_variables',\n '_watched_variables',\n 'batch_jacobian',\n 'gradient',\n 'jacobian',\n 'reset',\n 'stop_recording',\n 'watch',\n 'watched_variables']\n\n\n\nmytape=tf.GradientTape() \nmytape.__enter__() # 기록 시작 \ny=a*x**2 # y=ax^2 = 3x^2 (기록하고 싶은 것)\nmytape.__exit__(None,None,None) # 기록 끝 \n\n\n그럼 mytape에는 뭔가가 기록되어 있을 것이다.\n위의 코드에서 __enter__()와 __exit__()는 고정이라고 생각\n그 사이에는 수식쓰기\n\n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n\n미분 결과 12\n\n- 예제2: 조금 다른예제\n\nx=tf.Variable(2.0)\n#a=tf.constant(3.0)\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작 \na=(x/2)*3 ## a=(3/2)x \ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝 \n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n\n실행은 되는데 결과가 틀림! 왜 18이지?\n\n\\[a=\\frac{3}{2}x\\] \\[y=ax^2=\\frac{3}{2}x^3\\]\n\\[\\frac{dy}{dx}=\\frac{3}{2} 3x^2\\]\n\n3/2*3*4\n\n18.0\n\n\n- 테이프의 개념 (\\(\\star\\))\n(상황)\n우리가 어려운 미분계산을 컴퓨터에게 부탁하는 상황임. (예를들면 \\(y=3x^2\\)) 컴퓨터에게 부탁을 하기 위해서는 연습장(=테이프)에 \\(y=3x^2\\)이라는 수식을 써서 보여줘야하는데 이때 컴퓨터에게 target이 무엇인지 그리고 무엇으로 미분하고 싶은 것인지를 명시해야함.\n\nmytape = tf.GradientTape(): tf.GradientTape()는 연습장을 만드는 명령어, 만들어진 연습장을 mytape라고 이름을 붙인다.\nmytape.__enter__(): 만들어진 공책을 연다 (=기록할수 있는 상태로 만든다)\na=x/2*3; y=a*x**2: 컴퓨터에게 전달할 수식을 쓴다\nmytape.__exit__(None,None,None): 공책을 닫는다.\nmytape.gradient(y,x): \\(y\\)를 \\(x\\)로 미분하라는 메모를 남기고 컴퓨터에게 전달한다.\n\n- 예제3: 연습장을 언제 열고 닫을지 결정하는건 중요하다.\n\nx=tf.Variable(2.0)\na=(x/2)*3 ## a=(3/2)x\n\nmytape=tf.GradientTape()\nmytape.__enter__() # 기록 시작 \ny=a*x**2  ## y=ax^2 = (3/2)x^3\nmytape.__exit__(None,None,None) # 기록 끝 \n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n- 예제4: with문과 함께 쓰는 tf.GradientTape()\n열고 > 쓰고 > 닫고 > 컴퓨터에 전달 –>> 이 과정을 간략하게 매크로화 시키자.\n\nx=tf.Variable(2.0)\na=(x/2)*3 \n\n\nwith tf.GradientTape() as mytape:\n    ## with문 시작 \n    y=a*x**2 \n    ## with문 끝 \n\n\nmytape.gradient(y,x) # y를 x로 미분하라.\n\n<tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n\n\n(문법해설)\n아래와 같이 쓴다.\nwith expression as myname:\n    ## with문 시작: myname.__enter__() \n    blabla ~ \n    yadiyadi !! \n    ## with문 끝: myname.__exit__()\n\nexpression 의 실행결과 오브젝트가 생성, 생성된 오브젝트는 myname라고 이름붙임. 이 오브젝트는 .__enter__()와 .__exit__()를 숨겨진 기능으로 포함해야 한다.\nwith문이 시작되면서 myname.__enter__()이 실행된다.\n블라블라와 야디야디가 실행된다.\nwith문이 종료되면서 myname.__exit__()이 실행된다.\n\n- 예제5: 예제2를 with문과 함께 구현\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\nmytape.gradient(y,x) # y를 x로 미분하라. \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n- 예제6: persistent = True\n(관찰1)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape() as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상 실행해서 에러를 관측하라\n\nRuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n\n\n(관찰2)\n\nx=tf.Variable(2.0)\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nmytape.gradient(y,x) # 2번이상실행해도 에러가 나지않음 \n\n<tf.Tensor: shape=(), dtype=float32, numpy=18.0>\n\n\n- 예제7: watch\n(관찰1)\n\nx=tf.constant(2.0)\n\nwith tf.GradientTape(persistent=True) as mytape:\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰2)\n\nx=tf.constant(2.0)\nwith tf.GradientTape(persistent=True) as mytape:\n    mytape.watch(x) # 수동감시\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n(관찰3)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제 \n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\nNone\n\n\n(관찰4)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True,watch_accessed_variables=False) as mytape: # 자동감시 모드 해제\n    mytape.watch(x)\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n(관찰5)\n\nx=tf.Variable(2.0)\nwith tf.GradientTape(persistent=True) as mytape: \n    mytape.watch(x)\n    a=(x/2)*3 ## a=(3/2)x \n    y=a*x**2  ## y=ax^2 = (3/2)x^3\n\n\nprint(mytape.gradient(y,x))\n\ntf.Tensor(18.0, shape=(), dtype=float32)\n\n\n- 예제9: 카페예제로 돌아오자.\n- 예제10: 카페예제의 매트릭스 버전\n- 예제11: 위의 예제에서 이론적인 \\(\\boldsymbol{\\beta}\\)의 최적값을 찾아보고 (즉 \\(\\hat{\\boldsymbol{\\beta}}\\)을 찾고) 그곳에서 loss의 미분을 구하라. 구한결과가 \\(\\begin{bmatrix}0 \\\\ 0 \\end{bmatrix}\\) 임을 확인하라."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_14_(2주차)_3월14일.html",
    "href": "posts/3_STBDA2022/2022_03_14_(2주차)_3월14일.html",
    "title": "[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)",
    "section": "",
    "text": "(2주차) 3월14일\n\n강의노트\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-z8oR8bQZHR0mpy_9OcsWOz\n\n\n\nimport\n\nimport tensorflow as tf\nimport numpy as np\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\n\n\ntf.config.experimental.list_physical_devices('GPU')\n\n[]\n\n\n\n\ntf.constant\n\n예비학습: 중첩리스트\n- 리스트\n\nlst = [1,2,4,5,6]\nlst \n\n[1, 2, 4, 5, 6]\n\n\n\nlst[1] # 두번쨰원소 \n\n2\n\n\n\nlst[-1] # 마지막원소 \n\n6\n\n\n- (2,2) matrix 느낌의 list\n\nlst= [[1,2],[3,4]]\nlst\n\n[[1, 2], [3, 4]]\n\n\n위를 아래와 같은 매트릭스로 생각할수 있다.\n1 2 \n3 4 \n\nprint(lst[0][0]) # (1,1) \nprint(lst[0][1]) # (1,2) \nprint(lst[1][0]) # (2,1) \nprint(lst[1][1]) # (2,2) \n\n1\n2\n3\n4\n\n\n- (4,1) matrix 느낌의 list\n\nlst=[[1],[2],[3],[4]] # (4,1) matrix = 길이가 4인 col-vector\nlst\n\n[[1], [2], [3], [4]]\n\n\n\nnp.array(lst), np.array(lst).shape\n\n(array([[1],\n        [2],\n        [3],\n        [4]]),\n (4, 1))\n\n\n- (1,4) matrix 느낌의 list\n\nlst=[[1,2,3,4]] # (1,4) matrix = 길이가 4인 row-vector \nlst\n\n[[1, 2, 3, 4]]\n\n\n\nnp.array(lst), np.array(lst).shape\n\n(array([[1, 2, 3, 4]]), (1, 4))\n\n\n\n\n선언\n\n텐서플로우를 쓰려면 텐서로 바꿔줘야 한다.\n\n- 스칼라\n\ntf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n\n\n\ntf.constant(3.14)+tf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=6.28>\n\n\n- 벡터\n\ntype(1),type([1,2,3]), type(_vector) # int 혹은 list 타입 --> EagerTensor 타입으로 바꾸라는 뜻.\n\n(int, list, tensorflow.python.framework.ops.EagerTensor)\n\n\n\n_vector=tf.constant([1,2,3])\n\n\n_vector[-1]\n\n<tf.Tensor: shape=(), dtype=int32, numpy=3>\n\n\n- 매트릭스\n\n_matrix= tf.constant([[1,0],[0,1]])\n_matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 1]], dtype=int32)>\n\n\n- array\n\ntf.constant([[[0,1,1],[1,2,-1]],[[0,1,2],[1,2,-1]]])\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  1,  1],\n        [ 1,  2, -1]],\n\n       [[ 0,  1,  2],\n        [ 1,  2, -1]]], dtype=int32)>\n\n\n\n\n타입\n\ntype(tf.constant(3.14))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\nEagerTensor 타입이라는 것만 기억!\n\n\n\n인덱싱\n\n_matrix = tf.constant([[1,2],[3,4]])\n_matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n\n_matrix[0][0]\n\n<tf.Tensor: shape=(), dtype=int32, numpy=1>\n\n\n\n_matrix[0]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\n_matrix[0,:]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n\n\n\n_matrix[:,0]\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3], dtype=int32)>\n\n\n\n\ntf.constant는 불편하다.\n- 불편한점 1. 모든 원소가 같은 dtype을 가지고 있어야함. 2. 원소 수정이 불가능함. 3. 묵시적 형변환이 불가능하다.\n- 원소수정이 불가능함\n\na=tf.constant([1,22,33])\na\n\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 22, 33], dtype=int32)>\n\n\n\na[0]=11 \n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n- 묵시적 형변환이 불가능하다\n\n1 + 3.14 # 1(int), 3.14(float) --> 4.14(float)\n\n4.140000000000001\n\n\n\n1을 float으로 암묵적으로 바꿔서 계산함.\n\n\ntf.constant(1)+tf.constant(3.14) ## 에러!\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]\n\n\n\nint와 float이라 에러나는 것\n\n\ntf.constant(1.0)+tf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=4.1400003>\n\n\n- 같은 float도 안되는 경우가 있음\n\ntf.constant(1.0,dtype=tf.float64)\n\n<tf.Tensor: shape=(), dtype=float64, numpy=1.0>\n\n\n\ntf.constant(3.14)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n\n\n\ntf.constant(1.0,dtype=tf.float64)+tf.constant(3.14)\n\nInvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:AddV2]\n\n\n\n조금만 틀리면 에러남..\n\n\n\ntf.constant \\(\\to\\) 넘파이\n\nnp.array(tf.constant(1)) # 방법1\n\narray(1, dtype=int32)\n\n\n\nnumpy로 연산을 다 해놓고 tensor로 바꾼다..\n\n\na=tf.constant([3.14,-3.14])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na.numpy() # numpy라는 메서드가 있음.\n\narray([ 3.14, -3.14], dtype=float32)\n\n\n\n\n연산\n- 더하기\n\na=tf.constant([1,2])\nb=tf.constant([3,4])\na+b\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>\n\n\n처음에 int로 선언했으면 나머지도 모두 int로 선언해야해..\n\ntf.add(a,b)\n\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>\n\n\n\n결과는 동일\n\n- 곱하기\n\na=tf.constant([[1,2],[3,4]])\nb=tf.constant([[5,6],[7,8]])\na*b # elementwise 하게 곱한하고 한다.\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)>\n\n\n\ntf.multiply(a,b) # 이게 먼저 나왔음.\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[ 5, 12],\n       [21, 32]], dtype=int32)>\n\n\n- 매트릭스의곱\n\na=tf.constant([[1,0],[0,1]]) # (2,2)\nb=tf.constant([[5],[7]]) # (2,1) \na@b\n\n<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)>\n\n\n\ntf.matmul(a,b)\n\n<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[5],\n       [7]], dtype=int32)>\n\n\n- 역행렬\n\na=tf.constant([[1,0],[0,2]])\na\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 0],\n       [0, 2]], dtype=int32)>\n\n\n\ntf.linalg.inv(a)\n\nInvalidArgumentError: Value for attr 'T' of int32 is not in the list of allowed values: double, float, half, complex64, complex128\n    ; NodeDef: {{node MatrixInverse}}; Op<name=MatrixInverse; signature=input:T -> output:T; attr=adjoint:bool,default=false; attr=T:type,allowed=[DT_DOUBLE, DT_FLOAT, DT_HALF, DT_COMPLEX64, DT_COMPLEX128]> [Op:MatrixInverse]\n\n\n\n1/2을 계산하려면 애초에 float형이어야 했음.\n\n\na=tf.constant([[1.0,0.0],[0.0,2.0]])\ntf.linalg.inv(a)\n\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1. , 0. ],\n       [0. , 0.5]], dtype=float32)>\n\n\n- tf.linalg. + tab을 누르면 좋아보이는 연산들 많음\n\na=tf.constant([[1.0,2.0],[3.0,4.0]])\nprint(a)\ntf.linalg.det(a)\n\ntf.Tensor(\n[[1. 2.]\n [3. 4.]], shape=(2, 2), dtype=float32)\n\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>\n\n\n\ntf.linalg.trace(a)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=5.0>\n\n\n\n\n형태변환\n- 기본: tf.reshape() 를 이용\n\na=tf.constant([1,2,3,4]) #  길이가 4인 vector\na\n\n<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n\n\n\ntf.reshape(a,(4,1)) # column-vec로 변환.\n\n<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2))\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,1))\n\n<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\narray([[[1],\n        [2]],\n\n       [[3],\n        [4]]], dtype=int32)>\n\n\n- 다차원\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12]) # 길이가 12인 vector\na\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,3)) # 2*2*3\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\ntf.reshape(a,(4,3)) # 4*3\n\n<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)>\n\n\n- tf.reshape\n\na=tf.constant([1,2,3,4,5,6,7,8,9,10,11,12])\na\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\ntf.reshape(a,(4,-1)) # 원소 어짜피 12개 있으니까 4만 주면 나머지 3은 알아서 맞춰줌.\n\n<tf.Tensor: shape=(4, 3), dtype=int32, numpy=\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]], dtype=int32)>\n\n\n\ntf.reshape(a,(2,2,-1))\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\nb=tf.reshape(a,(2,2,-1))\nb\n\n<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]], dtype=int32)>\n\n\n\ntf.reshape(b,-1) # 길이가 12인 vector로 바꿔줌.\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>\n\n\n\n\n선언고급\n뭔가를 초기화할 때 필요한 기능을 정리한 것입니다.\n- 다른 자료형 (리스트나 넘파이)로 만들고 바꾸는것도 좋다.\n\nnp.diag([1,2,3,4])\n\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])\n\n\n\ntf.constant(np.diag([1,2,3,4]))\n\n<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])>\n\n\n- tf.ones, tf.zeros\n\ntf.zeros([3,3])\n\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)>\n\n\n\ntf.reshape(tf.constant([0]*9),(3,3)) # tensor로 바꾸고 shape을 바꿔주는 방법도 있다.\n\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]], dtype=int32)>\n\n\n- range(10)\n\na=range(0,12)\ntype(a) # type이 range임!\n\nrange\n\n\n\nlist(a) # 타입을 list로 바꿀 수 있음.\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n\n\n\na=range(0,12)\ntf.constant(a)\n\n<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)>\n\n\n\ntf.constant(range(1,20,3)) \n\n<tf.Tensor: shape=(7,), dtype=int32, numpy=array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32)>\n\n\n- tf.linspace\n\ntf.linspace(0,1,10) # 0부터시작해서 1까지 총 10개 // 여기서는 1(마지막 숫자)이 포함됨\n\n<tf.Tensor: shape=(10,), dtype=float64, numpy=\narray([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])>\n\n\n\n\ntf.concat\n- (2,1) concat (2,1) => (2,2) - 두번째 축이 바뀌었다. => axis=1\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b # 2개의 col-vec\n\n(<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)>,\n <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=1) # 2col-vec -> matrix\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 3],\n       [2, 4]], dtype=int32)>\n\n\n- (2,1) concat (2,1) => (4,1) - 첫번째 축이 바뀌었다. => axis=0\n\na=tf.constant([[1],[2]])\nb=tf.constant([[3],[4]])\na,b\n\n(<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[1],\n        [2]], dtype=int32)>,\n <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n array([[3],\n        [4]], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]], dtype=int32)>\n\n\n- (1,2) concat (1,2) => (2,2) - 첫번째 // axis=0\n\na=tf.constant([[1,2]])\nb=tf.constant([[3,4]])\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>\n\n\n- (1,2) concat (1,2) => (1,4) - 두번째 // axis=1\n- (2,3,4,5) concat (2,3,4,5) => (4,3,4,5) - 첫번째 // axis=0\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(4, 3, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]]],\n\n\n       [[[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,6,4,5) - 두번째 // axis=1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=1)\n\n<tf.Tensor: shape=(2, 6, 4, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59]],\n\n        [[   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119]],\n\n        [[ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,3,8,5) - 세번째 // axis=2\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=2)\n\n<tf.Tensor: shape=(2, 3, 8, 5), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4],\n         [   5,    6,    7,    8,    9],\n         [  10,   11,   12,   13,   14],\n         [  15,   16,   17,   18,   19],\n         [   0,   -1,   -2,   -3,   -4],\n         [  -5,   -6,   -7,   -8,   -9],\n         [ -10,  -11,  -12,  -13,  -14],\n         [ -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24],\n         [  25,   26,   27,   28,   29],\n         [  30,   31,   32,   33,   34],\n         [  35,   36,   37,   38,   39],\n         [ -20,  -21,  -22,  -23,  -24],\n         [ -25,  -26,  -27,  -28,  -29],\n         [ -30,  -31,  -32,  -33,  -34],\n         [ -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44],\n         [  45,   46,   47,   48,   49],\n         [  50,   51,   52,   53,   54],\n         [  55,   56,   57,   58,   59],\n         [ -40,  -41,  -42,  -43,  -44],\n         [ -45,  -46,  -47,  -48,  -49],\n         [ -50,  -51,  -52,  -53,  -54],\n         [ -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64],\n         [  65,   66,   67,   68,   69],\n         [  70,   71,   72,   73,   74],\n         [  75,   76,   77,   78,   79],\n         [ -60,  -61,  -62,  -63,  -64],\n         [ -65,  -66,  -67,  -68,  -69],\n         [ -70,  -71,  -72,  -73,  -74],\n         [ -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84],\n         [  85,   86,   87,   88,   89],\n         [  90,   91,   92,   93,   94],\n         [  95,   96,   97,   98,   99],\n         [ -80,  -81,  -82,  -83,  -84],\n         [ -85,  -86,  -87,  -88,  -89],\n         [ -90,  -91,  -92,  -93,  -94],\n         [ -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104],\n         [ 105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114],\n         [ 115,  116,  117,  118,  119],\n         [-100, -101, -102, -103, -104],\n         [-105, -106, -107, -108, -109],\n         [-110, -111, -112, -113, -114],\n         [-115, -116, -117, -118, -119]]]], dtype=int32)>\n\n\n- (2,3,4,5) concat (2,3,4,5) => (2,3,4,10) - 네번째 // axis=3 # 0,1,2,3 // -4 -3 -2 -1\n\na=tf.reshape(tf.constant(range(120)),(2,3,4,5))\nb=-a\n\n\ntf.concat([a,b],axis=-1)\n\n<tf.Tensor: shape=(2, 3, 4, 10), dtype=int32, numpy=\narray([[[[   0,    1,    2,    3,    4,    0,   -1,   -2,   -3,   -4],\n         [   5,    6,    7,    8,    9,   -5,   -6,   -7,   -8,   -9],\n         [  10,   11,   12,   13,   14,  -10,  -11,  -12,  -13,  -14],\n         [  15,   16,   17,   18,   19,  -15,  -16,  -17,  -18,  -19]],\n\n        [[  20,   21,   22,   23,   24,  -20,  -21,  -22,  -23,  -24],\n         [  25,   26,   27,   28,   29,  -25,  -26,  -27,  -28,  -29],\n         [  30,   31,   32,   33,   34,  -30,  -31,  -32,  -33,  -34],\n         [  35,   36,   37,   38,   39,  -35,  -36,  -37,  -38,  -39]],\n\n        [[  40,   41,   42,   43,   44,  -40,  -41,  -42,  -43,  -44],\n         [  45,   46,   47,   48,   49,  -45,  -46,  -47,  -48,  -49],\n         [  50,   51,   52,   53,   54,  -50,  -51,  -52,  -53,  -54],\n         [  55,   56,   57,   58,   59,  -55,  -56,  -57,  -58,  -59]]],\n\n\n       [[[  60,   61,   62,   63,   64,  -60,  -61,  -62,  -63,  -64],\n         [  65,   66,   67,   68,   69,  -65,  -66,  -67,  -68,  -69],\n         [  70,   71,   72,   73,   74,  -70,  -71,  -72,  -73,  -74],\n         [  75,   76,   77,   78,   79,  -75,  -76,  -77,  -78,  -79]],\n\n        [[  80,   81,   82,   83,   84,  -80,  -81,  -82,  -83,  -84],\n         [  85,   86,   87,   88,   89,  -85,  -86,  -87,  -88,  -89],\n         [  90,   91,   92,   93,   94,  -90,  -91,  -92,  -93,  -94],\n         [  95,   96,   97,   98,   99,  -95,  -96,  -97,  -98,  -99]],\n\n        [[ 100,  101,  102,  103,  104, -100, -101, -102, -103, -104],\n         [ 105,  106,  107,  108,  109, -105, -106, -107, -108, -109],\n         [ 110,  111,  112,  113,  114, -110, -111, -112, -113, -114],\n         [ 115,  116,  117,  118,  119, -115, -116, -117, -118, -119]]]],\n      dtype=int32)>\n\n\n- (4,) concat (4,) => (8,) - 첫번째축? // axis=0\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=0)\n\n<tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 1,  2,  3,  4, -1, -2, -3, -4], dtype=int32)>\n\n\n- (4,) concat (4,) => (4,2) - 두번째축? // axis=1 ==> 이런거없다..\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.concat([a,b],axis=1)\n\nInvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat\n\n\n\n에러남! 이럴때는 tf.stack을 쓰면 된다.\n\n\n\ntf.stack\n\nstack은 차원이 늘어남!\n\n\na=tf.constant([1,2,3,4])\nb=-a \na,b\n\n(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>,\n <tf.Tensor: shape=(4,), dtype=int32, numpy=array([-1, -2, -3, -4], dtype=int32)>)\n\n\n\ntf.stack([a,b],axis=0)\n\n<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[ 1,  2,  3,  4],\n       [-1, -2, -3, -4]], dtype=int32)>\n\n\n\ntf.stack([a,b],axis=1)\n\n<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3],\n       [ 4, -4]], dtype=int32)>\n\n\n\n\n\ntnp\n- tf는 넘파이에 비하여 텐서만들기가 너무힘듬\n\nnp.diag([1,2,3])\n\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])\n\n\n\nnp.diag([1,2,3]).reshape(-1)\n\narray([1, 0, 0, 0, 2, 0, 0, 0, 3])\n\n\n\n넘파이는 이런식으로 np.diag()도 쓸수 있고 reshape을 메소드로 쓸 수도 있는데…\n\n\ntnp 사용방법 (불만해결방법)\ntensorflow에서 numpy처럼 동작하도록 할 수 있는 모듈이라고 생각 즉, np의 모방버전으로 생각하면 된다.\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\n\ntype(tnp.array([1,2,3]))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n이렇게 만들어도 된다.\n\n- int와 float을 더할 수 있음\n\ntnp.array([1,2,3])+tnp.array([1.0,2.0,3.0])\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])>\n\n\n\ntf.constant([1,2,3])+tf.constant([1.0,2.0,3.0]) # 이게 원래 에러났었음!\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 6.])>\n\n\n\ntnp 모듈을 불러오는 순간 tf로 선언하는 모든 것들도 우리가 알고있는 넘파이처럼 동작합니다.\n\n\ntnp.array(1)+tnp.array([1.0,2.0,3.0])\n\n<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 3., 4.])>\n\n\n\ntnp.diag([1,2,3])\n\n<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])>\n\n\n\na=tnp.diag([1,2,3])\ntype(a)\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\na=tf.constant([1,2,3])\na.reshape(3,1)\n\n<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\narray([[1],\n       [2],\n       [3]], dtype=int32)>\n\n\n\n\n선언고급\n\nnp.random.randn(5) # random module\n\narray([1.12411749, 1.43127059, 0.61763568, 0.43586944, 0.33208259])\n\n\n\ntnp.random.randn(5) # 넘파이가 되면 나도 된다.\n\n<tf.Tensor: shape=(5,), dtype=float64, numpy=array([-0.64055227, -1.33606436, -0.71424816,  1.61243245, -2.07980232])>\n\n\n\n\n타입\n\ntype(tnp.random.randn(5))\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n\ntf.contant로 만들어도 마치 넘파이인듯 쓰는 기능들\n- 묵시적형변환이 가능\nint랑 float을 계산할 수 있다는 것\n\ntf.constant([1,1])+tf.constant([2.2,3.3])\n\n<tf.Tensor: shape=(2,), dtype=float64, numpy=array([3.20000005, 4.29999995])>\n\n\n- 메소드를 쓸수 있음.\n사용가능한 메소드가 많아짐..\n\na= tnp.array([[1,2,3,4]])\na.T\n\n<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\narray([[1],\n       [2],\n       [3],\n       [4]])>\n\n\n\n\n그렇지만 np.array는 아님\n- 원소를 할당하는것은 불가능\n\na=tf.constant([1,2,3])\na\n\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n\n\n\na[0]=11\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n그냥 새로 만들어서 할당해야 함. (그래도 많이 개선된 것@)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_05_01_(9주차)_5월2일(1).html",
    "href": "posts/3_STBDA2022/2022_05_01_(9주차)_5월2일(1).html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "(9주차) 5월2일 (1)\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wrJ6CivKKBuJUN7ukm5OHr\n\n\n\nimports\n\nimport numpy as np\nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport matplotlib.pyplot as plt \n\n\n\n우도함수와 최대우도추정량\n(예제)\n\\(X_i \\overset{iid}{\\sim} Ber(p)\\)에서 얻은 샘플이 아래와 같다고 하자.\n\nx=[0,1,0,1] \nx\n\n[0, 1, 0, 1]\n\n\n\\(p\\)는 얼마라고 볼 수 있는가? –> 0.5\n왜?? \\(p\\)가 0.5라고 주장할 수 있는 이론적 근거, 혹은 논리체계가 무엇인가?\n- suppose: \\(p=0.1\\) 이라고 하자.\n그렇다면 \\((x_1,x_2,x_3,x_4)=(0,1,0,1)\\)와 같은 샘플이 얻어질 확률이 아래와 같다.\n\n0.9 * 0.1 * 0.9 * 0.1\n\n0.008100000000000001\n\n\n- suppose: \\(p=0.2\\) 이라고 하자.\n그렇다면 \\((x_1,x_2,x_3,x_4)=(0,1,0,1)\\)와 같은 샘플이 얻어질 확률이 아래와 같다.\n\n0.8 * 0.2 * 0.8 * 0.2 \n\n0.025600000000000008\n\n\n- 질문1: \\(p=0.1\\)인것 같냐? 아니면 \\(p=0.2\\)인것 같냐? -> \\(p=0.2\\) - 왜?? \\(p=0.2\\)일 확률이 더 크다!\n\n(여기서 잠깐 중요한것) 확률이라는 말을 함부로 쓸 수 없다.\n- 0.0256은 “\\(p=0.2\\)일 경우 샘플 (0,1,0,1)이 얻어질 확률”이지 “\\(p=0.2\\)일 확률”은 아니다.\n“\\(p=0.2\\)인 확률” 이라는 개념이 성립하려면 아래코드에서 sum([(1-p)*p*(1-p)*p for p in _plist])이 1보다는 작아야 한다. (그런데 1보다 크다)\n\n_plist = np.linspace(0.499,0.501,1000) \nsum([(1-p)*p*(1-p)*p for p in _plist])\n\n62.49983299986714\n\n\n- 확률이라는 말을 쓸 수 없지만 확률의 느낌은 있음 -> 가능도라는 말을 쓰자. - 0.0256 \\(=\\) \\(p\\)가 0.2일 경우 샘플 (0,1,0,1)이 얻어질 확률 \\(=\\) \\(p\\)가 0.2일 가능도\n\n- 다시 질문1로 돌아가자! - 질문1: \\(p=0.1\\)인 것 같냐? 아니면 \\(p=0.2\\)인 것 같냐? -> 답 \\(p=0.2\\) -> 왜? \\(p=0.2\\)인 가능도가 더 크니까! - 질문2: \\(p=0.2\\)인 것 같냐? 아니면 \\(p=0.3\\)인 것 같냐? -> 답 \\(p=0.3\\) -> 왜? \\(p=0.3\\)인 가능도가 더 크니까! - 질문3: …\n- 궁극의 질문: \\(p\\)가 뭐일 것 같아? - \\(p\\)가 입력으로 들어가면 가능도가 계산되는 함수를 만들자. - 그 함수를 최대화하는 \\(p\\)를 찾자. - 그 \\(p\\)가 궁극의 질문에 대한 대답이 된다.\n- 잠깐 용어정리 - 가능도함수 \\(=\\) 우도함수 \\(=\\) likelihood function \\(:=\\) \\(L(p)\\) - \\(p\\)의 maximum likelihood estimator \\(=\\) p의 MLE \\(:=\\) \\(\\hat{p}^{mle}\\) \\(=\\) \\(\\text{argmax}_p L(p)\\) \\(=\\) \\(\\hat{p}\\)\n(예제의 풀이)\n- 이 예제의 경우 가능도함수를 정의하자. - \\(L(p)\\): \\(p\\)의 가능도함수 = \\(p\\)가 모수일때 샘플 (0,1,0,1)이 얻어질 확률 = \\(p\\)가 모수일때 \\(x_1\\)이 0일 확률 \\(\\times \\dots \\times\\) \\(p\\)가 모수일때 \\(x_4\\)가 1일 확률 - \\(L(p)=\\prod_{i=1}^{4} f(x_i;p)= \\prod_{i=1}^{4}p^{x_i}(1-p)^{1-x_i}\\)\n\nnote: 참고로 이 과정을 일반화 하면 \\(X_1,\\dots,X_n \\overset{iid}{\\sim} Ber(p)\\) 일때 \\(p\\)의 likelihood function은 \\(\\prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}\\) 라고 볼 수 있다.\n\n\nnote: 더 일반화: \\(x_1,\\dots,x_n\\)이 pdf가 \\(f(x)\\)인 분포에서 뽑힌 서로 독립인 샘플일때 likelihood function은 \\(\\prod_{i=1}^{n}f(x_i)\\)라고 볼 수 있다.\n\n- 이 예제의 경우 \\(p\\)의 최대우도추정량을 구하면\n\\[\\hat{p}^{mle} = \\text{argmax}_p L(p) = \\text{argmax}_p  \\big\\{ p^2(1-p)^2 \\big\\}= \\frac{1}{2}\\]\n\n\n중간고사 1번\n(1) \\(N(\\mu,\\sigma)\\)에서 얻은 샘플이 아래와 같다고 할때 \\(\\mu,\\sigma\\)의 MLE를 구하여라.\n<tf.Tensor: shape=(10000,), dtype=float64, numpy=\narray([ 4.12539849,  5.46696729,  5.27243374, ...,  2.89712332,\n        5.01072291, -1.13050477])>\n(2) \\(Ber(p)\\)에서 얻은 샘플이 아래와 같다고 할 때 \\(p\\)의 MLE를 구하여라.\n<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([1, 1, 1, ..., 0, 0, 1])>\n(3) \\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\), \\(\\epsilon_i \\overset{iid}{\\sim} N(0,1)\\) 일때 \\((\\beta_0,\\beta_1)\\)의 MLE를 구하여라. (회귀모형)\n(풀이) 가능도함수\n\\[L(\\beta_0,\\beta_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(y_i)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(y_i-\\mu_i)^2}, \\quad \\mu_i=\\beta_0+\\beta_1 x_i\\]\n를 최대화하는 \\(\\beta_0,\\beta_1\\)을 구하면된다. 그런데 이것은 아래를 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하는 것과 같다.\n\\[-\\log L(\\beta_0,\\beta_1) = \\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_i)^2\\]\n위의 식은 SSE와 같다. 결국 오차항이 정규분포를 따르는 회귀모형의 MLE는 MSE를 최소화하는 \\(\\beta_0,\\beta_1\\)을 구하면 된다.\n중간고사 1-(3)의 다른 풀이\nstep1: 생성\n\nx= tf.constant(np.arange(1,10001)/10000)\ny= tnp.random.randn(10000) + (0.5 + 2*x) \n\nstep2: minimize MSEloss (원래는 maximize log-likelihood)\n\nmaximize likelihood였던 문제를 minimize MSEloss로 바꾸어도 되는근거? 주어진 함수(=가능도함수)를 최대화하는 \\(\\beta_0,\\beta_1\\)은 MSE를 최소화하는 \\(\\beta_0,\\beta_1\\)과 동일하므로\n\n\nbeta0= tf.Variable(1.0)\nbeta1= tf.Variable(1.0) \nfor i in range(2000):\n    with tf.GradientTape() as tape: \n        #minus_log_likelihood = tf.reduce_sum((y-beta0-beta1*x)**2)\n        loss =  tf.reduce_sum((y-beta0-beta1*x)**2)\n    slope1, slope2 = tape.gradient(loss,[beta0,beta1]) \n    beta0.assign_sub(slope1* 0.1/10000) # N=10000 \n    beta1.assign_sub(slope2* 0.1/10000) \n\n\nbeta0,beta1\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.49661896>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0051448>)\n\n\n- 문제를 풀면서 생각해보니 손실함수는 -로그가능도함수로 선택하면 될 것 같다? - 손실함수를 선택하는 기준이 -로그가능도함수만 존재하는 것은 아니나 대부분 그러하긴함\n(4) 출제하지 못한 중간고사 문제\n아래의 모형을 생각하자. - \\(Y_i \\overset{iid}{\\sim} Ber(\\pi_i)\\) - \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}=\\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\)\n아래는 위의 모형에서 얻은 샘플이다.\n\nx = tnp.linspace(-1,1,2000)\npi = tnp.exp(-1+5*x) / (1+tnp.exp(-1+5*x))\ny = np.random.binomial(1,pi)\ny = tf.constant(y)\n\n함수 \\(L(w_0,w_1)\\)을 최대화하는 \\((w_0,w_1)\\)를 tf.GradeintTape()를 활용하여 추정하라. (경사하강법 혹은 경사상승법을 사용하고 \\((w_0,w_1)\\)의 초기값은 모두 0.1로 설정할 것)\n\\[L(w_0,w_1)=\\prod_{i=1}^{n}f(y_i), \\quad f(x_i)={\\pi_i}^{y_i}(1-\\pi_i)^{1-y_i},\\quad \\pi_i=\\text{sigmoid}(w_0+w_1x_i)\\]\n(풀이1)\n\nw0hat = tf.Variable(1.0) \nw1hat = tf.Variable(1.0) \n\n\nfor i in range(1000): \n    with tf.GradientTape() as tape: \n        pihat = tnp.exp(w0hat+w1hat *x) / (1+tnp.exp(w0hat+w1hat *x))\n        pdf = pihat**y * (1-pihat)**(1-y) \n        logL = tf.reduce_mean(tnp.log(pdf)) \n    slope1,slope2 = tape.gradient(logL,[w0hat,w1hat])\n    w0hat.assign_add(slope1*0.1) \n    w1hat.assign_add(slope2*0.1) \n\n\nw0hat,w1hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.8875932>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.3785405>)\n\n\n(해석) - 로지스틱에서 가능도함수와 BCEloss의 관계\n\\(L(w_0,w_1)\\)를 최대화하는 \\(w_0,w_1\\)은 아래를 최소화하는 \\(w_0,w_1\\)와 같다.\n\\[-\\log L(w_0,w_1) = - \\sum_{i=1}^{n}\\big(y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\big)\\]\n이것은 최적의 \\(w_0,w_1\\)을 \\(\\hat{w}_0,\\hat{w}_1\\)이라고 하면 \\(\\hat{\\pi}_i=\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\hat{y}_i\\)이 되고 따라서 위의 식은 \\(n\\times\\)BCEloss의 형태임을 쉽게 알 수 있다.\n결국 로지스틱 모형에서 \\((w_0,w_1)\\)의 MLE를 구하기 위해서는 BCEloss를 최소화하는 \\((w_0,w_1)\\)을 구하면 된다!\n(풀이2)\n\nw0hat = tf.Variable(1.0) \nw1hat = tf.Variable(1.0) \n\n\nfor i in range(1000): \n    with tf.GradientTape() as tape: \n        yhat = tnp.exp(w0hat+w1hat *x) / (1+tnp.exp(w0hat+w1hat *x))\n        loss = tf.losses.binary_crossentropy(y,yhat)\n    slope1,slope2 = tape.gradient(loss,[w0hat,w1hat])\n    w0hat.assign_sub(slope1*0.1) \n    w1hat.assign_sub(slope2*0.1) \n\n\nw0hat,w1hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.8875934>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.3785415>)\n\n\n\n\n손실함수의 설계 (선택)\n- 회귀분석이든 로지스틱이든 손실함수는 minus_log_likelihood 로 선택한다. - 그런데 (오차항이 정규분포인) 회귀분석 일때는 minus_log_likelihood 가 MSEloss가 되고 - 로지스틱일때는 minus_log_likelihood 가 BCEloss가 된다\n- minus_log_likelihood가 손실함수를 선택하는 유일한 기준은 아니다. <— 참고만하세요, 이 수업에서는 안중요합니다. - 오차항이 대칭이고 서로독립이며 등분산 가정을 만족하는 어떠한 분포에서의 회귀모형이 있다고 하자. 이 회귀모형에서 \\(\\hat{\\beta}\\)은 여전히 MSEloss를 최소화하는 \\(\\beta\\)를 구함으로써 얻을 수 있다. - 이 경우 MSEloss를 쓰는 이론적근거? \\(\\hat{\\beta}\\)이 BLUE가 되기 때문임 (가우스-마코프정리)"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html",
    "href": "posts/3_STBDA2022/2022_03_28_(4주차)_3월28일.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-xGxAT-3Sq_jpD-eBxpsT8L\n\n\n\n\n\nimport tensorflow as tf \nimport numpy as np \nimport matplotlib.pyplot as plt \n\n\nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior() \n\n\n\n\n\n\n- 예제9: 카페예제로 돌아오자.\n\nx= tnp.array([20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4])\n\n2022-03-28 22:00:22.099906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n\n\n\ntf.random.set_seed(43052)\nepsilon=tf.random.normal([10])\ny=10.2 + 2.2*x + epsilon\n\n\ny\n\n<tf.Tensor: shape=(10,), dtype=float64, numpy=\narray([55.4183651 , 58.19427589, 61.23082496, 62.31255873, 63.1070028 ,\n       63.69569103, 67.24704918, 71.43650092, 73.10130336, 77.84988286])>\n\n\n\nbeta0 = tf.Variable(9.0) \nbeta1 = tf.Variable(2.0)  \n\n\nwith tf.GradientTape(persistent=True) as tape: \n    loss = sum((y-beta0-beta1*x)**2)\n\n\ntape.gradient(loss,beta0), tape.gradient(loss,beta1)\n\n(<tf.Tensor: shape=(), dtype=float32, numpy=-126.78691>,\n <tf.Tensor: shape=(), dtype=float32, numpy=-3208.8396>)\n\n\n- 예제10: 카페예제의 매트릭스 버전\n\nX= tnp.array([1]*10 +[20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]).reshape(2,10).T\nX\n\n<tf.Tensor: shape=(10, 2), dtype=float64, numpy=\narray([[ 1. , 20.1],\n       [ 1. , 22.2],\n       [ 1. , 22.7],\n       [ 1. , 23.3],\n       [ 1. , 24.4],\n       [ 1. , 25.1],\n       [ 1. , 26.2],\n       [ 1. , 27.3],\n       [ 1. , 28.4],\n       [ 1. , 30.4]])>\n\n\n\nbeta= tnp.array([9.0,2.0]).reshape(2,1)\nbeta\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[9.],\n       [2.]])>\n\n\n\nX@beta\n\n<tf.Tensor: shape=(10, 1), dtype=float64, numpy=\narray([[49.2],\n       [53.4],\n       [54.4],\n       [55.6],\n       [57.8],\n       [59.2],\n       [61.4],\n       [63.6],\n       [65.8],\n       [69.8]])>\n\n\n\nbeta_true= tnp.array([10.2,2.2]).reshape(2,1)\ny= X@beta_true+epsilon.reshape(10,1) \ny\n\n<tf.Tensor: shape=(10, 1), dtype=float64, numpy=\narray([[55.4183651 ],\n       [58.19427589],\n       [61.23082496],\n       [62.31255873],\n       [63.1070028 ],\n       [63.69569103],\n       [67.24704918],\n       [71.43650092],\n       [73.10130336],\n       [77.84988286]])>\n\n\n\nwith tf.GradientTape(persistent=True) as tape: \n    tape.watch(beta)\n    yhat= X@beta\n    loss= (y-yhat).T @(y-yhat) \n\n\ntape.gradient(loss,beta)\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[ -126.78690968],\n       [-3208.83947922]])>\n\n\n- 이론적인 값을 확인하면\n\n-2*X.T @ y + 2*X.T@X@beta \n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[ -126.78690968],\n       [-3208.83947922]])>\n\n\n- 예제11: 위의 예제에서 이론적인 \\(\\boldsymbol{\\beta}\\)의 최적값을 찾아보고 (즉 \\(\\boldsymbol{\\hat\\beta}\\)을 찾고) 그 지점에서 loss의 미분값(=접선의 기울기)를 구하라. 결과가 \\(\\bf{0}\\)인지 확인하라. (단 \\({\\bf 0}\\)은 길이가 2이고 각 원소가 0인 벡터)\n\\(\\beta\\)의 최적값은 \\((X'X)^{-1}X'y\\)이다.\n\nbeta_optimal = tf.linalg.inv(X.T @ X) @ X.T  @y \n\n\nwith tf.GradientTape(persistent=True) as tape: \n    tape.watch(beta_optimal)\n    yhat= X@beta_optimal\n    loss= (y-yhat).T @(y-yhat) \n\n\ntape.gradient(loss,beta_optimal)\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[-6.67910172e-12],\n       [-1.67774636e-10]])>\n\n\n- beta_true에서의 기울기도 계산해보자.\n\nwith tf.GradientTape(persistent=True) as tape: \n    tape.watch(beta_true)\n    yhat= X@beta_true\n    loss= (y-yhat).T @(y-yhat) \n\n\ntape.gradient(loss,beta_true)\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[ -2.74690968],\n       [-71.45947922]])>\n\n\n\n샘플사이즈가 커진다면 tape.gradient(loss,beta_true) \\(\\approx\\) tape.gradient(loss,beta_optimal)\n샘플사이즈가 커진다면 beta_true \\(\\approx\\) beta_optimal\n\n\n\n\n\n\n\n- \\(loss=(\\frac{1}{2}\\beta-1)^2\\)를 최소하는 \\(\\beta\\)를 컴퓨터를 활용하여 구하는 문제를 생각해보자. - 답은 \\(\\beta=2\\)임을 알고 있다.\n\n\n\n\n\n\nbeta = [-10.00,-9.99,…,10.00] 와 같은 리스트를 만든다.\n(1)의 리스트의 각원소에 해당하는 loss를 구한다.\n(2)에서 구한 loss를 제일 작게 만드는 beta를 찾는다.\n\n\n\n\n\nbeta = np.linspace(-10,10,100) \nloss = (beta/2 -1)**2 \n\n\ntnp.argmin([1,2,-3,3,4])\n\n<tf.Tensor: shape=(), dtype=int64, numpy=2>\n\n\n\ntnp.argmin([1,2,3,-3,4])\n\n<tf.Tensor: shape=(), dtype=int64, numpy=3>\n\n\n\ntnp.argmin(loss)\n\n<tf.Tensor: shape=(), dtype=int64, numpy=59>\n\n\n\nbeta[59]\n\n1.9191919191919187\n\n\n\n\n\n- 비판1: [-10,10]이외에 해가 존재하면? - 이 예제의 경우는 운좋게 [-10,10]에서 해가 존재했음 - 하지만 임의의 고정된 \\(x,y\\)에 대하여 \\(loss(\\beta)=(x\\beta-y)^2\\) 의 형태의 해가 항상 [-10,10]에서 존재한다는 보장은 없음 - 해결책: 더 넓게 많은 범위를 탐색하자?\n- 비판2: 효율적이지 않음 - 알고리즘을 요약하면 결국 -10부터 10까지 작은 간격으로 조금씩 이동하며 loss를 조사하는 것이 grid search의 아이디어 - \\(\\to\\) 생각해보니까 \\(\\beta=2\\)인 순간 \\(loss=(\\frac{1}{2}\\beta-1)^2=0\\)이 되어서 이것보다 작은 최소값은 존재하지 않는다(제곱은 항상 양수이어야 하므로) - \\(\\to\\) 따라서 \\(\\beta=2\\) 이후로는 탐색할 필요가 없다\n\n\n\n\n\n\n\nbeta = -5 로 셋팅한다.\n\n\n(-5/2-1)**2\n\n12.25\n\n\n\nbeta=-5 근처에서 조금씩 이동하여 loss를 조사해본다.\n\n\n(-4.99/2-1)**2 ## 오른쪽으로 0.01 이동하고 loss조사\n\n12.215025\n\n\n\n(-5.01/2-1)**2 ## 왼쪽으로 0.01 이동하고 l`oss조사\n\n12.285025\n\n\n\n(2)의 결과를 잘 해석하고 더 유리한 쪽으로 이동\n위의 과정을 반복하고 왼쪽, 오른쪽 어느쪽으로 움직여도 이득이 없다면 멈춘다.\n\n\n\n\n- (2)-(3)의 과정은 beta=-5 에서 미분계수를 구하고 미분계수가 양수이면 왼쪽으로 움직이고 음수이면 오른쪽으로 움직인다고 해석가능. 아래그림을 보면 더 잘 이해가 된다.\n\nplt.plot(beta,loss)\n\n\n\n\n\n\n\n- 아래와 같이 해석가능\n\n오른쪽으로 0.01 간다 = beta_old에 0.01을 더함. (if, 미분계수가 음수)\n왼쪽으로 0.01 간다. = beta_old에 0.01을 뺀다. (if, 미분계수가 양수)\n\n- 그렇다면 $_{new} =\n\\[\\begin{cases}\n\\beta_{old} + 0.01, & loss'(\\beta_{old})< 0  \\\\\n\\beta_{old} - 0.01, & loss'(\\beta_{old})> 0\n\\end{cases}\\]\n$\n\n\n\n- 항상 0.01씩 움직여야 하는가?\n\nplt.plot(beta,loss)\n\n\n\n\n- \\(\\beta=-10\\) 일 경우의 접선의 기울기? \\(\\beta=-4\\) 일때 접선의 기울기?\n\n\\(\\beta=-10\\) => 기울기는 -6\n\\(\\beta=-4\\) => 기울기는 -3\n\n- 실제로 6,3씩 이동할순 없으니 적당한 \\(\\alpha\\) (예를들면 \\(\\alpha=0.01\\)) 를 잡아서 곱한만큼 이동하자.\n- 수식화하면\n\n\\(\\beta_{new} = \\beta_{old} - \\alpha~ loss'(\\beta_{old})\\)\n\\(\\beta_{new} = \\beta_{old} - \\alpha~ \\left[\\frac{\\partial}{\\partial \\beta }loss(\\beta)\\right]_{\\beta=\\beta_{old}}\\)\n\n- \\(\\alpha\\)의 의미 - \\(\\alpha\\)가 크면 크게크게 움직이고 작으면 작게작게 움직인다. - \\(\\alpha>0\\) 이어야 한다.\n\n\n\n- iter 1\n\\(\\beta=-10\\)이라고 하자.\n\nbeta = tf.Variable(-10.0) \n\n\nwith tf.GradientTape(persistent=True) as tape: \n    loss = (beta/2-1)**2 \n\n\ntape.gradient(loss,beta)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-6.0>\n\n\n\\(\\beta = -10\\) 에서 0.01만큼 움직이고 싶음\n\nalpha= 0.01/6\n\n\nalpha * tape.gradient(loss,beta)\n\n<tf.Tensor: shape=(), dtype=float32, numpy=-0.01>\n\n\n\nbeta.assign_sub(alpha * tape.gradient(loss,beta))\n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.99>\n\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n- iter2\n\nwith tf.GradientTape(persistent=True) as tape: \n    loss = (beta/2-1)**2 \n\n\nbeta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.980008>\n\n\n- for 문을 이용하자.\n(강의용)\n\nbeta = tf.Variable(-10.0) \n\n\nfor k in range(10000): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.997125>\n\n\n(시도1)\n\nbeta = tf.Variable(-10.0) \n\n\nfor k in range(100): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.040152>\n\n\n(시도2)\n\nbeta = tf.Variable(-10.0) \n\n\nfor k in range(1000): \n    with tf.GradientTape(persistent=True) as tape: \n        loss = (beta/2-1)**2 \n    beta.assign_sub(tape.gradient(loss,beta)*alpha)\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-3.2133687>\n\n\n- 너무 느린 것 같다? \\(\\to\\) \\(\\alpha\\)를 키워보자!\n\n\n\n- 목표: \\(\\alpha\\)에 따라서 수렴과정이 어떻게 달라지는 시각화해보자.\n\n\n\nfig = plt.figure() # 도화지가 만들어지고 fig라는 이름을 붙인다. \n\n<Figure size 432x288 with 0 Axes>\n\n\n\nax = fig.add_subplot() # fig는 ax라는 물체를 만든다. \n\n\nid(fig.axes[0])\n\n139622811236624\n\n\n\nid(ax)\n\n139622811236624\n\n\n\npnts, = ax.plot([1,2,3],[4,5,6],'or')\npnts\n\n<matplotlib.lines.Line2D at 0x7efc7071da20>\n\n\n\npnts.get_xdata()\n\narray([1, 2, 3])\n\n\n\npnts.get_ydata()\n\narray([4, 5, 6])\n\n\n\nfig\n\n\n\n\n\npnts.set_ydata([5,5,5])\n\n\npnts.get_ydata()\n\n[5, 5, 5]\n\n\n\nfig\n\n\n\n\n- 응용\n\nplt.rcParams[\"animation.html\"]=\"jshtml\"\nfrom matplotlib import animation \n\n\ndef animate(i): \n    if i%2 == 0: \n        pnts.set_ydata([4,5,6])\n    else: \n        pnts.set_ydata([5,5,5])\n\n\nani = animation.FuncAnimation(fig,animate,frames=10)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n예비학습 끝\n- beta_lst=[-10,-9,-8] 로 이동한다고 하자.\n\nbeta_lst = [-10,-9,-8]\nloss_lst = [(-10/2-1)**2,(-9/2-1)**2,(-8/2-1)**2] \n\n\nfig = plt.figure() \n\n<Figure size 432x288 with 0 Axes>\n\n\n\nax= fig.add_subplot()\n\n\n_beta = np.linspace(-15,19,100) \n\n\nax.plot(_beta,(_beta/2-1)**2)\n\n\nfig\n\n\n\n\n\npnts, = ax.plot(beta_lst[0],loss_lst[0],'ro')\nfig\n\n\n\n\n\ndef animate(i): \n    pnts.set_xdata(beta_lst[:(i+1)])\n    pnts.set_ydata(loss_lst[:(i+1)])\n\n\nani =animation.FuncAnimation(fig, animate, frames=3)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 최종아웃풋\n\nbeta = tf.Variable(-10.0) \nalpha = 0.01/6\n\n\nbeta_lst=[]\nloss_lst=[]\n\n\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\n\n\nwith tf.GradientTape(persistent=True) as tape: \n    tape.watch(beta) \n    loss = (beta/2-1)**2\n\n\nbeta.assign_sub(tape.gradient(loss,beta)*alpha) \n\n<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-9.99>\n\n\n\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\n\n\nbeta_lst, loss_lst\n\n([-10.0, -9.99], [36.0, 35.94002362785341])\n\n\n- for\n\nbeta = tf.Variable(-10.0) \nalpha = 0.01/6\nbeta_lst=[]\nloss_lst=[]\nbeta_lst.append(beta.numpy())\nloss_lst.append((beta.numpy()/2-1)**2)\nfor k in range(100): \n    with tf.GradientTape(persistent=True) as tape: \n        tape.watch(beta) \n        loss = (beta/2-1)**2\n    beta.assign_sub(tape.gradient(loss,beta)*alpha) \n    beta_lst.append(beta.numpy())\n    loss_lst.append((beta.numpy()/2-1)**2)\n\n\nfig = plt.figure() \nax = fig.add_subplot() \nax.plot(_beta,(_beta/2-1)**2) \npnts, = ax.plot(beta_lst[0],loss_lst[0],'or')\n\n\n\n\n\nani = animation.FuncAnimation(fig,animate,frames=100) \nani \n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\\(y=(x-1)^2\\)를 최소화 하는 \\(x\\)를 경사하강법을 이용하여 찾아라. 수렴과정을 animation으로 시각화하라.\n- x의 초기값은 -3으로 설정한다. - 적당한 \\(\\alpha\\)를 골라서 100번의 반복안에 수렴하도록 하라."
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_18_(7주차)_4월18일.html",
    "href": "posts/3_STBDA2022/2022_04_18_(7주차)_4월18일.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "(7주차) 4월18일\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-ws3T1xD-bBU46dtduUlwmP\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\npiece-wise linear regression\nmodel: \\(y_i=\\begin{cases} x_i +0.3\\epsilon_i & x\\leq 0 \\\\ 3.5x_i +0.3\\epsilon_i & x>0 \\end{cases}\\)\n\nnp.random.seed(43052)\nN=100\nx = np.linspace(-1,1,N)\nlamb = lambda x: x*1+np.random.normal()*0.3 if x<0 else x*3.5+np.random.normal()*0.3 \ny= np.array(list(map(lamb,x)))\ny\n\narray([-0.88497385, -0.65454563, -0.61676249, -0.84702584, -0.84785569,\n       -0.79220455, -1.3777105 , -1.27341781, -1.41643729, -1.26404671,\n       -0.79590224, -0.78824395, -0.86064773, -0.52468679, -1.18247354,\n       -0.29327295, -0.69373049, -0.90561768, -1.07554911, -0.7225404 ,\n       -0.69867774, -0.34811037,  0.11188474, -1.05046296, -0.03840085,\n       -0.38356861, -0.24299798, -0.58403161, -0.20344022, -0.13872303,\n       -0.529586  , -0.27814478, -0.10852781, -0.38294596,  0.02669763,\n       -0.23042603, -0.77720364, -0.34287396, -0.04512022, -0.30180793,\n       -0.26711438, -0.51880349, -0.53939672, -0.32052379, -0.32080763,\n        0.28917092,  0.18175206, -0.48988124, -0.08084459,  0.37706178,\n        0.14478908,  0.07621827, -0.071864  ,  0.05143365,  0.33932009,\n       -0.35071776,  0.87742867,  0.51370399,  0.34863976,  0.55855514,\n        1.14196717,  0.86421076,  0.72957843,  0.57342304,  1.54803332,\n        0.98840018,  1.11129366,  1.42410801,  1.44322465,  1.25926455,\n        1.12940772,  1.46516829,  1.16365096,  1.45560853,  1.9530553 ,\n        2.45940445,  1.52921129,  1.8606463 ,  1.86406718,  1.5866523 ,\n        1.49033473,  2.35242686,  2.12246412,  2.41951931,  2.43615052,\n        1.96024441,  2.65843789,  2.46854394,  2.76381882,  2.78547462,\n        2.56568465,  3.15212157,  3.11482949,  3.17901774,  3.31268904,\n        3.60977818,  3.40949166,  3.30306495,  3.74590922,  3.85610433])\n\n\n\nplt.plot(x,y,'.')\n\n\n\n\n\n풀이1: 단순회귀모형\n\nx= x.reshape(N,1)\ny= y.reshape(N,1) \n\n\nnet = tf.keras.Sequential()\nnet.add(tf.keras.layers.Dense(1)) \nnet.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\nnet.fit(x,y,batch_size=N,epochs=1000,verbose=0) # numpy로 해도 돌아감\n\n2022-04-18 11:40:03.840482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n\n\n<keras.callbacks.History at 0x7f3b7d0bf670>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[2.2616348]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.6069048], dtype=float32)>]\n\n\n\nyhat = x * 2.2616348 + 0.6069048\nyhat = net.predict(x)\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n- 실패: 이 모형은 epoch을 10억번 돌려도 실패할 모형임 - 왜? 아키텍처 설계자체가 틀렸음 - 꺽인부분을 표현하기에는 아키텍처의 표현력이 너무 부족하다 -> under fit의 문제\n\n\n풀이2: 비선형 활성화 함수의 도입\n- 여기에서 비선형 활성화 함수는 relu\n- 네트워크를 아래와 같이 수정하자.\n(수정전) hat은 생략\n\n#collapse\ngv('''\n\"x\" -> \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -> \"y\"[label=\"indentity\"] ''')\n\n\n\n\n(수정후) hat은 생략\n\n#collapse\ngv('''\n\"x\" -> \"x*w,    bias=True\"[label=\"*w\"] ;\n\"x*w,    bias=True\" -> \"y\"[label=\"relu\"] ''')\n\n\n\n\n\n마지막에 \\(f(x)=x\\) 라는 함수대신에 relu를 취하는 것으로 구조를 약간 변경\n활성화함수(acitivation function)를 indentity에서 relu로 변경\n\n- relu함수란?\n\n_x = np.linspace(-1,1,100)\ntf.nn.relu(_x)\n\n<tf.Tensor: shape=(100,), dtype=float64, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.01010101, 0.03030303, 0.05050505, 0.07070707, 0.09090909,\n       0.11111111, 0.13131313, 0.15151515, 0.17171717, 0.19191919,\n       0.21212121, 0.23232323, 0.25252525, 0.27272727, 0.29292929,\n       0.31313131, 0.33333333, 0.35353535, 0.37373737, 0.39393939,\n       0.41414141, 0.43434343, 0.45454545, 0.47474747, 0.49494949,\n       0.51515152, 0.53535354, 0.55555556, 0.57575758, 0.5959596 ,\n       0.61616162, 0.63636364, 0.65656566, 0.67676768, 0.6969697 ,\n       0.71717172, 0.73737374, 0.75757576, 0.77777778, 0.7979798 ,\n       0.81818182, 0.83838384, 0.85858586, 0.87878788, 0.8989899 ,\n       0.91919192, 0.93939394, 0.95959596, 0.97979798, 1.        ])>\n\n\n\nplt.plot(_x,_x)\nplt.plot(_x,tf.nn.relu(_x))\n\n\n\n\n\n파란색을 주황색으로 바꿔주는 것이 렐루함수임\n\\(f(x)=\\max(0,x)=\\begin{cases} 0 & x\\leq 0 \\\\ x & x>0 \\end{cases}\\)\n\n- 아키텍처: \\(\\hat{y}_i=relu(\\hat{w}_0+\\hat{w}_1x_i)\\), \\(relu(x)=\\max(0,x)\\)\n- 풀이시작\n1단계\n\nnet2 = tf.keras.Sequential() \n\n2단계\n\ntf.random.set_seed(43053)\nl1 = tf.keras.layers.Dense(1, input_shape=(1,)) \na1 = tf.keras.layers.Activation(tf.nn.relu) \n\n\nnet2.add(l1)\n\n\nnet2.layers\n\n[<keras.layers.core.dense.Dense at 0x7f3b5c6e74f0>]\n\n\n\nnet2.add(a1)\n\n\nnet2.layers\n\n[<keras.layers.core.dense.Dense at 0x7f3b5c6e74f0>,\n <keras.layers.core.activation.Activation at 0x7f3aa99a0ee0>]\n\n\n\nl1.get_weights()\n\n[array([[0.41721308]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nnet2.get_weights()\n\n[array([[0.41721308]], dtype=float32), array([0.], dtype=float32)]\n\n\n(네트워크 상황 확인)\n\nu1= l1(x)\n#u1= x@l1.weights[0] + l1.weights[1]\n\n\nv1= a1(u1)\n#v1= tf.nn.relu(u1) \n\n\nplt.plot(x,x)\nplt.plot(x,u1,'--r')\nplt.plot(x,v1,'--b')\n\n\n\n\n3단계\n\nnet2.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\n\n4단계\n\nnet2.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f3aa9885990>\n\n\n- result\n\nyhat = tf.nn.relu(x@l1.weights[0] + l1.weights[1]) \nyhat = net2.predict(x)\nyhat = net2(x)\nyhat = a1(l1(x))\nyhat = net2.layers[1](net2.layers[0](x))\n\n\nplt.plot(x,y,'.')\nplt.plot(x,yhat,'--')\n\n\n\n\n- discussion - 이것 역시 수백억번 에폭을 반복해도 이 이상 적합이 힘들다 \\(\\to\\) 모형의 표현력이 떨어진다. - 해결책: 주황색점선이 2개 있다면 어떨까?\n\n\n풀이3: 노드수추가 + 레이어추가\n목표: 2개의 주황색 점선을 만들자.\n1단계\n\nnet3 = tf.keras.Sequential()\n\n2단계\n\ntf.random.set_seed(43053)\nl1 = tf.keras.layers.Dense(2,input_shape=(1,))\na1 = tf.keras.layers.Activation(tf.nn.relu)\n\n\nnet3.add(l1)\nnet3.add(a1) \n\n(네트워크 상황 확인)\n\nl1(x).shape\n# l1(x) : (100,1) -> (100,2) \n\nTensorShape([100, 2])\n\n\n\nplt.plot(x,x)\nplt.plot(x,l1(x),'--')\n\n\n\n\n\nplt.plot(x,x)\nplt.plot(x,a1(l1(x)),'--')\n\n\n\n\n- 이 상태에서는 yhat이 안나온다. 왜? - 차원이 안맞음. a1(l1(x))의 차원은 (N,2)인데 최종적인 yhat의 차원은 (N,1)이어야 함. - 차원이 어찌저찌 맞다고 쳐도 relu를 통과하면 항상 yhat>0 임. 따라서 음수값을 가지는 y는 0으로 밖에 맞출 수 없음.\n- 해결책: a1(l1(x))에 연속으로(Sequential하게!) 또 다른 레이어를 설계! (N,2) -> (N,1) 이 되도록! - yhat= bias + weight1 * a1(l1(x))[0] + weight2 * a1(l1(x))[1]\n- 즉 a1(l1(x)) 를 새로운 입력으로 해석하고 출력을 만들어주는 선형모형을 다시태우면 된다. - 입력차원: 2 - 출력차원: 1\n\nnet3.layers\n\n[<keras.layers.core.dense.Dense at 0x7f3aa62bb3d0>,\n <keras.layers.core.activation.Activation at 0x7f3aa62baad0>]\n\n\n\ntf.random.set_seed(43053) \nl2 = tf.keras.layers.Dense(1, input_shape=(2,))\n\n\nnet3.add(l2) \n\n\nnet3.layers\n\n[<keras.layers.core.dense.Dense at 0x7f3aa62bb3d0>,\n <keras.layers.core.activation.Activation at 0x7f3aa62baad0>,\n <keras.layers.core.dense.Dense at 0x7f3aa61c3160>]\n\n\n\nnet3.summary()\n\nModel: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_10 (Dense)            (None, 2)                 4         \n                                                                 \n activation_9 (Activation)   (None, 2)                 0         \n                                                                 \n dense_11 (Dense)            (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 7\nTrainable params: 7\nNon-trainable params: 0\n_________________________________________________________________\n\n\n- 추정해야할 파라메터수가 4,0,3으로 나온다.\n- 수식표현: \\(X \\to X@W^{(1)}+b^{(1)} \\to relu(X@W^{(1)}+b^{(1)}) \\to relu(X@W^{(1)}+b^{(1)})@W^{(2)}+b^{(2)}=yhat\\)\n\n\\(X\\): (N,1)\n\\(W^{(1)}\\): (1,2) ==> 파라메터 2개 추정\n\\(b^{(1)}\\): (2,) ==> 파라메터 2개가 추가 // 여기까지 추정할 파라메터는 4개\n\\(W^{(2)}\\): (2,1) ==> 파라메터 2개 추정\n\\(b^{(2)}\\): (1,) ==> 파라메터 1개가 추가 // 따라서 3개\n\n- 참고: 추정할 파라메터수가 많다 = 복잡한 모형이다. - 초거대AI: 추정할 파라메터수가 엄청 많은..\n\nnet3.weights\n\n[<tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.34065306, -0.7533803 ]], dtype=float32)>,\n <tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.34065306],\n        [-0.7533803 ]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n\nl1.weights\n\n[<tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 0.34065306, -0.7533803 ]], dtype=float32)>,\n <tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n\n\n\nl2.weights\n\n[<tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 0.34065306],\n        [-0.7533803 ]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n- 좀 더 간단한 수식표현: \\(X \\to (u_1 \\to v_1) \\to (u_2 \\to v_2) = yhat\\) - \\(u_1= X@W^{(1)}+b^{(1)}\\) - \\(v_1= relu(u_1)\\) - \\(u_2= v_1@W^{(2)}+b^{(2)}\\) - \\(v_2= indentity(u_2):=yhat\\)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"u1[:,0]\"[label=\"*W1[0,0]\"]\n    \"X\" -> \"u1[:,1]\"[label=\"*W1[0,1]\"]\n    \"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -> \"yhat\"[label=\"*W2[0,0]\"]\n    \"v1[:,1]\" -> \"yhat\"[label=\"*W2[1,0]\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n3단계\n\nnet3.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1))\n\n4단계\n\nnet3.fit(x,y,epochs=1000,verbose=0, batch_size=N) \n\n<keras.callbacks.History at 0x7f3aa61ba560>\n\n\n- 결과확인\n\nnet3.weights\n\n[<tf.Variable 'dense_10/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[ 1.6352799 , -0.85507524]], dtype=float32)>,\n <tf.Variable 'dense_10/bias:0' shape=(2,) dtype=float32, numpy=array([-0.08284465,  0.85552216], dtype=float32)>,\n <tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6328746],\n        [-1.2001747]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([1.0253307], dtype=float32)>]\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,net3(x),'--')\n\n\n\n\n- 분석\n\nplt.plot(x,y,'.') \nplt.plot(x,l1(x),'--')\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,a1(l1(x)),'--')\n\n\n\n\n\nplt.plot(x,y,'.') \nplt.plot(x,l2(a1(l1(x))),'--')\n\n\n\n\n- 마지막 2개의 그림을 분석\n\nl2.weights\n\n[<tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[ 1.6328746],\n        [-1.2001747]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([1.0253307], dtype=float32)>]\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \nfig.set_figwidth(12) \nax1.plot(x,y,'.')\nax1.plot(x,a1(l1(x))[:,0],'--r')\nax1.plot(x,a1(l1(x))[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0]*1.6328746,'--r')\nax2.plot(x,a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*1.6328746+a1(l1(x))[:,1]*(-1.2001747)+1.0253307,'--')\n\n\n\n\n\n\n\n풀이3의 실패\n\ntf.random.set_seed(43054) \n## 1단계\nnet3 = tf.keras.Sequential() \n## 2단계\nnet3.add(tf.keras.layers.Dense(2))\nnet3.add(tf.keras.layers.Activation('relu')) \nnet3.add(tf.keras.layers.Dense(1))\n## 3단계 \nnet3.compile(optimizer=tf.optimizers.SGD(0.1),loss='mse')\n## 4단계 \nnet3.fit(x,y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f3a70c237c0>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n- 엥? 에폭이 부족한가?\n\nnet3.fit(x,y,epochs=10000,verbose=0,batch_size=N)\nplt.plot(x,y,'.')\nplt.plot(x,net3(x),'--')\n\n\n\n\n- 실패분석\n\nl1,a1,l2 = net3.layers\n\n\nl2.weights\n\n[<tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.65121335],\n        [1.8592643 ]], dtype=float32)>,\n <tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)>]\n\n\n\nfig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4) \nfig.set_figwidth(16) \nax1.plot(x,y,'.')\nax1.plot(x,l1(x)[:,0],'--r')\nax1.plot(x,l1(x)[:,1],'--b')\nax2.plot(x,y,'.')\nax2.plot(x,a1(l1(x))[:,0],'--r')\nax2.plot(x,a1(l1(x))[:,1],'--b')\nax3.plot(x,y,'.')\nax3.plot(x,a1(l1(x))[:,0]*0.65121335,'--r')\nax3.plot(x,a1(l1(x))[:,1]*(1.8592643)+(-0.60076195),'--b')\nax4.plot(x,y,'.')\nax4.plot(x,a1(l1(x))[:,0]*0.65121335+a1(l1(x))[:,1]*(1.8592643)+(-0.60076195),'--')\n\n\n\n\n\n보니까 빨간색선이 하는 역할을 없음\n그런데 생각해보니까 이 상황에서는 빨간색선이 할수 있는 일이 별로 없음\n왜? 지금은 나름 파란색선에 의해서 최적화가 된 상태임 \\(\\to\\) 빨간선이 뭔가 하려고하면 최적화된 상태가 깨질 수 있음 (loss 증가)\n즉 이 상황 자체가 나름 최적회된 상태이다. 이러한 현상을 “global minimum을 찾지 못하고 local minimum에 빠졌다”라고 표현한다.\n\n확인:\n\nnet3.weights\n\n[<tf.Variable 'dense_12/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[-0.03077251,  1.8713338 ]], dtype=float32)>,\n <tf.Variable 'dense_12/bias:0' shape=(2,) dtype=float32, numpy=array([-0.04834982,  0.3259186 ], dtype=float32)>,\n <tf.Variable 'dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.65121335],\n        [1.8592643 ]], dtype=float32)>,\n <tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([-0.60076195], dtype=float32)>]\n\n\n\nW1= tf.Variable(tnp.array([[-0.03077251,  1.8713338 ]]))\nb1= tf.Variable(tnp.array([-0.04834982,  0.3259186 ]))\nW2= tf.Variable(tnp.array([[0.65121335],[1.8592643 ]]))\nb2= tf.Variable(tnp.array([-0.60076195])) \n\n\nwith tf.GradientTape() as tape: \n    u = tf.constant(x) @ W1 + b1 \n    v = tf.nn.relu(u) \n    yhat = v@W2 + b2 \n    loss = tf.losses.mse(y,yhat) \n\n\ntape.gradient(loss,[W1,b1,W2,b2])\n\n[<tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[ 0.00000000e+00, -4.77330119e-05]])>,\n <tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.0000000e+00, 3.1478608e-06])>,\n <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n array([[ 0.00000000e+00],\n        [-4.74910706e-05]])>,\n <tf.Tensor: shape=(1,), dtype=float64, numpy=array([-2.43031263e-05])>]\n\n\n예상대로 계수값이 거의 다 0이다.\n\n\n풀이4: 노드수를 더 추가한다면?\n- 노드수를 더 추가해보면 어떻게 될까? (주황색 점선이 더 여러개 있다면?)\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    \"X\" -> \"...\"\n    \"X\" -> \"node512\"\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    \"...\" -> \"yhat\"\n    \"node512\" -> \"yhat\"\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\ntf.random.set_seed(43056)\nnet4= tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu')) # 이렇게 해도됩니다. \nnet4.add(tf.keras.layers.Dense(1))         \nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.1)) \nnet4.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f34ac815d20>\n\n\n\nplt.plot(x,y,'.')\nplt.plot(x,net4(x),'--')\n\n\n\n\n\n잘된다..\n한두개의 노드가 역할을 못해도 다른노드들이 잘 보완해주는듯!\n\n- 노드수가 많으면 무조건 좋다? -> 대부분 나쁘지 않음. 그런데 종종 맞추지 말아야할것도 맞춤.. (overfit)\n\nnp.random.seed(43052)\nN=100 \n_x = np.linspace(0,1,N).reshape(N,1) \n_y = np.random.normal(loc=0,scale=0.001,size=(N,1))\nplt.plot(_x,_y)\n\n\n\n\n\ntf.random.set_seed(43052) \nnet4 = tf.keras.Sequential()\nnet4.add(tf.keras.layers.Dense(512,activation='relu'))\nnet4.add(tf.keras.layers.Dense(1))\nnet4.compile(loss='mse',optimizer=tf.optimizers.SGD(0.5))\nnet4.fit(_x,_y,epochs=1000,verbose=0,batch_size=N)\n\n<keras.callbacks.History at 0x7f34ac2f3640>\n\n\n\nplt.plot(_x,_y)\nplt.plot(_x,net4(_x),'--')\n\n\n\n\n\n이 예제는 추후 다시 공부할 예정\n\n\n\n\nLogistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 올라간다.\n- 이러한 모형은 아래와 같이 설계할 수 있음 <– 외우세요!! - \\(y_i \\sim Ber(\\pi_i)\\), where \\(\\pi_i=\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\n\\(\\hat{y}_i =\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n- 위와 같은 손실함수를 BCEloss라고 부른다. (BCE는 Binary Cross Entropy의 약자)\n\n\n예제\n\nN = 2000 \n\n\nx = tnp.linspace(-1,1,N).reshape(N,1)\nw0 = -1 \nw1 = 5 \nu = w0 + x*w1 \n#v = tf.constant(np.exp(u)/(1+np.exp(u))) # v=πi \nv = tf.nn.sigmoid(u) \ny = tf.constant(np.random.binomial(1,v),dtype=tf.float64) \n\n\nplt.plot(x,y,'.',alpha=0.02)\nplt.plot(x,v,'--r')\n\n\n\n\n- 이 아키텍처(yhat을 얻어내는 과정)를 다어어그램으로 나타내면 아래와 같다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x\" -> \"x*w, bias=True\"[label=\"*w\"]\n    \"x*w, bias=True\" -> \"yhat\"[label=\"sigmoid\"]\n    label = \"Layer 1\"\n}\n''')\n\n\n\n\n- 또는 간단하게 아래와 같이 쓸 수 있다.\n\n#collapse\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    x\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    x -> \"node1=yhat\"\n    label = \"Layer 1: sigmoid\"\n}\n''')\n\n\n\n\n- 케라스를 이용하여 적합을 해보면\n\n\\(loss=-\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nbceloss_fn = lambda y,yhat: -tf.reduce_mean(y*tnp.log(yhat) + (1-y)*tnp.log(1-yhat))\nnet.compile(loss=bceloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f349c638670>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_28/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[4.1423755]], dtype=float32)>,\n <tf.Variable 'dense_28/bias:0' shape=(1,) dtype=float32, numpy=array([-0.820938], dtype=float32)>]\n\n\n\nplt.plot(x,y,'.',alpha=0.1)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x),'--b')\n\n\n\n\n\n\nMSE loss?\n- mse loss를 쓰면 왜 안되는지?\n\ntf.random.set_seed(43052)\nnet = tf.keras.Sequential() \nnet.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nmseloss_fn = lambda y,yhat: tf.reduce_mean((y-yhat)**2)\nnet.compile(loss=mseloss_fn, optimizer=tf.optimizers.SGD(0.1))\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f349df8cc10>\n\n\n\nplt.plot(x,y,'.',alpha=0.1)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x),'--b')\n\n\n\n\n\n일단 BCE loss와 비교해보니까 동일 초기값, 동일 epochs에서 적합이 별로임\n\n\n\nMSE loss vs BCE loss\n- MSEloss, BCEloss의 시각화\n\nw0, w1 = np.meshgrid(np.arange(-10,3,0.2), np.arange(-1,10,0.2), indexing='ij')\nw0, w1 = w0.reshape(-1), w1.reshape(-1)\n\ndef loss_fn1(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return mseloss_fn(y,yhat) \n\ndef loss_fn2(w0,w1):\n    u = w0+w1*x \n    yhat = np.exp(u)/(np.exp(u)+1)\n    return bceloss_fn(y,yhat) \n\nloss1 = list(map(loss_fn1,w0,w1))\nloss2 = list(map(loss_fn2,w0,w1))\n\n\nfig = plt.figure()\nfig.set_figwidth(9)\nfig.set_figheight(9)\nax1=fig.add_subplot(1,2,1,projection='3d')\nax2=fig.add_subplot(1,2,2,projection='3d')\nax1.elev=15\nax2.elev=15\nax1.azim=75\nax2.azim=75\nax1.scatter(w0,w1,loss1,s=0.1)\nax2.scatter(w0,w1,loss2,s=0.1) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f34a457df00>\n\n\n\n\n\n\n왼쪽곡면(MSEloss)보다 오른쪽곡면(BCEloss)이 좀더 예쁘게 생김 -> 오른쪽 곡면에서 더 학습이 잘될것 같음\n\n\n\n학습과정 시각화예시1\n- 파라메터학습과정 시각화 // 옵티마이저: SGD, 초기값: (w0,w1) = (-3.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.SGD(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 66ms/step - loss: 0.1554\n\n\n<keras.callbacks.History at 0x7f349dad3760>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.SGD(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 76ms/step - loss: 0.9265\n\n\n<keras.callbacks.History at 0x7f349da22fe0>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-0.5575908],\n         [ 1.1560522]], dtype=float32)],\n [array([[-0.8477989 ],\n         [-0.91781974]], dtype=float32)])\n\n\n\nnet_mse.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-3.],\n         [-1.]], dtype=float32)],\n [array([[-3.],\n         [-1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"SGD, Winit=(-3,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n학습과정 시각화예시2\n- 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-3.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.Adam(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 79ms/step - loss: 0.2311\n\n\n<keras.callbacks.History at 0x7f349d524070>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.Adam(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 94ms/step - loss: 0.5606\n\n\n<keras.callbacks.History at 0x7f349d526fb0>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[0.07441761],\n         [0.40206426]], dtype=float32)],\n [array([[-0.86062825],\n         [ 0.9297301 ]], dtype=float32)])\n\n\n\nnet_mse.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-3.],\n         [-1.]], dtype=float32)],\n [array([[-3.],\n         [-1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-3.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"Adam, Winit=(-3,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n학습과정 시각화예시3\n- 파라메터학습과정 시각화 // 옵티마이저: Adam, 초기값: (w0,w1) = (-10.0,-1.0)\n\n데이터정리\n\n\nX = tf.concat([tf.ones(N,dtype=tf.float64).reshape(N,1),x],axis=1)\nX\n\n<tf.Tensor: shape=(2000, 2), dtype=float64, numpy=\narray([[ 1.       , -1.       ],\n       [ 1.       , -0.9989995],\n       [ 1.       , -0.997999 ],\n       ...,\n       [ 1.       ,  0.997999 ],\n       [ 1.       ,  0.9989995],\n       [ 1.       ,  1.       ]])>\n\n\n\n1ter돌려봄\n\n\nnet_mse = tf.keras.Sequential()\nnet_mse.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_mse.compile(optimizer=tf.optimizers.Adam(0.1),loss=mseloss_fn) \nnet_mse.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 75ms/step - loss: 0.2175\n\n\n<keras.callbacks.History at 0x7f349c9d9e40>\n\n\n\nnet_bce = tf.keras.Sequential()\nnet_bce.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid')) \nnet_bce.compile(optimizer=tf.optimizers.Adam(0.1),loss=bceloss_fn) \nnet_bce.fit(X,y,epochs=1,batch_size=N)\n\n1/1 [==============================] - 0s 82ms/step - loss: 0.5323\n\n\n<keras.callbacks.History at 0x7f349caa17b0>\n\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-0.02143217],\n         [ 0.484821  ]], dtype=float32)],\n [array([[-0.8675074],\n         [ 1.1268172]], dtype=float32)])\n\n\n\nnet_mse.set_weights([tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)])\nnet_bce.set_weights([tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)])\n\n\nnet_mse.get_weights(), net_bce.get_weights()\n\n([array([[-10.],\n         [ -1.]], dtype=float32)],\n [array([[-10.],\n         [ -1.]], dtype=float32)])\n\n\n\n학습과정기록: 15에폭마다 기록\n\n\nWhat_mse = tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)\nWhat_bce = tnp.array([[-10.0 ],[ -1.0]],dtype=tf.float32)\n\n\nfor k in range(29): \n    net_mse.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    net_bce.fit(X,y,epochs=15,batch_size=N,verbose=0)\n    What_mse = tf.concat([What_mse,net_mse.weights[0]],axis=1) \n    What_bce = tf.concat([What_bce,net_bce.weights[0]],axis=1) \n\n\n시각화\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nfig = plt.figure()\nfig.set_figwidth(6)\nfig.set_figheight(6)\nfig.suptitle(\"Adam, Winit=(-10,-1)\")\nax1=fig.add_subplot(2,2,1,projection='3d')\nax2=fig.add_subplot(2,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nax3=fig.add_subplot(2,2,3)\nax4=fig.add_subplot(2,2,4)\n\nax1.scatter(w0,w1,loss1,s=0.1);ax1.scatter(-1,5,loss_fn1(-1,5),color='red',marker='*',s=200)\nax2.scatter(w0,w1,loss2,s=0.1);ax2.scatter(-1,5,loss_fn2(-1,5),color='red',marker='*',s=200)\n\nax3.plot(x,y,','); ax3.plot(x,v,'--r'); \nline3, = ax3.plot(x,1/(1+np.exp(-X@What_mse[:,0])),'--b')\nax4.plot(x,y,','); ax4.plot(x,v,'--r')\nline4, = ax4.plot(x,1/(1+np.exp(-X@What_bce[:,0])),'--b')\n\ndef animate(i):\n    _w0_mse,_w1_mse = What_mse[:,i]\n    _w0_bce,_w1_bce = What_bce[:,i]\n    ax1.scatter(_w0_mse, _w1_mse, loss_fn1(_w0_mse, _w1_mse),color='gray')\n    ax2.scatter(_w0_bce, _w1_bce, loss_fn2(_w0_bce, _w1_bce),color='gray')\n    line3.set_ydata(1/(1+np.exp(-X@What_mse[:,i])))\n    line4.set_ydata(1/(1+np.exp(-X@What_bce[:,i])))\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n아무리 아담이라고 해도 이건 힘듬\n\n- discussion - mse_loss는 경우에 따라서 엄청 수렴속도가 느릴수도 있음. - 근본적인 문제점: mse_loss일 경우 loss function의 곡면이 예쁘지 않음. (전문용어로 convex가 아니라고 말함) - 좋은 옵티마지어를 이용하면 mse_loss일 경우에도 수렴속도를 올릴 수 있음 (학습과정 시각화예시2). 그렇지만 이는 근본적인 해결책은 아님. (학습과정 시각화예시3)\n- 요약: 왜 logistic regression에서 mse loss를 쓰면 안되는가? - mse loss를 사용하면 손실함수가 convex하지 않으니까! - 그리고 bce loss를 사용하면 손실함수가 convex하니까!"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_11_(6주차)_4월11일.html",
    "href": "posts/3_STBDA2022/2022_04_11_(6주차)_4월11일.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "(6주차) 4월11일\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zueMdNhXiDTIMD-Dz5sbBD\n\n\n\nimports\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior()\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\n\n\\(x \\to \\hat{y}\\) 가 되는 과정을 그림으로 그리기\n- 단순회귀분석의 예시 - \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i, \\quad i=1,2,\\dots,n\\)\n(표현1)\n\n#collapse\ngv(''' \n    \"1\" -> \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xₙ\" -> \"β̂₀ + xₙ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xₙ*β̂₁,    bias=False\" -> \"ŷₙ\"[label=\"identity\"]\n\n    \".\" -> \"....................................\"[label=\"* β̂₀\"]\n    \"..\" -> \"....................................\"[label=\"* β̂₁\"]\n    \"....................................\" -> \"...\"[label=\" \"]\n\n    \"1 \" -> \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₂\" -> \"β̂₀ + x₂*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₂*β̂₁,    bias=False\" -> \"ŷ₂\"[label=\"identity\"]\n    \n    \"1  \" -> \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x₁\" -> \"β̂₀ + x₁*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x₁*β̂₁,    bias=False\" -> \"ŷ₁\"[label=\"identity\"]\n''')\n\n\n\n\n- 표현1의 소감? - 교수님이 고생해서 만든것 같음 - 그런데 그냥 다 똑같은 그림의 반복이라 사실 고생한 의미가 없음.\n(표현2)\n- 그냥 아래와 같이 그리고 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다”고 하면 될것 같다.\n\n#collapse\ngv(''' \n    \"1\" -> \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"xᵢ\" -> \"β̂₀ + xᵢ*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + xᵢ*β̂₁,    bias=False\" -> \"ŷᵢ\"[label=\"identity\"]\n\n''')\n\n\n\n\n(표현3)\n- 그런데 “모든 \\(i=1,2,3,\\dots,n\\)에 대하여 \\(\\hat{y}_i\\)을 아래의 그림과 같이 그린다” 라는 언급자체도 반복할 필요가 없을 것 같다. (어차피 당연히 그럴테니까) 그래서 단순히 아래와 같이 그려도 무방할듯 하다.\n\ngv(''' \n    \"1\" -> \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₀\"]\n    \"x\" -> \"β̂₀ + x*β̂₁,    bias=False\"[label=\"* β̂₁\"]\n    \"β̂₀ + x*β̂₁,    bias=False\" -> \"ŷ\"[label=\"identity\"]\n\n''')\n\n\n\n\n(표현4)\n- 위의 모델은 아래와 같이 쓸 수 있다. (\\(\\beta_0\\)를 바이어스로 표현)\n\n#collapse\ngv('''\n\"x\" -> \"x*β̂₁,    bias=True\"[label=\"*β̂₁\"] ;\n\"x*β̂₁,    bias=True\" -> \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n실제로는 이 표현을 많이 사용함\n\n(표현5)\n- 벡터버전으로 표현하면 아래와 같다. 이 경우에는 \\({\\bf X}=[1,x]\\)에 포함된 1이 bias의 역할을 해주므로 bias = False 임.\n\n#collapse\ngv('''\n\"X\" -> \"X@β̂,    bias=False\"[label=\"@β̂\"] ;\n\"X@β̂,    bias=False\" -> \"ŷ\"[label=\"indentity\"] ''')\n\n\n\n\n\n저는 이걸 좋아해요\n\n(표현5)’\n- 딥러닝에서는 \\(\\hat{\\boldsymbol{\\beta}}\\) 대신에 \\(\\hat{{\\bf W}}\\)을 라고 표현한다.\n\n#collapse\ngv('''\n\"X\" -> \"X@Ŵ,    bias=False\"[label=\"@Ŵ\"] ;\n\"X@Ŵ,    bias=False\" -> \"ŷ\"[label=\"identity\"] ''')\n\n\n\n\n- 실제로는 표현4 혹은 표현5를 외우면 된다.\n\n\nLayer의 개념\n- (표현4) 혹은 (표현5)의 그림은 레이어로 설명할 수 있다.\n- 레이어는 항상 아래와 같은 규칙을 가진다. - 첫 동그라미는 레이어의 입력이다. - 첫번째 화살표는 선형변환을 의미한다. - 두번째 동그라미는 선형변환의 결과이다. (이때 bias가 false인지 true인지에 따라서 실제 수식이 조금 다름) - 두번째 화살표는 두번째 동그라미에 어떠한 함수 \\(f\\)를 취하는 과정을 의미한다. (우리의 그림에서는 \\(f(x)=x\\)) - 세번째 동그라미는 레이어의 최종출력이다.\n- 엄청 복잡한데, 결국 레이어를 만들때 위의 그림들을 의미하도록 하려면 아래의 4개의 요소만 필요하다. 1. 레이어의 입력차원 2. 선형변환의 결과로 얻어지는 차원 3. 선형변환에서 바이어스를 쓸지? 안쓸지? 4. 함수 \\(f\\)\n- 주목: 1,2가 결정되면 자동으로 \\(\\hat{{\\bf W}}\\)의 차원이 결정된다.\n(예시) - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=1: \\(\\hat{\\bf W}\\)는 (2,1) 매트릭스 - 레이어의 입력차원=20, 선형변환의 결과로 얻어지는 차원=5: \\(\\hat{\\bf W}\\)는 (20,5) 매트릭스 - 레이어의 입력차원=2, 선형변환의 결과로 얻어지는 차원=50: \\(\\hat{\\bf W}\\)는 (2,50) 매트릭스\n- 주목2: 이중에서 절대 생략불가능 것은 “2. 선형변환의 결과로 얻어지는 차원” 이다. - 레이어의 입력차원: 실제 레이어에 데이터가 들어올 때 데이터의 입력차원을 컴퓨터 스스로 체크하여 \\(\\hat{\\bf W}\\)의 차원을 결정할 수 있음. - 바이어스를 쓸지? 안쓸지? 기본적으로 쓴다고 가정한다. - 함수 \\(f\\): 기본적으로 항등함수를 가정하면 된다.\n\n\nKeras를 이용한 풀이\n- 기본뼈대: net생성 \\(\\to\\) add(layer) \\(\\to\\) compile(opt,loss) \\(\\to\\) fit(data,epochs)\n- 데이터정리\n\\[{\\bf y}\\approx 2.5 +4*x\\]\n\ntnp.random.seed(43052)\nN= 200 \nx= tnp.linspace(0,1,N)\nepsilon= tnp.random.randn(N)*0.5 \ny= 2.5+4*x +epsilon\n\n\nX=tf.stack([tf.ones(N,dtype='float64'),x],axis=1)\n\n\n풀이1: 스칼라버전\n(0단계) 데이터정리\n\ny=y.reshape(N,1)\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1) \n# 입력차원? 데이터를 넣어보고 결정, 바이어스=디폴드값을 쓰겠음 (use_bias=true), 함수도 디폴트값을 쓰겠음 (f(x)=x)\nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE) \n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용 \n\n<keras.callbacks.History at 0x7f109a893550>\n\n\n(결과확인)\n\nnet.weights\n\n[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.9330251]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([2.5836723], dtype=float32)>]\n\n\n\n\n풀이2: 벡터버전\n(0단계) 데이터정리\n\nX.shape,y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net 생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False) \nnet.add(layer)\n\n(3단계) net.compile(opt,loss_fn)\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.keras.losses.MSE) \n\n(4단계) net.fit(x,y,epochs)\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) # batch_size=N 일 경우에 경사하강법이 적용, batch_size!=N 이면 확률적 경사하강법 적용 \n\n<keras.callbacks.History at 0x7f102c2b3b20>\n\n\n(결과확인)\n\nnet.weights\n\n[<tf.Variable 'dense_1/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n\n잠시문법정리\n- 잠깐 Dense layer를 만드는 코드를 정리해보자.\n\n아래는 모두 같은 코드이다.\n\n\ntf.keras.layers.Dense(1)\ntf.keras.layers.Dense(units=1)\ntf.keras.layers.Dense(units=1,activation=‘linear’) // identity 가 더 맞는것 같은데..\ntf.keras.layers.Dense(units=1,activation=‘linear’,use_bias=True)\n\n\n아래의 코드1,2는 (1)의 코드들과 살짝 다른코드이다. (코드1과 코드2는 같은코드임)\n\n\ntf.keras.layers.Dense(1,input_dim=2) # 코드1\ntf.keras.layers.Dense(1,input_shape=(2,)) # 코드2\n\n\n아래는 사용불가능한 코드이다.\n\n\ntf.keras.layers.Dense(1,input_dim=(2,)) # 코드1\ntf.keras.layers.Dense(1,input_shape=2) # 코드2\n\n- 왜 input_dim이 필요한가?\n\nnet1 = tf.keras.Sequential()\nnet1.add(tf.keras.layers.Dense(1,use_bias=False)) \n\n\nnet2 = tf.keras.Sequential()\nnet2.add(tf.keras.layers.Dense(1,use_bias=False,input_dim=2))\n\n\nnet1.weights\n\nValueError: Weights for model sequential_4 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\n\n\n\nnet2.weights\n\n[<tf.Variable 'dense_5/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[0.4367702],\n        [0.8878907]], dtype=float32)>]\n\n\n\nnet1.summary()\n\nValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n\n\n\nnet2.summary()\n\nModel: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_5 (Dense)             (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\n풀이3: 스칼라버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\ny=y.reshape(N,1)\nx=x.reshape(N,1)\nx.shape,y.shape\n\n(TensorShape([200, 1]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential() \n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,input_dim=1)\n\n\nnet.add(layer)\n\n\n초기값을 설정\n\nnet.weights\n\n[<tf.Variable 'dense_6/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.2078832]], dtype=float32)>,\n <tf.Variable 'dense_6/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n\n\n\nnet.get_weights()\n\n[array([[1.2078832]], dtype=float32), array([0.], dtype=float32)]\n\n\n\nweight, bias순으로 출력\n\n\nnet.set_weights?\n\n\nSignature: net.set_weights(weights)\nDocstring:\nSets the weights of the layer, from NumPy arrays.\nThe weights of a layer represent the state of the layer. This function\nsets the weight values from numpy arrays. The weight values should be\npassed in the order they are created by the layer. Note that the layer's\nweights must be instantiated before calling this function, by calling\nthe layer.\nFor example, a `Dense` layer returns a list of two values: the kernel matrix\nand the bias vector. These can be used to set the weights of another\n`Dense` layer:\n>>> layer_a = tf.keras.layers.Dense(1,\n...   kernel_initializer=tf.constant_initializer(1.))\n>>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n>>> layer_a.get_weights()\n[array([[1.],\n       [1.],\n       [1.]], dtype=float32), array([0.], dtype=float32)]\n>>> layer_b = tf.keras.layers.Dense(1,\n...   kernel_initializer=tf.constant_initializer(2.))\n>>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n>>> layer_b.get_weights()\n[array([[2.],\n       [2.],\n       [2.]], dtype=float32), array([0.], dtype=float32)]\n>>> layer_b.set_weights(layer_a.get_weights())\n>>> layer_b.get_weights()\n[array([[1.],\n       [1.],\n       [1.]], dtype=float32), array([0.], dtype=float32)]\nArgs:\n  weights: a list of NumPy arrays. The number\n    of arrays and their shape must match\n    number of the dimensions of the weights\n    of the layer (i.e. it should match the\n    output of `get_weights`).\nRaises:\n  ValueError: If the provided weights list does not match the\n    layer's specifications.\nFile:      ~/anaconda3/envs/py310/lib/python3.10/site-packages/keras/engine/base_layer.py\nType:      method\n\n\n\n\n\nlayer_b.set_weights(layer_a.get_weights()) 와 같은방식으로 쓴다는 것이군?\n\n- 한번따라해보자.\n\n_w = net.get_weights()\n_w\n\n[array([[1.2078832]], dtype=float32), array([0.], dtype=float32)]\n\n\n\n길이가 2인 리스트이고, 각 원소는 numpy array 임\n\n\nnet.set_weights(\n    [np.array([[10.0]],dtype=np.float32), # weight, β1_hat\n     np.array([-5.0],dtype=np.float32)] # bias, β0_hat \n)\n\n\nnet.weights\n\n[<tf.Variable 'dense_6/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[10.]], dtype=float32)>,\n <tf.Variable 'dense_6/bias:0' shape=(1,) dtype=float32, numpy=array([-5.], dtype=float32)>]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1),tf.losses.MSE) \n\n(4단계) net.fit()\n\nnet.fit(x,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f0f90b1d120>\n\n\n결과확인\n\nnet.weights\n\n[<tf.Variable 'dense_6/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.933048]], dtype=float32)>,\n <tf.Variable 'dense_6/bias:0' shape=(1,) dtype=float32, numpy=array([2.58366], dtype=float32)>]\n\n\n\n\n풀이4: 벡터버전, 임의의 초기값을 설정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False,input_dim=2) \n\n\nnet.add(layer)\n\n\n초기값을 설정하자\n\nnet.set_weights([np.array([[ -5.0],[10.0]], dtype=np.float32)])\n\n\nnet.get_weights()\n\n[array([[-5.],\n        [10.]], dtype=float32)]\n\n\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), tf.losses.MSE) \n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f0f7b9175e0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_7/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.58366 ],\n        [3.933048]], dtype=float32)>]\n\n\n- 사실 실전에서는 초기값을 설정할 필요가 별로 없음.\n\n\n풀이5: 벡터버전 사용자정의 손실함수\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nlayer = tf.keras.layers.Dense(1,use_bias=False) \n\n\nnet.add(layer)\n\n(3단계) net.compile()\n\nloss_fn = lambda y,yhat: (y-yhat).T @ (y-yhat) / N\n\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss_fn) \n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f0f914134f0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_8/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n\n풀이6: 벡터버전, net.compile의 옵션으로 손실함수 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(tf.keras.optimizers.SGD(0.1), loss='mse') \n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f0f7b9e02e0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_11/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5836723],\n        [3.9330251]], dtype=float32)>]\n\n\n\n\n풀이7: 벡터버전, net.compile의 옵션으로 손실함수 지정 + 옵티마이저 지정\n(0단계) 데이터정리\n\nX.shape, y.shape\n\n(TensorShape([200, 2]), TensorShape([200, 1]))\n\n\n(1단계) net생성\n\nnet = tf.keras.Sequential()\n\n(2단계) net.add(layer)\n\nnet.add(tf.keras.layers.Dense(1,use_bias=False))\n\n(3단계) net.compile()\n\nnet.compile(optimizer='sgd', loss='mse') \n#net.optimizer.lr = tf.Variable(0.1,dtype=tf.float32)\n#net.optimizer.lr = 0.1\n\n(4단계) net.fit()\n\nnet.fit(X,y,epochs=5000,verbose=0,batch_size=N) \n\n<keras.callbacks.History at 0x7f0f785482e0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_22/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.5848842],\n        [3.9307659]], dtype=float32)>]\n\n\n\n\n\n여러가지 회귀모형의 적합과 학습과정의 모니터링\n\n예제1\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 x_i\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.random.randn(N) \nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*x +epsilon\n\n\nX= np.stack([np.ones(N),x],axis=1)\ny= y.reshape(N,1)\n\n\nplt.plot(x,y,'o') # 관측한 자료 \n\n\n\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\n\n\nyhat = X@beta_hat \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-') \n\n\n\n\n더 좋은 적합선을 얻기위해서!\n\nslope = (2*X.T@X@beta_hat - 2*X.T@y)/ N \nbeta_hat2 = beta_hat - 0.1*slope  \nyhat2 = X@beta_hat2\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.reshape(-1),'-') \nplt.plot(x,yhat2.reshape(-1),'-') \n\n\n\n\n초록색이 좀 더 나아보인다.\n\nbeta_hat = np.array([-3,-2]).reshape(2,1) \nbeta_hats = beta_hat # beta_hats = beta_hat.copy() 가 더 안전한 코드입니다. \nfor i in range(1,30):\n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat - 2*X.T@y) / N \n    beta_hat = beta_hat - 1.0*slope # 0.1은 적당, 0.3은 쪼금빠르지만 그래도 적당, 0.9는 너무 나간것같음, 1.0 은 수렴안함, 1.2 \n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) \n\n\nbeta_hats\n\narray([[-3.        ,  7.12238255, -1.2575366 ,  5.73166742, -0.1555309 ,\n         4.86767499,  0.51106397,  4.36611576,  0.87316777,  4.12348617,\n         1.01165173,  4.07771926,  0.97282343,  4.19586617,  0.77814101,\n         4.46653491,  0.4299822 ,  4.89562729, -0.08537358,  5.50446319,\n        -0.79684366,  6.32975688, -1.74933031,  7.42517729, -3.00603683,\n         8.86442507, -4.6523303 , 10.74592463, -6.80132547, 13.19938129],\n       [-2.        ,  8.70824998,  0.16165717,  6.93399596,  1.62435964,\n         5.72089586,  2.63858056,  4.86387722,  3.37280529,  4.22385379,\n         3.94259478,  3.70397678,  4.43004465,  3.23363047,  4.89701606,\n         2.75741782,  5.39439054,  2.22728903,  5.96886945,  1.59655409,\n         6.66836857,  0.81489407,  7.54676324, -0.17628423,  8.66856437,\n        -1.44867655, 10.11401544, -3.09256176, 11.98507323, -5.22340389]])\n\n\n\nb0hats = beta_hats[0].tolist()\nb1hats = beta_hats[1].tolist()\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.5451404 ],\n       [3.94818596]])\n\n\n\nfrom matplotlib import animation \nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 \nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*x) \n# ax2: 오른쪽그림 \nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*x)**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02) \nax2.scatter(2.5451404,3.94818596,loss_fn(2.5451404,3.94818596),s=200,marker='*') \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*x) \n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제2\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) +epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nX= np.stack([np.ones(N),np.exp(-x)],axis=1)\ny= y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2]).reshape(2,1)\nbeta_hats = beta_hat.copy() # shallow copy, deep copy <--- 여름 방학 특강 \nfor i in range(1,30): \n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat - 2*X.T@y) /N \n    beta_hat = beta_hat - 0.05*slope \n    beta_hats = np.concatenate([beta_hats,beta_hat],axis=1) \n\n\nbeta_hats\n\narray([[-3.        , -1.74671631, -0.82428979, -0.14453919,  0.35720029,\n         0.72834869,  1.0036803 ,  1.20869624,  1.36209751,  1.47759851,\n         1.56525696,  1.63244908,  1.68458472,  1.72563174,  1.75850062,\n         1.78532638,  1.80767543,  1.82669717,  1.84323521,  1.85790889,\n         1.8711731 ,  1.88336212,  1.89472176,  1.90543297,  1.91562909,\n         1.92540859,  1.93484428,  1.94399023,  1.9528867 ,  1.96156382],\n       [-2.        , -0.25663415,  1.01939241,  1.95275596,  2.63488171,\n         3.13281171,  3.49570765,  3.75961951,  3.95098231,  4.08918044,\n         4.18842797,  4.2591476 ,  4.30898175,  4.34353413,  4.36691339,\n         4.38213187,  4.39139801,  4.39633075,  4.39811673,  4.3976256 ,\n         4.3954946 ,  4.3921905 ,  4.38805511,  4.3833386 ,  4.37822393,\n         4.37284482,  4.36729887,  4.36165718,  4.35597148,  4.35027923]])\n\n\n\nb0hats= beta_hats[0].tolist()\nb1hats= beta_hats[1].tolist()\n\n\nnp.linalg.inv(X.T@X)@X.T@y\n\narray([[2.46307644],\n       [3.99681332]])\n\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 \nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x))\n# ax2: 오른쪽그림 \nβ0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\nβ0=β0.reshape(-1)\nβ1=β1.reshape(-1)\nloss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\nloss = list(map(loss_fn, β0,β1))\nax2.scatter(β0,β1,loss,alpha=0.02) \nax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*') \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x))\n    ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) \ny=y.reshape(N,1)\n\n\nbeta_hat = np.array([-3,-2,-1]).reshape(3,1) \nbeta_hats = beta_hat.copy()\nfor i in range(1,30):\n    yhat = X@beta_hat \n    slope = (2*X.T@X@beta_hat -2*X.T@y) /N \n    beta_hat = beta_hat - 0.1 * slope \n    beta_hats= np.concatenate([beta_hats,beta_hat],axis=1)\n\n\nbeta_hats\n\narray([[-3.        , -0.71767532,  0.36255782,  0.89072137,  1.16423101,\n         1.31925078,  1.41819551,  1.48974454,  1.54713983,  1.59655416,\n         1.64091846,  1.68167278,  1.71956758,  1.75503084,  1.78833646,\n         1.81968188,  1.84922398,  1.877096  ,  1.90341567,  1.92828934,\n         1.95181415,  1.97407943,  1.99516755,  2.01515463,  2.0341111 ,\n         2.05210214,  2.06918818,  2.08542523,  2.10086524,  2.11555643],\n       [-2.        ,  1.16947474,  2.64116513,  3.33411605,  3.66880042,\n         3.83768856,  3.92897389,  3.98315095,  4.01888831,  4.04486085,\n         4.06516144,  4.08177665,  4.09571971,  4.10754954,  4.1176088 ,\n         4.12613352,  4.13330391,  4.13926816,  4.14415391,  4.14807403,\n         4.15112966,  4.1534121 ,  4.15500404,  4.15598045,  4.15640936,\n         4.15635249,  4.15586584,  4.15500014,  4.15380139,  4.1523112 ],\n       [-1.        , -0.95492718, -0.66119313, -0.27681968,  0.12788212,\n         0.52254445,  0.89491388,  1.24088224,  1.55993978,  1.85310654,\n         2.12199631,  2.36839745,  2.59408948,  2.8007666 ,  2.99000967,\n         3.16327964,  3.32192026,  3.46716468,  3.60014318,  3.72189116,\n         3.83335689,  3.93540864,  4.02884144,  4.11438316,  4.19270026,\n         4.26440288,  4.33004965,  4.39015202,  4.44517824,  4.49555703]])\n\n\n\nb0hats,b1hats,b2hats = beta_hats\n\n\nnp.linalg.inv(X.T@X) @ X.T @ y\n\narray([[2.46597526],\n       [4.00095138],\n       [5.04161877]])\n\n\n\nfig = plt.figure(); fig.set_figheight(5); fig.set_figwidth(12)\n\n<Figure size 864x360 with 0 Axes>\n\n\n\nax1= fig.add_subplot(1,2,1)\nax2= fig.add_subplot(1,2,2,projection='3d')\n# ax1: 왼쪽그림 \nax1.plot(x,y,'o')\nline, = ax1.plot(x,b0hats[0] + b1hats[0]*np.exp(-x) + b2hats[0]*np.cos(5*x))\n# ax2: 오른쪽그림 \n# β0,β1 = np.meshgrid(np.arange(-6,11,0.25),np.arange(-6,11,0.25),indexing='ij')\n# β0=β0.reshape(-1)\n# β1=β1.reshape(-1)\n# loss_fn = lambda b0,b1: np.sum((y-b0-b1*np.exp(-x))**2)\n# loss = list(map(loss_fn, β0,β1))\n# ax2.scatter(β0,β1,loss,alpha=0.02) \n# ax2.scatter(2.46307644,3.99681332,loss_fn(2.46307644,3.99681332),s=200,marker='*') \n\ndef animate(i):\n    line.set_ydata(b0hats[i] + b1hats[i]*np.exp(-x) + b2hats[i]*np.cos(5*x))\n    # ax2.scatter(b0hats[i],b1hats[i],loss_fn(b0hats[i],b1hats[i]),color=\"grey\") \n\nani = animation.FuncAnimation(fig,animate,frames=30) \nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n예제3: 케라스로 해보자!\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i} + \\beta_2 \\cos(5x_i)\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) + 5*np.cos(5*x) + epsilon\n\n\nX=np.stack([np.ones(N),np.exp(-x),np.cos(5*x)],axis=1) \ny=y.reshape(N,1)\n\n\nnet = tf.keras.Sequential() # 1: 네트워크 생성\nnet.add(tf.keras.layers.Dense(1,use_bias=False)) # 2: add layer \nnet.compile(tf.optimizers.SGD(0.1), loss='mse') # 3: compile\nnet.fit(X,y,epochs=30, batch_size=N) # 4: fit \n\nEpoch 1/30\n1/1 [==============================] - 0s 60ms/step - loss: 47.7087\nEpoch 2/30\n1/1 [==============================] - 0s 1ms/step - loss: 21.4259\nEpoch 3/30\n1/1 [==============================] - 0s 1ms/step - loss: 14.1095\nEpoch 4/30\n1/1 [==============================] - 0s 1ms/step - loss: 11.0534\nEpoch 5/30\n1/1 [==============================] - 0s 1ms/step - loss: 9.1350\nEpoch 6/30\n1/1 [==============================] - 0s 915us/step - loss: 7.6614\nEpoch 7/30\n1/1 [==============================] - 0s 758us/step - loss: 6.4544\nEpoch 8/30\n1/1 [==============================] - 0s 733us/step - loss: 5.4484\nEpoch 9/30\n1/1 [==============================] - 0s 741us/step - loss: 4.6063\nEpoch 10/30\n1/1 [==============================] - 0s 768us/step - loss: 3.9007\nEpoch 11/30\n1/1 [==============================] - 0s 766us/step - loss: 3.3093\nEpoch 12/30\n1/1 [==============================] - 0s 745us/step - loss: 2.8135\nEpoch 13/30\n1/1 [==============================] - 0s 735us/step - loss: 2.3979\nEpoch 14/30\n1/1 [==============================] - 0s 876us/step - loss: 2.0495\nEpoch 15/30\n1/1 [==============================] - 0s 889us/step - loss: 1.7574\nEpoch 16/30\n1/1 [==============================] - 0s 886us/step - loss: 1.5126\nEpoch 17/30\n1/1 [==============================] - 0s 788us/step - loss: 1.3073\nEpoch 18/30\n1/1 [==============================] - 0s 850us/step - loss: 1.1352\nEpoch 19/30\n1/1 [==============================] - 0s 717us/step - loss: 0.9910\nEpoch 20/30\n1/1 [==============================] - 0s 678us/step - loss: 0.8700\nEpoch 21/30\n1/1 [==============================] - 0s 695us/step - loss: 0.7686\nEpoch 22/30\n1/1 [==============================] - 0s 746us/step - loss: 0.6836\nEpoch 23/30\n1/1 [==============================] - 0s 703us/step - loss: 0.6123\nEpoch 24/30\n1/1 [==============================] - 0s 710us/step - loss: 0.5526\nEpoch 25/30\n1/1 [==============================] - 0s 838us/step - loss: 0.5025\nEpoch 26/30\n1/1 [==============================] - 0s 935us/step - loss: 0.4605\nEpoch 27/30\n1/1 [==============================] - 0s 947us/step - loss: 0.4252\nEpoch 28/30\n1/1 [==============================] - 0s 824us/step - loss: 0.3957\nEpoch 29/30\n1/1 [==============================] - 0s 864us/step - loss: 0.3709\nEpoch 30/30\n1/1 [==============================] - 0s 831us/step - loss: 0.3501\n\n\n<keras.callbacks.History at 0x7f0f68b8fbb0>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_23/kernel:0' shape=(3, 1) dtype=float32, numpy=\n array([[2.354784 ],\n        [3.9989622],\n        [4.58522  ]], dtype=float32)>]\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,(X@net.weights).reshape(-1),'--')\n\n\n\n\n\n\n\n숙제\n\n예제2: 케라스를 이용하여 아래를 만족하는 적절한 \\(\\beta_0\\)와 \\(\\beta_1\\)을 구하라. 적합결과를 시각화하라. (애니메이션 시각화 X)\nmodel: \\(y_i \\approx \\beta_0 +\\beta_1 e^{-x_i}\\)\n\nnp.random.seed(43052) \nN= 100 \nx= np.linspace(-1,1,N)\nepsilon = np.random.randn(N)*0.5 \ny= 2.5+4*np.exp(-x) +epsilon"
  },
  {
    "objectID": "posts/3_STBDA2022/2022_04_04_(5주차)_4월4일.html",
    "href": "posts/3_STBDA2022/2022_04_04_(5주차)_4월4일.html",
    "title": "Quarto-Blog",
    "section": "",
    "text": "(5주차) 4월4일\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wVWUAZ5xT35INvWbNOXpBx\n\n\n\nimports\n\n#\n#!conda install -c conda-forge python-graphviz -y\n\n\nimport tensorflow as tf \nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\nimport tensorflow.experimental.numpy as tnp \n\n\ntnp.experimental_enable_numpy_behavior() \n\n\n\n최적화의 문제\n- \\(loss=(\\frac{1}{2}\\beta-1)^2\\)\n- 기존에 했던 방법은 수식을 알고 있어야 한다는 단점이 있음\n\n\ntf.keras.optimizers를 이용한 최적화방법\n\n방법1: opt.apply_gradients()를 이용\n\nalpha= 0.01/6\n\n\nbeta= tf.Variable(-10.0) \n\n\nopt = tf.keras.optimizers.SGD(alpha)\n\n- iter1\n\nwith tf.GradientTape() as tape: \n    tape.watch(beta) \n    loss=(beta/2-1)**2 \nslope = tape.gradient(loss,beta)\n\n\nopt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n- iter2\n\nwith tf.GradientTape() as tape: \n    tape.watch(beta) \n    loss=(beta/2-1)**2 \nslope = tape.gradient(loss,beta)\nopt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.980008>\n\n\n- for문으로 정리\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0) \nopt = tf.keras.optimizers.SGD(alpha)\n\n\nfor epoc in range(10000): \n    with tf.GradientTape() as tape: \n        tape.watch(beta) \n        loss=(beta/2-1)**2 \n    slope = tape.gradient(loss,beta)\n    opt.apply_gradients([(slope,beta)]) # beta.assign_sub(slope * alpha) \n    beta\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9971251>\n\n\n\nopt.apply_gradients()의 입력은 pair 의 list\n\n\n\n방법2: opt.minimize()\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0) \nopt = tf.keras.optimizers.SGD(alpha)\n\n\nloss_fn = lambda: (beta/2-1)**2\n\n\nlambda x: x**2 <=> lambda(x)=x^2\nlambda x,y: x+y <=> lambda(x,y)=x+y\nlambda: y <=> lambda()=y, 입력이 없으며 출력은 항상 y인 함수\n\n\nloss_fn() # 입력은 없고 출력은 뭔가 계산되는 함수 \n\n<tf.Tensor: shape=(), dtype=float32, numpy=36.0>\n\n\n- iter 1\n\nopt.minimize(loss_fn, beta)\n\n<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>\n\n\n\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.99>\n\n\n- iter2\n\nopt.minimize(loss_fn, beta)\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-9.980008>\n\n\n- for문으로 정리하면\n\nalpha= 0.01/6\nbeta= tf.Variable(-10.0) \nopt = tf.keras.optimizers.SGD(alpha)\nloss_fn = lambda: (beta/2-1)**2\nfor epoc in range(10000): \n    opt.minimize(loss_fn, beta)\nbeta\n\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9971251>\n\n\n\n\n\n회귀분석 문제\n- \\({\\bf y} \\approx 2.5 + 4.0 {\\bf x}\\)\n\ntnp.random.seed(43052)\nN = 200\nx = tnp.linspace(0,1,N) \nepsilon = tnp.random.randn(N)*0.5\ny = 2.5+4*x + epsilon\ny_true = 2.5+4*x\n\n\nplt.plot(x,y,'.')\nplt.plot(x,y_true,'r--')\n\n\n\n\n\n\n이론적 풀이\n\n풀이1: 스칼라버전\n- 포인트 - \\(S_{xx}=\\), \\(S_{xy}=\\) - \\(\\hat{\\beta}_0=\\), \\(\\hat{\\beta}_1=\\)\n- 풀이\n\nSxx = sum((x-x.mean())**2)\nSxy = sum((x-x.mean())*(y-y.mean()))\n\n\nbeta1_hat = Sxy/Sxx \nbeta1_hat\n\n<tf.Tensor: shape=(), dtype=float64, numpy=3.933034516733168>\n\n\n\nbeta0_hat = y.mean() - x.mean()*beta1_hat\nbeta0_hat\n\n<tf.Tensor: shape=(), dtype=float64, numpy=2.583667211565867>\n\n\n\n\n풀이2: 벡터버전\n- 포인트 - \\(\\hat{\\beta}=(X'X)^{-1}X'y\\)\n- 풀이\n\ny=y.reshape(N,1)\nX=tf.stack([tf.ones(N,dtype=tf.float64),x],axis=1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\ntf.linalg.inv(X.T @ X ) @ X.T @ y \n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[2.58366721],\n       [3.93303452]])>\n\n\n\n\n풀이3: 벡터버전, 손실함수의 도함수이용\n- 포인트 - \\(loss'(\\beta)=-2X'y +2X'X\\beta\\) - \\(\\beta_{new} = \\beta_{old} - \\alpha \\times loss'(\\beta_{old})\\)\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tnp.array([-5,10]).reshape(2,1)\nbeta_hat\n\n<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\narray([[-5],\n       [10]])>\n\n\n\nslope = (-2*X.T @ y + 2*X.T @ X @ beta_hat) / N \nslope\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[-9.10036894],\n       [-3.52886113]])>\n\n\n\nalpha= 0.1 \n\n\nstep = slope*alpha\nstep\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[-0.91003689],\n       [-0.35288611]])>\n\n\n\nfor epoc in range(1000): \n    slope = (-2*X.T @ y + 2*X.T @ X @ beta_hat)/N \n    beta_hat = beta_hat - alpha* slope\n\n\nbeta_hat\n\n<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n\nGradientTape를 이용\n\n풀이1: 벡터버전\n- 포인트\n## 포인트코드1: 그레디언트 테입  \nwith tf.GradientTape() as tape: \n    loss = \n## 포인트코드2: 미분 \nslope = tape.gradient(loss,beta_hat) \n## 포인트코드3: update \nbeta_hat.assign_sub(slope*alph) \n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\nalpha=0.1\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= X@beta_hat\n        loss= (y-yhat).T @ (y-yhat) / N\n    slope = tape.gradient(loss,beta_hat) \n    beta_hat.assign_sub(alpha*slope) \n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이2: 스칼라버전\n- 포인트\n## 포인트코드: 미분\nslope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat])\n- 풀이\n\ny=y.reshape(-1)\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0)\n\n\nalpha=0.1\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= beta0_hat + x*beta1_hat \n        loss= tf.reduce_sum((y-yhat)**2)/N #loss= sum((y-yhat)**2)/N\n    slope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat]) \n    beta0_hat.assign_sub(alpha*slope0)\n    beta1_hat.assign_sub(alpha*slope1)\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\n\n\nGradientTape + opt.apply_gradients\n\n풀이1: 벡터버전\n- 포인트\n## 포인트코드: 업데이트\nopt.apply_gradients([(slope,beta_hat)])  ## pair의 list가 입력 \n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= X@beta_hat\n        loss= (y-yhat).T @ (y-yhat) / N\n    slope = tape.gradient(loss,beta_hat)\n    opt.apply_gradients([(slope,beta_hat)])\n    #beta_hat.assign_sub(alpha*slope) \n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이2: 스칼라버전\n- 포인트\n## 포인트코드: 업데이트 \nopt.apply_gradients([(slope0,beta0_hat),(slope1,beta1_hat)]) ## pair의 list가 입력 \n- 풀이\n\ny=y.reshape(-1)\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0)\n\n\nalpha=0.1\nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000):\n    with tf.GradientTape() as tape: \n        yhat= beta0_hat + beta1_hat*x #X@beta_hat\n        loss= tf.reduce_sum((y-yhat)**2) / N\n    slope0,slope1 = tape.gradient(loss,[beta0_hat,beta1_hat])\n    opt.apply_gradients([(slope0,beta0_hat),(slope1,beta1_hat)])\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\n\n\nopt.minimize\n\n풀이1: 벡터버전, 사용자정의 손실함수 with lambda\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\nloss_fn = lambda: (y-X@beta_hat).T @ (y-X@beta_hat) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,beta_hat)\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이2: 스칼라버전, 사용자정의 손실함수 with lambda\n- 포인트\n## 포인트코드: 미분 & 업데이트 = minimize \nopt.minimize(loss_fn,[beta0_hat,beta1_hat])\n- 풀이\n\ny=y.reshape(-1)\ny.shape,x.shape\n\n(TensorShape([200]), TensorShape([200]))\n\n\n\nbeta0_hat = tf.Variable(-5.0)\nbeta1_hat = tf.Variable(10.0) \n\n\nloss_fn = lambda: tf.reduce_sum((y-beta0_hat-beta1_hat*x )**2) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,[beta0_hat,beta1_hat])\n\n\nbeta0_hat,beta1_hat\n\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.58366>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.933048>)\n\n\n\n\n풀이3: 벡터버전, 사용자정의 (짧은) 손실함수\n- 포인트\n## 포인트코드: 손실함수정의 \ndef loss_fn():\n    return ??\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    return (y-X@beta_hat).T @ (y-X@beta_hat) / N \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,beta_hat)\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이4: 벡터버전, 사용자정의 (긴) 손실함수\n- 포인트\n## 포인트코드: 손실함수정의 \ndef loss_fn():\n    ??\n    ??\n    return ??\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = (y-yhat).T @ (y-yhat) / N # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,beta_hat)\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이5: 벡터버전, 사용자정의 손실함수 <- tf.losses.MSE\n- 포인트\n## 포인트코드: 미리구현되어있는 손실함수 이용 \ntf.losses.MSE(y,yhat)\n- 풀이\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = tf.keras.losses.MSE(y.reshape(-1),yhat.reshape(-1)) # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,beta_hat)\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n풀이6: 벡터버전, 사용자정의 손실함수 <- tf.losses.MeaSquaredError\n- 포인트\n## 포인트코드: 클래스로부터 손실함수 오브젝트 생성 (함수를 찍어내는 클래스) \nmse_fn = tf.losses.MeanSquaredError()\nmse_fn(y,yhat)\n- 풀이\n\nmseloss_fn = tf.losses.MeanSquaredError()\n\n\nmseloss_fn = tf.keras.losses.MSE 라고 보면된다.\n\n\ny=y.reshape(N,1)\ny.shape,X.shape\n\n(TensorShape([200, 1]), TensorShape([200, 2]))\n\n\n\nbeta_hat = tf.Variable(tnp.array([-5.0,10.0]).reshape(2,1))\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[-5.],\n       [10.]])>\n\n\n\ndef loss_fn():\n    yhat= X@beta_hat # 컴퓨터한테 전달할 수식1\n    loss = mseloss_fn(y.reshape(-1),yhat.reshape(-1)) # 컴퓨터한테 전달할 수식 2 \n    return loss # tape.gradient(loss,beta_hat) 에서의 미분당하는애 \n\n\nalpha=0.1 \nopt = tf.optimizers.SGD(alpha)\n\n\nfor epoc in range(1000): \n    opt.minimize(loss_fn,beta_hat)\n\n\nbeta_hat\n\n<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\narray([[2.58366061],\n       [3.93304684]])>\n\n\n\n\n\ntf.keras.Sequential\n- \\(\\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1x_i\\) 의 서로다른 표현\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+s + '; }')\n\n\ngv(''' \n    \"1\" -> \"beta0_hat + x*beta1_hat,    bias=False\"[label=\"* beta0_hat\"]\n    \"x\" -> \"beta0_hat + x*beta1_hat,    bias=False\"[label=\"* beta1_hat\"]\n    \"beta0_hat + x*beta1_hat,    bias=False\" -> \"yhat\"[label=\"indentity\"]\n    ''')\n\n\n\n\n\ngv('''\n\"x\" -> \"x*beta1_hat,    bias=True\"[label=\"*beta1_hat\"] ;\n\"x*beta1_hat,    bias=True\" -> \"yhat\"[label=\"indentity\"] ''')\n\n\n\n\n\ngv('''\n\"X=[1 x]\" -> \"X@beta_hat,    bias=False\"[label=\"@beta_hat\"] ;\n\"X@beta_hat,    bias=False\" -> \"yhat\"[label=\"indentity\"] ''')\n\n\n\n\n\n풀이1: 벡터버전, 사용자정의 손실함수\n- 포인트\n## 포인트코드1: 네트워크 생성 \nnet = tf.keras.Sequential()\n\n## 포인트코드2: 네트워크의 아키텍처 설계 \nnet.add(tf.keras.layers.Dense(1,input_shape=(2,),use_bias=False)) \n\n## 포인트코드3: 네트워크 컴파일 = 아키텍처 + 손실함수 + 옵티마이저\nnet.compile(opt,loss=loss_fn2)\n\n## 포인트코드4: 미분 & update \nnet.fit(X,y,epochs=1000,verbose=0,batch_size=N) \n- 풀이\n\nnet = tf.keras.Sequential() \n\n\nnet.add(tf.keras.layers.Dense(units=1,input_shape=(2,),use_bias=False)) ## yhat을 구하는 방법정의 = 아키텍처가 설계 \n\n\nunits는 layer의 출력의 차원, 이 경우는 yhat의 차원, yhat은 (200,1) 이므로 1임.\ninput_shape는 layer의 입력의 차원, 이 경우는 X의 차원, X는 (200,2) 이므로 2임.\n\n\ndef loss_fn2(y,yhat):\n    return (y-yhat).T @ (y-yhat) / N \n\n\nalpha=0.1\nopt =tf.optimizers.SGD(alpha)\n\n\n[np.array([[-5.0],[10.0]],dtype=np.float32)]\n\n[array([[-5.],\n        [10.]], dtype=float32)]\n\n\n\nnet.set_weights([np.array([[-5.0],[10.0]],dtype=np.float32)])\n\n\nnet.weights\n\n[<tf.Variable 'dense_5/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-5.],\n        [10.]], dtype=float32)>]\n\n\n\nnet.compile(opt,loss=tf.losses.MSE)\n# 아키텍처 + 손실함수 + 옵티마이저 => 네트워크에 다 합치자 => 네트워크를 컴파일한다. \n\n\nnet.fit(X,y,epochs=1000,batch_size=N,verbose=0) # 미분 + 파라메터업데이트 = net.fit \n\n<keras.callbacks.History at 0x7f6366237640>\n\n\n\nnet.weights\n\n[<tf.Variable 'dense_5/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[2.58366 ],\n        [3.933048]], dtype=float32)>]"
  },
  {
    "objectID": "posts/5_study/2023-02-20-ts1.html",
    "href": "posts/5_study/2023-02-20-ts1.html",
    "title": "ts1",
    "section": "",
    "text": "The classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\n\nlibrary(forecast)\nlibrary(tseries)\nlibrary(tidyverse)\n\n\nap <- AirPassengers\nap\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949 112 118 132 129 121 135 148 148 136 119 104 118\n1950 115 126 141 135 125 149 170 170 158 133 114 140\n1951 145 150 178 163 172 178 199 199 184 162 146 166\n1952 171 180 193 181 183 218 230 242 209 191 172 194\n1953 196 196 236 235 229 243 264 272 237 211 180 201\n1954 204 188 235 227 234 264 302 293 259 229 203 229\n1955 242 233 267 269 270 315 364 347 312 274 237 278\n1956 284 277 317 313 318 374 413 405 355 306 271 306\n1957 315 301 356 348 355 422 465 467 404 347 305 336\n1958 340 318 362 348 363 435 491 505 404 359 310 337\n1959 360 342 406 396 420 472 548 559 463 407 362 405\n1960 417 391 419 461 472 535 622 606 508 461 390 432\n\n\n\nap %>% glimpse()\n\n Time-Series [1:144] from 1949 to 1961: 112 118 132 129 121 135 148 148 136 119 ...\n\n\n\nclass(ap)\n\n[1] \"ts\"\n\n\n\nts 객체는 시계열 데이터를 처리하기 위한 속성\n\n\nstart(ap)\n\n[1] 1949    1\n\nend(ap)\n\n[1] 1960   12\n\nfrequency(ap)\n\n[1] 12\n\n\n\nplot(ap)\n\n\n\n\n\ncycle(ap)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1949   1   2   3   4   5   6   7   8   9  10  11  12\n1950   1   2   3   4   5   6   7   8   9  10  11  12\n1951   1   2   3   4   5   6   7   8   9  10  11  12\n1952   1   2   3   4   5   6   7   8   9  10  11  12\n1953   1   2   3   4   5   6   7   8   9  10  11  12\n1954   1   2   3   4   5   6   7   8   9  10  11  12\n1955   1   2   3   4   5   6   7   8   9  10  11  12\n1956   1   2   3   4   5   6   7   8   9  10  11  12\n1957   1   2   3   4   5   6   7   8   9  10  11  12\n1958   1   2   3   4   5   6   7   8   9  10  11  12\n1959   1   2   3   4   5   6   7   8   9  10  11  12\n1960   1   2   3   4   5   6   7   8   9  10  11  12\n\n\n\nboxplot(ap~cycle(ap))"
  },
  {
    "objectID": "posts/5_study/2023-02-25-jt-test.html",
    "href": "posts/5_study/2023-02-25-jt-test.html",
    "title": "JT test",
    "section": "",
    "text": "JT-test\n\nEx1\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.2.0     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\ngroup <- c(rep(3,8), rep(2,7), rep(1,7))\nspace <- c(54.0,67.0,47.2,71.1,62.7,44.8,67.4,80.2,\n           79.8,82.0,88.8,79.6,85.7,81.7,88.5,\n          98.6,99.5,95.8,93.3,98.9,91.1,94.5)\n\n\n# H0: m_N = m_U = m_S\n# H1: m_N >= m_U >= m_s (at least one strict inequality)\nlibrary(clinfun)\njonckheere.test(space, \n                group,\n                alternative = 'decreasing')\n\n\n    Jonckheere-Terpstra test\n\ndata:  \nJT = 2, p-value = 7.29e-09\nalternative hypothesis: decreasing\n\n\n\n\nLarge-Sample Approximation\nFor large sample sizes, J is approximately normally distributed with mean 0 and variance 1. When we use the normal approximation, we compute.\n\\[\nz = \\frac{J-[(N^2 - \\sum_{i=1}^kn_i^2)/4]}{\\sqrt{[N^2(2N+3)-\\sum_{k=1}^kn_i^2(2n_i+3)]/72}}\n\\] ### Ex2\n\njonckheere.test(mtcars$mpg,\n                as.integer(mtcars$cyl),\n                alternative = 'decreasing')\n\nWarning in jonckheere.test(mtcars$mpg, as.integer(mtcars$cyl), alternative = \"decreasing\"): Sample size > 100 or data with ties \n p-value based on normal approximation. Specify nperm for permutation p-value\n\n\n\n    Jonckheere-Terpstra test\n\ndata:  \nJT = 5, p-value = 1.153e-08\nalternative hypothesis: decreasing\n\n\n\nN <- nrow(mtcars)\nn1 <- filter(mtcars, mtcars$cyl == 4) %>% nrow()\nn2 <- filter(mtcars, mtcars$cyl == 6) %>% nrow()\nn3 <- filter(mtcars, mtcars$cyl == 8) %>% nrow()\n\n\nmu <- ((N^2 - (n1^2+n2^2+n3^2))/4)\nvar_ <- (N^2*(2*N+3)-((n1^2*(2*n1+3) + n2^2*(2*n2+3) + n3^2*(2*n3 + 3))))/72\nmu; var_\n\n[1] 164.5\n\n\n[1] 814.9167\n\n\n\npnorm(5, mu, sqrt(var_), lower.tail = TRUE)\n\n[1] 1.152957e-08\n\n\n\nz_ = (5 - mu) / sqrt(var_)\npnorm(z_,  lower.tail = TRUE)\n\n[1] 1.152957e-08"
  },
  {
    "objectID": "posts/5_study/2023-02-20-simul_eq.html",
    "href": "posts/5_study/2023-02-20-simul_eq.html",
    "title": "simultaneous equation",
    "section": "",
    "text": "파이썬에서 Numpy는 행렬 계산을 쉽게하기 위해 사용하는 패키지이다. R로도 행렬과 매트릭스를 구현해보자.\n- 예를 들어 아래와 같은 문제가 있다고 하자.\n\\[\\begin{cases}w+2x+ey+4z = 1 \\\\2w+2x+y=9 \\\\x-y = 4 \\\\3w+x-y+3y=7\\end{cases}\\]\n- 매트릭스 형태로 위의 식을 표현하면 아래와 같다.\n\\[\n\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\nw \\\\ x \\\\ y \\\\z\n\\end{bmatrix}=\\begin{bmatrix}\n1 \\\\ 9 \\\\ 4 \\\\7\n\\end{bmatrix}\n\\]\n- 양변에\n\\[\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}\\]\n의 역행렬을 취하면\n\\[\\begin{bmatrix}\nw \\\\ x \\\\ y \\\\z\n\\end{bmatrix}=\\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n2 & 2 & 1 & 0 \\\\\n0 & 1 &-1 & 0 \\\\\n3 & 1 &-1 & 3\n\\end{bmatrix}^{-1}\\begin{bmatrix}\n1 \\\\ 9 \\\\ 4 \\\\7\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/5_study/2023-02-20-simul_eq.html#r로-구현",
    "href": "posts/5_study/2023-02-20-simul_eq.html#r로-구현",
    "title": "simultaneous equation",
    "section": "R로 구현",
    "text": "R로 구현\n\n- 방법1\n\nA=rbind(c(1,2,3,4),c(2,2,1,0),c(0,1,-1,0),c(3,1,-1,3))\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    2    2    1    0\n[3,]    0    1   -1    0\n[4,]    3    1   -1    3\n\n\n\nb=c(1,9,4,7)\ndim(b)=c(4,1)\nb\n\n     [,1]\n[1,]    1\n[2,]    9\n[3,]    4\n[4,]    7\n\n\n\nsolve(A) %*% b \n\n     [,1]\n[1,]    2\n[2,]    3\n[3,]   -1\n[4,]   -1\n\n\n따라서 \\((w,x,y,z) = (2,3,-1,-1)\\) 이다.\n\n\n- 방법2\n\nA = rbind(c(1,2,3,4),c(2,2,1,0),c(0,1,-1,0),c(3,1,-1,3))\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    2    2    1    0\n[3,]    0    1   -1    0\n[4,]    3    1   -1    3\n\n\n\nb = c(1,9,4,7)\nb\n\n[1] 1 9 4 7\n\n\n\nsolve(A) %*% b\n\n     [,1]\n[1,]    2\n[2,]    3\n[3,]   -1\n[4,]   -1"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html",
    "href": "posts/4_TS2023/2023-05-12-2wk.html",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "",
    "text": "정의역: \\(\\Omega\\)\n치역: \\(\\mathbb{R}\\)의 부분집합\n\n\n\n\\(\\Omega = \\{H,T\\}\\)\n\\(X: \\Omega \\to \\mathbb{R}\\)\n\n- 기호\n집합: \\(\\Omega\\), 원소: \\(w\\), \\(\\quad w\\in \\Omega\\)\n\\(\\Omega = \\{H,T\\} = \\{w_1,w_2\\}\\)\n\\(X(w_1) = X(H)=0, X(w_2) = X(T)=1\\)\n- 주의\n\n\\(X: \\Omega \\to \\mathbb{R}\\)\n\\(P: \\cal{F} \\to [0,1]\\) (set function)\n\n(참고) \\(\\cal{F}\\): \\(\\Omega\\)의 부분집합 중 잴 수 있는 집합의 모임.\n\n\n\n\n“확률변수는 (특별한 성질을 가진) 함수다!”\n함수: \\(\\begin{align*}&y=f(x), \\quad f: \\text{function}, x: \\text{input}, y:\\text{outcome}\\\\ & x=X(w) \\quad X: \\text{random variable}, w: \\text{outcome}, x: \\text{realization}\\end{align*}\\)\n보통 \\(X(w)\\)에서 \\((w)\\)를 생략하고, 간단히 \\(X\\)로 표시 \\(\\to\\) 혼란의 이유!\n“확률변수는 결과가 랜덤으로 변한다.”\n1 맵핑규칙은 변화없음.\n\n\\(H\\to 0 \\quad w_1 \\to 0\\)\n\\(T\\to 1 \\quad w_2 \\to 1\\)\n\n2 입력. 즉, outcome은 실험결과에 따라 랜덤으로 변한다.\n\n\n\n\nw.p는 with probability를 의미.\n\n확률변수 \\(X = \\begin{cases} 0, & \\text{w.p. } \\frac{1}{2} \\\\ 1 & \\text{w.p. } \\frac{1}{2}\\end{cases}\\)\n(i) \\(X\\)는 변수처럼 보임.\n(ii) 변수의 값이 랜덤으로 변하는 것 같음\n\\(X(w) = \\begin{cases} 0, & w\\in \\{H\\} \\\\ 1, & w\\in \\{T\\} \\end{cases}\\)\n\n\n\n\n확률변수는 확률과 관련 없다.\n간접적으로는 관련있다. (\\(\\therefore\\) \\(X\\)의 역상 \\(= \\Omega\\)의 부분집합 \\(=P\\)의 정의역)\n\n\n\n\n- 시계예제\n\\(\\Omega=[0,2\\pi) \\qquad X: [0,2\\pi)\\to [0,2\\pi)\\)인 항등함수.\n\\(X\\)는 항등함수 \\(\\Rightarrow\\) 비탈리 집합의 역상은 비탈리집합 \\(\\Rightarrow\\) 확률을 정의할 수 X\n\n\n\n“확률변수 \\(X\\)를 그냥 함수가 아니라, 역상이 measurable set이 되는 함수라 하자.” \\(\\Leftrightarrow\\) \\(X\\)를 가측함수1라고 하자."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro1",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro1",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "시계열 intro1",
    "text": "시계열 intro1\n\n확률변수 \\(X\\): \\(\\Omega\\to \\mathbb{R}\\)인 특별한 함수.\n확률벡터 \\(\\bf{X}: \\Omega\\to \\mathbb{R}^m\\)인 특별한 함수\n\n- 기호\n확률변수: \\(X(w) = x\\)\n확률벡터: \\(\\bf{X}(w) = (x_1,\\dots, x_m)\\) \\(\\to\\) 출력이 벡터임을 강조!\n확률변수: \\(X\\)\n확률벡터: \\(\\mathbf{X} = (X_1,\\dots,X_m), \\quad X_1,\\dots,X_m\\)은 \\(r.v.\\)\n\\(\\therefore \\bf{X} = (X_1,\\dots, X_m)(w) = (X_1(w),\\dots,X_m(w))=(x_1,\\dots,x_m)\\)\n\\(x_1 = \\text{2019-03-20} \\\\ x_2 = \\text{2019-03-21} \\\\ \\qquad \\vdots\\)\n\\(\\therefore x_1,\\dots, x_m \\Rightarrow \\text{2019-03-20}\\) 부터 순서대로 \\(m\\)개의 삼전주식값을 나열\nNote! : \\(w\\)만 알면 \\(x_1,\\dots,x_m\\)의 값이 저절로 결정.\n\\(X_1(w) = x_1 \\\\ X_2(w) = x_2,\\\\ \\qquad \\vdots\\)\n- 가능한 설명모형\n\n\\(14,000,605\\) 개의 평행세계\n우리는 이 중 하나의 세계에 \\(\\frac{1}{14,000,605}\\)의 “확률”로 선택되어져 살고있음.\n\n\\(\\Rightarrow \\Omega=\\{w_1,w_2,\\dots, w_{14,000,605}\\}\\)\n\\(P(\\{w_1\\})=P(\\{w_2\\})=\\dots=P(\\{w_{14,000,605}\\})=\\frac{1}{14,000,605}\\)\n\n하나의 평행세계가 선택 \\(\\Rightarrow\\) 그 평행세계의 모든 사건이 이미 결정.\n\n우리의 우주 \\(=\\) \\(777\\)번째 평행세계 \\(\\Rightarrow w=w_{777}\\)\n\n- 반론 : 미래는 고정되지 않음.\n\\(m+1\\) 시점은 총 \\(52,210-38,590=13,620\\)개의 미래가 가능!\n- 반론의 반론 : 처음부터 \\(14,000,605 \\times 13,620\\) 의 미래를 고려.\n\n\\(m\\)개의 삼전 주가 \\(\\Rightarrow 14,000,605\\)\n\\(m+1\\)개의 삼전주가 \\(\\Rightarrow 14,000,605 \\times 13,620\\)\n\n- 동전 2회\n\\(\\Omega = \\{\\{H,H\\}, \\{H,T\\}\\,\\{T,H\\}, \\{T,T\\}\\}\\)\n\\(\\{H,H\\}: w_1 \\\\ \\{H,T\\}:w_2 \\\\ \\{T,H\\}: w_3 \\\\ \\{T,T\\}:w_4\\)\n\n복습: 확률변수\n\n\n\n기호정리\n\n확률변수: \\(X(w) = x\\).\n확률벡터: \\(\\bf{X}(w) = \\left(X_1(w),\\dots,X_m(w)\\right)=(x_1,\\dots,x_m)\\)\n확률과정: \\(X(w,t) = x_t = x(t)\\)\n\n확률과정은 \\(w\\)와 \\(t\\)의 함수.\n\\(X(w,t)\\)를 \\(X_t(w)\\)로 표기하기도 함.\n고정된 \\(w \\Rightarrow\\) relization이 시간에 따른 함수\n고정된 \\(t \\Rightarrow\\) random variable이 함수\n\n\n(참고) : 고정된 \\(w\\)에 대한 \\(X(w,t)\\)의 relization을 sample path 혹은 sample function이라고 부른다.\n\n\n용어정리1 (\\(\\star\\star\\star\\))\n\\(\\Omega = \\{w_1,\\dots, w_{14,000,605}\\}\\) 이런 평행세계가 있다…\n\n각각의 \\(\\omega\\)에 매핑되는 함수(무한 개의 값들)가 있을 것이고, 시점을 \\(t_0\\)로 고정하면, 첫번째 평행세계에 대해서는 \\(X(w_1, t_0)\\), 두번째 평행세계에 대해서는 \\(X(w_2, t_0)\\), 세번째 평행세계에 대해서는 \\(X(w_3, t_0)\\)가 된다.\n\n\n용어정리2\n모든 \\(\\omega\\)에 대하여 가능한 sample path를 모두 모은 뭉치. \\(\\Rightarrow\\) 앙상블(ensemble)\n\n\n\n앙상블(ensemble)\n\n\n\n앙상블 mean: 1번 timeseries, \\(\\dots\\) 14,000,605번 timeseries를 다 더해서 평균을 낸 것\n\n앙상블 mean : \\(\\sum_{i=1}^{14,000,605}\\frac{1}{14,000,605}\\times(w_i,t) \\Rightarrow \\sim\\)어떤 함수값 (mean function이라고 표현을 많이 함.)\n\n\n\n\nTime Average: 하나의 평행세계의 모든 시점에 대해 평균낸 것.\n\n\n결국 확률변수 \\(X(w)\\)를 줄여서 \\(X\\)로 쓰고, 확률벡터 \\(\\bf{X}(w)\\)를 줄여서 \\(\\bf{X}\\)라 쓰고, 확률과정 \\(X(w,t)\\)를 줄여서 \\(X(t)\\)라고 쓴다.\n\n\\(X(w) \\to X\\)\n\\(\\bf{X}(w) \\to \\bf{X}\\)\n\\(X(w,t) \\to X(t)\\) 또는 \\(X_t\\)\n\n연속 시계열은 확률과정 그 자체이고, 이산 시계열은 원소의 수가 무한한 확률벡터라고 생각할 수 있다.우리가 많이 다루는 것은 이산 시계열이다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro2",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#시계열-intro2",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "시계열 intro2",
    "text": "시계열 intro2\n시계열: 무한차원의 확률벡터 or. 확률과정의 smaple 버전이라고 생각할 수 있다. \\((x_1, x_2, \\dots, \\dots)\\)\n\\(\\{Z_t(w), \\quad t=1,2,\\dots\\}, \\quad\\) \\(\\omega\\): 평행세계의 인덱스\n\n교재의 표현정리\n\n확률과정: \\(X(t)\\)\n확률법칙: \\(P\\)\n확률공간: \\((\\Omega,\\cal{F}, P)\\)\n확률변수: \\(X\\)\n확률변수의 모임: \\(\\bf{X}, X(t)\\) \\(\\leftarrow\\) 확률벡터나 확률과정 모두 의미.\n집합 T: index set of random element2\n\nT의 원소가 1개이면 확률변수\nT의 원소가 유한개이면 확률벡터\nT의 원소가 무한개이면 확률과정\n\n연속형 확률과정 \\(= \\{X(t), \\quad t\\in (0,\\infty)\\}\\)\n\n집합 T가 \\((0,\\infty)\\)와 같이 구간으로 표현된 경우.\n\n이산형 확률과정: (\\(X_1,X_2,X_3,\\dots), (\\dots, X_{-1},X_0,X_1,X_2,\\dots)\\)\n\n집합T가 \\(\\{1,2,3,\\dots\\}, \\{\\dots,-1,0,1,2,\\dots\\}\\)\n\n실현값 (realization)\n\n\\(x\\) : 확률변수의 relization\n\\((x_1,\\dots, x_m)\\) : 확률벡터의 relization\n\\(x(t)\\) : 확률과정의 relization\n\n표본통로 (sample path): \\(x(t)\\)\n\n\n\n확률과정 노테이션 정리\n\n\n\n정상성\n\n정상성 가정이 안되면 시계열분석의 의미가 없다.\n\n\n\n\nensemble\n\n\n\n\n\n예제1. 동전 3번던지기\n동전을 3번 던지면 나올 수 있는 모든 경우의 수는 8가지. 따라서 평행세계가 8개 있다고 하자.\n\\(\\Omega = \\{w_1,\\dots,w_8\\} = \\{HHH,\\dots, TTT\\}\\)\n\\(P(w_1) = P(w_2) = \\dots = P(w_8)=\\frac{1}{8}\\)\n\n$\\bf{X}(HHH) = (X_1(HHH),X_2(HHH),X_3(HHH)) = (0,0,0) $확률벡터\n$\\bf{X}(TTT) = (X_1(TTT),X_2(TTT),X_3(TTT)) = (1,1,1) $확률벡터\n\n- 동전을 무한번 던진다? \\(\\to\\) 무한 개의 평행세계\n\\(X_t = (X_1,X_2,X_3,X_4,\\dots) \\leftarrow\\) 이산형확률과정 (베르누이 과정)\n\\(x_t = (x_1,x_2,x_3,x_4,\\dots) \\leftarrow\\) relization\n동전을 평생던져야 함.\n현실적인 관측 : \\((x_1,\\dots, x_{t^*-1})\\leftarrow t^*-1\\)\n질문 : \\(E(X+t^*)=\\frac{1}{2}\\times 0 + \\frac{1}{2}\\times 1 = \\frac{1}{2}\\)\n디펜스 : 니가 동전이 공평한 동전인지 어떻게 아느냐?\n\n\n\n큰수의 법칙: 동전을 계속던지다보면 1/2로 수렴하지 않느냐?\n\n\n계속 던지다 보니까 1/2이 나오잖아?\n하지만 시계열 문제에서는 이런식으로 대답을 못한다. 왜냐? \\(n\\)이 하나밖에 없잖아..(반복실험 자체가 불가능하다.3)\n시계열 문제 : \\(n=1\\)\n대안: \\(\\sum_{t=1}^{t^*-1}x_t/(t^*-1)\\)로 ensemble average를 추론.\n\n\\(\\sum_{t=1}^{t^*-1}x_t/(t^*-1)\\)를 time average라고 함.\n\n\niid 일경우 : time average로 ensemble average를 추론. (주황선)\n\\(\\Rightarrow\\) iid의 가정을 약화시키기 위한 노력이 필요함.\n\\(\\Rightarrow\\) 이러한 노력의 결과물이 stationary 가정임.\nstationary 가정은 관측치끼리 독립일 필요도 없고 uncorrelated 되어야할 필요도 없다.\n\\(\\Rightarrow\\) 정상성가정이 없다면 \\(\\Rightarrow\\) 시계열 분석을 할 이유가 없다.\n\n에르고딕..\n\niid일 경우 단점 : 쓸모가 없다. iid를 가정할 수 있으면, 회귀분석을 돌리면 되는데 시계열을 돌릴 필요가 없다. iid가 안되기 때문에 시계열을 돌리는 것. > 과거의 사건이 현재의 사건과 correlation이 있다고 믿고, 독립이 아니라고 믿기 때문에 분석이 어려운 것..\n결국 iid 보다 약한 가정을 찾다보니 stationary라는 가정이 생기게 됨."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-12-2wk.html#stationary-종류",
    "href": "posts/4_TS2023/2023-05-12-2wk.html#stationary-종류",
    "title": "[TS] 2wk. 확률과정과 정상성",
    "section": "Stationary 종류",
    "text": "Stationary 종류\nStationary 과정은 크게 2가지 버전이 있습니다. Strictly Stationary 버전과 Weak Stationary 버전.\nStrictly Stationary가 더 엄밀한 의미에서의 정상성인데 다루기 힘들다. 어떤 시계열이 strictly stationary하다는 것을 밝히기 쉽지 않다. 그래서 약화된 버전인 Weak Stationary를 많이 사용한다.\n에러텀이 normal 일 경우에는 strictly stationary와 weak stationary의 정의가 같아진다.\n\nStrictly Stationary\n\nDefinition: 시계열 \\(\\{X_t\\}\\) is strictly stationary.4\n\\(\\Leftrightarrow \\forall t_1,\\dots,t_n \\in T\\) & \\(h\\in \\mathbb{Z}\\): \\(\\quad (X_{t_1},\\dots,X_{t_n}) \\overset{d}{=}(X_{t_1+h}, \\dots, X_{t_n+h})\\)\n시계열 \\(X_t\\)의 모든 finite한 샘플에 대해 어떤 임의의 lag에 대해서 확률벡터가 뽑히게 될텐데 확률벡터의 결합분포는 확률벡터를 \\(h\\)만큼 민 또 다른 확률벡터의 결합분포와 동일하다는 의미입니다.\n\n예제\n\\(\\{X_t\\},\\quad t\\in \\cal{T}=\\{0,1,2,3,\\dots\\}\\) \\(\\Rightarrow X_0, X_1, X_2,X_3,X_4,X_5,X_6,X_7,X_8,X_9,X_{10}\\)\n다음의 6개의 샘플을 뽑았다고 하자. \\(h=3\\)이라고 하자.\n\\((X_1,X_3,X_5,X_7,X_9,X_{10}) \\overset{d}{=}(X_{1+3},X_{3+3},X_{5+3},X_{7+3},X_{9+3},X_{10+3})\\)\n이는 시간 축을 \\(h\\) 만큼 이동하여도 결합확률밀도함수가 동일하다는 것을 의미하며, “strictly stationary” 라고 합니다.\n\nlag이 3이든, 4이든 결합분포가 다 똑같아야 합니다. \\(\\to\\) 되게 강한 조건\nfinite sample을 예제 처럼 안뽑고 다르게 뽑더라도 어떤 lag에 관해서도 결합분포가 다 똑같아야 합니다.\n\n\n\nWeak Stationary\n\nDefinition: 시계열 \\(\\{X_t\\}\\) is weak stationary.5\n\\(\\Leftrightarrow E(X_t), \\text{Cov}(X_t, X_{t+h})\\) is not depend on \\(t\\).\n\n평균과 공분산이 \\(t\\)에 의존하지 않는다는 의미이고 그래서 당연히 strictly stationary 하면 weak stationary 하게 됩니다.\n\\(\\bf{X}=\\bf{X}_t = (o,o,\\dots, o,o,\\dots) \\to\\) 무한차원 확률벡터\n\\(E\\bf{X}_t = (o,o,\\dots, o,o,\\dots) \\to\\) 무한차원의 벡터\n\\(\\text{Cov}(\\bf{X}) = \\begin{bmatrix} Cov(X_0,X_0)&Cov(X_0,X_1)&Cov(X_0,X_2)&Cov(X_0,X_3)&\\dots \\\\ Cov(X_1,X_1)&Cov(X_1,X_1)&Cov(X_1,X_2)&Cov(X_1,X_3)&\\dots\\\\ Cov(X_2,X_1)&Cov(X_2,X_1)&Cov(X_2,X_2)&Cov(X_2,X_3)&\\dots\\\\ \\vdots&\\vdots&\\vdots&\\vdots&\\dots \\end{bmatrix}\\to\\) 무한차원의 매트릭스\n\\(t\\)에 디펜드 하지 않다는 것은 \\(t\\)에 따라 값이 일정하다는 의미. 즉, 분산이 일정하다는 의미!6\n\n\n\n색이 같은 부분은 값이 동일함을 나타냅니다.\n\n\n정의상 lag을 임의로 밀어도 평균이나 공분산은 바뀌지 않음을 말하고 있다. 강스테이셔너리에서는 lag을 임의로 밀어도 분포가 같은것을 의미하고 여기서는 lag을 임의로 밀어도 평균이나 공분산이 같음을 말함.\n\\[Cov(X_0,X_1) \\overset{lag1}{=}Cov(X_1,X_2)\\]\n\\[Cov(X_0,X_1) \\overset{lag2}{=}Cov(X_2,X_3)\\]"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html",
    "href": "posts/4_TS2023/2023-05-14-3wk.html",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "",
    "text": "\\(\\{\\epsilon_t\\}\\) is white noise iff1. \\(\\epsilon_t \\overset{\\text{i.i.d.}}{\\sim}(\\mu,\\sigma^2)\\) for all \\(t\\).\n회귀분석에서는 보통 normal 가정을 하는데2 여기서는 normal 가정이 필요 없다. (uniform이나 다른 가정 가능)\n- 특징\nfor all \\(t\\) \\(\\quad E(\\epsilon_t)=\\mu, V(\\epsilon_t)=\\sigma^2\\)\nfor all \\(l\\geq 0\\) \\(\\quad \\text{Cov}(\\epsilon_{t-l},\\epsilon_t)=0\\) 여기서 \\(l\\)은 lag의 약자.\n\\(\\Rightarrow\\) Stationary Process3\n히스토리를 보면 왜 당연한건지 알 수 있다. i.i.d.인 경우에는 에르고딕 성질이 있다..iid는 너무 강한 조건이니까 약한 조건을 찾다 약화시키고 약화시키다보니 Stationary Process가 되었다. 그러니까 당연히 iid는 stationary가 된다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#motive1-과거의-값에-계수값-반영",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#motive1-과거의-값에-계수값-반영",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "motive1 : 과거의 값에 계수값 반영",
    "text": "motive1 : 과거의 값에 계수값 반영\n랜덤워크 방식이 너무 아까움.. 분산이 안터지는 방법이 없을까?\n\\(Z_t = 0.999Z_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim (0,\\sigma^2)\\)\n\n현재=과거+오차\n\n\\(\\begin{align*}Z_t &= \\epsilon_t + 0.999 Z_{t-1}\\\\ &=\\epsilon_t + 0.999(0.999Z_{t-2} + \\epsilon_{t-1}) \\\\ &=\\epsilon_t + 0.999\\epsilon_{t-1} + 0.999^2Z_{t-2}\\\\ &\\vdots \\\\ &=\\epsilon_t + 0.999\\epsilon_{t-1} + 0.999^2 \\epsilon_{t-2} + \\dots \\end{align*}\\)\n\\(\\begin{align*}V(Z_t) &= \\sigma^2 + 0.999^2\\sigma^2 + 0.999^4\\sigma^2 + \\dots\\\\ &= \\sigma^2(1+0.999^2+0.999^4+\\dots) \\quad \\text{<- 무한등비급수}\\\\ &= \\sigma^2\\frac{1}{1-0.999^2} < \\infty \\Rightarrow \\text{t에 depend하지 X} \\end{align*}\\)\n\nCovariance 구하는 것은 생략.. 결과는 \\(t\\)에 depend하지 않습니다.\n\n따라서 Stationary 하다!"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#motive2-기울기-텀-추가",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#motive2-기울기-텀-추가",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "motive2 : 기울기 텀 추가",
    "text": "motive2 : 기울기 텀 추가\n좀 더 좋은 모델을 만들고 싶은 욕심이 생긴다..\n이런 모델을 생각해본다.\n\n\n\nmotive2: 현재 = 과거 + 오차 + 기울기\n\n\n모델 : 현재 = 과거 + 오차 + 기세(기울기)5\n\\(Z_t = \\frac{0.9}{2}Z_{t-1} + \\frac{(Z_{t-1} -Z_{t-2})}{2} + \\epsilon_t\\)\n\\(\\quad\\space = 0.45Z_{t-1} + \\frac{1}{2}Z_{t-1} -\\frac{1}{2}Z_{t-2} + \\epsilon_t\\)\n\\(\\quad\\space = 0.95Z_{t-1} - 0.5Z_{t-2} + \\epsilon_t\\)\n\\(\\quad\\space =\\phi_1 Z_{t-1} + \\phi_2Z_{t-2} + \\phi_3Z_{t-3} + \\dots + \\phi_pZ_{t-p} + \\epsilon_t\\)\n위의 두 모티브에 따라 Stationary를 만들기 위해 계수를 고려하고, 기울기를 적당히 추가해 고려하면 좀 더 일반적이고 설명이 잘 되는 모델을 만들 수 있을 것 같다.\n근데 결국 Stationary가 안되면 쓸모가 없으니까 모티브2의 모델이 Stationary를 만족하는지 확인해 볼 필요가 있다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar모델의-정상성-확인",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar모델의-정상성-확인",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "AR모델의 정상성 확인",
    "text": "AR모델의 정상성 확인\n- AR Process\n\\(\\{Z_t\\}\\) is AR process iff.\n\\(Z_t = \\phi_1Z_{t-1} + \\phi_2Z_{t-2} + \\dots + \\phi_pZ_{t-p} + \\epsilon_t\\)\n\\(BZ_t = Z_{t-1}\\)를 만족하는 \\(B\\)6를 생각하자.\n\\(BZ_{t-1} = Z_{t-2}\\)\n\\(BBZ_{t} = Z_{t-2}\\)\n\\(B^2Z_t = Z_{t-2}\\)\n\\(\\therefore Z_t = \\phi_1BZ_t + \\phi_2B^2Z_t + \\dots \\phi_pB^pZ_t + \\epsilon_t\\)\n\\(Z_t - \\phi_1BZ_t - \\phi_2B^2Z_t - \\dots - \\phi_pB^pZ_t = \\epsilon_t\\)\n\\((1-\\phi_1B-\\phi_2B^2-\\dots-\\phi_pB^p)Z_t = \\epsilon_t\\)\n여기에서 \\((1-\\phi_1B-\\phi_2B^2-\\dots-\\phi_pB^p)=0\\)으로 놓은 식을 특성방정식 이라고 합니다.\n\nAR process의 정상성을 체크하는 법 (교재 p215, p246): 1. 특성방정식을 구한다. 2. 특성방정식을 \\(B\\)에 대하여 푼다. 3. 모든 근의 절댓값이 1보다 큰지 조사한다.\n\n\n연습문제 5.1 (h)\n다음 모형에 의해 설명되는 확률과정 \\(\\{Z_t\\}\\)는 정상성을 갖는지 조사하라.\n\\(Z_t=100+0.5Z_{t-1}+\\epsilon_t, \\quad \\{\\epsilon_t\\}\\)는 \\(WN(0,5)\\) 이다.\n(sol)\n\\(Z_t = 100 + 0.5Z_{t-1} + \\epsilon_t.\\)7\n\\(\\Leftrightarrow Z_t-200 = 0.5(Z_{t-1}-200) + \\epsilon_t.\\)\n여기서 \\(Z_t - 200 = Y_t\\)로 놓고, \\(Z_{t-1}-200=Y_{t-1}\\)로 놓으면,\n\\(Y_t = 0.5Y_{t-1} + \\epsilon_t.\\)8\n\\(\\{Z_t\\}\\)의 정상성을 파악하는 일은 \\(\\{Y_t\\}\\)의 정상성을 파악하기만 하면 충분함.\n(참고) 절편은 생략해도 됩니다. 절편이 있든 없든 AR모델의 정상성을 체크하고 AR모델의 성질을 파악하는 것은 차이가 없어요.\n\\(Y_t = 0.5Y_{t-1} + \\epsilon_t.\\)에서 \\(\\{Y_t\\}\\)가 정상인지만 판단하면 됩니다.\n\\(\\Leftrightarrow Y_t = 0.5BY_t +\\epsilon_t\\)\n\\(\\Leftrightarrow Y_t-0.5BY_t = \\epsilon_t\\)\n\\(\\Leftrightarrow (1-0.5B)Y_t = \\epsilon_t\\)\n\\(\\therefore\\) 특성방정식: \\(1-0.5B=0 \\Rightarrow B=2 \\Rightarrow |B|>1 \\Rightarrow \\{Y_t\\}\\)는 정상.\n\\(\\Rightarrow \\{Z_t\\}\\)도 정상\n(다른 풀이) – 결과는 특성방정식을 이용해 푼 결과와 동일.\n관점1 (t: 시작, \\(-\\infty\\): 끝)\n\\(E(Z_t) = E(Y_t+200) = 200\\)\n\\(Y_t = 0.5Y_{t-1} +\\epsilon_t\\)\n\\(\\quad = \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\dots + Y_{-\\infty}.\\)9\n\\(E(Y_t) = 0 + 0 + \\dots + 0 = 0\\)\n관점2 (0: 시작, \\(\\infty\\): 끝)\n\\(Z_t = 100 + 0.5Z_{t-1}+\\epsilon_t\\)\n\n\\(Z_0 = 0\\)\n\\(Z_1 = 100 + 1\\cdot\\frac{1}{2}+\\epsilon_1\\)\n\\(Z_2 = 100 + (100+\\epsilon_1)\\frac{1}{2}+\\epsilon_2\\)\n\\(Z_3 = 100 + (100+(100+\\epsilon_1)\\frac{1}{2} + \\epsilon_2) + \\epsilon_3\\)\n\\(Z_t = 100 + 100\\times\\frac{1}{2}+ 100\\times \\frac{1}{4} + \\dots\\)\n\n\\(\\therefore E(Z_t) = \\frac{100}{1-\\frac{1}{2}}=200\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\n관점1과 2의 결과는 동일하다.\n\\(Y_t = \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots\\)\n\\(V(Y_t) = 1 + 0.5^2 + 0.5^4 + \\dots = \\frac{1}{1-0.5^2}=\\frac{4}{3}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=1: \\(\\quad Cov(Y_t, Y_{t-1})\\)\n\\(Cov(Y_t, Y_{t-1}) = Cov( \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots, 0 +\\epsilon_{t-1} + 0.5\\epsilon_{t-2} + 0.5^2\\epsilon_{t-3} + \\cdots)\\)\n\\(\\begin{align*}\\therefore Cov(Y_t, Y_{t-1}) &= 0+ 0.5\\sigma^2 + 0.5^3\\sigma^2 + 0.5^5\\sigma^2 + \\cdots \\\\ &= \\left(\\frac{0.5}{1-0.5^2}\\right)\\sigma^2\\end{align*}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=2: \\(\\quad Cov(Y_t, Y_{t-2})\\)\n\\(Cov(Y_t, Y_{t-2}) = Cov( \\epsilon_t + 0.5\\epsilon_{t-1} + 0.5^2\\epsilon_{t-2} + \\cdots, 0 + 0 +\\epsilon_{t-2} + 0.5\\epsilon_{t-3} + 0.5^2\\epsilon_{t-4} + \\cdots)\\)\n\\(\\begin{align*}\\therefore Cov(Y_t, Y_{t-2}) &= 0+ 0+ 0.5^2\\sigma^2 + 0.5^4\\sigma^2 + 0.5^6\\sigma^2 + \\cdots \\\\ &= \\left(\\frac{0.5^2}{1-0.5^2}\\right)\\sigma^2\\end{align*}\\) \\(\\quad \\leftarrow \\text{not depend on t}\\)\nlag=k: \\(\\quad Cov(Y_t, Y_{t-k})\\)\n\\(Cov(Y_t, Y_{t-k}) = \\sigma^2\\cdot\\frac{0.5^k}{1-0.5^2} \\quad \\leftarrow \\text{not depend on t}\\)\n\\(\\Rightarrow \\{Y_t\\} \\text{ is stationary!}\\)\n특성방정식을 이용해 푼 결과와 동일하다. 특성방정식 매우 좋은 방법이였음..\n\n\n연습문제 5.1 (i)\n\\(Z_t = 1.3Z_{t-1}+\\epsilon_t, \\quad \\epsilon_t \\overset{iid}{\\sim}(0,1)\\)\n(sol1)\n특성방정식: \\(1-1.3B = 0 \\Rightarrow B = \\frac{1}{1.3}\\)\n\\(\\Rightarrow\\) “비정상시계열”\n(sol2)\n\\(Z_t = \\epsilon_t + 1.3\\epsilon_{t-1} + 1.3^2\\epsilon_{t-2}+\\dots\\)\n$V(Z_t)=$ “비정상시계열”"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar1-특성방정식보다-쉽게-정상성-판단하는-법",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar1-특성방정식보다-쉽게-정상성-판단하는-법",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "AR(1): 특성방정식보다 쉽게 정상성 판단하는 법",
    "text": "AR(1): 특성방정식보다 쉽게 정상성 판단하는 법\n\n단, AR(1) 모델 한정해서 정상성 체크. (p191, p218)\n\n\\(\\begin{align*}AR(1): Z_t &= \\phi Z_{t-1} + \\epsilon_t\\\\ \\Rightarrow Z_t &= \\phi BZ_t + \\epsilon\\end{align*}\\)\n\\(\\therefore\\) 특성방정식\\(=1-\\phi B = 0 \\to B=\\frac{1}{\\phi}\\)\n따라서 \\(|\\frac{1}{\\phi}| > 1\\)인지만 체크하면 됨. \\(\\Leftrightarrow |\\phi| < 1\\)\n\n교재: 절편 무시/ 분산 & Cov 유한\n\n결국 AR(1): 현재 = \\(\\phi\\)과거 + 오차10 에서\n\n$|| < 1 $ 과거의 효과가 점차 사라진다.\n랜덤워크와의 차이점은 계수를 적당히 조절해서 수렴시키게 만들 수 있다는 것. 즉, 정상성을 만족하도록 만들 수 있다는 특징이 있다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar2과정이-정상일-조건",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar2과정이-정상일-조건",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "AR(2)과정이 정상일 조건",
    "text": "AR(2)과정이 정상일 조건\n\\(Z_t = \\phi_1 Z_{t-1} + \\phi_2Z_{t-2} + \\epsilon_t\\)\n\\(Z_t = \\phi+1BZ_t + \\phi_2B^2Z_t + \\epsilon_t\\)\n특성방정식: \\(1-\\phi_2B - \\phi_2B^2 = 0\\)\n근11 : \\(\\frac{\\phi_1\\pm \\sqrt{\\phi_1^2+4\\phi_2}}{-2\\phi_2}\\quad\\) 근의 절댓값이 1보다 클 조건.\n\nAR(2) 모델한정 정상성 쉽게 판단하는 법: 1. \\(\\phi_1 + \\phi_2 < 1\\) 2. \\(\\phi_2 - \\phi_1 < 1\\) 3. \\(|\\phi_2| < 1\\) \n다음 조건과 같은 조건을 만족하는 AR(2) 과정을 정상이라고 하며, 특성방정식의 근의 절대값이 1보다 커야한다는 조건과 동치이다.\n\n\n연습문제 5.1 (h)\n\\(Z_t = 100 + 0.5Z_{t-1} + \\epsilon_t\\)\n절편무시, \\(0.5 < 1 \\Rightarrow\\) “정상”\n\n\n연습문제 5.1 (i)\n\\(Z_t = 1.3Z_{t-t} + \\epsilon_t\\)\n\\(1.3 > 1 \\Rightarrow\\) “비정상”\n\n\n연습문제 5.1 (l)\n\\(Z_t = 0.12 + Z_{t-1} + \\epsilon_t\\)\n절편무시 \\(\\phi=1 \\Rightarrow\\) “비정상”\n\n\n\n\n자기공분산함수와 자기상관함수"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar1-acf를-구하자.-교재-6.1.1",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar1-acf를-구하자.-교재-6.1.1",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "# AR(1) acf를 구하자. (교재 6.1.1)",
    "text": "# AR(1) acf를 구하자. (교재 6.1.1)\nLeg \\(\\{Z_t\\}\\) be \\(AR(1)\\) with \\(\\phi\\). i.e\n\\(\\begin{align*}Z_t &= \\phi Z_{t-1} +\\epsilon_t, \\quad \\epsilon_t\\sim (0,\\sigma^2) \\\\ &=\\epsilon_t + \\phi \\epsilon_{t-1} + \\phi^2\\epsilon_{t-2}+\\dots\\end{align*}\\)\n\n\n\n$Cov(Z_t, Z_{t-h})\n\n\n\\(\\therefore Cov(Z_t, Z_{t-h}) = \\frac{\\phi^h}{1-\\phi^2}\\sigma^2=\\gamma(h)\\)\n\\(acf(h)=\\frac{\\gamma(h)}{\\gamma(0)}=\\frac{\\frac{\\phi^h}{1-\\phi^2}}{\\frac{1}{1-\\phi^2}}=\\phi^h\\)12\n\n\n\nacf를 쉽게 계산하는 방법 따윈 없어.. 정석대로 하자."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#gammah와-textacfh의-성질-교재-5.3",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#gammah와-textacfh의-성질-교재-5.3",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "\\(\\gamma(h)\\)와 \\(\\text{acf}(h)\\)의 성질 (교재 5.3)",
    "text": "\\(\\gamma(h)\\)와 \\(\\text{acf}(h)\\)의 성질 (교재 5.3)\n\n\n\n성질1. 분산은 시간에 depend 하지 않으니까~\n\n\n\n\n\n성질2.\n\n\n\n\n\n성질3.\n\n\n\n\n\n성질4. 코쉬-슈바르츠로 증명 가능"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#ar2-textacf를-구하라.",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#ar2-textacf를-구하라.",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "# \\(AR(2)\\) \\(\\text{ACF}\\)를 구하라.",
    "text": "# \\(AR(2)\\) \\(\\text{ACF}\\)를 구하라."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-14-3wk.html#교재6.1.2-ar2의-acf-형태.",
    "href": "posts/4_TS2023/2023-05-14-3wk.html#교재6.1.2-ar2의-acf-형태.",
    "title": "[TS] 3wk. 여러가지 확률과정",
    "section": "교재6.1.2 AR(2)의 ACF 형태.",
    "text": "교재6.1.2 AR(2)의 ACF 형태.\n\n\n\nAR(2)의 ACF 형태\n\n\n\n\n\nType1. 지수적으로 감소, Type2. 점차 소멸하는 sin 함수"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-13-5장연습.html",
    "href": "posts/4_TS2023/2023-05-13-5장연습.html",
    "title": "[TS] 2wk-2. 연습문제 5.1",
    "section": "",
    "text": "다음의 모형들에 의해 설명되는 확률과정 \\(\\{Z_t\\}\\)는 정상성을 갖는가? 이를 논하라.\n\n\n\\(Z_t = A\\sin(\\frac{2}{3}\\pi t + U)\\), \\(A\\)는 평균이 \\(0\\)이고, 분산이 \\(1\\)인 확률변수이고 \\(U\\)는 상수이다.\n\n\n\n5.1 (c)\n\n\n\n\n\n\\(Z_t=A\\sin(\\pi t+U)\\), \\(A\\)는 평균이 \\(0\\)이고 분산이 \\(1\\)인 확률변수이고 \\(U\\)는 구간 \\([-\\pi, \\pi]\\)에서 일양분포를 따르는 확률변수이다. 또한 \\(A\\)와 \\(U\\)는 서로 독립이다.\n\n\n\n5.1 (d)\n\n\n\n\n\n5.1 (d) lag=2\n\n\n\n\n\n5.1 (d) lag=3,4,…\n\n\n\n\n\n\\(Z_t = A\\cos(\\frac{1}{2}\\pi t) + B\\sin(\\frac{1}{2}\\pi t)\\), \\(A\\)와 \\(B\\)는 서로 독립이고 각각 평균 \\(0\\), 분산 \\(1\\)을 갖는 확률변수들이다.\n\n\n\n5.1 (e)\n\n\n\n\n\n\n\n\n5.1 (f), (k)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-16-4wk.html",
    "href": "posts/4_TS2023/2023-05-16-4wk.html",
    "title": "[TS] 4wk. ACF와 PACF",
    "section": "",
    "text": "확률정의 \\(\\to\\) 확률변수 정의 \\(\\to\\) 확률과정.\n\n\npoint: 확률과정의 1개의 relization. \\(\\Rightarrow\\) 정상확률과정\n\n\n정상성(Stationary): iid의 약화버전\n\n\n평균이 \\(t\\)에 depend하지 X\n분산이 \\(t\\)에 depend하지 X\n\\(lag=1,2,3,\\dots\\)에 대해서 \\(\\text{Cov}\\)가 \\(t\\)에 depend하지 X\n\n\n모델: \\(AR(1), AR(2), AR(p), ...\\)\n\n\n모델을 세우는 이유? 현상을 설명 + 예측 + anomally detection + \\(\\cdots\\)\nex. 모델1: 삼성전자 주가 = 과거값 + 랜덤오차(=white noise) \\(\\to\\) 비정상1\nex. 모델2: 삼성전자 주가 = 0.9*과거값 + white noise \\(\\to\\) 정상\nex. 모델3: 삼성전자 주가 = 0.45*과거값 + white noise + 기세 \\(\\to\\) ? AR(p)\n\n모델을 세운다 \\(\\Rightarrow\\) 정상인지 check! (이 과정이 매우 고통스럽다..) \\(\\Rightarrow\\) (1) 특성방정식을 풀어서 단위근의 절대값이 ~~ (2) 모델별로 암기2\n- 질문\n모델 1,2,3… \\(\\to\\) AR계열의 모델.\n세운 모델에서 정상성을 체크하는 것은 다음과 같다.\n\n\nAR모델 중 적당한 후보를 고른다.\n\n\n정상성 check!\n\n\n통과하면 사용 \\(\\to\\) goodness of fit.3\n\n\n(i),(ii)를 종합하면, 정상성을 만족하는 AR모델 중 적당한 모델을 고르겠다는 것이죠.\n그럼 삼성전자 주가가 정상성을 만족하는 AR모델 중 하나라는 증거가 어딨냐?\n사실 증거가 없었음. 삼성전자 주가는 과거값 플러스 랜덤오차 아닐까? 라고 나이브하게 생각했던 것이였다.\n그렇다면 뭐라고 답변해야 할까?\n- 답변 : ACF를 그려보니까 AR모델이라고 판단됩니다.\n논리전개\n\nAR(p) 모델의 이론적인 ACF는 1.exponential decay function4 혹은 2.damped sine wave5\n그런데 삼성전자 주식의 \\(\\widehat{ACF}\\)6를 그려보니, exponential decay 혹은 damped sine이 나왔어요.\n따라서 삼성전자 주식은 \\(AR(p)\\) 모델 중 하나를 따른다고 볼 수 있습니다.\n\n- 재질문: \\(AR(p)\\) 모델 \\(\\to\\) \\(ACF\\)는 exponential-decay or. damped-sine 이건 맞는데, \\(ACF\\)가 exponential-decay or. damped-sine \\(\\to\\) \\(AR(p)\\)가 맞다는 보장은 없지 않느냐?\n\n즉, 답변의 논리가 성립하려면 “ACF가 모델을 유일하게 결정” 한다는 전제가 필요.7\n당연히 성립 안합니다.8\n- 반론: “ACF가 모델을 유일하게 결정못함” But. 모델의 범위를 “정상시계열”에 한정하면 “ACF가 모델을 유일하게 결정함.” <– 매우매우 중요합니다.\n- 결론: ACF를 파악하는 일이 매우 중요함.\n시계열의 처음과 끝은 ACF..!\n모델을 선택할 수 있어요! 우리가 배운 AR모델에 한하여 생각해보면, AR모델에 대한 이론적인 ACF를 계산을 했잖아요. AR모델은 이런 모양이다~ 그런데 정상시계열에 한정해서 역도 성립한다고 했죠? AR모델이면 ACF가 이런모양이다 이건 당연히 성립하는데, 정상시계열에 한정하여 ACF를 그렸더니 이런 모양이 나왔어 그럼 AR모델이네? 이런 논리가 맞다는 말입니다.\n그래서 시계열 받자마자 ACF를 파악해야 합니다. ACF를 파악하려면 우리가 배운 ACF는 이론적인 ACF이기 때문에 ACF의 Sample 버전을 배웁니다. 이것을 SACF라고 표현해요.\n\n\n\n교재 5.3, p193\n\n\\(\\widehat{acf} = \\hat{\\rho}(h)=\\frac{\\hat{\\gamma}(h)}{\\hat{\\gamma}(0)}, \\quad \\hat{\\gamma}(h) = \\frac{\\sum_{i=1}^{n-h}(Z_t-\\bar{Z})(Z_{t+h}-\\bar{Z})}{n}, h=0,1,2,\\dots\\)\n- 연습문제 5.2\n다음의 시계열이 주어졌다. SACF \\(\\hat{\\rho}_k, k=1,2,3\\)과 \\(\\hat{\\phi}_{kk},k=1,2,3\\)을 직접 계산하라.\n\\(Z_t = \\{\\dots, 7,6,5,8,9,4,5,5,4,6,7,8,6,7,6,\\dots\\}\\)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html",
    "href": "posts/4_TS2023/2023-05-10-1wk.html",
    "title": "[TS] 1wk. 확률",
    "section": "",
    "text": "확률 \\(\\to\\) 확률변수 \\(\\to\\) 확률과정 \\(\\to\\) 시계열"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#ex1.-동전던지기",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#ex1.-동전던지기",
    "title": "[TS] 1wk. 확률",
    "section": "Ex1. 동전던지기",
    "text": "Ex1. 동전던지기\n\n\\(\\Omega = \\{H,T\\}\\): sample space\n\\(P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}\\): prob\n\\(\\Omega\\)의 모든(=임의의) 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)을 모순없이 정의할 수 있어야함.\n\n- 질문: \\(\\Omega\\)의 임의의 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있을까?\n\n당연한거 아냐?\n이게 왜 안돼?\n\n- 질문에 대한 대답\n즉, \\(\\Omega\\)의 부분집합: \\(\\emptyset, \\Omega, \\{H\\}, \\{T\\}\\)에 대해 \\(P(\\emptyset)=0, P(\\Omega)=1, P(\\{H\\})=1/2, P(\\{T\\})=1/2\\) 이런식으로 정의할 수 있어야 된다는 뜻이다.\n- 모순없이 의 의미?\n\n우리가 상식적으로 확률에 적용가능한 어떠한 연산들이 있음. (확률의 공리 + 기본성질)\n이러한 연산을 적용해도 상식적인 수준에서 납득이 가야함.\n\n\n확률의 성질\n\\(P(\\emptyset)=0, P(\\Omega)=1, P(\\{H\\})=1/2, P(\\{T\\})=1/2\\)\n\n\\(\\emptyset \\subset \\{H\\} \\Rightarrow P(\\emptyset)<P(\\{H\\})\\)\n\\(\\begin{align*} \\{H\\} \\cap \\{T\\} = \\emptyset &\\Rightarrow P(\\{H\\} \\cup \\{T\\}) = P(\\Omega)=1 \\\\ &=P(\\{H\\}) +P(\\{T\\})=1\\end{align*}\\)\n\\(\\begin{align*}\\Omega - \\{H\\} = \\{T\\} &\\Rightarrow P(\\Omega-\\{H\\}) = P(\\{T\\})=1/2 \\\\ &=P(\\Omega)-P(\\{H\\})=1/2\\end{align*}\\)\n\n\n모순없이 잘 정의되었다. 왜 확률을 정의하는 것이 어렵다는 걸까? \\(\\to\\) 앞의 예제에서는 \\(\\Omega\\)의 원소가 유한인 경우이지만 무한이라면 확률을 정의하기 쉽지 않다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#ex2.-바늘이-하나만-있는-시계",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#ex2.-바늘이-하나만-있는-시계",
    "title": "[TS] 1wk. 확률",
    "section": "Ex2. 바늘이 하나만 있는 시계",
    "text": "Ex2. 바늘이 하나만 있는 시계\n\n시계바늘을 돌려서 나오는 각도를 재는 일 \\(\\Leftrightarrow\\) \\([0,2\\pi)\\) 사이의 숫자중에 하나를 뽑는 일\n\nSample space: \\(\\Omega = [0,2\\pi]\\)\nProb: \\(\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\)\n- 질문: 바늘을 랜덤으로 돌렸을 때 12시-6시 사이에 바늘이 있을 확률? \\(\\frac{1}{2}\\)\n\\(\\Omega\\)의 부분집합을 \\(\\Omega^*\\)라 하자.\n\n\\(\\Omega^* = [0,\\pi)\\)\n\\(P(\\Omega^*)= \\frac{1}{2}\\)\n\n\\(\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\)\n단, 여기에서 \\(m\\)은 구간의 길이를 재는 함수.\n연습 : \\(m\\)의 사용 - \\(m(\\Omega)=m\\big([0,2\\pi)\\big)=2\\pi\\) - \\(m(\\Omega^*) = m\\big([0,\\pi)\\big)= \\pi\\)\n- 위와 같은 방식으로 확률을 정의하면 잘 정의될까? 이게 쉽지 않음. 왜냐하면 확률을 잘 정의하기 위해서는\n\n\\(\\Omega\\)의 모든 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있어야하는데, 이게 쉬운일이 아님.\n\n\n- 도전적 질문\n\n\\(\\emptyset\\subset \\Omega, \\quad P(\\Omega)=0\\)\n\\([0,\\pi) \\subset \\Omega, \\quad \\frac{m([0,\\pi)}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\)\n\n질문1 \\(\\{0\\} \\subset \\Omega, \\quad P(\\{0\\})=\\frac{m(\\{0\\})}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\) - 점 하나의 길이는 \\(0\\)??\n왜 \\(0\\)이지? 점은 원래 길이가 없는데 굳이 재야한다면 \\(0\\)이라고 대답한다. 찝찝하지만 여기까지는 별 문제가 없다.\n질문2 \\(\\emptyset \\subset \\{0\\} \\Rightarrow P(\\emptyset) \\leq P(\\{0\\})\\)\n우측 부등호에 등호를 넣어줌으로써 디펜스\n질문3 \\(\\{0,1\\} \\subset \\Omega \\Rightarrow P(\\{0,1\\})=P(\\{0\\}) + P(\\{1\\})=0+0=0\\)\n\n\\(\\{0,1\\} = \\{0\\} \\cup \\{1\\}\\)\n\\(\\{0\\} \\cap \\{1\\} = \\emptyset\\)\n\n질문4 \\([0,2\\pi)=\\) 무수히 많은 점들의 집합\n\n무수히 많은 것도 끕이 있다. (countable many, uncountable many)\n유리수 정도로 무수히 많은 것 \\(\\to\\) countable many\n무리수 정도로 무수히 많은 것 \\(\\to\\) uncountable many\n\n무수히 많은 점들의 집합이라고 하면 둘 중 뭔지 모르겠지만, 다 더해서 길이가 있다는 것은 uncountable many 겠지?\n\n점 하나의 길이 \\(= 0\\)\n\\(0\\)을 무한번 더해도 \\(0\\)\n\\([0,2\\pi)\\)의 길이 \\(= 0+0+0+\\dots = 0?\\)  \\(\\Rightarrow 2\\pi\\) \n\n논리전개는 틀린게 없어보이는데 말이 안됨. \\([0,2\\pi)\\) 의 길이는 \\(2\\pi\\) 아냐?\n\n디펜스 : 무한번 더해도 \\(0\\) 여기를 걸고 넘어지자. 점을 하나 합쳐도 점, 두개 합쳐도 점, 3개 합쳐도 점인데 무한번 합치면? 점이 선이 될 수 있잖아, 그런데 선은 길이가 될 수 있다고 했잖아. 그러니까 \\(2\\pi\\)가 되는거야!\n\n\n유한번 더하면 \\(0\\)이 맞는데 무한번 더하면 달라지는거야\n\n질문5 \\(A = [0,2\\pi) \\cap \\mathbb{Q}\\)\n\n결론: \\(0\\)도 아니고, \\(2\\pi\\)도 아니야..\n\n\\(A\\)의 원소는 무한개, \\(m(A) = 2\\pi\\)\n\\(A' = [0,2\\pi) \\cap (\\mathbb{R} - \\mathbb{Q})\\), \\(\\quad(\\mathbb{R} - \\mathbb{Q})\\) : 무리수 집합\n\\(m(A') = ?\\)\n\\(P(A\\cup A') = P(A) + P(A') = \\frac{m(A)}{m(\\Omega)}+\\frac{m(A')}{m(\\Omega)}\\)\n이렇게 되면 \\(m(A')=0\\) 이라는 소리인데 이건 말이안돼.. 무리수가 더 많고 무한개 더했는데??\n그럼 결론은 \\(A\\)의 길이를 \\(2\\pi\\) 라고 대답못해.. 근데 또 \\(0\\)이라고 할 수도 없는데? 에매하게 대답할 수밖에.\n디펜스\n\n\\(A\\)의 원소는 무한개\n\\(m(A) = a\\) \\(\\rightarrow\\)그냥 \\(0\\) 이야, \\(\\quad 0<a<2\\pi\\) (구체적으로 \\(a\\)가 뭔지는 나도 몰라.)\n\\(m(A') = 2\\pi -a\\)\n\n유리수만 뽑으면 길이가 \\(a\\)야. 그럼 무리수만 뽑으면 \\(2\\pi-a\\) 겠지? 이렇게 디펜스를 하고 넘어가자..\n질문6 디펜스 불가능한 질문\n\n\\(A=[0,\\pi) \\cap \\mathbb{Q}\\)\n\\(A' = A \\oplus \\frac{\\pi}{2}\\) (\\(A\\)를 \\(\\frac{\\pi}{2}\\)만큼 평행이동한 집합을 \\(A'\\)라고 하자.)\n\n\n\n\\(A\\)의 모든원소: 유리수 \\(\\to\\) 유리수 다 더하면 길이가 빵!\n\\(A'\\)의 모든 원소: 무리수 \\(\\to\\) \\([0,2\\pi)\\) 구간 안에 있는 값들을 다 포함해야지 길이가 생긴다. 고로 무리수여도 이건 길이가 빵! \n\n유리수 만큼의 길이를 평행이동 한거니까 그냥 유리수 숫자만큼의 무리수가 생긴 것 뿐\n\\(\\Rightarrow A\\cap A' = \\emptyset\\) (\\(A\\)와 \\(A'\\)은 서로소)\n그럼 \\(P(A\\cup A') = P(A) + P(A') = \\frac{m(A)}{m(\\Omega)}+\\frac{m(A')}{m(\\Omega)}\\)이 성립한다.\n\\(= \\frac{m(A)}{2\\pi}+\\frac{m(A')}{2\\pi}= \\frac{a/2}{2\\pi}+\\frac{a/2}{2\\pi}=\\frac{a}{2\\pi}\\)\n결국 종합하면, \\(m(A) + m(A') = a\\)라는 소린데\n그림을 참고해서 직접 계산해보면 각각의 길이에 겹치는 부분의 길이를 뺀 \\(\\frac{a}{2}+\\frac{a}{2}-\\frac{a}{4}=\\frac{3}{4}a\\)일 것 같은데, \\(a\\)라고 주장하고 있는것이다.\n우리가 알고있는 길이 상식과는 다르다. 모순발생!\n이건 디펜스가 불가능한 질문이다. 즉, 지금까지 했던 말이 다 거짓!! 확률을 이렇게 \\(\\frac{m(\\Omega^*)}{m(\\Omega)}\\)정의하는 것부터가 말이 안됨. 이렇게 정의할 수 없다."
  },
  {
    "objectID": "posts/4_TS2023/2023-05-10-1wk.html#약속-받아들이기",
    "href": "posts/4_TS2023/2023-05-10-1wk.html#약속-받아들이기",
    "title": "[TS] 1wk. 확률",
    "section": "약속: 받아들이기^^",
    "text": "약속: 받아들이기^^\n(i) 한 점에 대한 길이는 \\(0\\)\n(ii) \\([0,2\\pi)\\) 사이의 모든 유리수를 합친 집합의 길이\\(=0\\) - 아까 무한히 점을 더하면 선이된다? 다 없는소리.. (유한한 점을 더하면 길이가 0이된다.)\n(iii) \\([0,2\\pi)\\) 사이의 모든 무리수를 합친 집합의 길이\\(=2\\pi\\)\n\n위의 내용은 Measure Theory의 내용입니다. 그냥 받아들입시다~\n\n이제 모든 질문들에 대해서 깔끔하게 디펜스가 된다. \n이제 이 정의가 다시 살아나게 된다. \\(\\{0\\} \\subset \\Omega, \\quad P(\\{0\\})=\\frac{m(\\{0\\})}{m([0,2\\pi))}=\\frac{0}{2\\pi}=0\\)\n\n주장 (X) : 틀린주장\n위의 3가지 원리. 즉 (i)-(iii)를 사용하면(=받아들이면) \\([0,2\\pi)\\)의 어떤 부분집합 \\(\\Omega^*\\)에 대해서도 \\(\\Omega^*\\)의 길이를 모순없이 정의할 수 있다.\n길이를 잴 수 없는 집합이 존재함 : 비탈리 집합"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-20-6wk-연습문제5장.html",
    "href": "posts/4_TS2023/2023-05-20-6wk-연습문제5장.html",
    "title": "6wk. 연습문제5장 실습",
    "section": "",
    "text": "아래와 같이 자료를 입력한다.\n\nzt<-c(144.652,195.596,236.569,269.265,296.791,316.682,332.593,344.834,356.644,\n      363.775,370.994,377.784,382.254,386.211,388.574,391.118,394.627,395.785,\n      395.693,396.811,397.249,397.433,398.767,398.971,399.108,400.958,398.660,\n      399.348,398.293,397.886)\n\n\n\n시계열 그림을 그려라.\n\nplot(zt)\n\n\n\n\n\n\n\n(a)의 시계열로부터 \\(\\rho_1\\)은 양수, \\(0\\), 혹은 음수 중 어느 값이라 기대되는가?\n\n\\(\\rho_1>0\\) 일 것으로 기대함.\n\n\n\n\n\\(Z_t\\)에 대하여 \\(Z_{t-1}\\)의 산점도를 그려보고, 다시 \\(\\rho_1\\)은 어느 정도의 값이 되리라 기대되는가?\n\nyt<-c(zt-mean(zt),0)\nyt_lag1<-c(0,zt-mean(zt))\nplot(yt,yt_lag1)\n\n\n\nlm(yt~yt_lag1)$coefficients[2]\n\n  yt_lag1 \n0.7867225 \n\n\n\nacf의 계수값은 regression을 한 coefficient의 계수값이라고 생각해도 된다.\n\n\n\n\nSACF \\(\\hat{\\rho}_k,k=0,1,\\dots,10\\) 를 구하여 표본상관도표를 그려라.\n\nacf_result<-acf(zt)\nacfvalues<-acf_result$acf\nacfvalues\n\n, , 1\n\n             [,1]\n [1,]  1.00000000\n [2,]  0.78672246\n [3,]  0.61310906\n [4,]  0.47134840\n [5,]  0.35543318\n [6,]  0.26233059\n [7,]  0.18488731\n [8,]  0.11931704\n [9,]  0.06197039\n[10,]  0.01524803\n[11,] -0.02785225\n[12,] -0.06548592\n[13,] -0.09652258\n[14,] -0.12428019\n[15,] -0.14821524\n\nplot(acf_result)\n\n\n\n\n\n\n\n\\(Z_t\\)에 대하여 \\(Z_{t-2}\\)의 산점도를 그려보고, 이 그림이 (d)에서 계산된 \\(\\hat{\\rho}_2\\)에 상응하는지를 논하라.\n\nyt<-c(zt-mean(zt),0,0)\nyt_lag1<-c(0,zt-mean(zt),0)\nyt_lag2<-c(0,0,zt-mean(zt))\nplot(yt,yt_lag2)\n\n\n\nlm(yt~yt_lag2)$coefficients[2]\n\n  yt_lag2 \n0.6131091 \n\n\nsacf를 구하는 방법 1\n\ngamma_0 <- sum(yt*yt)\ngamma_1 <- sum(yt*yt_lag1)\nrho1 <- gamma_1/gamma_0\ngamma_2 <- sum(yt*yt_lag2)\nrho2 <- gamma_2/gamma_0\ncat(rho1, rho2)\n\n0.7867225 0.6131091\n\n\nsacf를 구하는 방법 2\n\nacf(zt)$acf\n\n\n\n\n, , 1\n\n             [,1]\n [1,]  1.00000000\n [2,]  0.78672246\n [3,]  0.61310906\n [4,]  0.47134840\n [5,]  0.35543318\n [6,]  0.26233059\n [7,]  0.18488731\n [8,]  0.11931704\n [9,]  0.06197039\n[10,]  0.01524803\n[11,] -0.02785225\n[12,] -0.06548592\n[13,] -0.09652258\n[14,] -0.12428019\n[15,] -0.14821524\n\n\nsacf를 구하는 방법 3\n\n# (1) rho1을 구하는 법: yt ~ yt_lag1\nlm(yt~yt_lag1)$coef[2]\n\n  yt_lag1 \n0.7867225 \n\n# (2) rho2을 구하는 법: yt ~ yt_lag2\nlm(yt~yt_lag2)$coef[2]\n\n  yt_lag2 \n0.6131091 \n\n\n\npar(mfrow=c(2,1))\nplot(yt_lag1, yt)\nplot(yt_lag2, yt)\n\n\n\n\n\n위에 있는 그래프의 기울기가 아래에 있는 그래프의 기울기보다 조금 더 가파르게 나타난다. (아주 미세한 차이지만..)\n즉, yt와 lag1의 correlation이 yt와 lag2의 correlation 보다 강하다고 추측을 할 수 있다.\n\n\n\n\nSPACF \\(\\hat{\\phi}_{kk},k=1,2,\\dots,10\\)을 구하여 표본상관도표를 그려라.\n\npacf_result<-pacf(zt)\npacfvalues<-pacf_result$acf\npacfvalues\n\n, , 1\n\n             [,1]\n [1,]  0.78672246\n [2,] -0.01528120\n [3,] -0.01665983\n [4,] -0.01737239\n [5,] -0.01327075\n [6,] -0.02047259\n [7,] -0.02399628\n [8,] -0.02955509\n [9,] -0.02187769\n[10,] -0.03562721\n[11,] -0.03251304\n[12,] -0.02901910\n[13,] -0.03540586\n[14,] -0.03479451\n\nplot(pacf_result)\n\n\n\n\n\n파란 점선보다 작으면 \\(0\\)으로 봐도 무방하다.\nPACF는 Lag=1일 때를 제외하고 나머지는 절삭된다. \\(\\to\\) Lag1은 의미있다. \\(\\to\\) AR(1) 모델로 추정.\n\n\nacf(zt) # exponential 하게 감소\n\n\n\n\n\nplot(zt) # 이것만 보면 non-stationary 같음.\n\n\n\n\n\nplot(zt[15:30]) # 무한대로 가면 stationary 하겠다!\n\n\n\n\n\n\n\n\\(\\hat{\\phi}_{22}\\)의 의미:\n\n교재의 설명: \\(\\hat{\\phi}_{22}\\)는 \\(Z_t\\)와 \\(Z_{t+2}\\)로부터 \\(Z_{t+1}\\)의 효과를 제거한후 2시차만큼 떨어진 \\(Z_t\\)와 \\(Z_{t+2}\\)의 순수한 상관계수. (p.199)\n좀더 엄밀한 정의\n\n\npartial correlation (conditional correlation)\ncoefficients in the multiple regression model\n(orthogonalization) partial regression coefficients – back fitting이라고도 함.\n\n\n\nlag=2에선 SPACF, 즉 \\(\\hat{\\phi}_{22}\\)는 아래와 같이 구할수 있다.\n\npacfvalues[2]\n\n[1] -0.0152812\n\n\n\n\n\n\nlm1<-lm(yt~yt_lag1+yt_lag2)\nlm1$coefficients[3]\n\n   yt_lag2 \n-0.0152812 \n\n\n\n\n\n\nstep1: residual을 구한다.\nstep2: residual끼리 regression\nstep3: 적합한 모델의 coef\n\n\nlm01<-lm(yt~yt_lag1)\nlm21<-lm(yt_lag2~yt_lag1)\nres1<-lm01$residuals\nres2<-lm21$residuals\nlm(res1~res2)$coefficients[2] # pacf(zt)$acf[2]\n\n      res2 \n-0.0152812 \n\n\n\npacf(zt)$acf[2]\n\n\n\n\n[1] -0.0152812\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nlm1$coefficient[3] : \\(\\phi_{21}\\)\nlm(yt~yt_lag1)$coef[2] : \\(\\phi_{11}\\)"
  },
  {
    "objectID": "posts/4_TS2023/2023-05-20-6wk-연습문제5장.html#연습문제-5.5",
    "href": "posts/4_TS2023/2023-05-20-6wk-연습문제5장.html#연습문제-5.5",
    "title": "6wk. 연습문제5장 실습",
    "section": "연습문제 5.5",
    "text": "연습문제 5.5\n확률과정 \\(Z_t=1+0.9Z_{t-1}+\\epsilon_t\\), \\(t=1,2,\\dots,100\\)으로부터 시계열 자료를 생성한 후 다음을 수행하라. 단, \\(Z_0=10\\)의 값을 주고 \\(\\{\\epsilon_t\\}\\)는 \\(\\text{WN}\\) \\(N(0,1)\\)이다.\nmodel: \\(Z_t=1+0.9Z_{t-1}+\\epsilon_t\\), \\(t=1,2,\\dots,100\\).\n\nset.seed(1306) # 평행세계의 인덱스 (1306번째 평행세계)\nzt<-c() # relization된 값.\nzt[1]<-1+0.9*10+rnorm(1)\n# zt[2]<-1+0.9*[1]+rnorm(1)\n# zt[3]<-1+0.9*z[2]+rnorm(1)\nfor(i in 2:100) zt[i]<-1+0.9*zt[i-1]+rnorm(1)\nzt\n\n  [1] 10.777675 10.660962 11.129924 10.729653  9.382788  9.291090 10.412269\n  [8]  9.280671  9.278990  9.050157  9.777134  9.382744  8.805521  8.574072\n [15]  9.663666 10.008613 10.057641  9.088979  9.827647 10.221844 12.170445\n [22] 12.868114 13.236760 12.939106 14.064829 14.689415 11.874574 10.117136\n [29] 10.736236 11.427874 10.870493 11.926313 13.313631 12.119023 13.091750\n [36] 11.537623 13.564257 12.867269 12.301226 12.746935 13.450774 14.667385\n [43] 13.411673 15.307674 14.310807 13.122243 13.087510 11.151739 12.500317\n [50] 12.134043 12.216240 13.294609 13.236690 13.206157 13.783242 12.746678\n [57] 12.107156 11.286982 10.709525 10.366019  8.197414  9.075633  8.349393\n [64]  9.305533  7.439775  8.190043  8.546629  8.696135 10.773879 10.591572\n [71] 10.394556 10.902747  9.770263 10.122317 10.469193  9.587717  9.321004\n [78]  8.713534  6.863494  8.102941  7.681025  7.309215  4.915844  5.597363\n [85]  6.577784  7.037914  7.518736  6.669018  4.465009  5.514308  7.445960\n [92]  6.222425  4.740820  5.294629  5.991279  5.196732  6.505054  6.643898\n [99]  7.958164  9.135744\n\n\n\n(a)\n\nplot(zt)\n\n\n\n\n\n\n(b)\n\nacf(zt)$acf\n\n\n\n\n, , 1\n\n           [,1]\n [1,] 1.0000000\n [2,] 0.9151428\n [3,] 0.8532663\n [4,] 0.7983751\n [5,] 0.7465985\n [6,] 0.6884379\n [7,] 0.6189412\n [8,] 0.5726526\n [9,] 0.5286664\n[10,] 0.5073208\n[11,] 0.4852742\n[12,] 0.4497323\n[13,] 0.4147162\n[14,] 0.3788675\n[15,] 0.3569531\n[16,] 0.3327448\n[17,] 0.3041227\n[18,] 0.2785423\n[19,] 0.2625320\n[20,] 0.2264291\n[21,] 0.1947804\n\n\n\n\n(c)\n\npacf(zt)$acf # 정상인 AR(1)\n\n\n\n\n, , 1\n\n              [,1]\n [1,]  0.915142832\n [2,]  0.097099164\n [3,]  0.027803130\n [4,]  0.002343684\n [5,] -0.060069904\n [6,] -0.111745287\n [7,]  0.080637070\n [8,]  0.010304596\n [9,]  0.132408979\n[10,]  0.031574334\n[11,] -0.088386730\n[12,] -0.058457746\n[13,] -0.044925052\n[14,]  0.045494186\n[15,]  0.033808509\n[16,] -0.006926641\n[17,]  0.001553929\n[18,]  0.031117106\n[19,] -0.171366229\n[20,] -0.022407217\n\n\n\n\n(d)-(e)\n\nyt<-c(zt,mean(zt),mean(zt))\nyt_lag1<-c(mean(zt),zt,mean(zt))\nyt_lag2<-c(mean(zt),mean(zt),zt)\nplot(yt,yt_lag1)\n\n\n\nlm(yt~yt_lag1)$coefficients\n\n(Intercept)     yt_lag1 \n  0.8585824   0.9151428 \n\nplot(yt,yt_lag2)\n\n\n\nlm(yt~yt_lag2)$coefficients\n\n(Intercept)     yt_lag2 \n  1.4846471   0.8532663"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-numpy4.html",
    "href": "posts/1_IP2022/2023-02-23-numpy4.html",
    "title": "Numpy 4단계(concat, stack)",
    "section": "",
    "text": "Numpy array를 결합하는 기능들에 대해 알아보자. (np.concatenate, np.concat)\n\n\n\n- 기본예제\n\nimport numpy as np\n\n\na = np.array([1,2])\nb = -a\n\n\nnp.concatenate([a,b])\n\narray([ 1,  2, -1, -2])\n\n\n- 응용\n\na = np.array([1,2])\nb = -a\nc = np.array([3,4,5])\n\n\nnp.concatenate([a,b,c])\n\narray([ 1,  2, -1, -2,  3,  4,  5])\n\n\n\n여기까진 딱히 concatenate의 메리트가 없어보임\n리스트였다면 a+b+c하면 되는 기능이니까?\n\n- 2d array에 적용해보자.\n\na = np.arange(4).reshape(2,2)\nb = -a\n\n\na\n\narray([[0, 1],\n       [2, 3]])\n\n\n\nb\n\narray([[ 0, -1],\n       [-2, -3]])\n\n\n\nnp.concatenate([a,b])\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n위아래로 붙었네! 그럼 옆으로 붙이려면 어떻게 하지?\n\n- 옆으로 붙이려면?\n\nnp.concatenate([a,b], axis=1)\n\narray([[ 0,  1,  0, -1],\n       [ 2,  3, -2, -3]])\n\n\n- 위의 코드에서 axis=1 이 뭐지? axis=0,2 등을 치면 결과가 어떻게 될까?\n\nnp.concatenate([a,b],axis=0)\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 0, -1],\n       [-2, -3]])\n\n\n\n이건 그냥 np.concatenate([a,b])와 같다.\nnp.concatenate([a,b])는 np.concatenate([a,b],axis=0)의 생략버전이군?\n\n\nnp.concatenate([a,b],axis=2)\n\nAxisError: axis 2 is out of bounds for array of dimension 2\n\n\n\n이런건 없다.\n\n- axis의 의미가 뭔지 궁금함. 좀 더 예제를 살펴보자.\n\na = np.array(range(2*3*4)).reshape(2,3,4) # 3d array\na\n\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\n\n\nb = -a\nb\n\narray([[[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=0)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b],axis=1)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\nnp.concatenate([a,b], axis=2)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\n이번에는 axis=2까지 된다?\n\n\nnp.concatenate([a,b], axis=3)\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\naxis=3까지는 안된다?\n\n- 뭔가 나름의 방식으로 합쳐지는데 원리가 뭘까?\n(분석1) np.concatenate([a,b], axis=0)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=0).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n첫번째 차원이 바뀌었다. \\(\\Rightarrow\\) 첫번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=0 (파이썬은 0부터 시작하니까!)\n\n(분석2) np.concatenate([a,b], axis=1)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n두번째 차원이 바뀌었다. \\(\\Rightarrow\\) 두번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=1\n\n(분석3) np.concatenate([a,b], axis=2)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n세번째 차원이 바뀌었다. \\(\\Rightarrow\\) 세번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=2\n\n(분석4) np.concatenate([a,b], axis=3)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\na.shape, b.shape, np.concatenate([a,b], axis=3).shape\n\nAxisError: axis 3 is out of bounds for array of dimension 3\n\n\n\n네번째 차원이 없다. \\(\\Rightarrow\\) 세번째 축이 없다. \\(\\Rightarrow\\) axis=3으로 하면 에러가 난다.\n\n(보너스)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-1)\n\narray([[[  0,   1,   2,   3,   0,  -1,  -2,  -3],\n        [  4,   5,   6,   7,  -4,  -5,  -6,  -7],\n        [  8,   9,  10,  11,  -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15, -12, -13, -14, -15],\n        [ 16,  17,  18,  19, -16, -17, -18, -19],\n        [ 20,  21,  22,  23, -20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-1).shape\n\n((2, 3, 4), (2, 3, 4), (2, 3, 8))\n\n\n\n마지막 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막 축이 바뀌었다. \\(\\Rightarrow\\) axis=-1\n\n(보너스2)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-2)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11],\n        [  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23],\n        [-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-2).shape\n\n((2, 3, 4), (2, 3, 4), (2, 6, 4))\n\n\n\n마지막에서 2번째 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막에서 2번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=-2\n\n(보너스3)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-3)\n\narray([[[  0,   1,   2,   3],\n        [  4,   5,   6,   7],\n        [  8,   9,  10,  11]],\n\n       [[ 12,  13,  14,  15],\n        [ 16,  17,  18,  19],\n        [ 20,  21,  22,  23]],\n\n       [[  0,  -1,  -2,  -3],\n        [ -4,  -5,  -6,  -7],\n        [ -8,  -9, -10, -11]],\n\n       [[-12, -13, -14, -15],\n        [-16, -17, -18, -19],\n        [-20, -21, -22, -23]]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-3).shape\n\n((2, 3, 4), (2, 3, 4), (4, 3, 4))\n\n\n\n마지막에서 3번째 차원이 바뀌었다. \\(\\Rightarrow\\) 마지막에서 3번째 축이 바뀌었다. \\(\\Rightarrow\\) axis=-3\n\n(보너스4)\n\n# a = np.array(range(2*3*4)).reshape(2,3,4)\na = np.arange(2*3*4).reshape(2,3,4)\nb = -a\n\n\nnp.concatenate([a,b], axis=-4)\n\nAxisError: axis -4 is out of bounds for array of dimension 3\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=-4).shape\n\nAxisError: axis -4 is out of bounds for array of dimension 3\n\n\n\n마지막에서 4번째 차원은 없다. \\(\\Rightarrow\\) 마지막에서 4번째 축은 없다. \\(\\Rightarrow\\) axis=-4는 에러가 난다.\n\n- 0차원은 축이 없으므로 concatenate를 쓸 수 없다.\n\na = np.array(1)\nb = np.array(-1)\n\n\na.shape, b.shape\n\n((), ())\n\n\n\nnp.concatenate([a,b])\n\nValueError: zero-dimensional arrays cannot be concatenated\n\n\n이게 만약에 이렇게 바뀌면 1차원이니까 쓸 수 있다.\n\na = np.array([1])\nb = np.array([-1])\na.shape, b.shape\n\n((1,), (1,))\n\n\n\nnp.concatenate([a,b])\n\narray([ 1, -1])\n\n\n- 꼭 a,b가 같은 차원일 필요는 없다.\n\na = np.array(range(4)).reshape(2,2)\nb = np.array(range(2)).reshape(2,1)\n\n\nnp.concatenate([a,b], axis=1)\n\narray([[0, 1, 0],\n       [2, 3, 1]])\n\n\n\na.shape, b.shape, np.concatenate([a,b], axis=1).shape\n\n((2, 2), (2, 1), (2, 3))\n\n\n\n\n\n- 혹시 아래가 가능할까?\n\n\\((3,)\\) 결합 : \\((3,) \\Rightarrow (3,2)\\)\n\n\na = np.array([1,2,3])\nb = -a\n\n\na,b\n\n(array([1, 2, 3]), array([-1, -2, -3]))\n\n\n\na.shape, b.shape\n\n((3,), (3,))\n\n\n\nnp.concatenate([a,b], axis=1)\n\nAxisError: axis 1 is out of bounds for array of dimension 1\n\n\n\n불가능\n\n- 아래와 같이 하면 해결 가능\n\na = np.array([1,2,3]).reshape(3,1)\nb = -a\n\n\na.shape, b.shape\n\n((3, 1), (3, 1))\n\n\n\na,b\n\n(array([[1],\n        [2],\n        [3]]),\n array([[-1],\n        [-2],\n        [-3]]))\n\n\n\nnp.concatenate([a,b], axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n\n분석: \\((3) (3) \\Rightarrow (3,1),(3,1)\\Rightarrow (3,1) \\space \\tt{concat} \\space (3,1)\\)\n\n- 위의 과정을 줄여서 아래와 같이 할 수 있다.\n\na = np.array([1,2,3])\nb = -a\n\n\nnp.stack([a,b], axis=1)\n\narray([[ 1, -1],\n       [ 2, -2],\n       [ 3, -3]])\n\n\n- 아래도 가능\n\nnp.stack([a,b],axis=0)\n\narray([[ 1,  2,  3],\n       [-1, -2, -3]])\n\n\n- 분석해보고 외우자\n(분석1)\n\na = np.array([1,2,3])\nb = -a\n\n\na.shape, b.shape, np.stack([a,b],axis=0).shape\n\n((3,), (3,), (2, 3))\n\n\n\n\\((3)(3) \\Rightarrow \\text{첫 위치에 축을 추가 (axis=0)} \\Rightarrow (1,3)(1,3) \\Rightarrow (2,3)\\)\n\n(분석2)\n\na = np.array([1,2,3])\nb = -a\n\n\na.shape, b.shape, np.stack([a,b],axis=1).shape\n\n((3,), (3,), (3, 2))\n\n\n\\((3)(3)\\Rightarrow \\text{두번째 위치에 축을 추가 (axis=1)} \\Rightarrow (3,1)(3,1) \\Rightarrow (3,2)\\)\n- 고차원예제\n\na = np.arange(3*4*5).reshape(3,4,5)\nb = -a\n\n\na.shape, b.shape\n\n((3, 4, 5), (3, 4, 5))\n\n\n\nnp.stack([a,b], axis=0).shape # (3,4,5) => (1,3,4,5) // 첫 위치에 축이 추가되고 스택\n\n(2, 3, 4, 5)\n\n\n\nnp.stack([a,b], axis=1).shape # (3,4,5) => (3,1,4,5) // 두번째 위치에 축이 추가되고 스택\n\n(3, 2, 4, 5)\n\n\n\nnp.stack([a,b], axis=2).shape # (3,4,5) => (3,4,1,5) // 세번째 위치에 축이 추가되고 스택\n\n(3, 4, 2, 5)\n\n\n\nnp.stack([a,b], axis=3).shape # (3,4,5) => (3,4,5,1) // 네번째 위치에 축이 추가되고 스택\n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b], axis=-1).shape # axis=-1 <=> axis=3\n\n(3, 4, 5, 2)\n\n\n\nnp.stack([a,b], axis=-2).shape # axis=-2 <=> axis=2\n\n(3, 4, 2, 5)\n\n\nnp.concatenate 는 축의 총 개수를 유지하면서 결합, np.stack은 축의 개수를 하나 증가시키면서 결합"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class3.html",
    "href": "posts/1_IP2022/2023-02-15-class3.html",
    "title": "class 3단계",
    "section": "",
    "text": "이 단계에서는 클래스오브젝트에 소속된 변수와 인스턴스오브젝트에 소속된 변수를 설명한다.\n\n\n\n- 파이썬은 모든 것이 오브젝트로 이루어져 있다. \\(\\leftarrow\\) 우선 그냥 외우기!\n- 오브젝트는 메모리 주소에 저장되는 모든 것을 의미한다.\n\na = 1\nid(a) # 메모리주소를 보는 명령어\n\n7618240\n\n\n\na = 'asdf'\nid(a)\n\n140366991918512\n\n\n\na = [1,2,3]\nid(a)\n\n140366923845376\n\n\n- 클래스와 인스턴스도 오브젝트다.\n\nclass A:\n    x = 0\n    def f(self):\n        print(self.x)\n\n\nid(A)\n\n39987760\n\n\n\nA는 오브젝트\n\n\nb = A()\n\n\nid(b)\n\n140366932540960\n\n\n\nb는 오브젝트\n\n- 앞으로는 A를 클래스 오브젝트, a,b를 인스턴스 오브젝트라고 부르자.\n\n\n- 시점0\n\n# 클래스 선언 시점\nclass A:\n    x = 0\n    y = 0\n    def f(self):\n        self.x = self.x + 1\n        A.y = A.y + 1\n        print('현재 인스턴스에서 f가 {}번 실행'.format(self.x))\n        print('A클래스에서 만들어진 모든 인스턴스들에서 f가 {}번 실행'.format(self.y))\n\n\nid(A) # A라는게 메모리 어딘가에 저장되어 있음.\n\n53014736\n\n\n\nA.x, A.y\n\n(0, 0)\n\n\n- 시점1\n\n# a라는 인스턴스\na = A()\n\n\n# b라는 인스턴스\nb = A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 0], [0, 0], [0, 0])\n\n\n- 시점2\n\na.f() # a에서 f라는 메소드 사용\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 1번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 1], [1, 1], [0, 1])\n\n\n\n여기서 현재 인스턴스라 함은 a를 의미한다.\n\n[1,1] 에서 첫번째 1은 현재 인스턴스(a)에서 f가 1번 실행되었다는 것을 의미하고\n[1,1] 에서 두번째 1은 A클래스에서 만들어진 모든 인스턴스들에서 f가 1번 실행되었음을 의미한다.\n\n\n- 시점3\n\nb.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 2번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 2], [1, 2], [1, 2])\n\n\n\n여기서 현재 인스턴스라 함은 b를 의미한다.\n\n[1,2] 에서 첫번째 1은 현재 인스턴스(b)에서 f가 1번 실행되었다는 것을 의미하고\n[1,2] 에서 두번째 2는 A클래스에서 만들어진 모든 인스턴스들에서 f가 2번 실행되었음을 의미한다 (왜냐면, 위에서 이미 한번 실행을 했기 때문)\n\n\n- 시점4\n\nb.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 3번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 3], [1, 3], [2, 3])\n\n\n- 시점5\n\na.f()\n\n현재 인스턴스에서 f가 2번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 4번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y]\n\n([0, 4], [2, 4], [2, 4])\n\n\n- 시점6\n\n# c라는 인스턴스를 만들어보자.\nc = A()\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 4], [2, 4], [2, 4], [0, 4])\n\n\n- 시점7\n\nc.f()\n\n현재 인스턴스에서 f가 1번 실행\nA클래스에서 만들어진 모든 인스턴스들에서 f가 5번 실행\n\n\n\n[A.x, A.y], [a.x, a.y], [b.x, b.y], [c.x, c.y]\n\n([0, 5], [2, 5], [2, 5], [1, 5])\n\n\n- 신기한 점: 각 인스턴스에서 인스턴스이름.f()를 실행한 횟수를 서로 공유하는 듯 하다. (마치 A가 관리하는 것 처럼 느껴진다.)"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class6.html",
    "href": "posts/1_IP2022/2023-02-23-class6.html",
    "title": "class 6단계",
    "section": "",
    "text": "상속, 사용자정의 자료형\n\n\n\n- 아래와 같은 클래스를 만들자.\n\n이름, 직급, 연봉에 대한 정보가 있다.\n연봉을 올려주는 메소드가 존재함.\n\n\nclass Employee:\n    def __init__(self, name,position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self, pct):\n        self.pay = self.pay * (1+pct)\n\n- 확인\n\niu = Employee('iu', position = 'staff', pay = 5000)\nhynn = Employee('hynn', position = 'staff', pay = 4000)\nhd = Employee('hodong', position = 'mgr', pay = 8000)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5000 \n        \n\n\n\niu.giveraise(0.1)\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn.giveraise(0.2)\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4800.0 \n        \n\n\n- 회사의 모든 직원의 연봉을 \\(10\\%\\)씩 올려보자.\n\niu = Employee('iu', position = 'staff', pay = 5000)\nhynn = Employee('hynn', position = 'staff', pay = 4000)\nhd = Employee('hodong', position = 'mgr', pay = 8000)\n\n\nfor i in [iu, hynn, hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 8800.0 \n        \n\n\n- 매니저직은 일반직원들의 상승분에서 \\(5\\%\\)의 보너스가 추가되어 상승한다고 가정하고 모든 직원의 연봉을 \\(10\\%\\)씩 올리는 코드를 구현해보자.\n\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Employee('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu, hynn, hd]:\n    if i.position == 'mgr':\n        i.giveraise(0.1 + 0.05)\n    else:\n        i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.0 \n        \n\n\n\n\n\n\nclass Manager:\n    def __init__(self, name, position=None, pay=0):\n        self.name = name\n        self.position = position\n        self.pay = pay\n    def _repr_html_(self):\n        html_str = \"\"\"\n        이름: {} <br/>\n        직급: {} <br/>\n        연봉: {} <br/>\n        \"\"\".format(self.name, self.position, self.pay)\n        return html_str\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Manager('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1)\n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n\n\n\n\nclass Manager(Employee):\n    def giveraise(self,pct):\n        self.pay = self.pay * (1+pct+0.05)\n\n\niu=Employee('iu',position='staff',pay=5000)\nhynn=Employee('hynn',position='staff',pay=4000)\nhd=Manager('hodong',position='mgr',pay=8000)\n\n\nfor i in [iu,hynn,hd]:\n    i.giveraise(0.1) \n\n\niu\n\n\n        이름: iu \n        직급: staff \n        연봉: 5500.0 \n        \n\n\n\nhynn\n\n\n        이름: hynn \n        직급: staff \n        연봉: 4400.0 \n        \n\n\n\nhd\n\n\n        이름: hodong \n        직급: mgr \n        연봉: 9200.000000000002 \n        \n\n\n- 요약: 이미 만들어진 클래스에서 대부분의 기능은 그대로 쓰지만 일부기능만 변경 혹은 추가하고 싶다면 클래스를 상속하면 된다!\n\n\n\n\nref: http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791165213190\n\n- list와 비슷한데 멤버들의 빈도가 계산되는 메소드를 포함하는 새로운 나만의 list를 만들고 싶다.\n\nlst = ['a','b','a','c','b','a','d']\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n- 아래와 같은 딕셔너리를 만들고 싶다.\n\nfreq = {'a':3, 'b':2, 'c':1, 'd':1} \nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n\nlst.frequency()를 입력하면 위의 기능이 수행되도록 변형된 list를 쓰고 싶다.\n\n- 구현\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = {'a':0, 'b':0, 'c':0, 'd':0}\nfreq\n\n{'a': 0, 'b': 0, 'c': 0, 'd': 0}\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq[item] + 1\n\nKeyError: 'a'\n\n\n에러이유? freq['a']를 호출할 수 없다. \\(\\to\\) freq.get('a',0) 이용\n\nfreq['a']\n\nKeyError: 'a'\n\n\n\nfreq.get?\n\n\nSignature: freq.get(key, default=None, /)\nDocstring: Return the value for key if key is in the dictionary, else default.\nType:      builtin_function_or_method\n\n\n\n\nkey에 대응하는 값이 있으면 그 값을 리턴하고 없으면 default를 리턴\n\n\nfreq.get('a') # freq['a']에 해당하는 자료가 없어도 에러가 나지 않음\n\n\nfreq.get('a',0) # freq['a']에 해당하는 자료가 없어도 에러가 나지 않음 + freq['a']에 해당하는 자료가 없으면 0을 리턴\n\n0\n\n\n\n\n\n\nlst\n\n['a', 'b', 'a', 'c', 'b', 'a', 'd']\n\n\n\nfreq = dict()\nfreq\n\n{}\n\n\n\nfor item in lst:\n    freq[item] = freq.get(item,0) + 1\n\n\nfreq\n\n{'a': 3, 'b': 2, 'c': 1, 'd': 1}\n\n\n- 이것을 내가 정의하는 새로은 list의 메소드로 넣고 싶다.\n\nclass L(list):\n    def frequency(self):\n        freq = dict()\n        for item in self:\n            freq[item] = freq.get(item,0) + 1\n        return freq\n\n\nlst = L([1,1,1,2,2,3])\n\n\nlst # 원래 list에 있는 repr 기능을 상속받아서 이루어지는 결과\n\n[1, 1, 1, 2, 2, 3]\n\n\n\n_lst = L([4,5,6])\nlst + _lst  # L자료형끼리의 덧셈\n\n[1, 1, 1, 2, 2, 3, 4, 5, 6]\n\n\n\nlst + [4,5,6] # lst + [4,5,6] # L자료형과 list자료형의 덧셈도 가능\n\n[1, 1, 1, 2, 2, 3, 4, 5, 6]\n\n\n\nL자료형의 덧셈은 list의 덧셈과 완전히 같음\n\n\nlst.append(10) # append 함수도 그대로 쓸 수 있음.\n\n\nlst\n\n[1, 1, 1, 2, 2, 3, 10]\n\n\n- 기존 리스트에서 추가로 frequency() 메소드가 존재함.\n\nlst.frequency()\n\n{1: 3, 2: 2, 3: 1, 10: 1}\n\n\n\n\n\n\n\n- 사용자정의 자료형이 어떤 경우에는 유용할 수 있다.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\nyear = ['2016','2017','2017','2017',2017,2018,2018,2019,2019] \nvalue = np.random.randn(9)\n\n\ndf = pd.DataFrame({'year':year, 'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      -0.140139\n    \n    \n      1\n      2017\n      1.412758\n    \n    \n      2\n      2017\n      -0.065478\n    \n    \n      3\n      2017\n      0.107847\n    \n    \n      4\n      2017\n      0.824112\n    \n    \n      5\n      2018\n      0.061573\n    \n    \n      6\n      2018\n      -0.463060\n    \n    \n      7\n      2019\n      -0.808921\n    \n    \n      8\n      2019\n      0.389417\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value)\n\nTypeError: 'value' must be an instance of str or bytes, not a int\n\n\n\n\n\n에러의 이유: df.year에 str,int가 동시에 있음.\n\nnp.array(df.year)\n\narray(['2016', '2017', '2017', '2017', 2017, 2018, 2018, 2019, 2019],\n      dtype=object)\n\n\n자료형을 바꿔주면 해결할 수 있다.\n\nnp.array(df.year, dtype=np.float64)\n#np.array(df.year).astype(np.float64)\n#df.year.astype(np.float64)\n\narray([2016., 2017., 2017., 2017., 2017., 2018., 2018., 2019., 2019.])\n\n\n\nplt.plot(df.year.astype(np.float64),df.value,'.')\n\n\n\n\n\n\n\n\nyear = ['2016','2017','2017','2017년','2017년',2018,2018,2019,2019] \nvalue = np.random.randn(9)\n\n\ndf= pd.DataFrame({'year':year,'value':value})\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      0.127739\n    \n    \n      1\n      2017\n      1.437921\n    \n    \n      2\n      2017\n      -1.137349\n    \n    \n      3\n      2017년\n      -0.178713\n    \n    \n      4\n      2017년\n      -0.276401\n    \n    \n      5\n      2018\n      2.467760\n    \n    \n      6\n      2018\n      -1.068202\n    \n    \n      7\n      2019\n      -0.313908\n    \n    \n      8\n      2019\n      1.049837\n    \n  \n\n\n\n\n\nnp.array(df.year,dtype=np.float64) # 타입을 일괄적으로 바꾸기 어렵다. \n\nValueError: could not convert string to float: '2017년'\n\n\n\nL(df.year).frequency()\n\n{'2016': 1, '2017': 2, '2017년': 2, 2018: 2, 2019: 2}\n\n\n\n’2016’와 같은 형태, ’2017년’와 같은 형태, 숫자형이 혼합 \\(\\to\\) 맞춤형 변환이 필요함\n\n\n'2017년'.replace('년','')\n\n'2017'\n\n\n\ndef f(a): ## 사실 데이터의 구조를 모르면 이런 함수를 짤 수 없음 --> 자료의 구조를 확인해준다는 의미에서 freq가 있다면 편리하다. \n    if type(a) is str:\n        if '년' in a:\n            return int(a.replace('년',''))\n        else:\n            return int(a)\n    else:\n        return a\n\n\n[f(a) for a in df.year]\n\n[2016, 2017, 2017, 2017, 2017, 2018, 2018, 2019, 2019]\n\n\n\ndf.year = [f(a) for a in df.year]\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      value\n    \n  \n  \n    \n      0\n      2016\n      0.127739\n    \n    \n      1\n      2017\n      1.437921\n    \n    \n      2\n      2017\n      -1.137349\n    \n    \n      3\n      2017\n      -0.178713\n    \n    \n      4\n      2017\n      -0.276401\n    \n    \n      5\n      2018\n      2.467760\n    \n    \n      6\n      2018\n      -1.068202\n    \n    \n      7\n      2019\n      -0.313908\n    \n    \n      8\n      2019\n      1.049837\n    \n  \n\n\n\n\n\nplt.plot(df.year, df.value,'.')"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas1.html",
    "href": "posts/1_IP2022/2023-03-14-pandas1.html",
    "title": "Pandas 1단계",
    "section": "",
    "text": "데이터프레임 선언, 행\\(\\cdot\\)열 이름부여, 자료형, pd.Series"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas1.html#pandas-공부-1단계",
    "href": "posts/1_IP2022/2023-03-14-pandas1.html#pandas-공부-1단계",
    "title": "Pandas 1단계",
    "section": "pandas 공부 1단계",
    "text": "pandas 공부 1단계\n\nimport numpy as np\nimport pandas as pd\n\n\n데이터프레임 선언\n- 방법1: dictionary에서 만든다.\n\npd.DataFrame({'att':[30,40,50], 'mid':[50,60,70]}) # 리스트\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':(30,40,50),'mid':(50,60,70)}) # 튜플\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n\npd.DataFrame({'att':np.array([30,40,50]),'mid':np.array([50,60,70])}) # numpy array\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: 2차원 ndarray에서 만든다.\n\nnp.arange(2*3).reshape(2,3)\n\narray([[0, 1, 2],\n       [3, 4, 5]])\n\n\n\npd.DataFrame(np.arange(2*3).reshape(2,3))\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n열의 이름 부여\n- 방법1: 딕셔너리를 통하여 만들면 딕셔너리의 key가 자동으로 열의 이름이 된다.\n\npd.DataFrame({'att':np.array([30,40,50]), 'mid':np.array([50,60,70])})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      50\n    \n    \n      1\n      40\n      60\n    \n    \n      2\n      50\n      70\n    \n  \n\n\n\n\n- 방법2: pd.DataFrame()의 옵션에 columns를 이용\n\npd.DataFrame(np.arange(2*3).reshape(2,3),columns=['X1','X2','X3'])\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n- 방법3: df.columns에 원하는 열이름 덮어씀 (1)\n\ndf=pd.DataFrame(np.arange(2*3).reshape(2,3))\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns = ['X1','X2','X3'] # columns 메소드 이용.\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns, type(df.columns)\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n- 방법4: df.columns에 원하는 열이름 덮어씀 (2)\n\ndf=pd.DataFrame(np.arange(2*3).reshape(2,3))\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.columns = pd.Index(['X1','X2','X3'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n  \n\n\n\n\n방법4 가 방법3 의 방식보다 컴퓨터가 이해하기 좋다. (=불필요한 에러를 방지할 수 있다.)\n\n## 방법3\ndf.columns, type(df.columns)  ## 내부적으로 list 타입을 pandas.core.indexes~~형태로 바꿔주긴 함.\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n\n['X1','X2','X3'], type(['X1','X2','X3'])\n\n(['X1', 'X2', 'X3'], list)\n\n\n\n처음부터 타입을 맞춰놓게 하는 게 좋다. (컴퓨터가 이해하기 명시적인 표현)\n\n\n## 방법4\npd.Index(['X1','X2','X3']), type(pd.Index(['X1','X2','X3']))\n\n(Index(['X1', 'X2', 'X3'], dtype='object'), pandas.core.indexes.base.Index)\n\n\n\n\n행의 이름 부여\n- 방법1: 중첩 dict이면 nested dic의 key가 알아서 행의 이름으로 된다.\n\n바깥쪽 딕셔너리의 키는 컬럼이름으로, 안쪽 딕셔너리의 키는 로우이름으로 들어간다.\n\n\npd.DataFrame({'att':{'guebin':30, 'iu':40, 'hynn':50} , 'mid':{'guebin':5, 'iu':45, 'hynn':90}})\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법2: pd.DataFrame()의 index옵션 이용\n\npd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]}, index=['guebin','iu','hynn'])\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법3: df.index에 덮어씌움.\n\ndf=pd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.index = pd.Index(['guebin','iu','hynn']) ## 좋은 코드!\n#df.index = ['guebin','iu','hynn'] <- 이것도 실행 되기는 된다.\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n- 방법4: df.set_index()를 이용하여 덮어씌운다.\n\ndf=pd.DataFrame({'att':[30,40,50] , 'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n\ndf.set_index(pd.Index(['guebin','iu','hynn'])) # set_index 메소드 이용\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n(주의) 아래는 에러가 난다.\n\ndf.set_index(['guebin','iu','hynn'])\n\nKeyError: \"None of ['guebin', 'iu', 'hynn'] are in the columns\"\n\n\n\ndf.set_index([['guebin','iu','hynn']]) # 꺽쇠를 한번 더 넣어주면 에러를 피할수 있다. \n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      guebin\n      30\n      5\n    \n    \n      iu\n      40\n      45\n    \n    \n      hynn\n      50\n      90\n    \n  \n\n\n\n\n\n\n자료형, len, shape, for문의 반복변수\n\ndf = pd.DataFrame({'att':[30,40,50],'mid':[5,45,90]})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      0\n      30\n      5\n    \n    \n      1\n      40\n      45\n    \n    \n      2\n      50\n      90\n    \n  \n\n\n\n\n- type\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n- len\n\nlen(df) # row의 개수\n\n3\n\n\n- shape\n\ndf.shape\n\n(3, 2)\n\n\n- for문의 반복변수\n\nfor k in df:\n    print(k) # 딕셔너리 같죠?\n\natt\nmid\n\n\n\nfor k in {'att':[30,40,50],'mid':[5,45,90]}:\n    print(k)\n\natt\nmid\n\n\n\n\npd.Series\n- 2차원 ndarray가 데이터프레임에 대응한다면 1차원 ndarray는 pd.Series에 대응한다.\n\na=pd.Series(np.random.randn(10))\na\n\n0   -0.015761\n1    0.793164\n2   -0.194785\n3   -1.704138\n4    0.196202\n5   -0.542479\n6    0.134923\n7   -1.151843\n8    0.567016\n9    2.469013\ndtype: float64\n\n\n\ntype(a)\n\npandas.core.series.Series\n\n\n\nlen(a)\n\n10\n\n\n\na.shape\n\n(10,)\n\n\n\nfor value in a:\n    print(value)\n\n-0.01576052104052408\n0.7931636561267669\n-0.19478516128697446\n-1.7041378729481649\n0.19620173234455546\n-0.542479066364815\n0.13492305158609827\n-1.1518431416352932\n0.5670160023697828\n2.4690128371679556\n\n\n\nfor value in np.random.randn(10):\n    print(value)\n\n-0.0864801362204059\n-0.9294913581613311\n-0.4818729848296065\n2.1539740078272693\n0.5075567770278344\n0.6907204209585092\n0.2885924769916613\n-0.5636921329605091\n-0.9741967151982581\n1.8705475972066663"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class9.html",
    "href": "posts/1_IP2022/2023-02-23-class9.html",
    "title": "class 9단계",
    "section": "",
    "text": "global/local 변수, 인스턴스/클래스 변수, 인스턴스/클래스 메서드\n\n\n\n커널을 재시작하고 아래를 관찰하자.\n\n\n- 관찰1: 함수내의 변수 출력\n\ndef f():\n    x = 10\n    print(x)\n\n\nf()\n\n10\n\n\n- 관찰2: 함수내의 변수가 없을 경우 출력이 되지 않음\n\ndef g():\n    print(x)\n\n\ng()\n\nNameError: name 'x' is not defined\n\n\n- 관찰3: 동일한 이름의 변수가 global에 있다면 함수내에 (local) 그 이름의 변수가 선언되지 않아도 global 변수를 빌려서 사용함.\n\nx = 20\ndef g():\n    print(x)\n\n\ng()\n\n20\n\n\n- 관찰4: f()가 실행되면서 x=10이 함수내에(=local에) 실행되지만 이 결과가 외부의 x=20에(=global에) 영향을 미치지는 못함.\n\nf()\n\n10\n\n\n\nx\n\n20\n\n\n\n\n\n(코드1)\n\nx = 38\ndef nextyear():\n    y = x+1\n    print(x,y)\nnextyear()\n\n38 39\n\n\n(코드2)\n\nx = 38\ndef nextyear():\n    y = x+1\n    print(x,y)\n    x = 0\nnextyear()\n\nUnboundLocalError: local variable 'x' referenced before assignment\n\n\n- 해석: - 잘못된해석: 코드1은 실행되었고, 코드2에서 에러가 났다. 코드1과 2의 차이점은 x=0 이라는 코드가 코드2에 추가로 포함되어있다는 것이다. 따라서 x=0이 잘못된 코드이고 이걸 실행하는 과정에서 에러가 발생했다.\n\n올바른해석: 코드1에서는 x가 global variable이고 코드2에서는 x가 local variable이어서 생기는 문제\n\n- 코드2의 올바른 수정\n\nx = 38\ndef nextyear():\n    x = 0\n    y = x+1\n    print(x,y)\nnextyear()\n\n0 1\n\n\n\n\n\n\n- 예비학습이 주는 교훈\n(원칙1) global에서 정의된 이름은 local에서 정의된 이름이 없을 경우 그를 대신할 수 있다. (local은 경우에 따라서 global에 있는 변수를 빌려 쓸 수 있다.)\n(원칙2) local과 global에서 같은 이름 ’x’가 각각 정의되어 있는 경우? global의 변수와 local의 변수는 각각 따로 행동하여 서로 영향을 주지 않는다. (독립적이다)\n\n만약에 local에 global의 변수를 같이 쓰고 있었다고 할지라도, 추후 새롭게 local에 이름이 새롭게 정의된다면 그 순간 local과 global의 변수를 각자 따로 행동하며 서로 영향을 주지 않는다.\\(\\to\\) 아래예제 확인\n\n\nx = 10\ndef f():\n    print(x)\n\n\nf() # x를 빌려쓰는 신세\n\n10\n\n\n\ndef f():\n    x = 20 # 이제 새롭게 x를 정의했으니까\n    print(x)\n\n\nf() # 다른길을 간다.\n\n20\n\n\n- 이전에 공부하였던 인스턴스변수와 클래스변수 역시 비슷한 행동을 보인다.\n\nclass Moo:\n    x = 0 # 클래스 변수\n\n\nmoo=Moo()\n\n(관찰1)\n\nMoo.x, moo.x\n\n(0, 0)\n\n\n\nmoo.x는 사실 정의한적이 없지만 Moo.x를 빌려쓰고 있다. (원칙1)\n\n(관찰2)\n\nMoo.x = 100\n\n\nMoo.x, moo.x\n\n(100, 100)\n\n\n\nMoo.x를 변화시키면 moo.x도 변화한다. (빌려쓰고 있는 것이니까, 원칙1의 재확인)\n\n(관찰3)\n\nmoo.x = 200\n\n\nMoo.x, moo.x\n\n(100, 200)\n\n\n\nmoo.x=200을 하는 순간 새롭게 인스턴스변수를 선언한 셈이된다. 따라서 원칙2가 적용되어 이제부터 Moo.x와 moo.x는 서로 독립적으로 행동한다.\n\n(관찰4)\n\nMoo.x = -99\n\n\nMoo.x, moo.x\n\n(-99, 200)\n\n\n\nmoo.x = 99\n\n\nMoo.x, moo.x\n\n(-99, 99)\n\n\n\nMoo.x를 바꾼다고 해서 moo.x가 영향받지 않고 moo.x를 바꿔도 Moo.x가 영향받지 않음. (완전히 독립, 원칙2의 재확인)\n\n\n\n\n\n클래스변수와 인스턴스 변수의 구분\n\n\n인스턴스 변수가 정의되지 않으면 클래스변수를 빌려쓸 수 있음(클래스변수가 상위개념)\n\n\n인스턴스변수와 클래스변수가 같은 이름으로 저장되어 있으면 각각 독립적으로 행동\n\n\n\n\n\n\n- self 비밀: 사실 클래스에서 정의된 함수의 첫번째 인자의 이름이 꼭 self일 필요는 없다. (무엇으로 전달하든 클래스 안에서 정의된 메소드의 첫번째 인자는 기본적으로 태명역할을 한다.)\n\nclass Moo:\n    def __init__(self):\n        self.name = 'jordy'\n    def f(self):\n        print(self.name)\n\n\nmoo = Moo()\n\n\nmoo.name\n\n'jordy'\n\n\n\nmoo.f()\n\njordy\n\n\n\n꼭 위와 같이 할 필요는 없다.\n\n\nclass Moo:\n    def __init__(abab):\n        abab.name = 'jordy'\n    def f(cdcd):\n        print(cdcd.name)\n\n\nmoo = Moo()\n\n\nmoo.name\n\n'jordy'\n\n\n\nmoo.f()\n\njordy\n\n\n- 인스턴스 메서드: 위의 __init__와 f와 같이 첫번째 인자를 인스턴스의 태명으로 받는 함수를 인스턴스 메서드 (간단히 메서드) 라고 한다.\n\n인스턴스 메소드는 self.f()와 같이 사용한다. 의미는 f(self) 이다.\n\n\nmoo.name = 'chunsik'\n\n\nmoo.name\n\n'chunsik'\n\n\n\nmoo.__init__()\n\n\nmoo.name # 인스턴스 메서드의 사용예시: self.__init__()의 꼴로 사용\n\n'jordy'\n\n\n\n오 신기하다.\n\n- 아래와 같이 사용할 수 없다.\n\nMoo.__init__() # 인스턴스가 들어와야하는데 클래스가 들어와버려서 이렇게 쓸순 없다.\n\nTypeError: __init__() missing 1 required positional argument: 'abab'\n\n\n\n인스턴스 메소드이기때문에 에러가 난다. 즉, 첫번째 입력 (.__init__()앞에)에 인스턴스가 들어가야 하는데 클래스가 들어와버렸다.\n\n\n\n\n- 클래스 메서드: 함수의 첫 인자로 클래스오브젝트를 받는 메서드를 클래스메서드라고 한다.\n- 목표: Moo.f() 와 같은 형태로 사용할 수 있는 함수를 만들어 보자. \\(\\to\\) 클래스메서드를 만들어보자.\n\nclass Moo:\n    def f(self): # 클래스 안에서 함수를 선언하면 디폴트로 인스턴스 메서드가 만들어진다.\n        print('인스턴스 메서드') \n\n\nmoo = Moo()\n\n\nmoo.f()\n\n인스턴스 메서드\n\n\n\nMoo.f() # 인스턴스 메서드니까 안되는게 당연\n\nTypeError: f() missing 1 required positional argument: 'self'\n\n\n\nclass Moo:\n    @classmethod\n    def f(cls): # 함수의 첫 인자로 클래스오브젝트를 받는다. cls는 클래스 Moo의 별명? 이라고 생각하면 된다.\n        print('클래스 메서드')\n\n\nmoo = Moo()\n\n\nMoo.f()\n\n클래스 메서드\n\n\n\nmoo.f() # 인스턴스 메서드를 따로 정의한적은 없지만 같은 이름의 클래스 메서드가 있으므로 빌려와서 씀!\n\n클래스 메서드\n\n\n- 예제\n\nclass Moo:\n    @classmethod\n    def set_class_x(cls, value): # 클래스 메서드\n        cls.x = value # 클래스변수선언, Moo.x = value와 같은 코드!\n    def set_instance_x(self, value): # 인스턴스 메서드\n        self.x = value # 인스턴스 변수선언\n\n\nmoo = Moo()\n\n\nMoo.set_class_x(10) # 클래스메서드로 클래스변수에 10을 설정\n\n\nMoo.x\n\n10\n\n\n\nMoo.set_instance_x(10) # 클래스에서 인스턴스 메서드 사용 -> 사용불가\n\nTypeError: set_instance_x() missing 1 required positional argument: 'value'\n\n\n\nMoo.x, moo.x # 인스턴스변수는 따로 설정하지 않았지만 클래스 변수값을 빌려쓰고 있음\n\n(10, 10)\n\n\n\nmoo.set_class_x(20) # 인스턴스에서는 원래 set_class_x 라는 메서드는 없지만 클래스에서 빌려씀\n\n\nMoo.x, moo.x # 현재 moo.x(인스턴스)는 클래스 변수를 빌려쓰고 있는 상황이므로 같이 바뀜\n\n(20, 20)\n\n\n\nmoo.set_instance_x(-20) \n# 인스턴스에서 인스턴스 메서드를 사용하여 인스턴스 변수값을 -20으로 설정 \n# -> 이때부터 인스턴스 변수와 클래스 변수는 서로 독립적인 노선을 간다.\n\n\nMoo.set_class_x(30) # 독립적인 노선을 가기로 헀으므로 클래스변수만 30으로 바뀜.\nMoo.x, moo.x\n\n(30, -20)\n\n\n\nmoo.set_class_x(-40) # 여전히 인스턴스에서 set_class_x라는 함수는 없으므로 클래스메소드를 빌려쓰고 있음.\n\n\n\n\n- 스태틱 메서드: 첫 인자로 인스턴스와 클래스 모두 받지 않음. (클래스안에 정의되어 있지만 그냥 함수와 같음)\n\nclass Cals:\n    @staticmethod\n    def add(a,b):\n        return a+b\n    @staticmethod\n    def sub(a,b):\n        return a-b\n\n\nfs = Cals()\n\n\nfs.add(1,2)\n\n3\n\n\n\nfs.sub(1,2)\n\n-1\n\n\n\nfs는 그냥 함수들을 묶어놓은 느낌? 정리하기 편하게?"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class8.html",
    "href": "posts/1_IP2022/2023-02-23-class8.html",
    "title": "class 8단계",
    "section": "",
    "text": "for문 복습, iterable object\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\n\n\n- 아래와 같은 예제들을 관찰하여 for문을 복습하자.\n(예제1)\n\nfor i in [1,2,3,4]:\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제2)\n\nfor i in (1,2,3,4):\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제3)\n\nfor i in '1234':\n    print(i)\n\n1\n2\n3\n4\n\n\n(예제4)\n\na=5\nfor i in a:\n    print(i)\n\nTypeError: 'int' object is not iterable\n\n\n\n5라고 출력되어야 하지 않나?\n\n- 의문1:\nfor i in ???:\n    print(i)\n에서 ???자리에 올 수 있는 것이 무엇일까?\n(예제5)\n상황1\n\nlst = [[1,2,3,4],[3,4,5,6]]\nlst\n\n[[1, 2, 3, 4], [3, 4, 5, 6]]\n\n\n\nfor l in lst:\n    print(l)\n\n[1, 2, 3, 4]\n[3, 4, 5, 6]\n\n\n상황2\n\ndf = pd.DataFrame(lst)\ndf\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\n0\n1\n2\n3\n\n\n칼럼이름들이 나오는 것 같음 \\(\\to\\) 확인해보자.\n\ndf.columns = pd.Index(['X'+str(i) for i in range(1,5)])\ndf\n\n\n\n\n\n  \n    \n      \n      X1\n      X2\n      X3\n      X4\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n- 의문2: for의 출력결과는 어떻게 예측할 수 있을까?\n\n\n\n- 의문1의 해결: 아래의 ??? 자리에 올 수 있는 것은 dir() 하여 __iter__ 가 있는 object이다.\nfor i in ???:\n    print(i)\n- 확인\n\na = [1,2,3] # list\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na = 1,2,3 # tuple\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na = '123' # string\nset(dir(a)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na=3\nset(dir(a)) & {'__iter__'}\n\nset()\n\n\niterable 하지 않다라는 것은dir()을 쳤을 때 __iter__ 라는 메소드가 없다는 것을 의미\n\n예상대로 예제1~예제4에서는 int클래스의 instance만 __iter__가 없다.\nfor문 뒤 ??? 자리에 올 수 있는 것은 iterable object만 올 수 있다.\n\n- __iter__의 역할: iterable object를 iterator로 만들 수 있다.\n\nlst = [1,2,3]\nlst\n\n[1, 2, 3]\n\n\n\nlst[1] # 충실한 리스트\n\n2\n\n\n\nltor = iter(lst) # 아래와 같은 표현 (a.__str__() = str(a)가 같은 것처럼)\n#ltor = lst.__iter__() # list iterator\nltor\n\n<list_iterator at 0x7f2dfc4c51f0>\n\n\n\nltor[1] # 더이상 리스트가 아니다.\n\nTypeError: 'list_iterator' object is not subscriptable\n\n\n\nltor?\n\n\nType:        list_iterator\nString form: <list_iterator object at 0x7f2dfc4c51f0>\nDocstring:   <no docstring>\n\n\n\n- iterator가 되면 무엇이 좋은가? \\(\\to\\) 숨겨진 기능 __next__가 열린다.\n\nlst\n\n[1, 2, 3]\n\n\n\nset(dir(lst)) & {'__next__'}, set(dir(ltor)) & {'__next__'}\n\n(set(), {'__next__'})\n\n\n\nlst에는 __next__ 가 없지만 ltor에는 있다.\n\n- 그래서 __next__의 기능은? \\(\\to\\) 원소를 차례대로 꺼내준다. + 더 이상 꺼낼 원소가 없으면 Stopiteration Error 발생시킨다.\n\nlst\n\n[1, 2, 3]\n\n\n\nltor.__next__()\n\n1\n\n\n\nltor.__next__()\n\n2\n\n\n\nltor.__next__()\n\n3\n\n\n\nltor.__next__()\n\nStopIteration: \n\n\n- for문의 동작원리\nfor i in lst:\n    print(i)\n\nlst.__iter__() 혹은 iter(lst)를 이용하여 lst를 iterator로 만든다. (iterable object를 iterator object로 만든다.)\niterator에서 .__next__() 함수를 호출하고 결과를 i에 저장한 뒤에 for문 블락안에 있는 내용 (들여쓰기 된 내용)을 실행한다. \\(\\to\\) 반복\nStopIteration 에러가 발생하면 for문을 멈춘다.\n\n- 아래의 ??? 자리에 올 수 있는 것이 iterable object 가 아니라 iterator 자체여도 for문이 돌아갈까? (당연히 돌아가야 할 것 같음)\nfor i in ???:\n    print(i)\n\nfor i in [1,2,3]: # iterable object\n    print(i)\n\n1\n2\n3\n\n\n\n당연히 가능!\n\n- a가 iterator일때 iter(a)의 출력결과가 a와 같도록 조정한다면 for문의 동작원리 (1)-(3)을 수행하지 않아도 좋다. \\(\\to\\) 실제로 이렇게 동작한다.\n- 요약\n\niterable object는 숨겨진 기능으로 __iter__를 가진다.\niterator object는 숨겨진 기능으로 __iter__와 __next__를 가진다. (즉 iterator는 그 자체로 iterable object가 된다!)\n\n\nlst = [1,2,3]\nltor = iter(lst)\n\n\nset(dir(lst)) & {'__iter__','__next__'}\n\n{'__iter__'}\n\n\n\nset(dir(ltor)) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n- 의문2의 해결: for의 출력결과는 어떻게 예측할 수 있을까? iterator를 만들어서 .__next__()의 출력값을 확인하면 알 수 있다.\n\nfor i in df:\n    print(i)\n\nX1\nX2\nX3\nX4\n\n\n\ndftor = iter(df)\ndftor?\n\n\nType:        map\nString form: <map object at 0x7f2dfc4c85b0>\nDocstring:  \nmap(func, *iterables) --> map object\nMake an iterator that computes the function using arguments from\neach of the iterables.  Stops when the shortest iterable is exhausted.\n\n\n\n\ndftor.__next__()\n\n'X1'\n\n\n\ndftor.__next__()\n\n'X2'\n\n\n\ndftor.__next__()\n\n'X3'\n\n\n\ndftor.__next__()\n\n'X4'\n\n\n\ndftor.__next__()\n\nStopIteration: \n\n\n\n\n\n- 파이썬에서 for문을 처음 배울 때: range(5)를 써라!\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\nrange(5)가 도대체 무엇이길래? ## iterator 아니면 iterable object 일건데..\n\n\nrange(5)\n\nrange(0, 5)\n\n\n\nrepr(range(5))\n\n'range(0, 5)'\n\n\n- range(5)의 정체는 그냥 iterable object이다.\n\nset(dir(range(5))) & {'__iter__', '__next__'}\n\n{'__iter__'}\n\n\n__next__ 는 갖고있지 않은데 __iter__만 갖고있으니까 range(5)는 iterable object\n- 그래서 언제든지 iterator로 바꿀 수 있다.\n\nrtor = iter(range(5))\n\n\nrtor?\n\n\nType:        range_iterator\nString form: <range_iterator object at 0x7f2dfc4c56c0>\nDocstring:   <no docstring>\n\n\n\n\nset(dir(rtor)) & {'__iter__','__next__'}\n\n{'__iter__', '__next__'}\n\n\n- for문에서 range(5)가 행동하는 방법?\n\nrtor.__next__()\n\n0\n\n\n\nrtor.__next__()\n\n1\n\n\n\nrtor.__next__()\n\n2\n\n\n\nrtor.__next__()\n\n3\n\n\n\nrtor.__next__()\n\n4\n\n\n\nrtor.__next__()\n\nStopIteration: \n\n\n\n\n\n- 이터레이터의 개념을 알면 for문에 대한 이해도가 대폭 상승한다.\n\nfor i in zip([1,2,3],'abc'):\n    print(i)\n\n(1, 'a')\n(2, 'b')\n(3, 'c')\n\n\n\nzip은 뭐지???\n\n\nzip([1,2,3],'abc')\n\n<zip at 0x7f2dfc4e8340>\n\n\n- 어차피 for i in ????: 의 ???? 자리는 iterable object(iterator)의 자리이다.\n\nset(dir(zip([1,2,3],'abc'))) & {'__iter__','__next__'}\n\n{'__iter__', '__next__'}\n\n\n\n__next__() 함수가 있음 \\(\\to\\) zip([1,2,3],'abc')는 그자체로 iterator 였다!\n\n\nz = zip([1,2,3],'abc')\n\n\nz.__next__()\n\n(1, 'a')\n\n\n\nz.__next__()\n\n(2, 'b')\n\n\n\nz.__next__()\n\n(3, 'c')\n\n\n\nz.__next__()\n\nStopIteration: \n\n\n\n\n\n- 내가 이터레이터를 만들어보자.\n\nclass Klass: # 찌를 내는 순간 for문이 멈추도록 하는 이터레이터를 만들자.\n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        if action == '찌':\n            print('찌가 나와서 for문을 멈춥니다.')\n            raise StopIteration\n        else:\n            return action\n\n\na = Klass() # 클래스로부터 인스턴스 만들기\n\n\na?\n\n\nType:        Klass\nString form: <__main__.Klass object at 0x7f2dfc373af0>\nDocstring:   <no docstring>\n\n\n\n\nset(dir(a)) & {'__iter__', '__next__'} # a는 이터레이터!\n\n{'__iter__', '__next__'}\n\n\n\na.__next__()\n\n'빠'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n'묵'\n\n\n\na.__next__()\n\n찌가 나와서 for문을 멈춥니다.\n\n\nStopIteration: \n\n\n\nfor i in a:\n    print(i)\n\n빠\n묵\n묵\n빠\n찌가 나와서 for문을 멈춥니다.\n\n\n\n\n\n\n파이썬의 비밀1: 자료형은 클래스의 이름이다.\n파이썬의 비밀2: 클래스에는 __str__ 처럼 숨겨진 매서드가 존재한다. 이를 이용하여 파이썬 내부의 기능을 가로챌 수 있다.\n파이썬의 비밀3: 주피터노트북(대화형 콘솔)에서는 “오브젝트이름 + 엔터”를 쳐서 나오는 출력은 __repr__로 가로챌 수 있다. (주피터의 비밀)\n파이썬의 비밀4: 함수와 클래스는 숨겨진 메소드에 __call__을 가진 오브젝트일 뿐이다.\n파이썬의 비밀5: for문의 비밀(iterable object, iterator, StopIteration Error)"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html",
    "href": "posts/1_IP2022/2023-05-27-class활용.html",
    "title": "Class 활용",
    "section": "",
    "text": "클래스(class)는 여러 정보를 하나의 객체에 담을 때 사용할 수 있다.\n캐릭터 객체를 만들 때, 캐릭터에 대한 정보로는 다음과 같은 것들이 있다.\n\n\n이름\n\n\n체력\n\n\n힘\n\n\n민첩도\n\n\n\n\nclass Character:\n    def __init__(self, name, hp, strength, agility):\n        self.name = name\n        self.hp = hp\n        self.strength = strength\n        self.agility = agility\n        \n    def show_character(self):\n        print('=======캐릭터 정보=======')\n        print(f'이름: {self.name}')\n        print(f'체력: {self.hp}')\n        print(f'힘: {self.strength}')\n        print(f'민첩도: {self.agility}')\n        \n    def attack(self):\n        print(f'[{self.name}] 기본 공격 수행 (공격력: {self.strength})')\n\n\ncharacter1 = Character(\"슬라임\", 50, 5, 3)\ncharacter1.show_character()\ncharacter1.attack()\n\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 50\n힘: 5\n민첩도: 3\n[슬라임] 기본 공격 수행 (공격력: 5)\n\n\n\ncharacter2 = Character(\"용사1\", 200, 10, 5)\ncharacter2.show_character()\ncharacter2.attack()\n\n=======캐릭터 정보=======\n이름: 용사1\n체력: 200\n힘: 10\n민첩도: 5\n[용사1] 기본 공격 수행 (공격력: 10)\n\n\n\ncharacter1, 2 각 각 인스턴스가 다르기 때문에 서로 다른 정보를 갖는다.\nCharacter라는 클래스 내에 character1, character2처럼 같은 클래스 내의 인스턴스는 다를 수 있다."
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#몬스터-클래스-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#몬스터-클래스-자식",
    "title": "Class 활용",
    "section": "2. 몬스터 클래스 (자식)",
    "text": "2. 몬스터 클래스 (자식)\n앞서 정의했던 Character 클래스를 이용해서 몬스터 클래스를 정의할 수 있다.\n\n클래스의 상속(inheritance) 은 체계적인 프로그램 개발을 위해 필요하다.1\n예를 들어 캐릭터 객체는 몬스터(monster) 와 주인공(hero) 로 나누어질 수 있다.\n\n이들은 공통적으로 이름(name), 힘(strength) 등의 정보를 가지고 있다.\n\n상속을 사용하여, 공통적으로 사용되는 변수를 매번 선언하지 않는다.\n몬스터는 모두 마력(MP) 정보를 가지고 있다고 가정하자.\n\n\nclass Monster(Character):\n    def __init__(self, name, hp, strength, agility, mp):\n        super().__init__(name, hp, strength, agility)\n        self.mp = mp\n    \n    def recovery(self):\n        print(f'[{self.name}] 자기 치유 (회복된 체력: {self.mp})')\n        self.hp += self.mp\n\n\nmonster1 = Monster('슬라임', 50, 5, 3, 5)\nmonster1.show_character()\nmonster1.attack()\nmonster1.recovery()\nmonster1.show_character()\n\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 50\n힘: 5\n민첩도: 3\n[슬라임] 기본 공격 수행 (공격력: 5)\n[슬라임] 자기 치유 (회복된 체력: 5)\n=======캐릭터 정보=======\n이름: 슬라임\n체력: 55\n힘: 5\n민첩도: 3\n\n\n\nMonster 클래스는 기존의 Character 클래스를 상속받은 것이기 때문에 기존 Character 클래스가 가지고 있던 기능까지 함께 사용할 수 있다."
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#주인공-클래스-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#주인공-클래스-자식",
    "title": "Class 활용",
    "section": "3. 주인공 클래스 (자식)",
    "text": "3. 주인공 클래스 (자식)\n\n주인공은 모두 직업(job) 정보를 가지고 있다고 가정하자.\n\n\nclass Hero(Character):\n    def __init__(self, name, hp, strength, agility, job):\n        super().__init__(name, hp, strength, agility)\n        self.job = job\n    def show_hero(self):\n        print('==========주인공 정보==========')\n        print(f'직업: {self.job}')\n\n\nhero1 = Hero('용사1', 200, 10, 5, '마법사')\nhero1.show_character()\n\n=======캐릭터 정보=======\n이름: 용사1\n체력: 200\n힘: 10\n민첩도: 5\n\n\n\nhero1.show_hero()\n\n==========주인공 정보==========\n직업: 마법사"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#딥러닝-모델-클래스-예시",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#딥러닝-모델-클래스-예시",
    "title": "Class 활용",
    "section": "딥러닝 모델 클래스 예시",
    "text": "딥러닝 모델 클래스 예시\n\n1. 딥러닝 이미지 모델 클래스 (부모)\n\n기초적인 이미지 처리 모델은 일반적으로 인코더 정보를 포함한다.\n인코더(encoder)\n\n특징 추출기(feature extractor)\n입력 모양(input shape)\n\n딥러닝 모델은 입력을 통해 출력을 뱉는 forward() 함수가 존재한다.\n\n\nclass Model:\n    def __init__(self, feature_extractor, input_shape):\n        self.feature_extractor = feature_extractor\n        self.input_shape = input_shape\n        \n    def show(self):\n        print('==========인코더 정보===============')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'입력 차원: {self.input_shape}')\n        \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기] {self.feature_extractor}')\n\n\nmodel = Model('ResNet50 backbone', (224,224,3))\nmodel.show()\n\n==========인코더 정보===============\n특징 추출기: ResNet50 backbone\n입력 차원: (224, 224, 3)\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기] ResNet50 backbone\n\n\n\n인코더는 동일하게 설정하되 디코더는 다르게 설정하는 경우가 많다.\n\n\n\n2. 이미지 분류 모델 (자식)\n\n기초적인 이미지 분류 모델은 다음의 두 가지를 포함하는 경우가 많다.\n\n분류기(classifier)\n출력 모양(output shape)\n\n오버라이딩(overriding) 을 이용해 forward() 함수를 재정의 할 수 있다.\n\n\nclass Classifier(Model):\n    def __init__(self, feature_extractor, input_shape, classifier, output_shape):\n        super().__init__(feature_extractor, input_shape)\n        self.classifier = classifier\n        self.output_shape = output_shape\n    \n    def show_classifier(self):\n        print('=======모델 정보=====')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'분류 모델: {self.classifier}')\n        print(f'입력 차원: {self.input_shape}')\n        print(f'출력 차원: {self.output_shape}')\n        \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기] {self.feature_extractor}')\n        print(f'[분류 모델] {self.classifier}')\n\n\nmodel = Classifier(\"ResNet50 backbone\", (256,256,3), \"FC layer\", (10))\nmodel.show_classifier()\n\n=======모델 정보=====\n특징 추출기: ResNet50 backbone\n분류 모델: FC layer\n입력 차원: (256, 256, 3)\n출력 차원: 10\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기] ResNet50 backbone\n[분류 모델] FC layer"
  },
  {
    "objectID": "posts/1_IP2022/2023-05-27-class활용.html#이미지-분할segmentation-모델-자식",
    "href": "posts/1_IP2022/2023-05-27-class활용.html#이미지-분할segmentation-모델-자식",
    "title": "Class 활용",
    "section": "3. 이미지 분할(Segmentation) 모델 (자식)",
    "text": "3. 이미지 분할(Segmentation) 모델 (자식)\n\n기초적인 이미지 분할 모델은 다음의 두 가지를 포함하는 경우가 많다.\n\n디코더(decoder)\n출력 모양(output shape)\n\n오버라이딩(overriding)을 이용해 forward() 함수를 재정의할 수 있다.\n\n\nclass SegmentationModel(Model):\n    def __init__(self, feature_extractor, input_shape, decoder, output_shape):\n        super().__init__(feature_extractor, input_shape)\n        self.decoder = decoder\n        self.output_shape = output_shape\n        \n    def show_segmentation_model(self):\n        print('========모델 정보========')\n        print(f'특징 추출기: {self.feature_extractor}')\n        print(f'디코더: {self.decoder}')\n        print(f'입력 차원: {self.input_shape}')\n        print(f'출력 차원: {self.output_shape}')\n    \n    def forward(self, x):\n        print(f'입력 데이터: {x}')\n        print(f'[특징 추출기]: {self.feature_extractor}')\n        print(f'[디코더]: {self.decoder}')\n\n\nmodel = SegmentationModel('ResNet50 backbone', (256,256,3), 'U-Net', (256,256,3))\n\n\nmodel.show_segmentation_model()\n\n========모델 정보========\n특징 추출기: ResNet50 backbone\n디코더: U-Net\n입력 차원: (256, 256, 3)\n출력 차원: (256, 256, 3)\n\n\n\nmodel.forward(x=None)\n\n입력 데이터: None\n[특징 추출기]: ResNet50 backbone\n[디코더]: U-Net"
  },
  {
    "objectID": "posts/1_IP2022/2022_06_09_2021년_파이썬입문_기말고사_(풀이포함).html",
    "href": "posts/1_IP2022/2022_06_09_2021년_파이썬입문_기말고사_(풀이포함).html",
    "title": "2021 final exam solution",
    "section": "",
    "text": "2021년 1학기 파이썬입문 기말고사 (풀이포함)\nLINK HERE!\n\n# 1. (20점)\nN사에서 게임유저들에게 여름방학 기념이벤트로 진명왕의 집판검이라는 이름의 아이템을 선물했다고 하자. 진명왕의 집판검은 총 5회에 걸쳐서 강화(upgrade)될 수 있데 강화의 성공확률은 10%라고 하자. 강화가 5번성공하면 더 이상 강화가 진행되지 않는다고 하자. (따라서 더 이상 강화시도를 하지 않아도 무방하다) 아래는 이 아이템에 강화를 진행하였을때 각 강화상태를 설명한 예시이다.\n\n\n\n시도횟수\n강화성공여부\n강화상태\n비고\n\n\n\n\n1\n강화실패\n+0 \\(\\to\\) +0\n강화실패로 인하여 강화상태 변화없음\n\n\n2\n강화성공\n+0 \\(\\to\\) +1\n강화성공으로 인한 강화상태 변화\n\n\n3\n강화실패\n+1 \\(\\to\\) +1\n강화실패로 인하여 강화상태 변화없음\n\n\n4\n강화성공\n+1 \\(\\to\\) +2\n강화성공으로 인한 강화상태 변화\n\n\n5\n강화성공\n+2 \\(\\to\\) +3\n강화성공으로 인한 강화상태 변화\n\n\n6\n강화성공\n+3 \\(\\to\\) +4\n강화성공으로 인한 강화상태 변화\n\n\n7\n강화실패\n+4 \\(\\to\\) +4\n강화실패로 인하여 강화상태 변화없음\n\n\n8\n강화성공\n+4 \\(\\to\\) +5\n모든 강화 성공\n\n\n9\n-\n+5 \\(\\to\\) +5\n더 이상 강화시도 하지 않음\n\n\n10\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\n강화는 하루에 한 번씩만 시도할 수 있으며 시도가능한 기간은 7월1일부터 8월31일까지로 한정되어 있다고 하자. 따라서 방학동안 유저들은 총 62번 시도를 할 수 있다. 방학이 끝난이후 100명 유저중 대략 몇명정도 +5 강화상태에 있겠는가? 파이썬을 통한 시뮬레이션을 활용하여 추론하라. (단, +5강화에 성공하지 못한 모든 유저는 반드시 하루에 한번 강화를 시도해야 한다고 가정하자.)\n(풀이1)\n\nimport numpy as np\nnp.random.seed(1)\nsum(np.random.binomial(n=62, p=0.1, size=10000)>=5)/10000\n\n0.7514\n\n\n(풀이2)\n\nclass ExecutionSword():\n    def __init__(self,prob):\n        self.nuser=100000\n        self.prob=prob\n        self.attemptresult=None\n        self.upgradestate=pd.DataFrame({'day0':[0]*self.nuser})\n        self.failstate=pd.DataFrame({'day0':[0]*self.nuser})\n        self.ratio=0\n        self.day=0\n    def addday(self):\n        self.day=self.day+1            \n    def attempt(self):\n        self.attemptresult = np.random.binomial(n=1, p=self.prob, size=self.nuser)\n    def update(self):\n        # 강화상태 업데이트\n        self.upgradestate['day%s' % self.day] = np.minimum(5,self.upgradestate['day%s' % (self.day-1)]+self.attemptresult)\n        # 강화실패누적횟수 업데이트 \n        self.failstate['day%s' % self.day]=self.failstate['day%s' % (self.day-1)]+(self.attemptresult==0)*1\n        # 강화상태==5 or 강화상태==0 일 경우 강화실패누적횟수 초기화 \n        self.failstate['day%s' % self.day][self.upgradestate['day%s' % self.day]== 0]=0\n        self.failstate['day%s' % self.day][self.upgradestate['day%s' % self.day]== 5]=0\n    def reset(self):\n        # 실패횟수 = 2 인것을 찾아 index_ 에 저장 -> index_ 에 해당하는 유저의 강화횟수와 실패횟수를 모두 0으로 초기화 \n        index_= self.failstate['day%s' % self.day]==2\n        self.failstate['day%s' % self.day][index_] = 0\n        self.upgradestate['day%s' % self.day][index_] = 0\n    def arrangeprob(self):\n        self.ratio=sum(self.upgradestate['day%s' % self.day]==5) / self.nuser\n        if self.ratio > 0.5:\n            self.prob = 0.9\n\n\n# 1 \nimport pandas as pd\ns1=ExecutionSword(0.1)\nfor i in range(62):\n    s1.addday()\n    s1.attempt()\n    s1.update()\n\n\nsum(s1.upgradestate.day62==5)/s1.nuser\n\n0.75551\n\n\n\n\n# 2. (70점)\n강화성공확률을 40%로 수정한다. 강화에 누적2회 실패하면 강화상태가 초기화 된다고 하자. (따라서 강화실패 누적횟수를 카운트하는 변수가 필요하다) 단, 강화실패 누적횟수는 누적2회 달성시 0으로 초기화 된다. 또한 강화상태가 +0인 경우는 실패하여도 강화실패 누적횟수가 추가되지 않는다.\n\n\n\n시도횟수\n강화성공여부\n강화상태\n강화실패누적\n비고\n\n\n\n\n1\n강화성공\n+0 \\(\\to\\) +1\n0 \\(\\to\\) 0\n-\n\n\n2\n강화성공\n+1 \\(\\to\\) +2\n0 \\(\\to\\) 0\n-\n\n\n3\n강화실패\n+2 \\(\\to\\) +2\n0 \\(\\to\\) 1\n-\n\n\n4\n강화성공\n+2 \\(\\to\\) +3\n1 \\(\\to\\) 1\n-\n\n\n5\n강화실패\n+3 \\(\\to\\) +0\n1 \\(\\to\\) 0\n강화실패로 누적2회로 인한 초기화\n\n\n6\n강화실패\n+0 \\(\\to\\) +0\n0 \\(\\to\\) 0\n강화실패 누적횟수 증가하지 않음\n\n\n7\n강화성공\n+0 \\(\\to\\) +1\n0 \\(\\to\\) 0\n-\n\n\n8\n강화성공\n+1 \\(\\to\\) +2\n0 \\(\\to\\) 0\n-\n\n\n9\n강화성공\n+2 \\(\\to\\) +3\n0 \\(\\to\\) 0\n-\n\n\n10\n강화성공\n+3 \\(\\to\\) +4\n0 \\(\\to\\) 0\n-\n\n\n11\n강화성공\n+4 \\(\\to\\) +5\n0 \\(\\to\\) 0\n모든 강화 성공\n\n\n12\n-\n+5 \\(\\to\\) +5\n0 \\(\\to\\) 0\n더 이상 강화시도 하지 않음\n\n\n13\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\n(1) 이 경우 62일의 방학뒤에 100명의 유저중 대략 몇명정도 +5 강화상태에 있겠는가? 시뮬레이션을 활용하여 추론하라. (단, +5강화에 성공하지 못한 모든 유저는 반드시 하루에 한번 강화를 시도해야 한다고 가정하자.)\n(2) 31번째 시도 이후 대략 몇명의 유저가 +5 강화상태에 있겠는가?\n\n# 2-1,2 \ns2=ExecutionSword(0.4)\n\n\nfor i in range(62):\n    s2.addday()\n    s2.attempt()\n    s2.update()\n    s2.reset() ## 초기화가 되는 조건이 있으므로 문제1에서 reset함수만 추가하면 된다. \n\n\n# 2-1\nsum(s2.upgradestate.day31==5)/s2.nuser\n\n0.36392\n\n\n\n# 2-2\nsum(s2.upgradestate.day62==5)/s2.nuser\n\n0.61803\n\n\n(3) 100명의 유저중 50명이상의 유저가 +5 강화상태에 도달하는 순간 모든 유저의 강화성공확률을 90%로 증가시킨다고 하자. 62일의 방학뒤에 100명의 유저 중 몇명 정도가 +5 강화상태에 있겠는가?\n\n# 2-3 \ns3=ExecutionSword(0.4)\n\n\nfor i in range(62):\n    s3.addday()\n    s3.attempt()\n    s3.update()\n    s3.reset() ## 초기화가 되는 조건이 있으므로 reset함수 추가\n    s3.arrangeprob() ## 전체유저의 50%가 강화성공하면 강화확률이 조정되는 조건이 있으므로 arragneprob 추가 \n\n\nsum(s3.upgradestate.day62==5)/s3.nuser\n\n0.9993"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class10.html",
    "href": "posts/1_IP2022/2023-02-23-class10.html",
    "title": "class 10단계",
    "section": "",
    "text": "문자열 join, matplotlib, 참조와 에일리어싱\n\n\n\n- 예제\n\n'abcd'\n\n'abcd'\n\n\n\nlst = list('abcd')\nlst\n\n['a', 'b', 'c', 'd']\n\n\n\n['a','b','c','d']를 붙여서 'abcd'로 하고 싶은데?\n\n\n''.join(lst)\n\n'abcd'\n\n\n\na='' # string object\n\n\na?\n\n\nType:        str\nString form: \nLength:      0\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n\na.join? # iterable이 와야함.\n\n\nSignature: a.join(iterable, /)\nDocstring:\nConcatenate any number of strings.\nThe string whose method is called is inserted in between each given string.\nThe result is returned as a new string.\nExample: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\nType:      builtin_function_or_method\n\n\n\n\na.join(lst) # lst도 일단 리스트니까 iterable object\n\n'abcd'\n\n\n\nset(dir(lst)) & {'__iter__' , '__next__'} # iterable object임을 확인\n\n{'__iter__'}\n\n\n- 해설: ''는 string object이고, .join는 string object에 소속된 메서드이다.\n\na = ''\na.join(lst) # join(a,lst) 와 같은 효과\n\n'abcd'\n\n\n- join의 간단한 사용방법\n\n'-'.join(lst)\n\n'a-b-c-d'\n\n\n\n\n\n- 파이썬의 모든것은 객체이다:matplotlib의 다른 사용 (객체지향적 언어로 그림그리기!)\n- 그림오브젝트 생성\n\nimport matplotlib.pyplot as plt\n\n\nfig = plt.figure() # plt라는 모듈안에서 figure()라는 함수 실행\n\n<Figure size 432x288 with 0 Axes>\n\n\n그림오브젝트가 실행되고 fig라는 이름이 붙음\n\nid(fig)\n\n140529470770096\n\n\n\nfig\n\n<Figure size 432x288 with 0 Axes>\n\n\n- 그림오브젝트의 액시즈를 확인 -> 아무것도 없음\n\nfig.axes\n\n[]\n\n\n- (0,0) 자리에 (가로=1, 세로=1) 크기의 액시즈를 넣어보자.\n\nfig.add_axes([0,0,1,1])\n\n<Axes: >\n\n\n\nfig.axes\n\n[<Axes: >]\n\n\n\n아까는 빈 리스트였는데 뭔가 추가되어 있다.\n\n\nfig\n\n\n\n\n- (0,1.2) 위치에 (가로=1,세로=1) 크기의 엑시즈 추가\n\nfig.add_axes([0,1.2, 1,1])\nfig\n\n\n\n\n- (0.5,0.5) 위치에 (가로=1, 세로=1) 크기의 그림 추가\n\nfig.add_axes([0.5,0.5,1,1])\n\n<Axes: >\n\n\n\nfig\n\n\n\n\n- fig의 세번째 엑시즈에 접근\n\na3 = fig.axes[2] # 이것역시 오브젝트임.\na3\n\n<Axes: >\n\n\n\nid(fig.axes[2]) # 어딘가에 저장이 되어있으니까 오브젝트!\n\n140529466106976\n\n\n- 엑시즈의 메소드 중에 plot이 있음 \\(\\to\\) 이것으로 그림을 그려봄.\n\na3.plot([1,2,3],[4,5,3],'--r')\n\n\nfig\n\n\n\n\n- 다시 세번째 축에 접근하여 다른 그림을 그려보자.\n\nfig.axes[-1].plot([1,2,3],[5,4,3],':o')\nfig\n\n\n\n\n- 이제 첫번째 축에 접근하여 새로운 그림을 그려보자.\n\nfig.axes[0].plot([1,2,3],[4,1,4],'--b')\nfig\n\n\n\n\n- 클래스에 대한 이해가 없다면 위와 같은 그림을 그리기도 힘들고 코드를 해석하기도 힘듬\n\n\n\n\n# !conda install -c conda-forge rise -y\n\n- 아래의 코드를 관찰하자.\n\na = [1,2,3]\nb = a\n\n\na, b\n\n([1, 2, 3], [1, 2, 3])\n\n\n\nid(a), id(b)\n\n(140529440320192, 140529440320192)\n\n\n같은 방문 앞에 a라는 포스트잇과, b라는 포스트잇이 같이 붙어있었음.\n\na = a + [4] ## 추가\na,b\n\n([1, 2, 3, 4], [1, 2, 3])\n\n\n\nid(a), id(b) # id 추적 -> a의 id 달라짐.\n\n(140529450518400, 140529440320192)\n\n\n새로운 공간(다른방)에 a라는 포스트잇을 붙인것 (방이 바뀐것)\n- 이제 다시 아래의 코드를 관찰하자.\n\na = [1,2,3]\nb = a\na.append(4)\n\n현재 a,b의 출력결과는?\n\na, b\n\n([1, 2, 3, 4], [1, 2, 3, 4])\n\n\n- 아래의 코드를 다시 살펴보자.\n\na = [1,2,3]\nb = a\na.append(4)\n\na,b라는 변수들은 메모리에 어떻게 저장이 되어있을까?\n상상력을 조금 발휘하면 아래와 같이 여길 수 있다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\n\na = [1,2,3]\n\n\n메모리주소1에 존재하는 방을 a라고 하고, 그 방에 [1,2,3]을 넣는다.\n\n\n아래를 실행하였을 경우\n\n\nb = a\n\n\n메모리주소 38에 존재하는 방을 b라고 하고, 그 방에 a를 넣어야하는데 a는 [1,2,3]이니까 [1,2,3]을 넣는다.\n\n\n아래를 실행하면\n\n\na.append(4)\n\n\n방 a로 가서 [1,2,3]을 [1,2,3,4]로 바꾼다.\n그리고 방 b에는 아무것도 하지 않는다.\n\n- R에서는 맞는 비유인데, 파이썬은 적절하지 않은 비유이다.\n\nid(a)\n\n140529439072192\n\n\n\nid(b)\n\n140529439072192\n\n\n실제로는 a,b가 저장된 메모리 주소가 동일함\n- 파이썬에서는 아래가 더 적절한 비유이다.\n\n메모리는 변수를 담을 방이 여러개 있는 호텔이라고 생각하자.\n아래를 실행하였을 경우\n\n\na = [1,2,3]\n\n\n메모리주소 140529439072192에서 [1,2,3]을 생성한다.\n방 140529439072192의 방문에 a라는 포스트잇을 붙인다.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방중에서 a라는 포스트잇이 붙은 방을 찾아가면 된다.\n\n\n아래를 실행하였을 경우\n\n\nb=a\n\n\na 라는 포스트잇이 있는데, a라는 포스트잇이랑 b라는 포스트잇과 같은 효과를 주도록 한다.\n쉽게말하면, b라는 포스트잇을 방 140529439072192의 방문에 붙인다는 이야기.\n앞으로 [1,2,3]에 접근하기 위해서는 여러 메모리방 중에서 a라는 포스트잇이 붙어있거나, b라는 포스트잇이 붙어있는 방을 찾아가면 된다.\n\n\n아래를 실행하면\n\n\na.append(4)\n\n\na라는 포스트잇이 붙어있는 방으로 가서, 그 내용물 append함수를 써서 4를 추가하라. 즉 내용물 [1,2,3]을 [1,2,3,4]로 바꾸라.\n같은방에 a,b라는 포스트잇이 모두 붙어있음. 따라서 b라는 포스트잇이 붙은 방을 찾아가서 내용물을 열어보면 [1,2,3,4]가 나온다.\n\n- 결론: 파이썬의 모든것은 오브젝트이다. 그리고 모든 오브젝트는 메모리주소 위에 올라간다. 하지만 그 메모리 주소에 붙어있는 포스트잇이 하나라는 보장은 없다."
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class1.html",
    "href": "posts/1_IP2022/2023-02-15-class1.html",
    "title": "class 1단계",
    "section": "",
    "text": "클래스 선언 및 사용 예시\n\n\n\n1. 이미지 자료 불러오기 (PIL 이용)\n2. 클래스 성능 정리\n3. 연습문제\n\n\n\n- 예제1\n\n# 이미지 출력을 위한 패키지 불러오기\nimport requests\nfrom PIL import Image\n\n\nurl= 'https://stat.jbnu.ac.kr/sites/stat/images/intro_about_02.jpg'\n\n\nImage.open(Image.io.BytesIO(requests.get(url).content))\n\n\n\n\n- 예제2\n\nurl1 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true' \n\n\nImage.open(Image.io.BytesIO(requests.get(url1).content))\n\n\n\n\n\nImage.open(Image.io.BytesIO(requests.get(url2).content))\n\n\n\n\n\n\n\nclass STOOOP:\n    title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n                \n\n\n규칙1 : 메소드(=class 안에서 정의된 함수)의 첫번째 인자는 무조건 self\n규칙2 : 메소드에서 class 안에 정의된 변수들 (title, url, end)을 사용하려면 self.변수이름 과 같은 형식으로 쓴다.\n\n즉, self.title, self.url, self.end 와 같은 방식으로 써야한다.\n\n(참고) : 규칙2에서 가끔 self 자리에 STOOOP.title, STOOOP.url, STOOOP.end 와 같이 클래스의 이름을 쓰기도 한다.\n\n\n\n\n\n\n\nschool = STOOOP()\n\n\nschool.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\nkospi = STOOOP()\n\n\nkospi.title = 'KOSPI 하락'\n\n\nkospi.stop()\n\nKOSPI 하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n\n\nschool = STOOOP()\nkospi = STOOOP()\n\n\n함수의 사용법과 비슷하다.\n클래스 이름을 쓰고, 콘텐츠를 구체화하는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. 이때는 STOOOP(입력1, 입력2) 와 같이 생성\n위의 예시는 따로 입력이 없으므로 비워둔 상태이다. 즉, STOOOP() 와 같은 식으로 생성\n\n\n\n\n\nschool.title # 출력\n\n'학교폭력!'\n\n\n\nkospi.title # 출력\n\n'학교폭력!'\n\n\n\nkospi.title = '코스피하락' # 변경\n\n\nkospi.title\n\n'코스피하락'\n\n\n\n\n\n\nschool.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~~\n\n\n\nkospi.stop()\n\n코스피하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 True이다.\n- 클래스에는 show()라는 메소드가 있다. show() 기능은 a의 값을 print하는 기능을 한다.\n\nclass Klass1:\n    a = True # 초기값\n    def show(self):\n        print(self.a)\n\n\nex1 = Klass1()\n\n\nex1.a # 초기값\n\nTrue\n\n\n\nex1.show()\n\nTrue\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 1이다.\n- 클래스에는 up()이라는 메소드가 있다. up()의 기능은 a의 값을 1증가시키는 기능을 한다.\n\nclass Klass2:\n    a = 1 # 초깃값\n    def up(self):\n        self.a = self.a + 1\n\n\nex2 = Klass2()\nex2.a\n\n1\n\n\n\nex2.up()\nex2.a\n\n2\n\n\n\nex2.up()\nex2.a\n\n3\n\n\n\nex2.up()\nex2.a\n\n4\n\n\n\n\n\n- 클래스 내에는 변수 a가 있다. 변수 a의 초기값은 \\(0\\) 이다.\n- 클래스에는 up(), down(), show() 라는 메소드가 있다. 각각은 a의 값을 1증가, a값을 1감소, a의 값을 print하는 기능을 한다.\n\nclass Klass3:\n    a = 0\n    def up(self):\n        self.a  = self.a + 1\n    def down(self):\n        self.a = self.a - 1\n    def show(self):\n        print(self.a)\n\n\nex3 = Klass3()\n\n\nex3.show()\n\n0\n\n\n\nex3.up()\nex3.show()\n\n1\n\n\n\nex3.up()\nex3.up()\nex3.show()\n\n3\n\n\n\nex3.down()\nex3.show()\n\n2\n\n\n\n\n\n- 클래스 내에는 변수 url이 있음. url의 초기값은 다음과 같다. https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true\n- 클래스에는 show() 라는 메소드(클래스 안에 정의된 함수)를 가지는데, 메소드는 아래와 같은 기능을 한다. - 기능1: url의 그림을 출력 - 기능2: ‘당신은 이 그림을 \\(n\\) 번 보았습니다.’ 출력. (여기에서 \\(n\\)은 그림을 본 횟수)\n\nclass Klass4:\n    n = 1 # 초기값\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 그림을 {}번 보았습니다.'.format(self.n))\n        self.n = self.n + 1\n\n\nex4 = Klass4()\nex4.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다.\n\n\n\nex4.show()\n\n\n\n\n당신은 이 그림을 2번 보았습니다.\n\n\n\n# url 변환 (학교 폭력 이미지 말고, SNL 이미지로 출력되게 바꿔보자.)\nex4_1 = Klass4()\nex4_1.url = url2 # SNL image link\n\n\nex4_1.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다.\n\n\n\n\n\n\n- 클래스를 선언하라. [‘가위’, ‘바위’, ‘보’] 중 하나를 골라서 내는 메소드를 정의하라.\n\n# hint\nimport numpy as np\nnp.random.choice(['가위', '바위', '보'])\n\n'가위'\n\n\n\nclass Klass5:\n    def game(self):\n        print(np.random.choice(['가위','바위','보']))\n\n\nex5 = Klass5()\n\n\nex5.game()\n\n보"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-13-pandas0.html",
    "href": "posts/1_IP2022/2023-03-13-pandas0.html",
    "title": "Pandas 0단계",
    "section": "",
    "text": "판다스를 왜 써야할까?, pandas 개발동기\n\n\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\n\n\n- 예제1: 기본인덱싱\n\na = 'asdf'\na[2]\n\n'd'\n\n\n\na[-1]\n\n'f'\n\n\n- 예제2: 슬라이싱\n\na='asdf'\na[1:3]\n\n'sd'\n\n\n- 예제3: 스트라이딩\n\na='asdf'\na[::2] # 1번째, 3번째 원소 출력\n\n'ad'\n\n\n- 예제4: 불가능한 것\n\na = 'asdf'\na[[1,2]] # 정수인덱스를 리스트화 시켜서 인덱싱하는 것을 불가능\n\nTypeError: string indices must be integers\n\n\n\n\n\n- 예제1: 인덱스의 리스트 (혹은 ndarray)를 전달\n\na = np.arange(5)\na,a[[1,2,-1]]\n\n(array([0, 1, 2, 3, 4]), array([1, 2, 4]))\n\n\n\na = np.arange(55,61)\na, a[[1,2,-1]]\n\n(array([55, 56, 57, 58, 59, 60]), array([56, 57, 60]))\n\n\n- 예제2: bool로 이루어진 리스트 (혹은 ndarray)를 전달\n\na[[True, True, False, False, False, False]]\n\narray([55, 56])\n\n\n\na[np.array([True, True, False, False, False, False])] # 꼭 리스트로 전달할 필요는 없음.\n\narray([55, 56])\n\n\n\na[a<58]\n\narray([55, 56, 57])\n\n\n\n\n\n- 예제1\n\na = np.arange(4*3).reshape(4,3)\na\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11]])\n\n\n\na[0:2,1]\n\narray([1, 4])\n\n\n- 예제2: 차원을 유지하면서 인덱싱을 하고 싶으면?\n\na = np.arange(4*3).reshape(4,3)\na[0:2, [1]]\n\narray([[1],\n       [4]])\n\n\n\n\n\n- 예제1: (key, value)o\n\nd = {'att':65, 'rep':45, 'mid':30, 'fin':100}\nd\n\n{'att': 65, 'rep': 45, 'mid': 30, 'fin': 100}\n\n\n\nd['att'] # key를 넣으면 value가 리턴\n\n65\n\n\n- 예제2: numpy와 비교\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,200)\nrep = np.random.choice(np.arange(5,21)*5,200)\nmid = np.random.choice(np.arange(0,21)*5,200)\nfin = np.random.choice(np.arange(0,21)*5,200)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),200,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(200)}\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\ndel(att);del(rep);del(mid);del(fin);del(key)\n\n\n#test_dic\n\n학번 202212460에 해당하는 학생의 출석점수를 알고 싶다면?\n- (풀이1)\n\ntest_dic['202212460']['att'] ## 가독성이 좋음.\n\n55\n\n\n- (풀이2)\n\ntest_ndarray[test_ndarray[:,0] == 202212460, 1] ## 가독성이 떨어짐.\n\narray([55])\n\n\n정보를 뽑을 때 Numpy indexing을 이용하는 것보다 딕셔너리를 이용하고 hash 타입으로 접근하는것이 편리할 때가 많이 있다.\n(풀이2)가 (풀이1)에 비하여 불편한 점\n\ntest_ndarray의 첫칼럼은 student id 이고 두번째 칼럼은 att라는 사실을 암기하고 있어야 한다.\nstudent id가 아니고 만약에 학생이름을 써서 데이터를 정리한다면 모든 자료형은 문자형이 되어야 한다.\n작성한 코드의 가독성이 없다. (위치로 접근하기 때문)\n\n- 요약: hash 스타일로 정보를 추출하는 것이 유용할 때가 있다. 그리고 보통 hash 스타일로 정보를 뽑는 것이 유리하다. (사실 Numpy는 정보추출을 위해 개발된 자료형이 아니라 행렬 및 벡터의 수학연산을 지원하기 위해 개발된 자료형이다.)\n- 소망: 정보를 추출할때는 hash 스타일도 유용하다는 것은 이해함 \\(\\to\\) 하지만 나는 넘파이스타일로 정보를 뽑고 싶은걸? 그리고 딕셔너리 형태가 아니고 엑셀처럼(행렬처럼) 데이터를 보고 싶은걸? \\(\\to\\) pandas의 개발\n\n\n\n\n\n\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\ntest_dic = {key[i] : {'att':att[i], 'rep':rep[i], 'mid':mid[i], 'fin':fin[i]} for i in range(20)}\n\n\ntest_dic\n\n{'202212380': {'att': 65, 'rep': 55, 'mid': 50, 'fin': 40},\n '202212370': {'att': 95, 'rep': 100, 'mid': 50, 'fin': 80},\n '202212363': {'att': 65, 'rep': 90, 'mid': 60, 'fin': 30},\n '202212488': {'att': 55, 'rep': 80, 'mid': 75, 'fin': 80},\n '202212312': {'att': 80, 'rep': 30, 'mid': 30, 'fin': 100},\n '202212377': {'att': 75, 'rep': 40, 'mid': 100, 'fin': 15},\n '202212463': {'att': 65, 'rep': 45, 'mid': 45, 'fin': 90},\n '202212471': {'att': 60, 'rep': 60, 'mid': 25, 'fin': 0},\n '202212400': {'att': 95, 'rep': 65, 'mid': 20, 'fin': 10},\n '202212469': {'att': 90, 'rep': 80, 'mid': 80, 'fin': 20},\n '202212318': {'att': 55, 'rep': 75, 'mid': 35, 'fin': 25},\n '202212432': {'att': 95, 'rep': 95, 'mid': 45, 'fin': 0},\n '202212443': {'att': 95, 'rep': 55, 'mid': 15, 'fin': 35},\n '202212367': {'att': 50, 'rep': 80, 'mid': 40, 'fin': 30},\n '202212458': {'att': 50, 'rep': 55, 'mid': 15, 'fin': 85},\n '202212396': {'att': 95, 'rep': 30, 'mid': 30, 'fin': 95},\n '202212482': {'att': 50, 'rep': 50, 'mid': 45, 'fin': 10},\n '202212452': {'att': 65, 'rep': 55, 'mid': 15, 'fin': 45},\n '202212387': {'att': 70, 'rep': 70, 'mid': 40, 'fin': 35},\n '202212354': {'att': 90, 'rep': 90, 'mid': 80, 'fin': 90}}\n\n\n\n테이블형태로 보고싶다.\n\n(방법1) – 행렬이기는 하지만 방법 2,3,4,5에 비하여 우리가 원하는 만큼 가독성을 주는 형태는 아님.\n\ntest_ndarray = np.array([key,att,rep,mid,fin],dtype=np.int64).T\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n(방법2)\n\npd.DataFrame(test_dic).T\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법3)\n\ntest_dic2 = {'att':{key[i]:att[i] for i in range(20)},\n             'rep':{key[i]:rep[i] for i in range(20)},\n             'mid':{key[i]:mid[i] for i in range(20)},\n             'fin':{key[i]:fin[i] for i in range(20)}}\n\n\npd.DataFrame(test_dic2)\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법4)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin}, index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n(방법5)\n\ndf = pd.DataFrame({'att':att, 'rep':rep, 'mid':mid, 'fin':fin})\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      0\n      65\n      55\n      50\n      40\n    \n    \n      1\n      95\n      100\n      50\n      80\n    \n    \n      2\n      65\n      90\n      60\n      30\n    \n    \n      3\n      55\n      80\n      75\n      80\n    \n    \n      4\n      80\n      30\n      30\n      100\n    \n    \n      5\n      75\n      40\n      100\n      15\n    \n    \n      6\n      65\n      45\n      45\n      90\n    \n    \n      7\n      60\n      60\n      25\n      0\n    \n    \n      8\n      95\n      65\n      20\n      10\n    \n    \n      9\n      90\n      80\n      80\n      20\n    \n    \n      10\n      55\n      75\n      35\n      25\n    \n    \n      11\n      95\n      95\n      45\n      0\n    \n    \n      12\n      95\n      55\n      15\n      35\n    \n    \n      13\n      50\n      80\n      40\n      30\n    \n    \n      14\n      50\n      55\n      15\n      85\n    \n    \n      15\n      95\n      30\n      30\n      95\n    \n    \n      16\n      50\n      50\n      45\n      10\n    \n    \n      17\n      65\n      55\n      15\n      45\n    \n    \n      18\n      70\n      70\n      40\n      35\n    \n    \n      19\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf = df.set_index([key])\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n\n\n- 예제1: 출석점수를 출력\n\ntest_dic2['att']\n\n{'202212380': 65,\n '202212370': 95,\n '202212363': 65,\n '202212488': 55,\n '202212312': 80,\n '202212377': 75,\n '202212463': 65,\n '202212471': 60,\n '202212400': 95,\n '202212469': 90,\n '202212318': 55,\n '202212432': 95,\n '202212443': 95,\n '202212367': 50,\n '202212458': 50,\n '202212396': 95,\n '202212482': 50,\n '202212452': 65,\n '202212387': 70,\n '202212354': 90}\n\n\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 예제2: 학번 202212380의 출석점수 출력\n\ntest_dic2['att']['202212380']\n\n65\n\n\n\ndf['att']['202212380']\n\n65\n\n\n\n\n\n- 예제1: 첫번째 학생의 기말고사 성적을 출력하고 싶다.\n\ntest_ndarray[0,-1]\n\n40\n\n\n\ndf.iloc[0,-1]\n\n40\n\n\n\n벼락치기: df에서 iloc이라는 특수기능을 이용하면 넘파이 인덱싱처럼 원소출력이 가능하다.\n\n- 예제2: 홀수번째 학생의 점수를 뽑고 싶다.\n\ntest_ndarray[::2]\n\narray([[202212380,        65,        55,        50,        40],\n       [202212363,        65,        90,        60,        30],\n       [202212312,        80,        30,        30,       100],\n       [202212463,        65,        45,        45,        90],\n       [202212400,        95,        65,        20,        10],\n       [202212318,        55,        75,        35,        25],\n       [202212443,        95,        55,        15,        35],\n       [202212458,        50,        55,        15,        85],\n       [202212482,        50,        50,        45,        10],\n       [202212387,        70,        70,        40,        35]])\n\n\n\ndf.iloc[::2]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 예제3: 맨 끝에서 3명의 점수를 출력하고 싶다.\n\ntest_ndarray[-3:]\n\narray([[202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ndf.iloc[-3:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 예제4: 맨 끝에서 3명의 점수 중 마지막 2개의 칼럼만 출력하고 싶다.\n\ntest_ndarray[-3:,-2:]\n\narray([[15, 45],\n       [40, 35],\n       [80, 90]])\n\n\n\ndf.iloc[-3:,-2:]\n\n\n\n\n\n  \n    \n      \n      mid\n      fin\n    \n  \n  \n    \n      202212452\n      15\n      45\n    \n    \n      202212387\n      40\n      35\n    \n    \n      202212354\n      80\n      90\n    \n  \n\n\n\n\n\n\n\n- 예제1: 중간고사 점수가 20점 이상이면서 동시에 출석점수가 60점미만인 학생들의 기말고사 점수를 출력\n\ndf.query('mid >= 20 and att < 60')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n  \n\n\n\n\n\ndf.query('mid >= 20 and att < 60')['fin']\n\n202212488    80\n202212318    25\n202212367    30\n202212482    10\nName: fin, dtype: int64\n\n\n(방법2) 넘파이 스타일이라면?\n\ntest_ndarray\n\narray([[202212380,        65,        55,        50,        40],\n       [202212370,        95,       100,        50,        80],\n       [202212363,        65,        90,        60,        30],\n       [202212488,        55,        80,        75,        80],\n       [202212312,        80,        30,        30,       100],\n       [202212377,        75,        40,       100,        15],\n       [202212463,        65,        45,        45,        90],\n       [202212471,        60,        60,        25,         0],\n       [202212400,        95,        65,        20,        10],\n       [202212469,        90,        80,        80,        20],\n       [202212318,        55,        75,        35,        25],\n       [202212432,        95,        95,        45,         0],\n       [202212443,        95,        55,        15,        35],\n       [202212367,        50,        80,        40,        30],\n       [202212458,        50,        55,        15,        85],\n       [202212396,        95,        30,        30,        95],\n       [202212482,        50,        50,        45,        10],\n       [202212452,        65,        55,        15,        45],\n       [202212387,        70,        70,        40,        35],\n       [202212354,        90,        90,        80,        90]])\n\n\n\ntest_ndarray[:,3] >= 20 ## 중간고사가 20점이상\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True,  True, False,\n        True,  True])\n\n\n\ntest_ndarray[:,1] < 60 ## 출석이 60미만 \n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True,  True, False,  True, False,\n       False, False])\n\n\n\n(test_ndarray[:,3] >= 20) & (test_ndarray[:,1] < 60)\n\narray([False, False, False,  True, False, False, False, False, False,\n       False,  True, False, False,  True, False, False,  True, False,\n       False, False])\n\n\n\nnote: test_ndarray[:,3] >= 20 & test_ndarray[:,1] >= 60와 같이 하면 에러가 난다. 조심하자! 괄호!!!\n\n\ntest_ndarray[(test_ndarray[:,3] >= 20) & (test_ndarray[:,1] < 60),-1]\n\narray([80, 25, 30, 10])\n\n\n\n구현난이도 어려움, 가독성 꽝..\n\n- 예제2: 중간고사점수<기말고사점수인 학생들의 출석점수 평균을 구하자.\n\ndf.query('mid < fin')\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\ndf.query('mid < fin')['att'].mean()\n\n76.66666666666667\n\n\n\n\n\n\n\n- 방법1: dictionary에서 만든다.\n\npd.DataFrame({'att':[30,40,50], 'mid':[50,60,70]}"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class2.html",
    "href": "posts/1_IP2022/2023-02-15-class2.html",
    "title": "class 2단계",
    "section": "",
    "text": "__init__\nself의 의미\n파이썬의 비밀1\n파이썬의 비밀2\n\n\n\n\n\n\n# 이미지 출력을 위한 패키지 불러오기\nfrom PIL import Image\nimport requests\n\n\n\n- STOOOP을 다시 복습\n\nurl1 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\nurl2 = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop2.png?raw=true' \n\n\nclass STOOOP:\n    title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~'\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\ns1 = STOOOP() # STOOOP 이라는 클래스에서 s1이라는 인스턴스를 만드는 과정\n\n\ns1.title, s1.url, s1.end\n\n('학교폭력!',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~')\n\n\n\ns1.stop()\n\n학교폭력!\n\n\n\n\n\n멈춰~~~\n\n\n- 왜 s1의 default title이 항상 ‘학교폭력’ 이어야 하는가? \\(\\to\\) __init__ 의 개발\n- 성능4: __init__() 함수를 이용하여 ‘클래스 \\(\\to\\) 인스턴스’ 의 시점에서 수행하는 일련의 동작들을 묶어서 수행할 수 있음.\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n- 잘못된 사용\n\ns1 = STOOOP() # 이 시점에서 __init__ 이 수행된다.\n\nTypeError: __init__() missing 1 required positional argument: 'title'\n\n\n- 올바른 사용\n\ns1 = STOOOP('수강신청매크로') # 이 시점에서 __init__ 이 수행된다!\n\n\ns1.title, s1.url, s1.end\n\n('수강신청매크로',\n 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true',\n '멈춰~~~~')\n\n\n\ns1.stop()\n\n수강신청매크로\n\n\n\n\n\n멈춰~~~~\n\n\n- 잘못된 사용에서 에러가 발생한 이유는?\nTypeError: __init__() missing 1 required positional argument: 'title'\n\ns1 = STOOOP() 이 실행되는 순간 __init__() 이 내부적으로 실행된다.\n그런데 __init__() 의 첫번째 입력인 self는 입력안해도 무방했음. 그런데 두번째 입력은 title은 입력을 해야했음.\n그런데 title을 입력하지 않아서 발생하는 에러.\n\n- __init__(self, arg1, arg2,...) 함수에 대하여\n\n엄청나게 특별해 보이지만 사실 몇가지 특별한 점을 제외하고는 어떠한 마법도 없는 함수이다.\n특별한 점1: 첫번째 입력으로 반드시 self를 넣어야함. (이건 사실 클래스 내의 메소드 거의 다 그러함)\n특별한 점2: 클래스에서 인스턴스를 만드는 시점에 자동으로 실행된다.\n특별한 점3: __init(self, arg1, arg2,...)의 입력중 self 이외의 입력들은 ‘클래스 \\(\\to\\) 인스턴스’ 시점에서 ’인스턴스이름 = 클래스이름(arg1, arg2,…)’와 같이 사용한다. (이 예제의 경우 STOOOP(title) 와 같이 사용해야함)\n\n- title이 디폴트로 들어가는 상황도 불편했지만, title을 명시적으로 넣지 않으면 에러가 발생하는 것도 불편하다?\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title=None):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\ns2 = STOOOP()\ns3 = STOOOP('KOSPI 하락')\n\n\ns2.stop() # title 없는 경우\n\nNone\n\n\n\n\n\n멈춰~~~~\n\n\n\n제목이 없으면 없는대로 잘 출력이 된다.\n\n\ns3.stop() # title = 'KOSPI 하락'\n\nKOSPI 하락\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n- 이전 예제를 복습\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(\"당신은 이 이미지를 {}번 보았습니다\".format(self.n))\n        self.n = self.n+1 \n\n\nk4 = Klass4()\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 2번 보았습니다\n\n\n- 위의 예제는 아래와 같이 구현할 수도 있다.\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 이미지를 {}번 보았습니다.'.format(self.n))\n        # slef.n = self.n + 1\n\n\nk4 = Klass4()\n\n\nk4.n\n\n1\n\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 1번 보았습니다.\n\n\n\nk4.n = k4.n + 1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 2번 보았습니다.\n\n\n\nk4.n = k4.n + 1\n\n\nk4.show()\n\n\n\n\n당신은 이 이미지를 3번 보았습니다.\n\n\n\n결국에는 k4.n = k4.n + 1의 기능을 구현하여 넣은 것이 self.n = self.n + 1 이다.\n따라서 self는 k4에 대응한다. 즉, self는 인스턴스 이름에 대응한다.\n\n우리가 하고 싶은 것은 클래스를 선언하는 시점에서 인스턴스가 생성된 이후 시점에 대한 어떠한 동작들을 정의하고 싶다.\n그런데 클래스가 설계하는 시점에서 인스턴스의 이름이 정해지지 않았으므로 이러한 동작들을 정의하기에 불편하다.\n그래서 클래스를 설계하는 시점에 그 클래스로부터 만들어지는 인스턴스는 그냥 self라는 가칭으로 부른다.\n\n굳이 비유를 하자면 self는 인스턴스의 태명 같은 것이다.\n\n\n요약: self의 의미는 (후에 만들어질 ) 인스턴스의 이름이다. (즉, self는 인스턴스의 태명같은 것!)\n\n\n\n탐구: 인스턴스의 자료형이 무엇인지 탐구해보자.\n- 아래의 두 클래스를 선언해보자.\n\nclass STOOOP:\n    # title = '학교폭력!'\n    url = url1\n    end = '멈춰~~~~'\n    def __init__(self, title=None):\n        self.title = title\n    def stop(self):\n        print(self.title)\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print(self.end)\n\n\nclass Klass4:\n    n = 1\n    url = 'https://github.com/guebin/IP2022/blob/master/_notebooks/2022-05-07-stop1.jpeg?raw=true'\n    def show(self):\n        display(Image.open(Image.io.BytesIO(requests.get(self.url).content)))\n        print('당신은 이 이미지를 {}번 보았습니다.'.format(self.n))\n        # self.n = self.n + 1\n\n- 인스턴스를 생성해보자.\n\nk4 = Klass4()\ns1 = STOOOP()\n\n\n\n\nk4?\n\n\nType:        Klass4\nString form: <__main__.Klass4 object at 0x7fb4956082b0>\nDocstring:   <no docstring>\n\n\n\n\ns1?\n\n\nType:        STOOOP\nString form: <__main__.STOOOP object at 0x7fb495608310>\nDocstring:   <no docstring>\n\n\n\n- ??? 타입은 자료형 즉, int, float, list 이런 것 아니었나?\n\na = [1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n- 그런데 지금 k4, s1의 타입은 Klass4, STOOOP이다.\n\n가설1 : 사실 파이썬 내부에 Klass4, STOOOP이라는 자료형이 있었다. 그런데 내가 만든 k4, s1이 우연히 그 자료형을 따르는 것! (이건 너무 억지스럽다.)\n가설2: type이 list인 것은 사실 list라는 클래스에서 생긴 인스턴스이다. \\(\\to\\) 리스트 자료형을 찍어낼 수 있는 어떤 클래스가 파이썬에 내부적으로 존재할 것이다. (이게 맞는 것 같다.)\n\n꺠달음1\n- 가설2가 맞다? 그렇다면 아래는 모두 어딘가에서 찍혀진 인스턴스이다.\n\na = [1,2,3]\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\na = 1,2,3\na\n\n(1, 2, 3)\n\n\n\na = 1\na?\n\n\nType:        int\nString form: 1\nDocstring:  \nint([x]) -> integer\nint(x, base=10) -> integer\nConvert a number or string to an integer, or return 0 if no arguments\nare given.  If x is a number, return x.__int__().  For floating point\nnumbers, this truncates towards zero.\nIf x is not a number or if base is given, then x must be a string,\nbytes, or bytearray instance representing an integer literal in the\ngiven base.  The literal can be preceded by '+' or '-' and be surrounded\nby whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\nBase 0 means to interpret the base from the string as an integer literal.\n>>> int('0b100', base=0)\n4\n\n\n\n\na = '1'\na?\n\n\nType:        str\nString form: 1\nLength:      1\nDocstring:  \nstr(object='') -> str\nstr(bytes_or_buffer[, encoding[, errors]]) -> str\nCreate a new string object from the given object. If encoding or\nerrors is specified, then the object must expose a data buffer\nthat will be decoded using the given encoding and error handler.\nOtherwise, returns the result of object.__str__() (if defined)\nor repr(object).\nencoding defaults to sys.getdefaultencoding().\nerrors defaults to 'strict'.\n\n\n\n- 그리고 위의 a=[1,2,3] 과 같은 것들은 모두 ‘클래스\\(\\to\\) 인스턴스’ 에 해당하는 과정이었다.\n깨달음2\n- 생각해보니까 아래와 같이 list를 선언하는 방식도 있었음\n\na = list()\na\n\n[]\n\n\n\n이거 지금 생각해보니까 list라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법이다?!\n\n- 아래도 가능함\n\na = list((1,2,3))\na?\n\n\n\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:  \nBuilt-in mutable sequence.\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\n\n\n\n이것도 지금 보니까 list라는 이름의 클래스에서 a라는 인스턴스를 찍어내는 문법이다. 여기에서 (1,2,3)은 __init__() 의 입력이다.\n\n깨달음3\n- 그러고보니까 각 자료형마다 특수한 기능들이 있었음.\n- a. + tab을 하면 append, clear 등등이 나온다.\n- 이러한 기능은 지금까지 우리가 ‘list자료형 특수기능들’ 이라고 부르면서 사용했었다. 그런데 a가 list 클래스에서 생성된 인스턴스라는 관점에서 보면 이러한 기능들은 list 클래스에서 정의된 메소드라고 볼 수 있다.\n깨달음4 - a.f() 는 f(a) 로 해석 가능하다고 하였다. 이 해석에 따르면 메소드의 첫번째 입력은 메소드가 소속된 인스턴스라고 해석할 수 있다.\n- 동일한 논리로 아래의 코드는 stop() 의 입력에서 s1을 넣는다는 의미이다.\n\ns1.stop()\n\nNone\n\n\n\n\n\n멈춰~~~~\n\n\n\n\n\n\n\n아래의 조건에 맞는 클래스를 생성하라.\n\n['가위', '바위'] 와 같은 리스트를 입력으로 받아 인스턴스를 생성한다.\n위의 리스트에서 하나의 값을 뽑는 메소드 f를 가지고 있다.\n\n# 사용예시\na = Klass(['가위', '바위'])\na.f() # 가위가 1/2 바위가 1/2의 확률로 출력\nb = Klass(['가위', '바위', '보'])\nb.f() # 가위, 바위, 보가 1/3의 확률로 출력"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html",
    "href": "posts/1_IP2022/2023-02-23-class7.html",
    "title": "class 7단계",
    "section": "",
    "text": "함수형 프로그래밍, callable object, 파이썬의 비밀"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제1-숫자입력-함수출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제1-숫자입력-함수출력",
    "title": "class 7단계",
    "section": "(예제1) 숫자입력, 함수출력",
    "text": "(예제1) 숫자입력, 함수출력\n\ndef f(a):\n    def _f(x):\n        return (x-a)**2\n    return _f\n\n\ng = f(10) # g(x) = (x-10)**2\n\n\ng(2) # (2-10)**2 = 64\n\n64\n\n\n\n해석: \\(f(a)\\)는 \\(a\\)를 입력으로 받고 \\(g(x)=(x-a)^2\\)를 함수를 리턴해주는 함수"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제1의-다른-표현-익명함수-lambda",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제1의-다른-표현-익명함수-lambda",
    "title": "class 7단계",
    "section": "(예제1)의 다른 표현: 익명함수 lambda",
    "text": "(예제1)의 다른 표현: 익명함수 lambda\n\n표현1\n\ndef f(a):\n    _f = lambda x: (x-a)**2 ### lambda x: (x-a)**2 가 실행되는 순간 함수오브젝트가 만들어지고 그것이 _f 로 저장됨 \n    return _f\n\n\ng = f(10) # g(x) = (x-10)**2\n\n\ng(3)\n\n49\n\n\n\n\n표현2\n\ndef f(a):\n    return lambda x: (x-a)**2\n\n\ng = f(10)\n\n\ng(3)\n\n49\n\n\n\nlambda x: (x-a)**2는 \\(\\text{lambda}(x) = (x-a)^2\\)의 느낌으로 기억하면 외우기 쉽다.\nlambda x: (x-a)**2는 “아직 이름이 없는 함수 오브젝트를 (가칭 lambda라고 하자) 만들고 기능은 x를 입력으로 하고 (x-2)**2를 출력하도록 하자” 라는 뜻으로 해석하면 된다."
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제2-함수입력-숫자출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제2-함수입력-숫자출력",
    "title": "class 7단계",
    "section": "(예제2) 함수입력, 숫자출력",
    "text": "(예제2) 함수입력, 숫자출력\n\ndef f(x):\n    return x**2\n\n\ndef d(f,x): # 함수를 입력을 받는 함수를 정의\n    h=0.000000000001\n    return (f(x+h)-f(x))/h \n\n\\[f'(x)\\approx \\frac{f(x+h)-f(x)}{h}\\]\n\n\\(h\\)의 값이 점점 0에 가까울수록 등호에 가까워짐.\n\n\nd(f,4) # f'(4) = 2*4 = 8\n\n8.000711204658728"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제3-함수입력-함수출력",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제3-함수입력-함수출력",
    "title": "class 7단계",
    "section": "(예제3) 함수입력, 함수출력",
    "text": "(예제3) 함수입력, 함수출력\n\ndef f(x): \n    return x**2 \n\n\ndef derivate(f): \n    def df(x): \n        h=0.000000000001\n        return (f(x+h)-f(x))/h \n    return df\n\n\nff = derivate(f)\n\n\nff(7) # f의 도함수\n\n14.004797321831575\n\n\n원래함수 시각화\n\nx = np.linspace(-1,1,100)\nplt.plot(x,f(x))\n\n\n\n\n도함수 시각화\n\nx = np.linspace(-1,1,100)\nplt.plot(x, ff(x))"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제3의-다른-표현",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제3의-다른-표현",
    "title": "class 7단계",
    "section": "(예제3)의 다른 표현",
    "text": "(예제3)의 다른 표현\n\ndef f(x): \n    return x**2\n\n\ndef derivate(f): \n    h=0.000000000001\n    return lambda x: (f(x+h)-f(x))/h \n\n\nff = derivate(f)\n\n\nff(10)\n\n20.00888343900442"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class7.html#예제4-함수들의-리스트",
    "href": "posts/1_IP2022/2023-02-23-class7.html#예제4-함수들의-리스트",
    "title": "class 7단계",
    "section": "(예제4) 함수들의 리스트",
    "text": "(예제4) 함수들의 리스트\n[오브젝트, 오브젝트, 오브젝트]\n\nflst = [lambda x: x, lambda x: x**2, lambda x: x**3]  # [함수오브젝트,함수오브젝트,함수오브젝트]\nflst # 이것의 타입은 function\n\n[<function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>,\n <function __main__.<lambda>(x)>]\n\n\n\nfor f in flst:\n    print(f(2))\n\n2\n4\n8\n\n\n\n첫번째 함수에 적용될 때는 2출력, 2번째 함수에 적용될 때는 4출력, 3번째 함수에 적용될 때는 8출력\n\n\nfor f in flst:\n    plt.plot(x,f(x),'--')\n\n\n\n\n위의 코드는 아래와 같음.\n\nplt.plot(x, (lambda x: x)(x),'--')\nplt.plot(x, (lambda x: x**2)(x),'--')\nplt.plot(x, (lambda x: x**3)(x),'--')"
  },
  {
    "objectID": "posts/1_IP2022/2023-03-14-pandas2.html",
    "href": "posts/1_IP2022/2023-03-14-pandas2.html",
    "title": "Pandas 2단계",
    "section": "",
    "text": "하나 혹은 여러개의 col\\(\\cdot\\)row 선택하는 법\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\n- 데이터\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nkey = ['202212'+str(s) for s in np.random.choice(np.arange(300,501),20,replace=False)]\n\n\ndf=pd.DataFrame({'att':att,'rep':rep,'mid':mid,'fin':fin},index=key)\ndf\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n    \n      202212377\n      75\n      40\n      100\n      15\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      60\n      25\n      0\n    \n    \n      202212400\n      95\n      65\n      20\n      10\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212318\n      55\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      95\n      45\n      0\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212367\n      50\n      80\n      40\n      30\n    \n    \n      202212458\n      50\n      55\n      15\n      85\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      50\n      45\n      10\n    \n    \n      202212452\n      65\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      90\n      80\n      90\n    \n  \n\n\n\n\n\n\n- 방법1\n\ndf.att\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법2: dict 스타일\n\ndf['att']\n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n\ntype(df['att'])\n\npandas.core.series.Series\n\n\n- 방법3: dict 스타일\n\ndf[['att']]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ntype(df[['att']])\n\npandas.core.frame.DataFrame\n\n\n\ndf.att나 df['att']는 series를 리턴하고 df[['att']]는 dataframe을 리턴한다.\n\n- 방법4: ndarray스타일\n\ndf.iloc[:,0] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n\ntype(df.iloc[:,0] )\n\npandas.core.series.Series\n\n\n- 방법5: ndarray 스타일\n\ndf.iloc[:,[0]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ntype(df.iloc[:,[0]])\n\npandas.core.frame.DataFrame\n\n\n\ndf.iloc[:,0]은 series를 리턴하고 df.iloc[:,[0]]은 dataframe을 리턴한다.\n\n- 방법6: ndarray 스타일과 dict스타일의 혼합\n\ndf.loc[:,'att'] \n\n202212380    65\n202212370    95\n202212363    65\n202212488    55\n202212312    80\n202212377    75\n202212463    65\n202212471    60\n202212400    95\n202212469    90\n202212318    55\n202212432    95\n202212443    95\n202212367    50\n202212458    50\n202212396    95\n202212482    50\n202212452    65\n202212387    70\n202212354    90\nName: att, dtype: int64\n\n\n- 방법7: ndarray 스타일과 dict스타일의 혼합\n\ndf.loc[:,['att']] \n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\ndf.loc[:,'att']은 series를 리턴하고 df.loc[:,['att']] 은 dataframe을 리턴한다.\n\n- 방법7: ndarray 스타일 + bool 인덱싱\n\ndf.iloc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n- 방법8: ndarray와 dict의 혼합형 + bool 인덱싱\n\ndf.loc[:,[True,False,False,False]]\n\n\n\n\n\n  \n    \n      \n      att\n    \n  \n  \n    \n      202212380\n      65\n    \n    \n      202212370\n      95\n    \n    \n      202212363\n      65\n    \n    \n      202212488\n      55\n    \n    \n      202212312\n      80\n    \n    \n      202212377\n      75\n    \n    \n      202212463\n      65\n    \n    \n      202212471\n      60\n    \n    \n      202212400\n      95\n    \n    \n      202212469\n      90\n    \n    \n      202212318\n      55\n    \n    \n      202212432\n      95\n    \n    \n      202212443\n      95\n    \n    \n      202212367\n      50\n    \n    \n      202212458\n      50\n    \n    \n      202212396\n      95\n    \n    \n      202212482\n      50\n    \n    \n      202212452\n      65\n    \n    \n      202212387\n      70\n    \n    \n      202212354\n      90\n    \n  \n\n\n\n\n\n\n\n- 방법1: dict 스타일\n\ndf[['att','fin']]\n\n\n\n\n\n  \n    \n      \n      att\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      40\n    \n    \n      202212370\n      95\n      80\n    \n    \n      202212363\n      65\n      30\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      100\n    \n    \n      202212377\n      75\n      15\n    \n    \n      202212463\n      65\n      90\n    \n    \n      202212471\n      60\n      0\n    \n    \n      202212400\n      95\n      10\n    \n    \n      202212469\n      90\n      20\n    \n    \n      202212318\n      55\n      25\n    \n    \n      202212432\n      95\n      0\n    \n    \n      202212443\n      95\n      35\n    \n    \n      202212367\n      50\n      30\n    \n    \n      202212458\n      50\n      85\n    \n    \n      202212396\n      95\n      95\n    \n    \n      202212482\n      50\n      10\n    \n    \n      202212452\n      65\n      45\n    \n    \n      202212387\n      70\n      35\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n- 방법2: ndarray 스타일 (정수리스트로 인덱싱, 슬라이싱, 스트라이딩)\n\ndf.iloc[:,[0,1]] # 정수의 리스트를 전달하여 컬럼추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,range(2)] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,:2]  # 슬라이싱 , 0,1,2에서 마지막 2는 제외되고 0,1에 해당하는 것만 추출\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n    \n  \n  \n    \n      202212380\n      65\n      55\n    \n    \n      202212370\n      95\n      100\n    \n    \n      202212363\n      65\n      90\n    \n    \n      202212488\n      55\n      80\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      40\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      60\n    \n    \n      202212400\n      95\n      65\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      75\n    \n    \n      202212432\n      95\n      95\n    \n    \n      202212443\n      95\n      55\n    \n    \n      202212367\n      50\n      80\n    \n    \n      202212458\n      50\n      55\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      50\n    \n    \n      202212452\n      65\n      55\n    \n    \n      202212387\n      70\n      70\n    \n    \n      202212354\n      90\n      90\n    \n  \n\n\n\n\n\ndf.iloc[:,::2]  # 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n- 방법3: ndarray와 dict의 혼합형\n\ndf.loc[:,['att','mid']] \n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,'att':'mid']  # 마지막의 mid도 포함된다. \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n    \n    \n      202212370\n      95\n      100\n      50\n    \n    \n      202212363\n      65\n      90\n      60\n    \n    \n      202212488\n      55\n      80\n      75\n    \n    \n      202212312\n      80\n      30\n      30\n    \n    \n      202212377\n      75\n      40\n      100\n    \n    \n      202212463\n      65\n      45\n      45\n    \n    \n      202212471\n      60\n      60\n      25\n    \n    \n      202212400\n      95\n      65\n      20\n    \n    \n      202212469\n      90\n      80\n      80\n    \n    \n      202212318\n      55\n      75\n      35\n    \n    \n      202212432\n      95\n      95\n      45\n    \n    \n      202212443\n      95\n      55\n      15\n    \n    \n      202212367\n      50\n      80\n      40\n    \n    \n      202212458\n      50\n      55\n      15\n    \n    \n      202212396\n      95\n      30\n      30\n    \n    \n      202212482\n      50\n      50\n      45\n    \n    \n      202212452\n      65\n      55\n      15\n    \n    \n      202212387\n      70\n      70\n      40\n    \n    \n      202212354\n      90\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,'rep':] \n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212370\n      100\n      50\n      80\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212312\n      30\n      30\n      100\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212400\n      65\n      20\n      10\n    \n    \n      202212469\n      80\n      80\n      20\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212432\n      95\n      45\n      0\n    \n    \n      202212443\n      55\n      15\n      35\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212396\n      30\n      30\n      95\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n    \n      202212354\n      90\n      80\n      90\n    \n  \n\n\n\n\n- 방법4: bool을 이용한 인덱싱\n\ndf.iloc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\ndf.loc[:,[True,False,True,False]]\n\n\n\n\n\n  \n    \n      \n      att\n      mid\n    \n  \n  \n    \n      202212380\n      65\n      50\n    \n    \n      202212370\n      95\n      50\n    \n    \n      202212363\n      65\n      60\n    \n    \n      202212488\n      55\n      75\n    \n    \n      202212312\n      80\n      30\n    \n    \n      202212377\n      75\n      100\n    \n    \n      202212463\n      65\n      45\n    \n    \n      202212471\n      60\n      25\n    \n    \n      202212400\n      95\n      20\n    \n    \n      202212469\n      90\n      80\n    \n    \n      202212318\n      55\n      35\n    \n    \n      202212432\n      95\n      45\n    \n    \n      202212443\n      95\n      15\n    \n    \n      202212367\n      50\n      40\n    \n    \n      202212458\n      50\n      15\n    \n    \n      202212396\n      95\n      30\n    \n    \n      202212482\n      50\n      45\n    \n    \n      202212452\n      65\n      15\n    \n    \n      202212387\n      70\n      40\n    \n    \n      202212354\n      90\n      80\n    \n  \n\n\n\n\n\n\n\n- 방법1\n\ndf.iloc[0]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.iloc[0])\n\npandas.core.series.Series\n\n\n- 방법2\n\ndf.iloc[[0]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.iloc[[0]])\n\npandas.core.frame.DataFrame\n\n\n- 방법3\n\ndf.iloc[0,:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.iloc[0,:])\n\npandas.core.series.Series\n\n\n- 방법4\n\ndf.iloc[[0],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.iloc[[0],:])\n\npandas.core.frame.DataFrame\n\n\n- 방법5\n\ndf.loc['202212380']\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.loc['202212380'])\n\npandas.core.series.Series\n\n\n- 방법6\n\ndf.loc[['202212380']]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.loc[['202212380']])\n\npandas.core.frame.DataFrame\n\n\n- 방법7\n\ndf.loc['202212380',:]\n\natt    65\nrep    55\nmid    50\nfin    40\nName: 202212380, dtype: int64\n\n\n\ntype(df.loc['202212380',:])\n\npandas.core.series.Series\n\n\n- 방법8\n\ndf.loc[['202212380'],:]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ntype(df.loc[['202212380'],:])\n\npandas.core.frame.DataFrame\n\n\n- 방법9\n\nlen(df)\n\n20\n\n\n\n_lst = [True]+[False]*19\n\n\ndf.iloc[_lst] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.iloc[_lst,:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\ndf.loc[_lst,:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n  \n\n\n\n\n\n\n\n- 방법1\n\ndf.iloc[[0,2]]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.iloc[[0,2],:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 방법2\n\ndf.loc[['202212380','202212363']] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n\ndf.loc[['202212380','202212363'],:] \n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n  \n\n\n\n\n- 그 밖의 방법들\n\ndf.iloc[::3] # 스트라이딩\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212463\n      65\n      45\n      45\n      90\n    \n    \n      202212469\n      90\n      80\n      80\n      20\n    \n    \n      202212443\n      95\n      55\n      15\n      35\n    \n    \n      202212396\n      95\n      30\n      30\n      95\n    \n    \n      202212387\n      70\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.iloc[:5]\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.loc[:'202212312']\n\n\n\n\n\n  \n    \n      \n      att\n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      65\n      55\n      50\n      40\n    \n    \n      202212370\n      95\n      100\n      50\n      80\n    \n    \n      202212363\n      65\n      90\n      60\n      30\n    \n    \n      202212488\n      55\n      80\n      75\n      80\n    \n    \n      202212312\n      80\n      30\n      30\n      100\n    \n  \n\n\n\n\n\ndf.loc[list(df.att<80),'rep':]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.loc[df.att<80,'rep':]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n\ndf.iloc[list(df.att<80),1:]\n\n\n\n\n\n  \n    \n      \n      rep\n      mid\n      fin\n    \n  \n  \n    \n      202212380\n      55\n      50\n      40\n    \n    \n      202212363\n      90\n      60\n      30\n    \n    \n      202212488\n      80\n      75\n      80\n    \n    \n      202212377\n      40\n      100\n      15\n    \n    \n      202212463\n      45\n      45\n      90\n    \n    \n      202212471\n      60\n      25\n      0\n    \n    \n      202212318\n      75\n      35\n      25\n    \n    \n      202212367\n      80\n      40\n      30\n    \n    \n      202212458\n      55\n      15\n      85\n    \n    \n      202212482\n      50\n      45\n      10\n    \n    \n      202212452\n      55\n      15\n      45\n    \n    \n      202212387\n      70\n      40\n      35\n    \n  \n\n\n\n\n- 아래는 에러가 난다 주의!\n\ndf.iloc[df.att<80, 1:]\n\nValueError: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-15-class4.html",
    "href": "posts/1_IP2022/2023-02-15-class4.html",
    "title": "class 4단계",
    "section": "",
    "text": "프린트 가로채기 __str__, __repr__ (파이썬의 비밀2,3)\n\n\n\n\n\nmotivating example\n__str__, 파이썬의 비밀2\n__repr__, 파이썬의 비밀3\n주피터 노트북의 비밀 (_repr_html_), __repr__와 __str__의 우선적용 순위\n\n\n\n\n\n\nimport numpy as np\n\n\n\n\n\n\n\n\n\n# class1 hw's review\nclass RPC:\n    def throw(self):\n        print(np.random.choice(['가위','바위','보']))\n\n\na = RPC()\n\n\na.throw()\n\n가위\n\n\n\n\n\n[가위, 바위, 보] 말고 [가위, 보] 혹은 [바위, 보] 처럼 정해진 케이스가 아닌 입력으로 받고 싶을 수도 있다.\n\nclass RPC:\n    def throw(self, candidate):\n        print(np.random.choice(candidate))\n\n\na = RPC()\n\n\n# throw(a, ['가위','바위','보'])\na.throw(['가위','바위','보'])\n\n보\n\n\n\na.throw(['가위', '보']) # 보, 가위만.\n\n가위\n\n\n\n\n\n\nclass RPC:\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def throw(self):\n        print(np.random.choice(self.candidate))\n\n\na = RPC() # __init__ 는 암묵적으로 실행\n\n\na.throw()\n\n보\n\n\n\n\n\n위의 코드 3줄과 동일한 코드이며, 풀어써보면 다음과 같다.\n\nclass RPC2:\n    pass\n\n\nb = RPC2() # 아무것도 없음..\n\n\ndef initt(b, candidate = ['가위','바위','보']):\n    b.candidate = candidate\n\n\ninitt(b)\n\n\n# 던져서 화면에 보여주는 과정까지 추가\ndef throw(b):\n    print(np.random.choice(b.candidate))\n\n\nthrow(b)\n\n보\n\n\n\n\n\n풀어쓴 코드를 조합해보면?\n\nclass RPC2:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n    def throw(self):\n        print(np.random.choice(self.candidate))\n\n\nb = RPC2()\n\n\nb.candidate\n\n['가위', '바위', '보']\n\n\n\nb.throw()\n\n가위\n\n\n\n\n\n생각해보니까 throw는 choose + show의 결합인 것 같다.\n\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def choose(self):\n        self.actions = np.random.choice(self.candidate)\n    def show(self):\n        print(self.actions)\n\n\na = RPC()  ## 시점2\n\n\na.actions ## 시점3 (지금은 정의되지 않음, choose를 해야함)\n\nAttributeError: 'RPC' object has no attribute 'actions'\n\n\n\na.choose() # 뭔가 선택했겠지?    ## 시점4\n\n\na.actions # 바위를 선택했구만     ## 시점5 \n\n'바위'\n\n\n\na.show()   ## 시점6\n\n바위\n\n\n\n\n\n위와 같은 코드입니다.\n\nclass _RPC:  ## 시점1 \n    pass  # <-- 이렇게하면 아무 기능이 없는 비어있는 클래스가 정의된다.\n\n\n_a  = _RPC()  ## 시점2\n\ndef _init(_a, candidate = ['가위','바위','보']):\n    _a.candidate = candidate\n    \n_init(_a)\n\n\n_a.actions ## 시점3\n\nAttributeError: '_RPC' object has no attribute 'actions'\n\n\n\n# choose 선언      ## 시점4\ndef _choose(_a):\n    _a.actions = np.random.choice(_a.candidate)\n_choose(_a)\n\n\n_a.actions  ## 시점5\n\n'바위'\n\n\n\n# show 선언    ## 시점6\ndef _show(_a):\n    print(_a.actions)\n_show(_a)\n\n바위\n\n\n\n\n\n\n또 다른 인스턴스 b를 만들자. b는 가위만 낼 수 있다.\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n    def choose(self):\n        self.actions = np.random.choice(self.candidate)\n    def show(self):\n        print(self.actions)\n        \n\nb = RPC()\n\n\nb.candidate\n\n['가위', '바위', '보']\n\n\n\n아무것도 없으면 b의 candidate이 가위, 가위, 보로 들어감\n\n\nb = RPC(['가위']) # 가위만 포함된 리스트 전달\n\n\nb.candidate\n\n['가위']\n\n\n\nb.choose()\nb.show()\n\n가위\n\n\n- a, b의 선택들을 모아서 기록하고 싶다.\n\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n        self.actions = list() ## 추가\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate)) ## 추가\n    def show(self):\n        print(self.actions)\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nnp.random.seed(123)\nfor i in range(5):\n    a.choose()\n    a.show()\n\n['보']\n['보', '바위']\n['보', '바위', '보']\n['보', '바위', '보', '보']\n['보', '바위', '보', '보', '가위']\n\n\n\nshow() 지난 히스토리까지 다 나오니까 보기 좀 불편하댜\n\n\nnp.random.seed(123)\nclass RPC: ## 시점1\n    def __init__(self, candidate = ['가위', '바위', '보']):\n        self.candidate = candidate\n        self.actions = list() ## 추가\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate)) ## 추가\n    def show(self):\n        print(self.actions[-1]) ### 추추가\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n바위\n보\n보\n가위\n\n\n\na.actions\n\n['보', '바위', '보', '보', '가위']\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\nb.actions\n\n['가위', '가위', '가위', '가위', '가위']\n\n\n\na.candidate, a.actions # (낼 수 있는 패, 내가 낸 패)\n\n(['가위', '바위', '보'], ['보', '바위', '보', '보', '가위'])\n\n\n\nb.candidate, b.actions # (낼 수 있는 패, 내가 낸 패)\n\n(['가위'], ['가위', '가위', '가위', '가위', '가위'])\n\n\n- info라는 함수를 만들어서 a의 오브젝트가 가지고 있는 정보를 모두 보도록 하자.\n(예비학습) 문자열 \\n 이 포함된다면?\n\n'클래스\\n어렵네..'\n\n'클래스\\n어렵네..'\n\n\n\nprint('클래스\\n어렵네..')\n\n클래스\n어렵네..\n\n\n예비학습 끝\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])      \n    def info(self):\n        print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\nb = RPC(['가위'])\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n바위\n가위\n보\n가위\n바위\n\n\n\nfor i in range(5):\n    b.choose()\n    b.show()\n\n가위\n가위\n가위\n가위\n가위\n\n\n\na.info()\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위', '가위', '보', '가위', '바위']\n\n\n\nb.info()\n\n낼 수 있는 패: ['가위']\n기록: ['가위', '가위', '가위', '가위', '가위']\n\n\n- 만들고보니까 info와 print의 기능이 거의 비슷함 \\(\\to\\) print(a)를 하면 a.info()와 동일한 효과를 내도록 만들 수 있을까?\n- 말도 안되는 소리같다. 왜? - 안될것 같은 이유1: print는 파이썬 내장기능, 내장기능을 우리가 맘대로 커스터마이징해서 쓰기는 어려울 것 같다. - 안될 것 같은 이유2: 이유1이 해결된다 해도 문제다. 그럼 지금까지 우리가 사용했던 수 많은 print()의 결과는 어떻게 되는가?\n결론은 가능하다\n- 그런데 a의 자료형(RPC 자료형)에 해당하는 오브젝트에 한정하여 print를 수정하는 방법이 가능하다면? (그럼 다른 오브젝트들은 수정된 print에 영향을 받지 않음)\n\n\n\n\n- 관찰1: 현재 print(a)의 결과는 아래와 같다.\n\nprint(a)\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n\na는 RPC클래스에서 만든 오브젝트이며 a가 저장된 메모리 주소는 0x7faaa7500850라는 의미\n\n- 관찰2: a에는 __str__ 이 있다.\n\ndir(a)\n\n['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n 'actions',\n 'candidate',\n 'choose',\n 'info',\n 'show']\n\n\n\nset(dir(a)) & {'__str__'}\n\n{'__str__'}\n\n\n이것을 함수처럼 사용하니까 아래와 같다.\n\na.__str__\n\n<method-wrapper '__str__' of RPC object at 0x7faaa7500850>\n\n\n\na.__str__() # 클래스 안에 있는 메소드, 문자열 리턴\n\n'<__main__.RPC object at 0x7faaa7500850>'\n\n\n\nprint(a.__str__()) # 이거 print(a)를 실행한 결과와 같다?\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n\nprint(a)\n\n<__main__.RPC object at 0x7faaa7500850>\n\n\n- 생각: 만약에 내가 a.__str__() 라는 함수를 재정의 하여 리턴값을 ’너는 해킹당했다’로 바꾸게 되면 print(a)해서 나오는 결과는 어떻게 될까? (약간 해커같죠)\n(예비학습) 함수 덮어씌우기\n\ndef f():\n    print('asdf')\n\n\nf()\n\nasdf\n\n\n\ndef f():\n    print('guebin hahaha')\n\n\nf()\n\nguebin hahaha\n\n\n이런식으로 함수가 이미 정의되어 있더라도, 내가 나중에 덮어씌우면 그 함수의 기능을 다시 정의한다.\n(해킹시작)\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return '너는 해킹당했다'\n    def info(self):\n        print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\nprint(a)\n\n너는 해킹당했다\n\n\n- __str__ 의 리턴값을 info에서 타이핑했던 문자열로 재정의한다면?\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    # def info(self):\n    #     print('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n    def __str__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.choose()\na.show()\n\n바위\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위']\n\n\n\na.choose()\na.show()\n\n가위\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['바위', '가위']\n\n\n\n\n- print(a) 와 print(a.__str__()) 는 같은 문법이다.\n- 참고로 a.__str__() 와 str(a) 도 같은 방법이다.\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['바위', '가위']\"\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: ['바위', '가위']\"\n\n\n- 지금까지 우리가 썼던 기능을 확인!\n(예제1)\n\na = [1,2,3]\n\n\nprint(a)\n\n[1, 2, 3]\n\n\n\na.__str__()\n\n'[1, 2, 3]'\n\n\n\nstr(a)\n\n'[1, 2, 3]'\n\n\n(예제2)\n\na = {1,2,3}\nprint(a)\n\n{1, 2, 3}\n\n\n\nstr(a)\n\n'{1, 2, 3}'\n\n\n\na.__str__()\n\n'{1, 2, 3}'\n\n\n(예제3)\n\na = np.array(1)\na.shape\n\n()\n\n\n\ntype(a.shape)\n\ntuple\n\n\n\nprint(a.shape)\n\n()\n\n\n\na.shape.__str__()\n\n'()'\n\n\n\nstr(a.shape)\n\n'()'\n\n\n(예제4)\n\na = range(10)\nprint(a)\n\nrange(0, 10)\n\n\n\na.__str__()\n\n'range(0, 10)'\n\n\n(예제5)\n\na = np.arange(100).reshape(10,10)\nprint(a)\n\n[[ 0  1  2  3  4  5  6  7  8  9]\n [10 11 12 13 14 15 16 17 18 19]\n [20 21 22 23 24 25 26 27 28 29]\n [30 31 32 33 34 35 36 37 38 39]\n [40 41 42 43 44 45 46 47 48 49]\n [50 51 52 53 54 55 56 57 58 59]\n [60 61 62 63 64 65 66 67 68 69]\n [70 71 72 73 74 75 76 77 78 79]\n [80 81 82 83 84 85 86 87 88 89]\n [90 91 92 93 94 95 96 97 98 99]]\n\n\n\na.__str__()\n\n'[[ 0  1  2  3  4  5  6  7  8  9]\\n [10 11 12 13 14 15 16 17 18 19]\\n [20 21 22 23 24 25 26 27 28 29]\\n [30 31 32 33 34 35 36 37 38 39]\\n [40 41 42 43 44 45 46 47 48 49]\\n [50 51 52 53 54 55 56 57 58 59]\\n [60 61 62 63 64 65 66 67 68 69]\\n [70 71 72 73 74 75 76 77 78 79]\\n [80 81 82 83 84 85 86 87 88 89]\\n [90 91 92 93 94 95 96 97 98 99]]'\n\n\n\n\n\n\n- 생각해보니까 print를 써서 우리가 원하는 정보를 확인하는건 아니였음\n\na = [1,2,3]\n\n\na\n\n[1, 2, 3]\n\n\n\nprint(a) # print(a.__str__()) + enter ==> a + enter\n\n[1, 2, 3]\n\n\n-`` a + 엔터를 하면 print(a) + 엔터를 하는 것과 같은 효과인가?\n(반례)\n\na = np.array([1,2,3,4]).reshape(2,2)\n\n\na\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nprint(a)\n\n[[1 2]\n [3 4]]\n\n\n- a + 엔터 는 print(a) + 엔터 가 다른 경우도 있다. \\(\\to\\) 추측: 서로 다른 숨겨진 기능이 있다! \\(\\to\\) 결론: 그 기능은 __repr__ 에 저장되어 있음.\n\n__repr__ 추가 전\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\na\n\n<__main__.RPC at 0x7faaa6d821c0>\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\n__repr__ 추가 후\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return('낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions))\n\n\na = RPC()\n\n\na # print(a.__repr__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- 그럼 우리가 지금까지 했던 것?\n\na = np.array([1,2,3])\n\n\na\n\narray([1, 2, 3])\n\n\n\nprint(a)\n\n[1 2 3]\n\n\n\na.__repr__()\n\n'array([1, 2, 3])'\n\n\n\na.__str__()\n\n'[1 2 3]'\n\n\n\n\n- 대화형콘솔에서 오브젝트이름 + 엔터를 쳐서 나오는 출력은 __repr__의 결과와 연관이 있다.\n\na = np.array(range(10000)).reshape(100,100)\na\n\narray([[   0,    1,    2, ...,   97,   98,   99],\n       [ 100,  101,  102, ...,  197,  198,  199],\n       [ 200,  201,  202, ...,  297,  298,  299],\n       ...,\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])\n\n\n\na.__repr__()\n\n'array([[   0,    1,    2, ...,   97,   98,   99],\\n       [ 100,  101,  102, ...,  197,  198,  199],\\n       [ 200,  201,  202, ...,  297,  298,  299],\\n       ...,\\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])'\n\n\n- 참고로 a.__repr__()은 repr(a)와 같다.\n\nrepr(a)\n\n'array([[   0,    1,    2, ...,   97,   98,   99],\\n       [ 100,  101,  102, ...,  197,  198,  199],\\n       [ 200,  201,  202, ...,  297,  298,  299],\\n       ...,\\n       [9700, 9701, 9702, ..., 9797, 9798, 9799],\\n       [9800, 9801, 9802, ..., 9897, 9898, 9899],\\n       [9900, 9901, 9902, ..., 9997, 9998, 9999]])'\n\n\n\n\n\n- 요즘에는 IDE 발전에 따라서 오브젝트 + 엔터 칠 때 나오는 출력의 형태도 다양해지고 있음.\n\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,2,3],\n                   'b':[2,3,4]})\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n예쁘게 나온다.\n\n- 위의 결과는 print(df.__repr__())의 결과와 조금 다르게 나온다?\n\nprint(df.__repr__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n- print(df.__repr__())는 예전 검은화면에서 코딩할 때 나오는 출력임\nPython 3.10.2 | packaged by conda-forge | (main, Feb  1 2022, 19:28:35) [GCC 9.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n> >> import pandas as pd \n>>> df = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})>>> df\n   a  b\n0  1  2\n1  2  3\n2  3  4\n>>>\n- 주피터에서는 ‘오브젝트이름 + 엔터’ 치면 HTML(df.__repr_html())이 실행되고 repr_html_()이 정의되어 있지 않으면 print(df.__rept__())이 실행된다.\n\ndf._repr_html_()\n\n'<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>a</th>\\n      <th>b</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>1</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>2</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>3</td>\\n      <td>4</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>'\n\n\n\nhtml 코드!\n\n\nfrom IPython.core.display import HTML\n\n\nHTML(df._repr_html_())\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n- 물론 df._repr_html_()함수가 내부적으로 있어도 html이 지원되지 않는 환경이라면 print(df.__repr__())이 내부적으로 수행된다.\n\n\n\n\n(예제1)\n- 아래의 예제를 관찰하자.\n\nclass RPS:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPS()\na\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__repr__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nrepr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n- 여기까지는 상식수준의 결과임. 이제 아래를 관찰하라.\n\nprint(a) # print(a.__repr__())\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\nstr(a)\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\n__str__()은 건드린적이 없는데?\n\n\na.__repr__??\n\n\nSignature: a.__repr__()\nDocstring: Return repr(self).\nSource:   \n    def __repr__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\nFile:      ~/Dropbox/Quarto-Blog/posts/Python/<ipython-input-296-bcd76efb6380>\nType:      method\n\n\n\n\na.__str__??\n\n\nSignature:      a.__str__()\nCall signature: a.__str__(*args, **kwargs)\nType:           method-wrapper\nString form:    <method-wrapper '__str__' of RPS object at 0x7faaa47aae20>\nDocstring:      Return str(self).\n\n\n\n\n__str__()은 건드린 적이 없는데 \\(\\to\\) 건드린적은 없는데 기능이 바뀌어있음.\n\n(예제2)\n- 아래의 예제를 관찰하자.\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n\na.__str__()\n\n\"낼 수 있는 패: ['가위', '바위', '보']\\n기록: []\"\n\n\n\na.__repr__()\n\n'<__main__.RPC object at 0x7f8f38ca22e0>'\n\n\n\na.__str__??\n\n\nSignature: a.__str__()\nDocstring: Return str(self).\nSource:   \n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\nFile:      ~/Dropbox/Quarto-Blog/posts/Python/<ipython-input-3-2e46ee18321f>\nType:      method\n\n\n\n\na.__repr__??\n\n\nSignature:      a.__repr__()\nCall signature: a.__repr__(*args, **kwargs)\nType:           method-wrapper\nString form:    <method-wrapper '__repr__' of RPC object at 0x7f8f38ca22e0>\nDocstring:      Return repr(self).\n\n\n\n2번째 예제에서는 건드린 애만 바뀌었는데 첫번째 예제에서는 건드리지 않은 애들까지 기능이 바뀌었다.\n(예제3)\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def __repr__(self):\n        return '너는 해킹당했다. 하하하'\n    def __str__(self):\n        return '낼 수 있는 패: {}\\n기록: {}'.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\na\n\n너는 해킹당했다. 하하하\n\n\n\nprint(a)\n\n낼 수 있는 패: ['가위', '바위', '보']\n기록: []\n\n\n- __str__ 와 __repr__을 건드리지 않고 출력결과를 바꾸고 싶다면?\n\nclass RPC:\n    def __init__(self, candidate = ['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions)\n\n\na = RPC()\n\n\nstr(a)\n\n'<__main__.RPC object at 0x7f8f38bb7730>'\n\n\n\nrepr(a)\n\n'<__main__.RPC object at 0x7f8f38bb7730>'\n\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: []\n        \n\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n바위\n가위\n바위\n보\n\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['보', '바위', '가위', '바위', '보']\n        \n\n\n\n\n\n아래의 클래스를 수정하여\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(self.candidate,self.actions)\n클래스에서 생성된 인스턴스의 출력결과가 아래와 같도록 하라.\n학번: 202143052 \n낼 수 있는 패: ['가위', '바위', '보']\n기록: ['가위', '가위', '보', '보', '바위']\n\nclass RPS: \n    def __init__(self,candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list() \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def show(self):\n        print(self.actions[-1])\n    def _repr_html_(self):\n        html_str = \"\"\"\n        학번: {} <br/>\n        낼 수 있는 패: {} <br/> \n        기록: {}\n        \"\"\"\n        return html_str.format(202143052,self.candidate,self.actions)\n\n\na = RPS()\n\n\na\n\n\n        학번: 202143052 \n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: []\n        \n\n\n\nfor i in range(5):\n    a.choose()\n    a.show()\n\n보\n가위\n바위\n바위\n가위\n\n\n\na\n\n\n        학번: 202143052 \n        낼 수 있는 패: ['가위', '바위', '보']  \n        기록: ['보', '가위', '바위', '바위', '가위']"
  },
  {
    "objectID": "posts/1_IP2022/2022-06-13-final.html",
    "href": "posts/1_IP2022/2022-06-13-final.html",
    "title": "2022 final exam",
    "section": "",
    "text": "ref: 기말고사 풀이 링크\n\n\n\n아래코드를 이용하여 numpy, matplotlib, pandas를 import하라.\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nfrom IPython.display import HTML\n\n\n\n\n(1) 도함수를 구하는 함수 derivate를 선언하라. 이 함수를 이용하여 \\(f(x)=x^2\\)의 그래프와 \\(f'(x)=2x\\)의 그래프를 \\(x \\in (-1,1)\\)의 범위에서 그려라.\n\ndef f(x):\n    return x**2\n\n\ndef derivate(f): \n    def df(x): \n        h=0.00000000000001\n        return (f(x+h)-f(x))/h \n    return df\n\n\nx = np.linspace(-1,1,100)\nplt.plot(x, f(x))  ## f(x)=x**2\nplt.plot(x, derivate(f)(x)) ## f'(x)=2*x\n\n\n\n\n(2) 적당한 클래스 정의하여 인스턴스 a를 만들고 print(a)의 출력결과가 본인의 학번이 나오도록 하라.\n## 코드예시\nclass Klass:\n    ???\n    ???\na=Klass()\nprint(a)\n## 출력결과\n2022-43052\n\nclass Klass:\n    def __str__(self):\n        return('12345678')\n\n\na = Klass()\n\n\nprint(a)\n\n12345678\n\n\n(3) for문이 실행될때마다 [묵,찌,빠] 중에 하나를 내며 빠를 누적 3회 낼경우 for문이 멈추는 이터레이터를 생성하라.\n(나의풀이)\n\nclass Klass: # 빠를 누적 3회 낼 경우 for문이 멈추는 이터레이터를 만들자.\n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n        self.n = 0\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        if action == '빠':\n            self.n += 1\n            print(action,self.n)\n            if self.n == 3:\n                print('빠가 누적3회 나와서 for문을 멈춥니다.')\n                raise StopIteration\n            else:\n                return action\n        else:\n            return action\n\n\na = Klass()\n\n\nfor i in a:\n    print(i)\n\n찌\n찌\n묵\n찌\n찌\n묵\n빠 1\n빠\n찌\n빠 2\n빠\n빠 3\n빠가 누적3회 나와서 for문을 멈춥니다.\n\n\n(모범답안)\n\nclass Klass: \n    def __init__(self):\n        self.candidate = ['묵','찌','빠']\n        self.dic = {'묵':0,'찌':0,'빠':0}\n    def __iter__(self):\n        return self\n    def __next__(self):\n        action = np.random.choice(self.candidate)\n        self.dic[action] += 1\n        if self.dic['빠'] == 3:\n            print('빠가 3번 누적되어 for문을 멈춥니다.')\n            raise StopIteration\n        else:\n            return action\n\n\na = Klass()\nfor i in a:\n    print(i)\n\n묵\n빠\n찌\n찌\n빠\n빠가 3번 누적되어 for문을 멈춥니다.\n\n\n(4)-(6)\nclass GS25: \n    n=0 \n    total_number_of_guests = 0 \n    def __init__(self):\n        self.number_of_guests = 0 \n(4) 위의 클래스를 수정하여 아래와 같이 GS25에서 새로운 인스턴스가 생성될때마다\nGS25의 점포수가 ?개로 늘었습니다.\n라는 메시지가 출력되도록 하라.\n(5) 함수 come를 인스턴스 메소드로 정의하라. 이 메소드가 실행될때마다 각 점포의 손님 인스턴스 변수 number_of_guests와 클래스변수 total_number_of_guests를 1씩 증가시키고 아래의 메시지를 출력하라.\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 n명입니다. \n현재 GS25 점포를 방문한 손님수는 m명입니다. \n(6) 새로운 클래스메서드 show를 만들고 아래와 같은 메시지를 출력하도록 하라.\nGS25의 점포수: ??\nGS25를 방문한 총 손님수: ??\n(사용예시) (4)-(6)을 모두 적용한 경우 사용예시는 아래와 같다.\n\nclass GS25:\n    n = 0\n    total_numer_of_guests = 0\n    def __init__(self):\n        self.number_of_guests = 0\n        GS25.n += 1\n        print('GS25의 점포수가 {}개로 늘었습니다.'.format(GS25.n))\n    def come(self):\n        GS25.total_number_of_guests += 1\n        self.number_of_guests += 1\n        print('새로운 손님이 오셨습니다.')\n        print('GS25를 방문한 총 손님 수는 {}명입니다.'.format(GS25.total_number_of_guests))\n        print('현재 GS25 점포를 방문한 손님수는 {}명입니다.'.format(self.number_of_guests))\n    @classmethod\n    def show(cls):\n        print('GS25의 점포수:{}'.format(cls.n))\n        print('GS를 방문한 총 손님 수: {}'.format(cls.total_number_of_guests))\n\n\na = GS25()\n\nGS25의 점포수가 5개로 늘었습니다.\n\n\n\na=GS25() ## (4)의 사용예시\n\nGS25의 점포수가 1개로 늘었습니다.\n\n\n\nb=GS25() ## (4)의 사용예시\n\nGS25의 점포수가 2개로 늘었습니다.\n\n\n\na.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 1명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다. \n\n\n\na.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 2명입니다.\n현재 GS25 점포를 방문한 손님수는 2명입니다. \n\n\n\nb.come() ## (5)의 사용예시\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 모든 손님수는 3명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다. \n\n\n\nGS25.show() ## (6)의 사용예시\n\nGS25의 점포수: 2\nGS25를 방문한 총 손님수: 3\n\n\n(풀이시작)\n\nclass GS25: \n    n=0 \n    total_number_of_guests = 0 \n    def __init__(self):\n        self.number_of_guests = 0\n        GS25.n += 1\n        print('GS25의 점포수가 {}개로 늘었습니다.'.format(GS25.n))\n    def come(self):\n        self.number_of_guests += 1\n        GS25.total_number_of_guests += 1\n        print('새로운 손님이 오셨습니다!')\n        print('GS25를 방문한 총 손님수는 {}명입니다.'.format(GS25.total_number_of_guests))\n        print('현재 GS25 점포를 방문한 손님수는 {}명입니다.'.format(self.number_of_guests))\n    @classmethod\n    def show(cls):\n        print('GS25의 점포수: {}'.format(cls.n))\n        print('GS25를 방문한 총 손님수: {}'.format(cls.total_number_of_guests))\n\n\na = GS25()\n\nGS25의 점포수가 1개로 늘었습니다.\n\n\n\nb = GS25()\n\nGS25의 점포수가 2개로 늘었습니다.\n\n\n\na.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 1명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다.\n\n\n\na.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 2명입니다.\n현재 GS25 점포를 방문한 손님수는 2명입니다.\n\n\n\nb.come()\n\n새로운 손님이 오셨습니다!\nGS25를 방문한 총 손님수는 3명입니다.\n현재 GS25 점포를 방문한 손님수는 1명입니다.\n\n\n\nGS25.show()\n\nGS25의 점포수: 2\nGS25를 방문한 총 손님수: 3\n\n\n(7) __eq__는 연산 == 를 재정의하는 메소드이다. 클래스 RPS_BASE를 상속하여 새로운 클래스 RPS5를 만들라. 연산 ==를 재정의하여 RPS5의 두 인스턴스의 action이 같은 경우 true를 리턴하는 기능을 구현하라.\n\nclass RPS_BASE:\n    def __init__(self):\n        self.action = np.random.choice(['가위','바위','보'])\n\nhint: Appendix를 참고할 것\nhint: RPS5의 선언부분은 아래와 같은 형태를 가지고 있다.\nclass RPS5(???):\n    def __eq__(self,other):\n        return ??????\nhint: RPS5클래스의 사용예시는 아래와 같다.\n\na=RPS5()\na.action\n\n'바위'\n\n\n\nb=RPS5()\nb.action\n\n'보'\n\n\n\na==b\n\nFalse\n\n\n(풀이시작)\n(8) __gt__는 연산 > 를 재정의하는 메소드이다. 클래스 RPS_BASE를 상속하여 새로운 클래스 RPS6를 만들라. 연산 >를 재정의하여 RPS6의 두 인스턴스 a,b의 action이 각각 (‘가위’,‘보’), (‘바위’,‘가위’), (‘보’,‘바위’) 인 경우 true를 리턴하는 기능을 구현하라.\nhint: Appendix를 참고할 것\nhint: RPS6클래스의 사용예시는 아래와 같다.\n\na=RPS6()\na.action\n\n'바위'\n\n\n\nb=RPS6()\nb.action\n\n'보'\n\n\n\na>b, a<b\n\n(False, True)\n\n\n(9)-(10)\n아래와 같은 데이터프레임을 선언하고 물음에 답하라.\n\nnp.random.seed(43052)\ndf=pd.DataFrame({'type':np.random.choice(['A','B'],100), 'score':np.random.randint(40,95,100)})\ndf\n\n\n\n\n\n  \n    \n      \n      type\n      score\n    \n  \n  \n    \n      0\n      B\n      45\n    \n    \n      1\n      A\n      40\n    \n    \n      2\n      B\n      79\n    \n    \n      3\n      B\n      46\n    \n    \n      4\n      B\n      57\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      B\n      69\n    \n    \n      96\n      A\n      71\n    \n    \n      97\n      A\n      93\n    \n    \n      98\n      A\n      63\n    \n    \n      99\n      A\n      82\n    \n  \n\n100 rows × 2 columns\n\n\n\n(9) type==’A’의 평균score를 구하는 코드를 작성하라.\n(10) type==’A’의 평균score보다 같거나 큰 값을 가지는 행을 출력하라.\n\n\n\n(1) 플레이어A는 (가위,가위) 중 하나를 선택할 수 있고 플레이어B는 (가위,바위) 중 하나를 선택할 수 있다. 각 플레이어는 각 패 중 하나를 랜덤으로 선택하는 액션을 한다고 가정하자. 아래에 해당하는 확률을 시뮬레이션을 이용하여 추정하라.\n\n플레이어A가 승리할 확률:\n플레이어B가 승리할 확률:\n플레이어A와 플레이어B가 비길 확률:\n\nhint: 50% 확률로 b가 승리하고 50% 확률로 비긴다.\n(2) 문제 (1)과 같이 아래의 상황을 가정하자.\n\n\n\n\n플레이어A\n플레이어B\n\n\n\n\n각 플레이어가 낼 수 있는 패 (candidate)\n(가위,가위)\n(가위,바위)\n\n\n각 패를 선택할 확률 (prob)\n(0.5,0.5)\n(0.5,0.5)\n\n\n\n각 플레이어는 아래와 같은 규칙으로 가위바위보 결과에 따른 보상점수를 적립한다고 하자. - 승리: 보상점수 2점 적립 - 무승부: 보상점수 1점 적립 - 패배: 보상점수 0점 적립\n100번째 대결까지 시뮬레이션을 시행하고 플레이어B가 가위를 낼 경우 얻은 보상점수의 총합과 바위를 낼 경우 얻은 보상점수의 총합을 각각 구하라. 플레이어B는 가위를 내는것이 유리한가? 바위를 내는것이 유리한가?\nhint: 플레이어B는 바위를 내는 것이 유리하다.\nhint: 플레이어B가 100번중에 49번 가위를 내고 51번 바위를 낸다면 플레이어B가 적립할 보상점수는 각각 아래와 같다. - 가위를 내었을 경우: 49 * 1 = 49점 - 바위를 내었을 경우: 51 * 2 = 102점 - 총 보상점수 = 49점 + 102점 = 151점\n(3) (2)에서 얻은 데이터를 학습하여 플레이어B가 “가위” 혹은 “바위” 를 선택할 확률을 매시점 조금씩 조정한다고 가정하자. 구체적으로는 현재시점까지 얻은 보상점수의 비율로 확률을 결정한다. 예를들어 플레이어B가 100회의 대결동안 누적한 보상점수의 총합이 아래와 같다고 하자.\n\n가위를 내었을 경우 보상점수 총합 = 50점\n바위를 내었을 경우 보상점수 총합 = 100점\n\n그렇다면 플레이어B는 각각 (50/150,100/150) 의 확률로 (가위,바위) 중 하나를 선택한다. 101번째 대결에 플레이어B가 가위를 내서 비겼다면 이후에는 (51/151,100/151) 의 확률로 (가위,바위) 중 하나를 선택한다. 102번째 대결에 플레이어B가 바위를 내서 이겼다면 이후에는 각각 (51/153,102/153) 의 확률로 (가위,바위) 중 하나를 선택한다. 이러한 상황을 요약하여 표로 정리하면 아래와 같다.\n\n\n\n\n\n\n\n\n\n시점\n플레이어B가 가위를 냈을 경우 얻은 점수 총합\n플레이어B가 바위를 냈을 경우 얻은 점수 총합\nt+1시점에서 플레이어B가 (가위,바위)를 낼 확률\n\n\n\n\nt=100\n50\n100\n(50/150, 100/150)\n\n\nt=101\n51\n100\n(51/151, 100/151)\n\n\nt=102\n51\n102\n(51/153, 102/153)\n\n\n\n이러한 방식으로 500회까지 게임을 진행하며 확률을 수정하였을 경우 501번째 대결에서 플레이어B가 (가위,바위)를 낼 확률은 각각 얼마인가?\nhint: 시간이 지날수록 플레이어B는 (가위,바위)중 바위를 내는 쪽이 유리하다는 것을 알게 될 것이다.\n\n앞으로 아래와 같은 용어를 사용한다. - (정의) 어떠한 플레이어가 양손 중 하나를 선택하는 확률을 데이터를 바탕으로 매 순간 업데이트 한다면 그 플레이어는 “학습모드 상태이다”고 표현한다. - (정의) 반대로 어떠한 플레이어가 양손 중 하나를 항상 동일한 확률로 낸다면 그 플레이어는 “학습모드 상태가 아니다”라고 표현한다.\n\n(4) 새로운 두명의 플레이어C와 플레이어D를 만들어라. 두 플레이어는 모두 동일하게 (가위,바위) 중 하나를 선택할 수 있다. 두 명의 플레이어는 100번째 대결까지는 두 가지 패중 하나를 랜덤하게 선택하고 101번째 대결부터 500번째 대결까지는 문제(3)의 플레이어B와 같은 방식으로 확률을 업데이트 하여 두 가지 패를 서로 다른 확률로 낸다고 하자. 즉 100번째 대결까지는 두 플레이어가 모두 학습모드 상태가 아니고 101번째부터 500번째 대결까지는 두 플레이어가 모두 학습모드 상태이다. 500번째 대결까지의 학습이 끝났을 경우 플레이어 C와 플레이어D가 각 패를 낼 확률은 각각 얼마인가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어C가 (가위,바위)를 낼 확률\n플레이어D가 (가위,바위)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n대결 데이터를 학습하여 수정한 확률\n대결 데이터를 학습하여 수정한 확률\n양쪽 플레이어 모두 학습모드임\n\n\n\nhint: 시간이 지날수록 두 플레이어 모두 바위를 내는 쪽이 유리하다는 것을 알게 될 것이다.\n(5) 새로운 플레이어 E와 F를 생각하자. 플레이어E와 플레이어F는 각각 (가위,바위) 그리고 (가위,보) 중 하나를 선택할 수 있다고 가정하자. 시뮬레이션 대결결과를 이용하여 아래의 확률을 근사적으로 추정하라.\n\n플레이어E가 승리할 확률:\n플레이어F가 승리할 확률:\n플레이어E와 플레이어F가 비길 확률:\n\nhint: 플레이어E가 가위를 낸다면 최소한 지지는 않기 때문에 플레이어E가 좀 더 유리한 패를 가지고 있다. 따라서 플레이어E의 결과가 더 좋을 것이다.\n(6) (5)와 동일한 두 명의 플레이어E, F를 생각하자. 두 플레이어는 100회까지는 랜덤으로 자신의 패를 선택한다. 그리고 101회부터 500회까지는 플레이어F만 데이터로 부터 학습을 하여 수정된 확률을 사용한다. 500번의 대결이 끝나고 플레이어F가 (가위,보)를 선택하는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\n\nhint: 플레이어F는 보를 내는 것이 낫다고 생각할 것이다. (가위를 내면 지거나 비기지만 보를 내면 지거나 이긴다.)\n(7) (6)번의 플레이어E와 플레이어F가 500회~1000회까지 추가로 게임을 한다. 이번에는 플레이어E만 데이터로부터 학습한다. 1000회까지 대결을 끝낸 이후 플레이어E가 (가위,바위)를 내는 확률은 어떻게 업데이트 되었는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\nt=500시점에 업데이트된 확률\n플레이어E는 학습모드 / 플레이어F는 학습모드아님\n\n\n\nhint: 플레이어F는 보를 내도록 학습되어 있다. 따라서 플레이어E가 바위를 내면 지고 가위를 내면 이길것이다. 따라서 플레이어E는 가위가 유리하다고 생각할 것이다.\n(8) (7)번의 플레이어E와 플레이어F가 1000회~30000회까지 추가로 게임을 한다. 이번에는 플레이어F만 데이터로부터 학습한다. 30000회까지 대결을 끝낸 이후 플레이어F가 (가위,보)를 내는 확률은 어떻게 업데이트 되었는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(1/2, 1/2)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 500\n(1/2, 1/2)\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\nt=500시점에 업데이트된 확률\n플레이어E는 학습모드 / 플레이어F는 학습모드아님\n\n\nt <= 30000\nt=1000시점에 업데이트된 확률\n데이터를 학습하여 수정한 확률\n플레이어E는 학습모드아님 / 플레이어F는 학습모드\n\n\n\nhint: 플레이어F는 원래 보가 유리하다고 생각하여 보를 자주 내도록 학습되었다. 하지만 플레이어E가 그러한 플레이어F의 성향을 파악하고 가위를 주로 내도록 학습하였다. 플레이어F는 그러한 플레이어E의 성향을 다시 파악하여 이번에는 가위을 자주 내는 것이 유리하다고 생각할 것이다.\n(9) 플레이어E와 플레이어F의 대결기록을 초기화 한다. 이번에는 플레이어F가 항상 (3/4)의 확률로 가위를 (1/4)의 확률로 보를 낸다고 가정한다. 플레이어E는 100번의 대결까지는 랜덤으로 (가위,바위)중 하나를 내고 101번째 대결부터 1000번째 대결까지는 대결 데이터를 학습하여 수정한 확률을 사용한다고 하자. 1000번째 대결이후에 플레이어E가 (가위,바위)를 내는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(3/4, 1/4)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\n(3/4, 1/4)\n플레이어E는 학습모드 / 플레이어F는 학습모드 아님\n\n\n\n(10) 플레이어E와 플레이어F의 대결기록을 초기화 한다. 이번에는 플레이어F가 항상 (2/3)의 확률로 가위를 (1/3)의 확률로 보를 낸다고 가정한다. 플레이어E는 100번의 대결까지는 랜덤으로 (가위,바위)중 하나를 내고 101번째 대결부터 1000번째 대결까지는 대결 데이터를 학습하여 수정한 확률을 사용한다고 하자. 1000번째 대결이후에 플레이어E가 (가위,바위)를 내는 확률이 어떻게 업데이트 되어있는가?\n\n\n\n\n\n\n\n\n\n시점\n플레이어E가 (가위,바위)를 낼 확률\n플레이어F가 (가위,보)를 낼 확률\n비고\n\n\n\n\nt <= 100\n(1/2, 1/2)\n(2/3, 1/3)\n양쪽 플레이어 모두 학습모드가 아님\n\n\nt <= 1000\n데이터를 학습하여 수정한 확률\n(2/3, 1/3)\n플레이어E는 학습모드 / 플레이어F는 학습모드 아님\n\n\n\n\n\n\n- 아래의 클래스를 참고하여 문제1,2을 풀어라. (5월25일 강의노트에 소개된 클래스를 약간 정리한 것) - 참고하지 않아도 감점은 없음\n\nclass RPS:\n    def __init__(self,candidate):\n        self.candidate = candidate\n        self.actions = list() \n        self.rewards = list()\n        self.prob = [0.5,0.5]\n\n    def __eq__(self,other): # 연산 == 를 재정의 \n        return self.actions[-1] == other.actions[-1] \n        #note: 둘의 액션이 같으면 무승부 \n    \n    def __gt__(self,other): # 연산 > 를 재정의 \n        pair = self.actions[-1], other.actions[-1]\n        return pair == ('가위','보') or pair == ('바위','가위') or pair == ('보','바위') \n        #note: 가위>보, 바위>가위, 보>가위 \n    \n    def __mul__(self,other):\n        # step1: 각자의 패를 선택 \n        self.choose()\n        other.choose()\n        \n        # step2: 승패 판단 + upate reward\n        if self == other: # 무승부일경우 \n            self.rewards.append(1)\n            other.rewards.append(1)\n        elif self > other: # self의 승리 \n            self.rewards.append(2)\n            other.rewards.append(0)\n        else: # other의 승리 \n            self.rewards.append(0)\n            other.rewards.append(2)\n        \n        # step3: update data\n        self.update_data()\n        other.update_data()\n    \n    def update_data(self):\n        self.data = pd.DataFrame({'actions':self.actions, 'rewards':self.rewards})\n    \n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/> \n        데이터: <br/>\n        {}\n        \"\"\"        \n        return html_str.format(self.candidate,self.data._repr_html_())\n    \n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate,p=self.prob))\n\n- 사용예시\n\na=RPS(['가위','가위'])\nb=RPS(['가위','보'])\n\n\nfor i in range(5):\n    a*b\n\n\na\n\n\n\n        낼 수 있는 패: ['가위', '가위']  \n        데이터: \n        \n\n\n  \n    \n      \n      actions\n      rewards\n    \n  \n  \n    \n      0\n      가위\n      2\n    \n    \n      1\n      가위\n      2\n    \n    \n      2\n      가위\n      1\n    \n    \n      3\n      가위\n      2\n    \n    \n      4\n      가위\n      2\n    \n  \n\n\n        \n\n\n\nb\n\n\n\n        낼 수 있는 패: ['가위', '보']  \n        데이터: \n        \n\n\n  \n    \n      \n      actions\n      rewards\n    \n  \n  \n    \n      0\n      보\n      0\n    \n    \n      1\n      보\n      0\n    \n    \n      2\n      가위\n      1\n    \n    \n      3\n      보\n      0\n    \n    \n      4\n      보\n      0"
  },
  {
    "objectID": "posts/1_IP2022/2023-02-23-class5.html",
    "href": "posts/1_IP2022/2023-02-23-class5.html",
    "title": "class 5단계",
    "section": "",
    "text": "특정 자료형에 한정하여 print 이외에 파이썬 내부기능을 재정의해보자.\n\n- 지난시간까지 배운 것: RPC자료형에 한정해서 print() 등의 기능을 조작할 수 있었다. (재정의 할 수 있었다.)\n- 이번시간에 배울 것: 특정 자료형에 한정하여 print 이외에 파이썬 내부기능을 조작하여 보자. (재정의하여 보자.)\n\nimport numpy as np\n\n\n\n- 아래의 연산구조를 관찰하자.\n\na = 1\nb = 2\n\n\na?? # a는 int class에서 만들어진 인스턴스다.\n\n\nType:        int\nString form: 1\nDocstring:  \nint([x]) -> integer\nint(x, base=10) -> integer\nConvert a number or string to an integer, or return 0 if no arguments\nare given.  If x is a number, return x.__int__().  For floating point\nnumbers, this truncates towards zero.\nIf x is not a number or if base is given, then x must be a string,\nbytes, or bytearray instance representing an integer literal in the\ngiven base.  The literal can be preceded by '+' or '-' and be surrounded\nby whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\nBase 0 means to interpret the base from the string as an integer literal.\n>>> int('0b100', base=0)\n4\n\n\n\n\na + b\n\n3\n\n\n\na라는 인스턴스와 b라는 인스턴스를 +라는 기호가 연결하고 있다.\n\n- 이번에는 아래의 연산구조를 관찰하자.\n\na = [1,2]\nb = [3,4]\na+b\n\n[1, 2, 3, 4]\n\n\n\na라는 인스턴스와 b라는 인스턴스를 +라는 기호가 연결하고 있다.\n\n- 동작이 다른 이유?\n\n클래스를 배우기 이전: int자료형의 +는 “정수의 덧셈”을 의미하고 list자료형의 +는 “자료의 추가”를 의미한다.\n클래스를 배운 이후: 아마 클래스는 + 라는 연산을 정의하는 숨겨진 메소드가 있을 것이다. (print가 그랬듯이) 그런데 int 클래스에서는 그 메소드를 “정수의 덧셈”이 되도록 정의하였고, list클래스에서는 그 메소드를 “자료의 추가”를 의마하도록 정의하였을 것이다.\n\n- 아래의 결과를 관찰\n\na = 1\nb = 2\n\n\nset(dir(a)) & {'__add__'}\n\n{'__add__'}\n\n\n\na.__add__(b)\n\n3\n\n\n\nb.__add__(a)\n\n3\n\n\n\na = [1,2]\nb = [3,4]\n\n\na.__add__(b)\n\n[1, 2, 3, 4]\n\n\n\nb.__add__(a)\n\n[3, 4, 1, 2]\n\n\n- a+b는 사실 내부적으로 a.__add(b)의 축약구문이다. 따라서 만약 a.__add__(b)의 기능을 바꾸면 (재정의 하면) a+b의 기능도 바뀔 것이다.\n\n\n- 학생예제\n\nclass Student: # student class를 만들어보자. (student 자료형인것.)\n    def __init__(self, age = 20.0, semester = 0):\n        self.age = age\n        self.semester = semester\n        print('입학을 축하합니다. 당신의 나이는 {}이고 현재 학기는 {}학기입니다.'.format(self.age, self.semester))\n    def __add__(self, val):\n        # val == 0: 휴학\n        # val == 1: 등록\n        if val == 0:\n            self.age = self.age + 0.5\n        elif val == 1:\n            self.age = self.age + 0.5\n            self.semester = self.semester + 1\n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {} <br/>\n        학기: {} <br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기입니다.\n\n\n\niu\n\n\n        나이: 20.0 \n        학기: 0 \n        \n\n\n\niu + 1 ## 1학년 1학기 등록\niu\n\n\n        나이: 20.5 \n        학기: 1 \n        \n\n\n\niu + 0 ## 휴학함\niu\n\n\n        나이: 21.0 \n        학기: 1 \n        \n\n\n\niu.__add__(1)\n\n\niu\n\n\n        나이: 21.5 \n        학기: 2 \n        \n\n\n- 연산을 연속으로 하고 싶다.\n\niu + 1 + 0 + 0 + 0 + 0\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러의 이유?\n(되는코드)\n\n(1+1)+1 # 1+1+1은 이렇게 볼 수 있다.\n\n3\n\n\n\n_a = (1+1)\ntype(_a)\n\nint\n\n\n\n_a+1 # 이 연산은 int 인스턴스 + int인스턴스\n\n3\n\n\n(안되는코드)\n\niu + 1 + 1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n\n_a = iu + 1\ntype(_a)\n\nNoneType\n\n\n\n_a + 1\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n\n\n- 에러를 해결하는 방법: iu + 1의 결과로 Student클래스가 리턴되면 된다.\n\nclass Student: # student class를 만들어보자. (student 자료형인것.)\n    def __init__(self, age = 20.0, semester = 0):\n        self.age = age\n        self.semester = semester\n        print('입학을 축하합니다. 당신의 나이는 {}이고 현재 학기는 {}학기입니다.'.format(self.age, self.semester))\n    def __add__(self, val):\n        # val == 0: 휴학\n        # val == 1: 등록\n        if val == 0:\n            self.age = self.age + 0.5\n        elif val == 1:\n            self.age = self.age + 0.5\n            self.semester = self.semester + 1\n        return self\n    def _repr_html_(self):\n        html_str = \"\"\"\n        나이: {} <br/>\n        학기: {} <br/>\n        \"\"\"\n        return html_str.format(self.age, self.semester)\n\n\niu = Student()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기입니다.\n\n\n\niu+1  # __add__의 return에 Student 클래스의 인스턴스가 리턴되면서 자동으로 _repr_html_() 실행\n\n\n        나이: 20.5 \n        학기: 1 \n        \n\n\n\niu + 1 + 0 + 0 + 0 + 0\n\n\n        나이: 23.0 \n        학기: 2 \n        \n\n\n\n\n\n\na = 1\nb = 0\na*b\n\n0\n\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n        self.results = list()\n    def __mul__(self, other):\n        self.choose()\n        other.choose()\n        if self.actions[-1] == '가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '가위' and other.actions[-1]=='보':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='가위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='바위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '바위' and other.actions[-1]=='보':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '보' and other.actions[-1]=='보':\n            self.results.append(0)\n            other.results.append(0)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions, self.results)\n\n\na = RPC()\nb = RPC()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\na*b\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: ['보'] \n        승패: [-1]\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        액션: ['가위'] \n        승패: [1]\n        \n\n\n\nfor i in range(50000):\n    a*b\n\n\n#a\n\n\n#b\n\n\nsum(a.results), sum(b.results)\n\n(175, -175)\n\n\n\nsum(a.results)/50000\n\n0.0035\n\n\n\nsum(b.results)/50000\n\n-0.0035\n\n\n\n\n\n\nRPC클래스에서 Player a와 Player b를 만들어라. - Player a는 [‘가위’,‘보’] 중에 하나를 낼 수 있다. - 그리고 Player b는 [‘가위’,‘바위’] 중에 하나를 낼 수 있다. - 두 Player는 가지고 있는 패를 (같은 확률로) 랜덤으로 낸다. (즉, Player a가 가위만 내거나 보만 내는 경우는 없다.)\n\n누가 더 유리한가? 이유를 스스로 생각해보라.\n\n\n비슷하지 않을까?\n\n\n50000번을 시뮬레이션을 해보고 결과를 분석해보라.\n\n\nclass RPC:\n    def __init__(self, candidate=['가위','바위','보']):\n        self.candidate = candidate\n        self.actions = list()\n        self.results = list()\n    def __mul__(self, other):\n        self.choose()\n        other.choose()\n        if self.actions[-1] == '가위' and other.actions[-1]=='가위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '가위' and other.actions[-1]=='바위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '가위' and other.actions[-1]=='보':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='가위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '바위' and other.actions[-1]=='바위':\n            self.results.append(0)\n            other.results.append(0)\n        if self.actions[-1] == '바위' and other.actions[-1]=='보':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='가위':\n            self.results.append(-1)\n            other.results.append(1)\n        if self.actions[-1] == '보' and other.actions[-1]=='바위':\n            self.results.append(1)\n            other.results.append(-1)\n        if self.actions[-1] == '보' and other.actions[-1]=='보':\n            self.results.append(0)\n            other.results.append(0)\n    def choose(self):\n        self.actions.append(np.random.choice(self.candidate))\n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} <br/>\n        액션: {} <br/>\n        승패: {}\n        \"\"\"\n        return html_str.format(self.candidate, self.actions, self.results)\n\n\nplayer_a = RPC(['가위', '보'])\nplayer_b = RPC(['가위', '바위'])\n\n\nplayer_a\n\n\n        낼 수 있는 패: ['가위', '보'] \n        액션: [] \n        승패: []\n        \n\n\n\nplayer_b\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        액션: [] \n        승패: []\n        \n\n\n\nplayer_a*player_b\n\n\nplayer_a\n\n\n        낼 수 있는 패: ['가위', '보'] \n        액션: ['보'] \n        승패: [1]\n        \n\n\n\nplayer_b\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        액션: ['바위'] \n        승패: [-1]\n        \n\n\n\nfor i in range(50000):\n    player_a*player_b\n\n\nsum(player_a.results), sum(player_b.results)\n\n(-12279, 12279)\n\n\n\nsum(player_a.results)/50000, sum(player_b.results)/50000\n\n(-0.24558, 0.24558)"
  },
  {
    "objectID": "4_ts2023.html",
    "href": "4_ts2023.html",
    "title": "TS2023",
    "section": "",
    "text": "This page is organized based on the contents of the Time Series Analysis lectures and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 20, 2023\n\n\n6wk. 연습문제5장 실습\n\n\nJiyunLim\n\n\n\n\nMay 16, 2023\n\n\n[TS] 4wk. ACF와 PACF\n\n\nJiyunLim\n\n\n\n\nMay 14, 2023\n\n\n[TS] 3wk. 여러가지 확률과정\n\n\nJiyunLim\n\n\n\n\nMay 13, 2023\n\n\n[TS] 2wk-2. 연습문제 5.1\n\n\nJiyunLim\n\n\n\n\nMay 12, 2023\n\n\n[TS] 2wk. 확률과정과 정상성\n\n\nJiyunLim\n\n\n\n\nMay 10, 2023\n\n\n[TS] 1wk. 확률\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "5_study.html",
    "href": "5_study.html",
    "title": "STUDY",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nFeb 25, 2023\n\n\nJT test\n\n\njiyun Lim\n\n\n\n\nFeb 19, 2023\n\n\nts1\n\n\njiyun Lim\n\n\n\n\nFeb 19, 2023\n\n\nsimultaneous equation\n\n\njiyun Lim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "1_ip2022.html",
    "href": "1_ip2022.html",
    "title": "IP2022",
    "section": "",
    "text": "This page is organized based on the contents of the Introduction to Python (2022-1) and lecture notes of Professor Guebin Choi of Jeonbuk National University.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 27, 2023\n\n\nClass 활용\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 1단계\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 0단계\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nPandas 2단계\n\n\njiyun Lim\n\n\n\n\nFeb 27, 2023\n\n\n2022 final exam\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nNumpy 4단계(concat, stack)\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 6단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 9단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 8단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 10단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 7단계\n\n\njiyun Lim\n\n\n\n\nFeb 23, 2023\n\n\nclass 5단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 3단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 1단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 2단계\n\n\njiyun Lim\n\n\n\n\nFeb 15, 2023\n\n\nclass 4단계\n\n\njiyun Lim\n\n\n\n\nJun 9, 2022\n\n\n2021 final exam solution\n\n\nGuebinChoi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2023 study blog",
    "section": "",
    "text": "(9주차) 5월2일 (1)\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(4주차) 3월28일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(7주차) 4월18일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(6주차) 4월11일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(5주차) 4월4일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nClass 활용\n\n\n\n\n\n\n\nPython\n\n\nClass\n\n\nStudy\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6wk. 연습문제5장 실습\n\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 4wk. ACF와 PACF\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 3wk. 여러가지 확률과정\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 2wk-2. 연습문제 5.1\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 3wk. 텐서플로우 intro2\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 2wk. 확률과정과 정상성\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 2wk. 텐서플로우 intro1 (tf.constant선언, tnp사용법)\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n[TS] 1wk. 확률\n\n\n\n\n\n\n\nSTUDY\n\n\nTS\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[STBDA] 1wk. 강의소개 및 단순선형회귀\n\n\n\n\n\n\n\n빅데이터분석특강\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nJiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-2 아이스크림을 많이 먹으면 걸리는 병(2)\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n아이스크림을 많이 먹으면 걸리는 병\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2023\n\n\njiyunLim\n\n\n\n\n\n\n  \n\n\n\n\n10wk-2 심슨의 역설\n\n\n\n\n\n\n\n통계와 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\njiyunLim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 1단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 0단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 2단계\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 final exam\n\n\n\n\n\n\n\npython\n\n\nclass\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJT test\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumpy 4단계(concat, stack)\n\n\n\n\n\n\n\nPython\n\n\nNumpy\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 6단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 9단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 8단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 10단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 7단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 5단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nts1\n\n\n\n\n\n\n\nR\n\n\nts\n\n\nbasic\n\n\n\n\ntimeseries study1\n\n\n\n\n\n\nFeb 19, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimultaneous equation\n\n\n\n\n\n\n\nR\n\n\nlinear algebra\n\n\nbasic\n\n\n\n\nimplementation with R\n\n\n\n\n\n\nFeb 19, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 3단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 1단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 2단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass 4단계\n\n\n\n\n\n\n\nclass\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n05wk-2\n\n\n\n\n\n\n\n훌륭한 시각화\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05wk-1\n\n\n\n\n\n\n\nseaborn\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021 final exam solution\n\n\n\n\n\n\n\npython\n\n\nclass\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2022\n\n\nGuebinChoi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-1 [Pandas] 새로운 열 할당, 아이스크림을 많이 먹으면 걸리는 병(1)\n\n\n\n\n\n\n\npandas\n\n\n통계와 시각화\n\n\n아이스크림을 많이 먹으면 걸리는 병\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2022\n\n\nJiyunLim\n\n\n\n\n\n\nNo matching items"
  }
]